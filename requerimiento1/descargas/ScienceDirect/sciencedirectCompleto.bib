@article{SANATIZADEH2025104178,
title = {Engagement or entanglement? The dual impact of generative artificial intelligence in online knowledge exchange platforms},
journal = {Information & Management},
volume = {62},
number = {6},
pages = {104178},
year = {2025},
issn = {0378-7206},
doi = {https://doi.org/10.1016/j.im.2025.104178},
url = {https://www.sciencedirect.com/science/article/pii/S0378720625000813},
author = {Aida Sanatizadeh and Yingda Lu and Keran Zhao and Yuheng Hu},
keywords = {Generative AI, ChatGPT, Online knowledge exchange platforms, User engagement},
abstract = {Generative artificial intelligence (AI) tools, such as ChatGPT and Gemini, have the potential to substantially transform various domains, particularly platforms centered on information exchange. This study investigates the impact of generative AI on content contribution and knowledge-seeking behavior within online knowledge exchange platforms by leveraging a comprehensive dataset from a leading Q&A community. The results indicate a decrease in engagement levels, as evidenced by fewer posts and users, especially within the technology sector. However, this decline is accompanied by a notable benefit: an enhancement in the quality and complexity of questions, leading to an increased number of visits to these types of posts. Furthermore, our findings show a reduction in the number of questions and answers contributed by users with lower expertise, making communities more efficient. Our research highlights the importance of generative AI tools in the dynamics of knowledge exchange and offers suggestions for platform designers to revitalize their ecosystems to enhance user engagement.}
}
@article{SUCHANEK2025100781,
title = {Generative artificial intelligence expectations and experiences in management education: ChatGPT use and student satisfaction},
journal = {Journal of Innovation & Knowledge},
volume = {10},
number = {5},
pages = {100781},
year = {2025},
issn = {2444-569X},
doi = {https://doi.org/10.1016/j.jik.2025.100781},
url = {https://www.sciencedirect.com/science/article/pii/S2444569X2500126X},
author = {Petr Suchanek and Maria Kralova},
keywords = {Generative artificial intelligence (AI), ChatGPT, Management studies, Student satisfaction, AI student satisfaction with studies model},
abstract = {Generative artificial intelligence (AI) has witnessed a major boom in recent years and is increasingly penetrating the higher education sector. This study focused on the use of ChatGPT by undergraduate management students. We developed a model called the “AI Student Satisfaction with Studies model” (AI 3S-model) to investigate how generative AI, specifically ChatGPT, affects student satisfaction with their management studies. Factors used in the model included AI-related student expectations, AI-related student job expectations, perceived quality of AI among students, and AI-related overall student satisfaction. An online questionnaire was administered to students from economics faculties at various universities in the Czech Republic. We deliberately focused on one specialized economics college and several large economics faculties. The sample comprised 231 respondents. To analyze the data, we applied covariance-based structural equation modelling using maximum likelihood estimation. Our findings indicate that two factors directly and positively affect overall student satisfaction with AI use: their perceived quality of studies and their expectations. Additionally, perceived quality acts as a significant mediator between student expectations and overall satisfaction, as well as between job expectations and overall satisfaction. Students believe that ChatGPT enhances their quality of education, which boosts their overall satisfaction. For management education programs, this means that finding ways to effectively integrate generative AI into students’ learning and establishing reasonable limits is highly beneficial, whereas prohibiting the use of generative AI tools would likely decrease student satisfaction and diminish the perceived quality of their studies.}
}
@article{HAMIDI2025100237,
title = {A model for generative artificial intelligence in customer decision-making process using social interaction},
journal = {Telematics and Informatics Reports},
volume = {19},
pages = {100237},
year = {2025},
issn = {2772-5030},
doi = {https://doi.org/10.1016/j.teler.2025.100237},
url = {https://www.sciencedirect.com/science/article/pii/S2772503025000519},
author = {Hodjat (Hojatollah) Hamidi},
keywords = {Artificial intelligence, Generative Artificial Intelligence (GAI), Social interaction, Consumer decision making process, Customer satisfaction},
abstract = {In light of the rapid and unpredictable developments in artificial intelligence (AI), there is a growing need for innovative marketing strategies that can expand market reach and effectively promote services. AI and social interaction have emerged as powerful tools in modern marketing, particularly through the use of social media platforms to enhance product awareness and drive customer engagement. This study investigates the factors influencing customer decision-making in relation to participation in Generative Artificial Intelligence (GAI)-based marketing. Drawing on prior research in the field, the study introduces a conceptual model incorporating key variables such as age, Internet usage, information quality, and information credibility. To examine the proposed model, a questionnaire was administered to students from universities in Tehran. The collected data were analyzed using appropriate statistical methods. The findings reveal that customer satisfaction and customer inertia significantly influence customer decisions to engage in smart marketing practices. Among the evaluated variables, information quality was identified as the most impactful factor, while Internet usage had the least influence. These results provide practical insights for marketers and researchers aiming to leverage GAI in customer-oriented strategies.}
}
@article{JUSOH2025117825,
title = {How generative Artificial Intelligence can transform drug discovery?},
journal = {European Journal of Medicinal Chemistry},
volume = {295},
pages = {117825},
year = {2025},
issn = {0223-5234},
doi = {https://doi.org/10.1016/j.ejmech.2025.117825},
url = {https://www.sciencedirect.com/science/article/pii/S0223523425005902},
author = {Ainin Sofia Jusoh and Muhammad Akmal Remli and Mohd Saberi Mohamad and Tristan Cazenave and Chin Siok Fong},
keywords = {Generative artificial Intelligence, Drug discovery, Protein-protein interactions, Drug-target interactions, Database, Performance metrics, Molecules representations},
abstract = {Generative Artificial Intelligence (Generative AI) is transforming drug discovery by enabling advanced analysis of complex biological and chemical data. This review explores key Generative AI models, including Generative Adversarial Networks (GANs), Variational Autoencoders (VAEs), flow-based models and Transformer-based models, with Transformers gaining prominence due to the abundance of text-based biological data and the success of language models like ChatGPT. The paper discusses molecular representations, performance evaluation metrics, and current trends in Generative AI-driven drug discovery, such as protein-protein interactions (PPIs), drug-target interactions (DTIs) and de-novo drug design. However, these approaches face significant challenges, including applicability domain issues, lack of interpretability, data scarcity, novelty, scalability, computational resource limitations, and the absence of standardized evaluation metrics. These challenges hinder model performance, complicate decision-making, and limit the generation of novel and viable drug candidates. To address these issues, strategies such as hybrid models, integration of multiomics datasets, explainable AI (XAI) techniques, data augmentation, transfer learning, and cloud-based solutions are proposed. Additionally, a curated list of databases supporting drug discovery research is provided. The review concludes by emphasizing the need for optimized AI models, robust validation methods, interdisciplinary collaboration, and future academic efforts to fully realize the potential of Generative AI in advancing drug discovery.}
}
@article{PARK2025100487,
title = {A systematic literature review of generative artificial intelligence (GenAI) literacy in schools},
journal = {Computers and Education: Artificial Intelligence},
volume = {9},
pages = {100487},
year = {2025},
issn = {2666-920X},
doi = {https://doi.org/10.1016/j.caeai.2025.100487},
url = {https://www.sciencedirect.com/science/article/pii/S2666920X25001274},
author = {Joonhyeong Park},
keywords = {Generative artificial intelligence, Generative AI literacy, AI literacy, GenAI literacy, Systematic review},
abstract = {Given the rapid integration of generative artificial intelligence (GenAI) technologies, such as large language models, into educational contexts, fostering students’ GenAI literacy has become essential. However, previous AI literacy frameworks may inadequately reflect specific competencies necessary for proficient GenAI use. To address this gap, this study aimed to conceptualise a GenAI specific literacy framework tailored explicitly for educational settings and systematically examine recent research trends concerning GenAI literacy. Employing a systematic literature review approach, 51 empirical studies published in 2023 and 2024 were selected and analysed based on five identified competencies of GenAI literacy: (1) know and understand GenAI, (2) use and apply GenAI, (3) evaluate and incorporate GenAI, (4) GenAI ethics, and (5) attitudes towards GenAI. The findings indicate that students demonstrated moderate understanding of GenAI concepts but frequently faced challenges in prompt engineering and critical evaluation of AI-generated outputs. Ethical considerations, particularly related to academic integrity, privacy, and data security, were highlighted as significant concerns. Furthermore, positive student attitudes towards GenAI, including curiosity and self-efficacy, emerged as vital components enhancing engagement with GenAI tools. A five-step interaction model was proposed to help in fostering students' GenAI literacy, emphasising iterative and dynamic engagement with GenAI tools. This study underscores the necessity of explicitly integrating GenAI-specific competencies into educational practices and recommends clear institutional policies, and further empirical research to support the responsible, effective, and reflective use of GenAI in school settings.}
}
@article{RASHID2025,
title = {Role of Generative Artificial Intelligence in Assisting Systematic Review Process in Health Research: A Systematic Review},
journal = {Value in Health},
year = {2025},
issn = {1098-3015},
doi = {https://doi.org/10.1016/j.jval.2025.07.001},
url = {https://www.sciencedirect.com/science/article/pii/S1098301525024325},
author = {Muhammed Rashid and Cheng Su Yi and Thipsukhon Sathapanasiri and Sariya Udayachalerm and Kansak Boonpattharatthiti and Suppachai Insuk and Sajesh K. Veettil and Nai Ming Lai and Nathorn Chaiyakunapruk and Teerapon Dhippayom and Muhammed Rashid and Su Yi Cheng and Thipsukhon Sathapanasiri and Sariya Udayachalerm and Kansak Boonpattharatthiti and Suppachai Insuk and Sajesh K. Veettil and Nai {Ming Lai} and Nathorn Chaiyakunapruk and Teerapon Dhippayom and Suwapat Lawin and Pongsapat Limhensin and Kirana Wechkunanukul and Noramon Mayang and Natnicha Rattanachaisit and Xiangyang Ye},
keywords = {artificial intelligence, evidence synthesis, GPT, healthcare, systematic review},
abstract = {Objectives
Artificial intelligence (AI) is widely used in healthcare for various purposes, with generative AI (GAI) increasingly being applied to systematic review (SR) processes. We aimed to summarize the evidence on the performance metrics of GAI in the SR process.
Methods
PubMed, EMBASE, Scopus, and ProQuest Dissertations & Theses Global were searched from their inception up to March 2025. Only experimental studies that compared GAI with other GAIs or human reviewers at any stage of the SR were included. Modified Quality Assessment of Diagnostic Accuracy Studies version 2 was used to assess the quality of the studies that used GAI in the study selection process. We summarized the findings of the included studies using a narrative approach.
Results
Out of 7418 records screened, 30 studies were included. These studies used GAI tools such as ChatGPT, Bard, and Microsoft Bing AI. GAI appears to be effective for participant, intervention, comparator, and outcome formulation and data extraction processes, including complex information. However, because of inconsistent reliability, GAI is not recommended for literature search and study selection as it may retrieve nonrelevant articles and yield inconsistent results. There was mixed evidence on whether GAI can be used for risk of bias assessment. Studies using GAI for study selection were generally of high quality based on the modified Quality Assessment of Diagnostic Accuracy Studies version 2.
Conclusions
GAI shows promising support in participant, intervention, comparator, and outcome-based question formulation and data extraction. Although it holds potential to enhance the SR process in healthcare, further practical application and validated evidence are needed before it can be fully integrated into standard workflows.}
}
@article{FLEURENCE2025,
title = {A Taxonomy of Generative Artificial Intelligence in Health Economics and Outcomes Research: An ISPOR Working Group Report},
journal = {Value in Health},
year = {2025},
issn = {1098-3015},
doi = {https://doi.org/10.1016/j.jval.2025.04.2167},
url = {https://www.sciencedirect.com/science/article/pii/S1098301525023356},
author = {Rachael L. Fleurence and Xiaoyan Wang and Jiang Bian and Mitchell K. Higashi and Turgay Ayer and Hua Xu and Dalia Dawoud and Jagpreet Chhatwal},
keywords = {artificial intelligence, economic models, generative AI, large language models, systematic reviews},
abstract = {Objectives
This article presents a taxonomy of generative artificial intelligence (AI) for health economics and outcomes research (HEOR), explores emerging applications, outlines methods to improve the accuracy and reliability of AI-generated outputs, and describes current limitations.
Methods
Foundational generative AI concepts are defined, and current HEOR applications are highlighted, including for systematic literature reviews, health economic modeling, real-world evidence generation, and dossier development. Techniques such as prompt engineering (eg, zero-shot, few-shot, chain-of-thought, and persona pattern prompting), retrieval-augmented generation, model fine-tuning, domain-specific models, and the use of agents are introduced to enhance AI performance. Limitations associated with the use of generative AI foundation models are described.
Results
Generative AI demonstrates significant potential in HEOR, offering enhanced efficiency, productivity, and innovative solutions to complex challenges. Although foundation models show promise in automating complex tasks, challenges persist in scientific accuracy and reproducibility, bias and fairness, and operational deployment. Strategies to address these issues and improve AI accuracy are discussed.
Conclusions
Generative AI has the potential to transform HEOR by improving efficiency and accuracy across diverse applications. However, realizing this potential requires building HEOR expertise and addressing the limitations of current AI technologies. Ongoing research and innovation will be key to shaping AI’s future role in our field.}
}
@article{ZAMORA2025103161,
title = {Generative artificial intelligence, large language models and ChatGPT in musculoskeletal Oncology: Current applications and future potential},
journal = {Journal of Clinical Orthopaedics and Trauma},
volume = {69},
pages = {103161},
year = {2025},
issn = {0976-5662},
doi = {https://doi.org/10.1016/j.jcot.2025.103161},
url = {https://www.sciencedirect.com/science/article/pii/S0976566225002590},
author = {Tomas Zamora and Paulina Salas and Sebastian Zuñiga and Eduardo Botello and Marcelo E. Andia},
keywords = {Musculoskeletal neoplasms, Artificial intelligence, Natural language processing, Machine learning, Decision support systems, Clinical, Medical informatics},
abstract = {Generative artificial intelligence (AI), particularly large language models (LLMs), has emerged as a transformative technology across all medical specialties, including musculoskeletal (MSK) oncology. These models, such as ChatGPT and others, can process natural language, synthesize vast amounts of information, and generate contextually relevant outputs that resemble human communication. In orthopedic oncology, LLMs show promise in facilitating literature reviews, enhancing patient education, and supporting clinical decision-making by analyzing multidimensional data while providing improved logic-based reasoning. Additionally, they can assist in radiological and pathological workflows by interpreting imaging reports and drafting diagnostic summaries, thereby increasing efficiency and accuracy. In the near future, they are expected to aid in real-time patient follow-up and counseling, information transfer, efficient diagnostics, and even continuous surgical education and assistance. Despite their potential, challenges such as the risk of inaccuracies and biases, as well as the necessity for continuous supervision, warrant a cautious and responsible integration into clinical practice. This narrative review examines the current applications of LLMs in MSK oncology, their limitations, and their future potential in shaping precision medicine and equitable healthcare delivery.}
}
@article{HAMAGUCHI2025,
title = {Comparison of the performances of different updated generative artificial intelligence models on the Japanese National Dental Examination},
journal = {Journal of Dental Sciences},
year = {2025},
issn = {1991-7902},
doi = {https://doi.org/10.1016/j.jds.2025.10.003},
url = {https://www.sciencedirect.com/science/article/pii/S1991790225003617},
author = {Shuma Hamaguchi and Masakazu Hamada and Shunya Ikeda and Satoru Kusaka and Tatsuya Akitomo and Ryota Nomura},
keywords = {Artificial intelligence, Dental education, National dental examination},
abstract = {Background/purpose
Artificial intelligence (AI) has become widely used and applied in various fields. Although several studies have been conducted using generative AI for various qualification exams, to the best of our knowledge, none has focused on performance changes over time.
Materials and methods
In August 2025, ChatGPT 5, Gemini 2.5, Microsoft Copilot, and MediSearch were asked to answer compulsory questions from five years of the Japanese National Dental Examination. In 2024, we also conducted similar tests on other ChatGPT series and Gemini, and the scores were compared.
Results
In 2025, Copilot, Gemini, and MediSearch scored 80 % or higher, which was the passing standard, for all five years. Although ChatGPT 3.5 did not meet the passing standard for any of the five years, ChatGPT 4o mini and ChatGPT 5 exceeded it for two and three years, respectively. In addition, both Chat GPT's and Gemini's scores substantially improved over time and with each update.
Conclusion
This report suggests that generative AI is improving annually and adapting to the National Dental Examination. Although each AI model is suited to different fields, the trends may change over time. It is necessary to continue comparing and analyzing AI models and provide users with the latest information.}
}
@article{LIU2025113544,
title = {Enhancing mRNA translation efficiency with discriminative and generative artificial intelligence by optimizing 5′ UTR sequences},
journal = {iScience},
volume = {28},
number = {10},
pages = {113544},
year = {2025},
issn = {2589-0042},
doi = {https://doi.org/10.1016/j.isci.2025.113544},
url = {https://www.sciencedirect.com/science/article/pii/S258900422501805X},
author = {Yu Liu and Chunmei Cui and Limei Liu and Qinghua Cui},
keywords = {Biochemistry, artificial intelligence},
abstract = {Summary
The mRNA-based therapeutics, notably mRNA vaccines, represent a new era of powerful tools to combat various diseases. However, the relatively low translation efficiency of exogenous mRNA often limits its wide application. Here, we propose a computational framework called UTailoR (UTR tailor), which significantly improves the challenge by optimizing 5′ UTR sequences based on a two-step artificial intelligence strategy. We first develop a deep-learning-based discriminative model for predicting mRNA translation efficiency with 5′ UTR sequences and then present a generative model to generate optimized 5′ UTR sequences, which are designed to be highly close to the original sequences but predicted to result in high translation efficiency. The experimental results show that the UTailoR-optimized sequences outstrip the corresponding original sequences by ∼200%. This work provides an efficient and convenient method for mRNA 5′ UTR optimization, which can be easily accessed online.}
}
@article{CHUANG2025103846,
title = {Language assessment in the era of generative artificial intelligence: Opportunities, challenges, and future directions},
journal = {System},
volume = {134},
pages = {103846},
year = {2025},
issn = {0346-251X},
doi = {https://doi.org/10.1016/j.system.2025.103846},
url = {https://www.sciencedirect.com/science/article/pii/S0346251X25002568},
author = {Ping-Lin Chuang and Xun Yan},
keywords = {Generative artificial intelligence, Language testing and assessment, Challenges and opportunities},
abstract = {Recent breakthroughs in generative artificial intelligence (GenAI) have shaken the field of language assessment in unprecedented ways. On one hand, large-scale testing companies and organizations have spearheaded AI-based assessment models, infusing GenAI elements into various test development and quality management procedures. On the other hand, in local institutional contexts, although the interest in incorporating AI-based elements in instructional programs has also been soaring, little discussion has been made regarding the affordances and affordability of AI-based assessment systems in local contexts, and the impact of AI on language assessment across contexts remains underexplored. This paper presents a systematic review of 77 articles published on GenAI use in language testing and assessment, to synthesize assessment challenges, opportunities, and solutions involving GenAI. We review issues of GenAI in the domains of reliability, validity, fairness, and practicality in large-scale, local, and classroom-based assessments. Based on the findings from the systematic review, we identify principles and best practices of language assessment in the age of GenAI. Additionally, we provide future directions for assessment research and practice related to GenAI, with a focus on impact and sustainability of GenAI in language assessment across contexts. We caution researchers and practitioners about the danger of following the trend of incorporating GenAI in an unmeasured and unselective manner.}
}
@article{KANTOR2025603,
title = {Generative Artificial Intelligence in Dermatology: A Primer},
journal = {Dermatologic Clinics},
volume = {43},
number = {4},
pages = {603-609},
year = {2025},
note = {Artificial Intelligence in Dermatology},
issn = {0733-8635},
doi = {https://doi.org/10.1016/j.det.2025.05.007},
url = {https://www.sciencedirect.com/science/article/pii/S0733863525000464},
author = {Jonathan Kantor},
keywords = {Artificial intelligence, Generative artificial intelligence, Epidemiology, Neural networks, Machine learning, ChatGPT, Gemini}
}
@article{NEO2025101819,
title = {Generative artificial intelligence in healthcare simulation-based education: A scoping review},
journal = {Clinical Simulation in Nursing},
volume = {108},
pages = {101819},
year = {2025},
issn = {1876-1399},
doi = {https://doi.org/10.1016/j.ecns.2025.101819},
url = {https://www.sciencedirect.com/science/article/pii/S1876139925001355},
author = {Nicholas Wee Siong Neo and Joko Gunawan and Tracy Levett-Jones and Eng Tat Khoo and Wei Ling Chua and Sok Ying Liaw},
keywords = {Artificial intelligence, Healthcare education, Large language model, Review, Simulation training},
abstract = {Aims
This review aimed to explore the current state of generative artificial intelligence (GenAI) use in simulation-based healthcare education through a comprehensive examination of GenAI types, applications and reported outcomes.
Methods
A scoping review was conducted utilizing the Joanna Briggs Institute’s methodological guidance. Six databases were searched from their inception until February 2025.
Results
We included 28 articles that were published between 2023 and 2025. Articles were mainly in the fields of medicine (n = 14) and nursing (n = 10). OpenAI’s GPT models were most frequently used to portray simulated characters and deliver automated feedback. GenAI-enhanced simulation was generally perceived as accurate, realistic and feasible, with some evidence supporting its use as a supplement to conventional simulation and to enhance learning outcomes. Perspectives, ethical considerations and recommendations for GenAI-enhanced simulation were also highlighted.
Conclusion
GenAI-enhanced simulation is gaining popularity and is likely to evolve alongside human-facilitated simulation. Future developments should focus on building AI expertise among simulation educators and harnessing the synergy between human intelligence and GenAI. Further rigorous research is needed to establish best practices.}
}
@article{BLANCO2025103083,
title = {The challenge of generative artificial intelligence for future communication professionals: Experiences and usability},
journal = {Telecommunications Policy},
pages = {103083},
year = {2025},
issn = {0308-5961},
doi = {https://doi.org/10.1016/j.telpol.2025.103083},
url = {https://www.sciencedirect.com/science/article/pii/S0308596125001806},
author = {Sonia Blanco and María {Sánchez González} and Francisco Marcos Martín-Martín and Hada M. {Sánchez Gonzales}},
keywords = {Digital literacy, User experience, GenAI, Generative artificial intelligence, Journalism, Usability},
abstract = {This paper explores the interaction of undergraduates with generative artificial intelligence (genAI) tools applied to journalism, analysing their usability and user perception. Using an experimental approach, a user test was conducted with journalism undergraduates at the University of Malaga, evaluating generative text, image and video tools. Data were collected through questionnaires, recordings and direct observation to assess performance and perceptions. Although the tools showed potential for innovation and usefulness, participants made mistakes, mainly linked to the elaboration of prompts and follow-up of instructions. Pikaso and Gemini stood out in terms of satisfaction, while Visla presented technical challenges. The difficulties identified show deficiencies in digital skills and reading comprehension, highlighting the need for specific training. Similarly, users' limited experience and familiarity with the tools negatively impact their interaction, underlining the relevance of incorporating tutorials and practical guides to facilitate their use and understanding. Incorporating more intuitive tools and strengthening genAI training would contribute to optimising the use of these technologies in journalism, although improving the usability and accessibility of these technologies is key to their integration into the professional sphere.}
}
@article{SOROUSH2025502,
title = {Generative Artificial Intelligence in Clinical Medicine and Impact on Gastroenterology},
journal = {Gastroenterology},
volume = {169},
number = {3},
pages = {502-517.e1},
year = {2025},
note = {Shaping the Future of Gastroenterology and Hepatology With Artificial Intelligence},
issn = {0016-5085},
doi = {https://doi.org/10.1053/j.gastro.2025.03.038},
url = {https://www.sciencedirect.com/science/article/pii/S0016508525006341},
author = {Ali Soroush and Mauro Giuffrè and Sunny Chung and Dennis L. Shung},
keywords = {Generative Artificial Intelligence, Gastroenterology, AI Safety, Human–AI Collaboration},
abstract = {The pace of artificial intelligence (AI) integration into health care has accelerated with rapid advances in generative AI (genAI). Gastroenterology and hepatology in particular will be transformed due to the multimodal workflows that integrate endoscopic video, radiologic imaging, tabular data, and unstructured note text. GenAI will impact the entire spectrum of clinical experience, from administrative tasks, diagnostic guidance, and treatment recommendations. Unlike traditional machine learning approaches, genAI is more flexible, with one platform able to be used across multiple tasks. Initial evidence suggests benefits in lower-level administrative tasks, such as clinical documentation, medical billing, and scheduling; and information tasks, such as patient education and summarization of the medical literature. No evidence exists for genAI solutions for more complex tasks relevant to clinical care, such as clinical reasoning for diagnostic and treatment decisions that may affect patient outcomes. Challenges of output reliability, data privacy, and useful integration remain; potential solutions include robust validation, regulatory oversight, and "human–AI teaming" strategies to ensure safe, effective deployment. We remain optimistic in the potential of genAI to augment clinical expertise due to the adaptability of genAI to handle multiple data modalities to obtain and focus relevant information flows and the human-friendly interfaces that facilitate ease of use. We believe that the potential of genAI for dynamic human-algorithmic interactions may allow for a degree of clinician-directed customization to enhance human presence.}
}
@article{LUO2025111903,
title = {Lack of methodological rigor and limited coverage of generative artificial intelligence in existing artificial intelligence reporting guidelines: a scoping review},
journal = {Journal of Clinical Epidemiology},
volume = {186},
pages = {111903},
year = {2025},
issn = {0895-4356},
doi = {https://doi.org/10.1016/j.jclinepi.2025.111903},
url = {https://www.sciencedirect.com/science/article/pii/S0895435625002367},
author = {Xufei Luo and Bingyi Wang and Qianling Shi and Zijun Wang and Honghao Lai and Hui Liu and Yishan Qin and Fengxian Chen and Xuping Song and Long Ge and Lu Zhang and Zhaoxiang Bian and Yaolong Chen and Hongfeng He and Ye Wang and Haodong Li and Huayu Zhang and Di Zhu and Yuanyuan Yao and Dongrui Peng and Zhewei Li and Jie Zhang and Yishan Qin and Fan Wang and Zhenyu Tang and Yueyan Li and Hanxiang Liu and Jungang Zhao},
keywords = {Reporting guidelines, Artificial intelligence, Scoping review, Generative artificial intelligence, Large language models, Methodological quality},
abstract = {Objectives
This study aimed to systematically map the development methods, scope, and limitations of existing artificial intelligence (AI) reporting guidelines in medicine and to explore their applicability to generative AI (GAI) tools, such as large language models (LLMs).
Study Design and Setting
We reported a scoping review adhering to the Preferred Reporting Items for Systematic Reviews and Meta-Analyses extension for Scoping Reviews. Five information sources were searched, including MEDLINE (via PubMed), Enhancing the QUAlity and Transparency Of health Research (EQUATOR) Network, China National Knowledge Infrastructure, FAIRsharing, and Google Scholar, from inception to December 31, 2024. Two reviewers independently screened records and extracted data using a predefined Excel template. Data included guideline characteristics (eg, development methods, target audience, AI domain), adherence to EQUATOR Network recommendations, and consensus methodologies. Discrepancies were resolved by a third reviewer.
Results
Sixty-eight AI reporting guidelines were included; 48.5% focused on general AI, whereas only 7.4% addressed GAI/LLMs. Methodological rigor was limited; 39.7% described development processes, 42.6% involved multidisciplinary experts, and 33.8% followed EQUATOR recommendations. Significant overlap existed, particularly in medical imaging (20.6% of guidelines). GAI-specific guidelines (14.7%) lacked comprehensive coverage and methodological transparency.
Conclusion
Existing AI reporting guidelines in medicine have suboptimal methodological rigor, redundancy, and insufficient coverage of GAI applications. Future and updated guidelines should prioritize standardized development processes, multidisciplinary collaboration, and expanded focus on emerging AI technologies like LLMs.}
}
@article{TONG2025210,
title = {Perceptions and experiences of generative artificial intelligence training to support research for Chinese nurses: A qualitative focus group study},
journal = {International Journal of Nursing Sciences},
volume = {12},
number = {3},
pages = {210-217},
year = {2025},
issn = {2352-0132},
doi = {https://doi.org/10.1016/j.ijnss.2025.04.010},
url = {https://www.sciencedirect.com/science/article/pii/S2352013225000535},
author = {Ling Tong and Yirou Niu and Lixue Zhou and Shuai Jin and Yanling Wang and Qian Xiao},
keywords = {Experience, Generative artificial intelligence, Nurse, Perceptions, Qualitative study, Research capacity},
abstract = {Objectives
Nurses’ clinical research activities have contributed to optimizing the care process and improving patient outcomes, and generative artificial intelligence (GAI) may help clinical nurses strengthen their research skills. To support research, this study aimed to explore the Chinese nurses’ perceptions and experiences of GAI training.
Methods
This study used a descriptive qualitative design. The China Nurses Network conducted a three-day training session on “GAI for Nursing Research” theme, we selected 23 nurses by a convenience sampling method among participating in the training. The researchers conducted three focus group interviews at the end of each day. All focus groups were interviewed face-to-face to facilitate interaction, data collection, and observation. The data were analyzed using conventional content analysis and coded manually.
Results
The results showed that nurses’ use of GAI to support scientific research was dynamic and characterized by evolving perceptions and practices. Four themes and 11 sub-themes emerged from the analysis: 1) utilization efficacy: cope with research ability, affected by many factors; 2) booster research: growth and challenges go hand in hand; 3) role reversal: from GAI-dominated to nurse-dominated; 4) beautiful dream: more features on research, more assistants on clinical care.
Conclusions
The effectiveness of GAI in supporting clinical nurses in conducting research is mainly limited by differences in personal research literacy, lack of ethical regulation, and information accuracy. In the future, it is necessary to improve nurses’ relevant skills through specialized training and promote the standardization of technical regulations to ensure the appropriate application of GAI in nursing research.}
}
@article{ZHANG2025100115,
title = {Applications of generative artificial intelligence in battery research: Current status and prospects},
journal = {Acta Physico-Chimica Sinica},
volume = {41},
number = {10},
pages = {100115},
year = {2025},
issn = {1000-6818},
doi = {https://doi.org/10.1016/j.actphy.2025.100115},
url = {https://www.sciencedirect.com/science/article/pii/S1000681825000712},
author = {Hengrui Zhang and Xijun Xu and Xun-Lu Li and Xiangwen Gao},
keywords = {Lithium battery, Generative artificial intelligence, Material design, Microstructure characterization, State estimation},
abstract = {With the rapid development of renewable energy and electric vehicles, batteries, as the core components of electrochemical energy storage systems, have become a global focus in both scientific research and industrial sectors due to their critical impact on system efficiency and safety. However, the complex multi-physics reactions within batteries make traditional mathematical models inadequate for comprehensively revealing their mechanisms. The key to solving this problem lies in introducing data-driven approaches, which have laid a solid foundation for battery research and development through extensive accumulation of experimental data and extraction of effective information. Generative artificial intelligence (GAI), leveraging its powerful latent pattern learning and data generation capabilities, has already found widespread applications in protein structure prediction, material inverse design, and data augmentation, demonstrating its broad application prospects. Applying GAI to battery research workflows with diverse battery data resources could provide innovative solutions to challenges in battery research. In this perspective, we introduce the core principles and latest advancements of generative models (GMs), including Generative Adversarial Network (GAN), Variational Auto-Encoder (VAE), and Diffusion Model (DM), which can learn the latent distribution of the input samples to generate new data by sampling from it. Applications of GAI in battery research are then reviewed. For battery materials design, by learning material compositions, structures, and properties, GM can generate novel candidate materials with desired properties through conditional constraints, significantly extending the chemical space to be explored. For electrode microstructure characterization, GM can serve as a bridge for interconversion and integration of different image data, enhance the quality of microscopic characterization, and generate realistic synthetic data. For battery state estimation, GM can perform data augmentation and feature extraction on battery datasets, which benefits the model performance for battery state estimation. Lastly, we discuss the challenges and future development directions in terms of data governance and model design, including data quality and diversity, data standardization and sharing, usability of synthetic data, interpretability of GM, and foundational models for battery research. For the innovation and advancement of battery technology, this perspective offers theoretical references and practical guidelines for implementing GAI as an effective tool in battery research workflows by discussing its status and prospects in this field.}
}
@article{VILLENA2025100160,
title = {Generative artificial intelligence in dentistry: A narrative review of current approaches and future challenges},
journal = {Dentistry Review},
volume = {5},
number = {4},
pages = {100160},
year = {2025},
issn = {2772-5596},
doi = {https://doi.org/10.1016/j.dentre.2025.100160},
url = {https://www.sciencedirect.com/science/article/pii/S2772559625000094},
author = {Fabián Villena and Claudia Véliz and Rosario García-Huidobro and Sebastian Aguayo},
keywords = {Artificial intelligence, Dentistry, Generative artificial intelligence models, Dental education},
abstract = {Artificial intelligence (AI) has become a commodity for laypeople and domain experts because of the advent of generative AI (GenAI) models that bridge the usability gap of AI by providing a natural language interface to interact with complex models. GenAI models perform tasks ranging from text generation, such as two-way chat systems, to image and video generation from user-provided textual descriptions. These advancements in AI have impacted Dentistry in multiple aspects. Dental education now benefits from GenAI models by enabling students to address numerous questions through intuitive prompts, receiving instant answers. Dental healthcare practitioners utilize GenAI to gather knowledge quickly and efficiently, improving patient care. In dental research, GenAI supports activities such as academic writing and the discovery of new drugs and therapies. In this narrative review, we summarize the current state of GenAI in dentistry as of 2025, define GenAI models, describe their multiple generation modalities, and discuss their current and potential applications in Dentistry. Finally, we describe the challenges these new technologies impose in our area.}
}
@article{LIU2025103757,
title = {Analysis of the application of generative artificial intelligence in interior design education},
journal = {Ain Shams Engineering Journal},
volume = {16},
number = {12},
pages = {103757},
year = {2025},
issn = {2090-4479},
doi = {https://doi.org/10.1016/j.asej.2025.103757},
url = {https://www.sciencedirect.com/science/article/pii/S2090447925004988},
author = {Yao Liu and Beiyuan Xu and Jiarong Feng and Pengjun Wu},
keywords = {Generative artificial intelligence, Interior design education, Creative thinking, Technology acceptance and use model, Analytic hierarchy process},
abstract = {The rapid advancement of artificial intelligence (AI) has introduced generative AI tools as transformative resources in interior design education, enhancing creativity, aesthetic quality, and practical design outcomes. Traditional interior design education often limits students’ theoretical knowledge, aesthetic skills, and technical abilities development. Generative AI tools such as Stable Diffusion and Midjourney, which utilize big data and deep learning, offer innovative design concepts to address these limitations. This study applies established models—UTAUT and AHP—in a novel educational context to evaluate generative AI tools in terms of creativity, aesthetics, practicality, and feasibility, offering empirically grounded insights for interior design pedagogy. Results showed that Stable Diffusion excelled in creativity, while Midjourney outperformed in aesthetics and functionality, with both tools proved more feasible than traditional methods. Despite challenges such as limited technical support and high hardware requirements, generative AI tools can significantly enhance interior design education by fostering innovation and improving design efficiency.}
}
@article{CHEN2025100737,
title = {Effect of Generative Artificial Intelligence on University Students Learning Outcomes: A Systematic Review and Meta-Analysis},
journal = {Educational Research Review},
pages = {100737},
year = {2025},
issn = {1747-938X},
doi = {https://doi.org/10.1016/j.edurev.2025.100737},
url = {https://www.sciencedirect.com/science/article/pii/S1747938X25000740},
author = {Shuzhen Chen and Alan C.K. Cheung},
keywords = {Artificial intelligence, ChatGPT, Academic performance, Meta-analysis, Experimental studies, Higher education},
abstract = {Generative artificial intelligence (Gen-AI) is transforming higher education by enhancing students’ learning outcomes. Noteworthy, the magnitude of effect sizes has not reached consensus, reflecting substantial variability arising from contextual conditions and methodological approaches. To bridge this gap, grounded in activity theory-mobile computer-supported collaborative learning (AT-MCSCL) framework, this meta-analysis comprehensively synthesized 57 studies and 97 estimations and confirmed that Gen-AI had large effect size on university students’ learning outcomes (g+ = 0.804), particularly in language skills (g+ = 2.331), academic achievement (g+ = 0.633), affective-motivational status (g+ = 0.617), and higher-order thinking (g+ = 0.580), except for a lack of statistically significant effect on metacognition (g+ = 0.078). Meanwhile, this study revealed moderators related to learner, tool, roles, rules and contextual features: (a) freshmen and language learners benefited the most; (b) outcomes measured by tests, studies with medium-sized samples (40-100), medium (4-12 weeks) intervention, and published in journals yielded the higher effect sizes; (c) studies conducted in classroom settings, Middle East, low ICT levels, low socioeconomic status, and higher power distance produced higher effect sizes. This study provides more robust evidence to effectiveness of Gen-AI in higher education and elucidates contextual heterogeneity comprehensively, offering reliable insights for Gen-AI integration in diverse learning environments.}
}
@article{ANNA2025105129,
title = {AI-driven digital humans for E-contact: A pre-registered study on reducing intergroup bias with generative artificial intelligence},
journal = {Acta Psychologica},
volume = {258},
pages = {105129},
year = {2025},
issn = {0001-6918},
doi = {https://doi.org/10.1016/j.actpsy.2025.105129},
url = {https://www.sciencedirect.com/science/article/pii/S0001691825004421},
author = {Manfredi Anna and Puzella Giulio and David Landi and Iolanda Iacono and Jacopo Michilli and Gabbiadini Alessandro},
keywords = {E-contact interventions, Prejudice reduction, Artificial intelligence, Intergroup relations, intergroup contact},
abstract = {The present pre-registered report explores the potential of AI-driven contact interventions by integrating generative Artificial Intelligence-based artificial humans into E-contact paradigms. Grounded in Allport's (1954) Contact Hypothesis and the Dual Identity Model (DIM; Gaertner & Dovidio, 2000), the study examines whether structured interactions with artificial humans can foster positive intergroup attitudes. Following the framework of E-contact interventions (White & Abu-Rayya, 2012), participants (N = 70 Caucasian university students) will engage in a within-between mixed-design experiment over three days. They will interact daily with an AI-powered 3D digital assistant representing either an outgroup member (Black avatar) or an ingroup member (White avatar) depending on the experimental condition, with pre- and post-intervention measures of intergroup attitudes. The structured interactions will follow the two-phase design of E-contact interventions, initially fostering personal acquaintance, then emphasizing group salience, and finally reinforcing a shared superordinate identity—a process aligned with the principles of DIM to maximize the generalization of positive intergroup attitudes. The virtual assistant will facilitate cooperative activities designed to enhance inclusivity, promote cultural exchange, and maintain subgroup distinctiveness while fostering a common identity. To ensure the effectiveness and coherence of the intervention, the scripted interactions will be pretested through a pilot study before implementation. This research offers a preliminary step toward understanding how artificial intelligence might contribute to enhancing E-contact interventions, potentially providing scalable and structured tools for fostering positive intergroup relations and supporting social integration.}
}
@article{SONG2025104549,
title = {Effects of generative artificial intelligence on higher-order thinking skills and artificial intelligence literacy in nursing undergraduates: A quasi-experimental study},
journal = {Nurse Education in Practice},
volume = {88},
pages = {104549},
year = {2025},
issn = {1471-5953},
doi = {https://doi.org/10.1016/j.nepr.2025.104549},
url = {https://www.sciencedirect.com/science/article/pii/S1471595325003063},
author = {Dan Song and Panpan Zhang and Yuyun Zhu and Shutong Qi and Yajuan Yang and Lili Gong and Lihua Zhou},
keywords = {Artificial intelligence literacy, Generative artificial intelligence, Higher-order thinking skills, Nursing undergraduates, Outcome-based Education},
abstract = {Aims
This study aimed to explore the effects of interactive teaching strategies based on generative artificial intelligence (GenAI) under the guidance of outcome-based education (OBE) theory on higher-order thinking skills (HOTS) and artificial intelligence (AI) literacy of undergraduate nursing students.
Background
Recently, GenAI-assisted teaching has been widely recognised as a trend in nursing education reform. HOTS and AI literacy are important for nursing students in the era of artificial intelligence. However, studies on the use of GenAI to enhance the HOTS and AI literacy of undergraduate nursing students are limited.
Design
A quasi-experimental study.
Methods
Based on OBE theory, interactive teaching strategies using GenAI were introduced into a nursing course. Overall, 132 third-year nursing undergraduates enrolled in this course were randomly divided into experimental (n = 66) and control groups (n = 66).
Results
After completing the course, the HOTS scores of nursing undergraduates (P = 0.018) and AI literacy (P < 0.001) in the experimental group were significantly better than those in the control group. There was a significant difference in the HOTS scores (P < 0.001) and AI literacy (P < 0.001) between the experimental group before and after the course.
Conclusion
GenAI-assisted teaching could help nursing undergraduates improve their HOTS and AI literacy. As an important auxiliary teaching tool, GenAI should be integrated into other nursing courses and widely applied in nursing education in the future.}
}
@article{HOURI2025102040,
title = {Evaluating Knowledge Gaps in Cardio-Obstetrics: A Comparative Analysis of Cardiologists, Obstetricians, and Generative Artificial Intelligence},
journal = {JACC: Advances},
volume = {4},
number = {8},
pages = {102040},
year = {2025},
issn = {2772-963X},
doi = {https://doi.org/10.1016/j.jacadv.2025.102040},
url = {https://www.sciencedirect.com/science/article/pii/S2772963X25004648},
author = {Ohad Houri and Nili {Schamroth Pravda}}
}
@article{OSTICK2025e1296,
title = {The use of generative artificial intelligence (AI) in nursing education},
journal = {Teaching and Learning in Nursing},
volume = {20},
number = {4},
pages = {e1296-e1301},
year = {2025},
issn = {1557-3087},
doi = {https://doi.org/10.1016/j.teln.2025.05.025},
url = {https://www.sciencedirect.com/science/article/pii/S1557308725001799},
author = {Mollie Ostick and Bette Mariani and Catherine Lovecchio},
keywords = {AI literacy, Artificial intelligence (AI), Ethical implications, Generative chatbots, Nursing education, Personalized learning},
abstract = {Background
Generative artificial intelligence (AI) tools such as ChatGPT and Gemini are increasingly used in higher education, including nursing, with the potential to transform content delivery and student engagement. However, their use and broader implications in nursing education remain underexplored.
Innovation
This paper synthesizes current literature on generative AI in nursing education, focusing on applications such as AI-generated NCLEX-style questions, automated feedback on assignments, and simulation scenario development. It highlights AI’s potential to support personalized learning, enhance efficiency, and assist faculty, while also identifying key research gaps and ethical concerns.
Implications
By outlining benefits and challenges, this paper offers a foundation for responsible integration and emphasizes the need to prepare faculty and students for its ethical and effective use.
Conclusions
As AI becomes more embedded in nursing education, ongoing evaluation is essential to ensure it enhances learning, supports faculty, and aligns with nursing’s professional values.}
}
@article{ZHU2025102434,
title = {SpectroGen: A physically informed generative artificial intelligence for accelerated cross-modality spectroscopic materials characterization},
journal = {Matter},
pages = {102434},
year = {2025},
issn = {2590-2385},
doi = {https://doi.org/10.1016/j.matt.2025.102434},
url = {https://www.sciencedirect.com/science/article/pii/S2590238525004771},
author = {Yanmin Zhu and Loza F. Tadesse},
keywords = {spectral transfer, generative neural network, materials characterization, Raman spectroscopy, infrared spectroscopy, X-ray diffraction},
abstract = {Summary
Artificial intelligence (AI)-driven materials discovery offers rapid design of novel material compositions, yet synthesis and characterization lag behind. Characterization, in particular, remains bottlenecked by labor-intensive experiments using expert-operated instruments that typically rely on electromagnetic spectroscopy. We introduce SpectroGen, a generative AI model for transmodality spectral generation, designed to accelerate materials characterization. SpectroGen generates high-resolution, high-signal-to-noise ratio spectra with 99% correlation to ground truth and a root-mean-square error of 0.01 a.u. Its performance is driven by two key innovations: (1) a novel distribution-based physical prior and (2) a variational autoencoder (VAE) architecture. The prior simplifies complex structural inputs into interpretable Gaussian or Lorentzian distributions, while the VAE maps them into a physically grounded latent space for accurate spectral transformation. SpectroGen generalizes across spectral domains and promises rapid, accurate spectral predictions, potentially transforming high-throughput discovery in domains such as battery materials, catalysts, superconductors, and pharmaceuticals.}
}
@article{LI2025100820,
title = {Elevating entrepreneurship with generative artificial intelligence},
journal = {Journal of Innovation & Knowledge},
volume = {10},
number = {6},
pages = {100820},
year = {2025},
issn = {2444-569X},
doi = {https://doi.org/10.1016/j.jik.2025.100820},
url = {https://www.sciencedirect.com/science/article/pii/S2444569X25001659},
author = {Yaojie Li and John Kirk Ring and Dan Jin and Saleh Bajaba},
keywords = {Entrepreneurship, Information gathering, Information foraging, Generative artificial intelligence, Prompt engineering},
abstract = {Generative artificial intelligence (GenAI) transforms the entrepreneurial landscape by providing contextual information, identifying viable opportunities, and facilitating entrepreneurial decision-making. Despite the growing acknowledgment of its use in entrepreneurial activities, this field lacks a robust theoretical framework and practical implementation. This study seeks to fill this gap by drawing on information behavior literature to explore the effect of GenAI across the entrepreneurial spectrum. By leveraging large language models and prompt engineering patterns, we examined how GenAI could generate accurate, relevant, and inspiring content through various interaction scenarios. Our findings suggest that GenAI significantly mitigates early-stage entrepreneurial information asymmetry and supports sophisticated problem-solving when coupled with appropriate domain knowledge and prompt engineering techniques. However, GenAI’s task complexity limits its use in late-stage entrepreneurial exploitation activities. Finally, this study provides insight into research avenues and practical applications.}
}
@article{LV2025103889,
title = {Good deeds deserve good outcomes: Leveraging generative artificial intelligence to reduce tourists' avoidance of ethical brands embracing stigmatized groups},
journal = {Annals of Tourism Research},
volume = {110},
pages = {103889},
year = {2025},
issn = {0160-7383},
doi = {https://doi.org/10.1016/j.annals.2024.103889},
url = {https://www.sciencedirect.com/science/article/pii/S016073832400166X},
author = {Linxiang Lv and Yongheng Liang and Siyun Chen and Gus Guanrong Liu and Jiancai Liao},
keywords = {Diversity, equity, and inclusivity, Ethical brand, Tourists' brand avoidance, Generative artificial intelligence, ChatGPT},
abstract = {Incorporating diversity, equity, and inclusivity often leads tourism brands to support stigmatized groups, yet tourists may perceive these groups negatively and avoid these brands. Drawing from one field study on the Facebook Ad platform and two experimental studies, we find that brand avoidance among tourists is reduced when tourism brands adopt AI-generated (vs. human-generated) moral content to support stigmatized dissociative out-groups. This effect is mediated by tourists' psychological proximity to these groups and is weakened for those with a strong sense of common fate with these out-groups. These insights contribute to tourism literature on generative AI and diversity, equity, and inclusivity while offering strategic guidance for brands seeking to embrace stigmatized groups.}
}
@article{PAHUJA20253731,
title = {Comprehensive Review of Generative artificial Intelligence: Mechanisms, Models, and Applications},
journal = {Procedia Computer Science},
volume = {258},
pages = {3731-3740},
year = {2025},
note = {International Conference on Machine Learning and Data Engineering},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2025.04.628},
url = {https://www.sciencedirect.com/science/article/pii/S1877050925017326},
author = {Shivani Pahuja and Sonal kukreja and Akansha Singh},
keywords = {Generative AI, ChatGPT, GANs, artificial Intelligence, Deep Learning, Large Language Models},
abstract = {Generative artificial Intelligence is a kind of artificial Intelligence which generates new content for the user like text, images, product suggestion etc. In the current era, we can see for the very first time that humans are performing supervision where as machines are generating and so it is shredding of down the difficult and risky tasks from the human’s shoulder. In this way, its a complete paradigm shift for the future of jobs. Generative AI will bring a revolutionary change in the life of human as happened few years back when came the concept of photography which helped us to no longer rely on the interpretation of an artist to capture the reality. The purpose of our comprehensive study is to review the mechanism of generative AI and their models with its applications in the current era. Firstly various fundamental models namely Natural language models, text-to-image models, GAN’s, VAE’s, and RLHF are discussed in detail. Furthermore, our comprehensive study explores the various kinds of Language models along with their detailed architecture. This study seeks to provide a comprehensive overview and taxonomy of generative models in order to better comprehend its wide applications. We concluded this paper with a comparative study among various language models of Generative artificial Intelligence.}
}
@article{WANG2025102898,
title = {Generative artificial intelligence and internationalization green innovation: Roles of supply chain innovations and AI regulation for SMEs},
journal = {Technology in Society},
volume = {82},
pages = {102898},
year = {2025},
issn = {0160-791X},
doi = {https://doi.org/10.1016/j.techsoc.2025.102898},
url = {https://www.sciencedirect.com/science/article/pii/S0160791X25000880},
author = {Shaofeng Wang and Hao Zhang},
keywords = {Generative artificial intelligence, Sustainable innovation, Supply chain innovation, Artificial intelligence regulation, Social transformation, SMEs},
abstract = {This study investigates how generative artificial intelligence (GenAI) impacts internationalization green innovation performance in cross-border e-commerce small and medium-sized enterprises (SMEs). Drawing on the resource-based view, we employed a mixed-methods approach, including partial least squares structural equation modeling (PLS-SEM), importance-performance map analysis (IPMA), fuzzy-set qualitative comparative analysis (fsQCA), and semi-structured interviews with 377 cross-border e-commerce SMEs. Our findings reveal that GenAI capability positively influences internationalization green innovation performance, both directly and indirectly, through supply chain exploratory and exploitative innovation. Notably, artificial intelligence (AI) regulation strengthens, rather than weakens, the positive relationship between GenAI capability and supply chain innovation. This highlights the potential for responsible AI governance to foster sustainable practices. The study contributes to understanding technology's role in societal transformation by illuminating how GenAI can promote sustainable business practices in internationalization contexts. Our findings offer valuable insights for policymakers and business leaders on effectively managing the societal implications of AI adoption while pursuing sustainability goals.}
}
@article{FINI2025102568,
title = {Application of generative artificial intelligence in the aquacultural sector},
journal = {Aquacultural Engineering},
volume = {111},
pages = {102568},
year = {2025},
issn = {0144-8609},
doi = {https://doi.org/10.1016/j.aquaeng.2025.102568},
url = {https://www.sciencedirect.com/science/article/pii/S0144860925000573},
author = {Chiara Fini and Simone Gaetano Amato and Daniela Scutaru and Sara Biancardi and Francesca Antonucci and Simona Violino and Luciano Ortenzi and Eugenio Nerio Nemmi and Alessandro Mei and Federico Pallottino and Simone Figorilli and Corrado Costa},
keywords = {Smart aquaculture, GAI, Feed optimization, Fish monitoring, Seafood security, Seafood traceability, Animal welfare},
abstract = {Artificial Intelligence (AI) applications in aquaculture have recently attracted growing attention, as these technologies are becoming vital for data analysis, improving production processes, and optimizing the use of natural resources. Among the different AI approaches, Generative Artificial Intelligence (GAI) emerges as one of the most innovative and promising.This paper explores the use of Generative Artificial Intelligence (GAI) in aquaculture, evaluating its advantages and challenges within the industry's unique context. It begins with an overview of generative model architectures, then delves into their potential contributions to aquatic resource management, the improvement of farming practices, and the promotion of environmental sustainability.To obtain the most up-to-date insights, research was carried out using database such as SCOPUS, Google Scholar, and Web of Science databases. GAI holds significant promise for aquaculture, with applications that include enhanced water quality management, fish stock health prediction, and automated feeding supervision. When applied responsibly, GAI can streamline routine operations while contributing to a more resilient and sustainable future for the aquaculture industry. With its ability to extract valuable insights from big data, GAI proves to be a powerful tool for tackling future challenges, ensuring food production that meets the demands of a growing global population while addressing increasingly urgent environmental concerns.}
}
@article{NGUYEN2025172,
title = {Generative Artificial Intelligence (AI) in education: from organizing visions to official guidelines},
journal = {Information Technology & People},
volume = {38},
number = {8},
pages = {172-199},
year = {2025},
issn = {0959-3845},
doi = {https://doi.org/10.1108/ITP-08-2024-1026},
url = {https://www.sciencedirect.com/science/article/pii/S095938452500003X},
author = {Andy Nguyen and Shohil Kishore and Yvonne Hong and Saima Qutab and Belle Dang},
keywords = {Generative Artificial Intelligence, Organizing visions, AI in education, Educational information systems},
abstract = {Purpose
This paper aims to explore the initial formation of organizing visions within digital platforms regarding the use of Generative Artificial Intelligence (GAI) in education. It examines how these emerging visions align with official guidelines. Understanding the early development of these organizing visions and the consensus formation around official guidelines for GAI in education has significant research and practical implications.
Design/methodology/approach
The present study uses a multimethodological approach with qualitative content-coding and inductive thematic analysis of digital trace data from the social media platform X and deductive thematic analysis of guideline documents. It first examines organizing visions within digital platforms through 1,260 tweets, focusing on opportunities and challenges posed by GAI, particularly ChatGPT, in educational settings. The study then analyses practical guidelines from international organizations, governments, and universities.
Findings
The empirical findings demonstrate that, although all three Organizing Vision (OV) functions are present in the early development of OVs for GAI in education, early-stage online discourse predominantly emphasizes the legitimation function. The findings also indicate a noticeable alignment between the topics discussed in the early development of OVs for GAI in education and the official guidelines and policies issued by international organizations, governments, and universities worldwide, indicating the need for educational reform, and ethical considerations.
Originality/value
This study contributes to the existing literature on the emergence of OVs in digital platforms by examining the context of GAI in education. This study also provides insights into the collective stance and recommendations from various authoritative sources, offering a comprehensive perspective on early-stage GAI policy development in an educational context.}
}
@article{HAN2025113715,
title = {Evaluating generative artificial intelligence products using fuzzy social network multi-attribute decision-making model: User perspective},
journal = {Applied Soft Computing},
volume = {183},
pages = {113715},
year = {2025},
issn = {1568-4946},
doi = {https://doi.org/10.1016/j.asoc.2025.113715},
url = {https://www.sciencedirect.com/science/article/pii/S1568494625010269},
author = {Minglong Han and Yupeng Liu},
keywords = {Fuzzy social network, Generative Artificial Intelligence, Grounded theory, DANP method, VIKOR method},
abstract = {The rapid expansion of Generative Artificial Intelligence (GAI) has transformed various industries, giving rise to an array of GAI products. However, inconsistent product quality complicates user decisions, jeopardizing both the sustainability of GAI technologies and their broader adoption. To address these challenges, this study proposes a user-centered evaluation framework that integrates fuzzy social networks with advanced multi-attribute decision-making (MADM) approaches. Grounded theory is first employed to establish a ''marketing-information-product-individual'' system of factors influencing GAI product adoption. Next, fuzzy social networks reduce semantic ambiguity and mitigate expert bias, while the Decision-Making Trial and Evaluation Laboratory (DEMATEL) method uncovers causal relationships among these factors. The DEMATEL-based Analytic Network Process (DANP) then quantifies the relative importance of each factor, followed by a modified VlseKriterijumska Optimizacija I Kompromisno Resenje (VIKOR) method to comprehensively evaluate representative GAI products. The findings reveal that product maturity exerts the strongest driving force, whereas perceived effect experiences the highest overall impact. Information reliability and the individual dimension carry the greatest weights. Moreover, current products display notable deficiencies in risk management, user service, and ease of use, all of which warrant developers' attention to enhance user satisfaction and adoption. In light of these results, the study proposes targeted optimization strategies for four distinct GAI products. By integrating fuzzy social networks and MADM methodologies, this framework offers a rigorous, systematic evaluation tool that significantly improves decision-making accuracy and promotes the sustainable development of GAI applications.}
}
@article{WEN2025101010,
title = {Generative artificial intelligence for enzyme design: Recent advances in models and applications},
journal = {Current Opinion in Green and Sustainable Chemistry},
volume = {52},
pages = {101010},
year = {2025},
issn = {2452-2236},
doi = {https://doi.org/10.1016/j.cogsc.2025.101010},
url = {https://www.sciencedirect.com/science/article/pii/S2452223625000148},
author = {Shuixiu Wen and Wen Zheng and Uwe T. Bornscheuer and Shuke Wu},
keywords = {artificial intelligence, biocatalysis, enzyme design, generative models},
abstract = {Enzyme catalysis is a key enabling technology for green and sustainable production of chemicals. Developing suitable enzymes is at the heart of this technology, which is currently changing by Artificial Intelligence (AI) such as machine learning. AI-based methods were used for enzyme discovery and design. We review the recent advances in generative AI models for enzyme design, with a particular focus on those that have been validated by experiments. Furthermore, we discuss the applications of the enzymes designed by generative AI, including artificial luciferases, non-heme iron (II)-dependent oxygenases, and P450 enzymes. We provide our opinions on several current issues encountered in computational enzyme design. With the fast development of new generative models in enzymes and the implementation of these models by the research community, we believe that the precise design of efficient enzymes with new catalytic functions and/or potential industrial applications will be a mature method in the near future.}
}
@article{VOLPATO2025100195,
title = {Trusting emotional support from generative artificial intelligence: a conceptual review},
journal = {Computers in Human Behavior: Artificial Humans},
volume = {5},
pages = {100195},
year = {2025},
issn = {2949-8821},
doi = {https://doi.org/10.1016/j.chbah.2025.100195},
url = {https://www.sciencedirect.com/science/article/pii/S2949882125000799},
author = {Riccardo Volpato and Lisa DeBruine and Simone Stumpf},
keywords = {Trust, Generative AI, Theory, Emotional support, Multidisciplinary},
abstract = {People are increasingly using generative artificial intelligence (AI) for emotional support, creating trust-based interactions with limited predictability and transparency. We address the fragmented nature of research on trust in AI through a multidisciplinary conceptual review, examining theoretical foundations for understanding trust in the emerging context of emotional support from generative AI. Through an in-depth literature search across human-computer interaction, computer-mediated communication, social psychology, mental health, economics, sociology, philosophy, and science and technology studies, we developed two principal contributions. First, we summarise relevant definitions of trust across disciplines. Second, based on our first contribution, we define trust in the context of emotional support provided by AI and present a categorisation of relevant concepts that recur across well-established research areas. Our work equips researchers with a map for navigating the literature and formulating hypotheses about AI-based mental health support, as well as important theoretical, methodological, and practical implications for advancing research in this area.}
}
@article{KARAOGLANYILMAZ2025100187,
title = {Exploring the role of cognitive flexibility, digital competencies, and self-regulation skills on students' generative artificial intelligence anxiety},
journal = {Computers in Human Behavior: Artificial Humans},
volume = {5},
pages = {100187},
year = {2025},
issn = {2949-8821},
doi = {https://doi.org/10.1016/j.chbah.2025.100187},
url = {https://www.sciencedirect.com/science/article/pii/S2949882125000714},
author = {Fatma Gizem {Karaoglan Yilmaz} and Ramazan Yilmaz and Ahmet Berk Ustun and Hatice Uzun},
keywords = {Generative artificial intelligence, Artificial intelligence anxiety, University students, Cognitive flexibility, Digital competencies, Self-regulation skills},
abstract = {The purpose of the study is to examine the role of cognitive flexibility, digital competencies and self-regulation skills in reducing university students' artificial intelligence (AI) anxiety. The study proposes that it isn't possible to harness the potential benefits of AI technologies unless students' concerns about these technologies are suitably addressed. Although the number of potential benefits specifically related to the use of AI in education is enormous, addressing students' concerns about AI is essential to ensure the effective use of these technologies in education. The correlational survey model was used in this study. Four well-established instruments were employed to collect data from students who studied in different public university faculties in Turkey. Participants were selected from students who had been using AI tools for educational purposes for at least six months. The findings showed that cognitive flexibility, digital competencies and self-regulation skills impact on AI anxiety. Students with high cognitive flexibility had lower AI anxiety, while students with high digital competencies were better able to comprehend and use AI technologies. In addition, students with high self-regulation skills were able to manage their own learning processes more effectively and experienced less anxiety in using AI. As a result, increasing university students' digital competencies and self-regulation skills can be influential in reducing their AI anxiety. Accordingly, educational institutions could offer programs to develop students' digital competencies and AI literacy. These programs can help them adapt to AI technologies more easily and reduce their anxiety about these technologies by teaching students how to use AI technologies effectively and efficiently.}
}
@article{ROBISON2025101822,
title = {Development of a prompt template to support simulation design: Maximizing the potential of generative artificial intelligence},
journal = {Clinical Simulation in Nursing},
volume = {108},
pages = {101822},
year = {2025},
issn = {1876-1399},
doi = {https://doi.org/10.1016/j.ecns.2025.101822},
url = {https://www.sciencedirect.com/science/article/pii/S1876139925001380},
author = {Elizabeth Robison and Theresa Cooney and Tammy Schwaab and Sami Rahman},
keywords = {Artificial intelligence, Healthcare simulation, Nursing education, Prompt engineering, Scenario design},
abstract = {Background
Generative AI tools like ChatGPT are rapidly changing academia and healthcare, particularly in nursing education through their ability to assist in creating clinical simulation scenarios. The key to effectively using these tools lies in prompt engineering, the careful crafting of inputs to guide AI outputs.
Aim
An initiative by nurse educators explored how prompt engineering, aligned with established simulation standards, could streamline scenario design.
Findings
The findings revealed variations in output quality and focus among different AI platforms (ChatGPT, CoPilot, Claude), highlighting the need for careful selection and human oversight to ensure accuracy and relevance in AI-generated simulation content.
Conclusions
This iterative process of prompt refinement holds significant promise for creating more engaging and effective learning experiences, but AI serves as a tool that augments, not replaces, the expertise of nursing simulationists.}
}
@article{FOOTE2025101593,
title = {Embracing Generative Artificial Intelligence in Clinical Research and Beyond: Opportunities, Challenges, and Solutions},
journal = {JACC: Advances},
volume = {4},
number = {3},
pages = {101593},
year = {2025},
issn = {2772-963X},
doi = {https://doi.org/10.1016/j.jacadv.2025.101593},
url = {https://www.sciencedirect.com/science/article/pii/S2772963X25000109},
author = {Henry P. Foote and Chuan Hong and Mohd Anwar and Maria Borentain and Kevin Bugin and Nancy Dreyer and Josh Fessel and Nitender Goyal and Morgan Hanger and Adrian F. Hernandez and Christoph P. Hornik and Jennifer G. Jackman and Alistair C. Lindsay and Michael E. Matheny and Kerem Ozer and Jan Seidel and Norman Stockbridge and Peter J. Embi and Christopher J. Lindsell},
keywords = {artificial intelligence, clinical research, generative AI, participant engagement, research ethics},
abstract = {To explore threats and opportunities and to chart a path for safely navigating the rapid changes that generative artificial intelligence (AI) will bring to clinical research, the Duke Clinical Research Institute convened a multidisciplinary think tank in January 2024. Leading experts from academia, industry, nonprofits, and government agencies highlighted the potential opportunities of generative AI in automation of documentation, strengthening of participant and community engagement, and improvement of trial accuracy and efficiency. Challenges include technical hurdles, ethical dilemmas, and regulatory uncertainties. Success is expected to require establishing rigorous data management and security protocols, fostering integrity and trust among stakeholders, and sharing information about the safety and effectiveness of AI applications. Meeting insights point towards a future where, through collaboration and transparency, generative AI will help to shorten the translational pipeline and increase the inclusivity and equitability of clinical research.}
}
@article{OBEN2025790,
title = {Can Generative Artificial Intelligence Improve Adolescent Health?},
journal = {Journal of Adolescent Health},
volume = {77},
number = {4},
pages = {790},
year = {2025},
issn = {1054-139X},
doi = {https://doi.org/10.1016/j.jadohealth.2025.05.020},
url = {https://www.sciencedirect.com/science/article/pii/S1054139X25002265},
author = {Awu Isaac Oben}
}
@article{KHATRI2026103379,
title = {Development and validation of the generative artificial intelligence appropriation (GAIA) Scale: A comprehensive measurement tool for assessing user engagement and utilisation},
journal = {Technovation},
volume = {150},
pages = {103379},
year = {2026},
issn = {0166-4972},
doi = {https://doi.org/10.1016/j.technovation.2025.103379},
url = {https://www.sciencedirect.com/science/article/pii/S0166497225002111},
author = {Puja Khatri and Harshleen Kaur Duggal and Asha Thomas and Vincenzo Corvello and Ewa Prałat and Atul Shiva},
keywords = {Appropriation, Generative AI, Scale development, Hierarchical component modeling, Mixed-method},
abstract = {Generative Artificial Intelligence Appropriation (GAIA) encapsulates how users adopt Generative Artificial Intelligence tools, adapt them according to their needs, and integrate them into their work. The rapid adoption of generative AI tools has demonstrated their transformative potential to effect significant improvements in the field of business management and change the work habits of their users. Considering the multitude of applicative possibilities offered by the technology, in addition to its nascence, there are significant concerns regarding how the technology can be utilised, necessitating GAIA assessment in the workplace. Existing instruments prove inadequate in providing a comprehensive measurement of GAIA. In response, this research adopts a mixed-method approach, comprising qualitative and quantitative insights from multiple studies. Drawing on multiple samples, this study develops and validates a second-order, reflective-reflective GAIA measure, comprising dimensions of integrative appropriation, adoptive appropriations, customised appropriation, interface appropriation and ethical appropriation. The research encompasses four studies with a distinctive focus on item generation, scale purification, scale refinement and nomological validation. The GAIA scale developed herein offers a robust and comprehensive measure that can be used to explicate, assess, and improve GAIA in the workplace.}
}
@article{SHIN2025101216,
title = {Use and perception of generative artificial intelligence in traditional Korean medicine education: A cross-sectional survey of undergraduate students in Korea},
journal = {Integrative Medicine Research},
volume = {14},
number = {4},
pages = {101216},
year = {2025},
issn = {2213-4220},
doi = {https://doi.org/10.1016/j.imr.2025.101216},
url = {https://www.sciencedirect.com/science/article/pii/S2213422025000964},
author = {Seungwon Shin and Jihyun Sang and Ji-sun You},
keywords = {Education, Medical, Generative Artificial Intelligence, Medicine, Korean Traditional, Surveys and Questionnaires},
abstract = {Background
This study aimed to examine the usage, awareness, and satisfaction related to generative AI (GenAI) among undergraduate students at a Traditional Korean Medicine (TKM) college in Korea and to identify factors associated with GenAI use and satisfaction.
Methods
A structured questionnaire consisting of 56 items across six domains was administered, covering demographics, general and TKM-specific GenAI use, satisfaction, educational experiences, and future expectations. Descriptive statistics, univariable analysis, multivariable logistic regression, and correlation analysis were performed.
Results
A total of 234 students across six academic years participated in the survey. Most respondents were aware of GenAI (88.5 %) and used it for general purposes (79.9 %). However, only 16.2 % actively used it for TKM learning. While 70.4 % were satisfied with using GenAI in general, only 45.8 % felt satisfied with its use for TKM education. Factors significantly associated with GenAI use or satisfaction included enrollment in the TKM curriculum, older age, prior major, scholarship receipt, and self-directed GenAI learning. Although only 18.8 % had experienced GenAI in formal TKM courses, 96.2 % viewed GenAI as necessary in TKM education.
Conclusion
A notable gap exists between students’ interest and the limited integration of GenAI in TKM curricula. To close this gap, GenAI should be systematically incorporated into educational programs, accompanied by faculty training and institutional support to enhance students’ digital readiness and learning outcomes.}
}
@article{SHAHRIAR2025101787,
title = {The role of generative artificial intelligence in digital agri-food},
journal = {Journal of Agriculture and Food Research},
volume = {20},
pages = {101787},
year = {2025},
issn = {2666-1543},
doi = {https://doi.org/10.1016/j.jafr.2025.101787},
url = {https://www.sciencedirect.com/science/article/pii/S2666154325001589},
author = {Sakib Shahriar and Maria G. Corradini and Shayan Sharif and Medhat Moussa and Rozita Dara},
keywords = {Generative artificial intelligence, Agri-food, Digital agriculture, Smart food, Food security, Food quality, Food safety, Food authenticity, Sustainable agriculture},
abstract = {The agriculture and food (agri-food) sector faces rising global concerns about its sustainability and resilience to climate events. Thus, new solutions are needed to ensure environmental and food security. Artificial Intelligence (AI) offers inventive solutions to improve agricultural and food production practices. Generative AI methods, such as generative adversarial networks (GANs), variational autoencoders, and large language models (LLMs), add to the transformative process initiated by AI and expert systems in agricultural and food-related practices to enhance productivity, sustainability, and resilience. This study categorizes generative AI approaches and their capabilities in agri-food systems and provides a comprehensive review of the current landscape of generative AI applications in the sector. It discusses the impact of these technologies on enhancing agricultural productivity, food quality, and safety, as well as sustainability, presenting potential use cases like combatting climate change and foodborne disease modeling that highlight the practical applications and benefits of generative AI in agri-food. Furthermore, it addresses the ethical implications of deploying generative AI, including privacy, security, reliability, and unbiased decision-making.}
}
@article{CAAMANOGORDILLO20251408,
title = {Impact of generative artificial intelligence on workload, efficiency and labour productivity},
journal = {IFAC-PapersOnLine},
volume = {59},
number = {10},
pages = {1408-1413},
year = {2025},
note = {11th IFAC Conference on Manufacturing Modelling, Management and Control MIM 2025},
issn = {2405-8963},
doi = {https://doi.org/10.1016/j.ifacol.2025.09.237},
url = {https://www.sciencedirect.com/science/article/pii/S240589632500998X},
author = {Daniel Caamaño-Gordillo and Josefa Mula and Rocio {de la Torre}},
keywords = {Generative artificial intelligence, productivity, efficiency, workload, workforce},
abstract = {In recent years, generative artificial intelligence (GAI) has gained significant importance in production and operations management (POM) due to its potential to enhance worker productivity. This article aims to characterise the impact of GAI on workload, efficiency and labour productivity across various industries. The research question was formulated and, using the CIMO framework (context, intervention, mechanism, outcome), the search and retrieval of articles were conducted in the Scopus and Web of Science (WoS) databases, and yielded 149 articles. After the selection, evaluation and content analysis of each study, 74 articles were ultimately included in the systematic literature review. Seven industries were identified in which GAI has demonstrated impacts on workload, efficiency and labour productivity, with four sectors accounting for 80% of the studies. The impacts of GAI reveal four trends, all of them key in POM: automation and optimisation of workflows; support in decision making; improvement in human-machine interactions; enhancement in communication. To fully apply the potential of this technology, it is necessary to continue researching and addressing the identified issues, including ethical, employment, privacy and information quality challenges.}
}
@article{MENG2025,
title = {A generative artificial intelligence approach to modular skeletal framework modeling: Bamboo stilt houses as a case study},
journal = {Frontiers of Architectural Research},
year = {2025},
issn = {2095-2635},
doi = {https://doi.org/10.1016/j.foar.2025.06.004},
url = {https://www.sciencedirect.com/science/article/pii/S2095263525000846},
author = {Xianchuan Meng and Jiadong Liang and Ximing Zhong},
keywords = {Graph neural networks, Modular components, Bamboo architecture, Computational design, Generative artificial intelligence method},
abstract = {This paper presents a new generative artificial intelligence (AI) approach for creating modular skeletal frameworks, using vernacular bamboo stilt houses as examples to investigate an innovative methodological perspective. By transforming building skeletons to connected graphs, our method uses Variational Graph Autoencoders (VGAE) and Graph Sample and Aggregate (GraphSAGE) to generate 3D modular components based on spatial constraints set by users, such as axis grids and chosen room areas. The graph representation encodes structural elements as edges and their connections as nodes, maintaining critical dimensional constraints and spatial relationships. Using data from bamboo stilt houses built without architects, we make a specialized dataset of geometric skeletons for model training. Experimental results demonstrate the effectiveness of our approach in capturing the distribution of featured elements in building frameworks and in generating structurally sound designs, with GraphSAGE showing better performance compared to alternative methods. The probabilistic edge prediction approach allows for a collaborative human-AI design process, empowering designers while utilizing computational capabilities. The inherent flexibility of the graph-based representation makes it adaptable to a wide range of materials and scales.}
}
@article{BLONDEEL2025100987,
title = {The effects of generative artificial intelligence (GenAI) on learning in an accounting data analytics course},
journal = {Journal of Accounting Education},
volume = {72},
pages = {100987},
year = {2025},
issn = {0748-5751},
doi = {https://doi.org/10.1016/j.jaccedu.2025.100987},
url = {https://www.sciencedirect.com/science/article/pii/S0748575125000387},
author = {Eva Blondeel and Taylor Bullock and James Gaskin and Ryan Schuetzler and Rachel Serre and Jacob Steffen and Taylor M. Wells and David A. Wood},
keywords = {ChatGPT, Generative artificial intelligence (GenAI), Learning performance, Accounting education},
abstract = {We study how generative AI (GenAI) relates to learning in an accounting data analytics course. Using survey data from 312 junior-level students (Fall 2023), we examine help-seeking preferences (ChatGPT vs. professors/TAs/peers) and whether ChatGPT expertise is associated with course performance. Students preferred seeking help from group members most, but consulted ChatGPT more than professors or TAs, citing convenience and comfort. ChatGPT was perceived as less useful and satisfying than human support when accuracy was paramount. Regression results show that ChatGPT expertise is positively associated with course GPA, especially for students with lower prior GPAs. Findings imply that modest, structured training can help students—particularly lower-performing students—use GenAI productively. We discuss limitations (context specificity, self-report, LLM-assisted coding) and recommend scaffolding responsible GenAI use across accounting curricula.}
}
@article{CHAN2025115276,
title = {Using generative artificial intelligence (GenAI) in marketing: Development and practices},
journal = {Journal of Business Research},
volume = {191},
pages = {115276},
year = {2025},
issn = {0148-2963},
doi = {https://doi.org/10.1016/j.jbusres.2025.115276},
url = {https://www.sciencedirect.com/science/article/pii/S0148296325000992},
author = {Hau-Ling Chan and Tsan-Ming Choi},
keywords = {Generative artificial intelligence, Marketing, Classification, Practices, Future research},
abstract = {Generative artificial intelligence (GenAI) is an emerging topic in business research and marketing. This study discusses and classifies the applications of GenAI in the field of marketing. To be specific, this study first conducts a systematic literature search to learn about development on the topic of GenAI in marketing. Then, the collected articles are classified into four major themes, namely (i) applications, adoption and concerns of consumers toward GenAI, (ii) service, (iii) advertising, and (iv) innovation. Next, we discuss the related industrial practices to highlight the current real-world applications of GenAI in various major industries to support marketing activities. Finally, based on the reviewed literature and observed real-world practices, we propose a promising future research agenda that lays the foundation for further studies in the area.}
}
@article{KUNZE2025,
title = {Commercial Products Using Generative Artificial Intelligence Include Ambient Scribes, Automated Documentation and Scheduling, Revenue Cycle Management, Patient Engagement and Education, and Prior Authorization Platforms},
journal = {Arthroscopy: The Journal of Arthroscopic & Related Surgery},
year = {2025},
issn = {0749-8063},
doi = {https://doi.org/10.1016/j.arthro.2025.05.021},
url = {https://www.sciencedirect.com/science/article/pii/S0749806325003974},
author = {Kyle N. Kunze and Jennifer Bepple and Asheesh Bedi and Prem N. Ramkumar and Christian A. Pean},
abstract = {The integration of artificial intelligence into clinical practice is rapidly transforming health care workflows. At the forefront are large language models (LLMs), embedded within commercial and enterprise platforms to optimize documentation, streamline administration, and personalize patient engagement. The evolution of LLMs in health care has been driven by rapid advancements in natural language processing and deep learning. Emerging commercial products include ambient scribes, automated documentation and scheduling, revenue cycle management, patient engagement and education assistants, and prior authorization platforms. Ambient scribes remain the leading commercial generative artificial intelligence product, with approximately 90 platforms in existence to date. Emerging applications may improve provider efficiency and payer-provider alignment by automating the prior authorization process to reduce the manual labor burden placed on clinicians and staff. Current limitations include (1) lack of regulatory oversight, (2) existing biases, (3) inconsistent interoperability with electronic health records, and (4) lack of physician and stakeholder buy-in due to lack of confidence in LLM outputs. Looking forward requires discussion of ethical, clinical, and operational considerations.}
}
@article{XIA2026105465,
title = {A systematic literature review on designing self-regulated learning using generative artificial intelligence and its future research directions},
journal = {Computers & Education},
volume = {240},
pages = {105465},
year = {2026},
issn = {0360-1315},
doi = {https://doi.org/10.1016/j.compedu.2025.105465},
url = {https://www.sciencedirect.com/science/article/pii/S0360131525002337},
author = {Qi Xia and Qian Liu and Ahmed Tlili and Thomas K.F. Chiu},
keywords = {Generative artificial intelligence, Self-regulated learning, Forethought, Performance, Self-reflection, Systematic review},
abstract = {A growing body of research suggests that generative AI (GenAI) can significantly enhance self-regulated learning (SRL) through its immediacy and interactivity. Nevertheless, challenges remain, including the lack of clarity regarding the mechanisms by which generative AI influences SRL, as well as the difficulties teachers encounter when trying to incorporate it into their classrooms. This systematic review study investigates how to design SRL activities using GenAI. We examined 73 articles published over the past five years, drawn from four databases: Web of Science, ProQuest, ERIC, and Scopus. This study has three major empirical findings. First, six pedagogical affordances from GenAI across the three phases of SRL—forethought, Performance, and self-reflection—are (i) creating personalized learning objectives; (ii) searching for, analyzing, and integrating resources; (iii) monitoring and evaluating progress; (iv) recommending learning strategies; (v) recording progress and providing feedback; and (vi) generating new ideas and examples. Second, popular student learning activities using GenAI in each phase are information searching in the forethought; strategies for problem-solving in the performance, and obtaining feedback and conducting self-assessments in the self-reflection. Third, two major dimensions influencing student engagement in SRL using GenAI are individual and environmental. Finally, we visualize how the three empirical findings relate to each other. Our findings help us understand how AI as a human-machine collaborative tool affects the SRL process. This study provides practical recommendations for facilitating SRL in GenAI-enhanced environments and offers guidance for the design and development of personalized GenAI learning tools.}
}
@article{CHAN2025101795,
title = {Strategies to incorporate generative artificial intelligence in simulation-based education among undergraduate students of healthcare professions: A scoping review},
journal = {Clinical Simulation in Nursing},
volume = {106},
pages = {101795},
year = {2025},
issn = {1876-1399},
doi = {https://doi.org/10.1016/j.ecns.2025.101795},
url = {https://www.sciencedirect.com/science/article/pii/S1876139925001124},
author = {Jackie Hoi Man Chan and Ken Hok Man Ho and Jacqueline Maria Dias},
keywords = {Generative artificial intelligence, Integration, Review, Simulation, Strategies, Undergraduate},
abstract = {Background
Complex prompting and unreadiness among faculty and students are some of the reported challenges when incorporating generative artificial intelligence (GenAI) into simulation-based education (SBE) in undergraduate healthcare programmes. However, strategies for incorporating GenAI into SBE are unclear. This scoping review identified current evidence on GenAI technology, its role, study outcomes, and strategies to incorporate GenAI into the SBE of undergraduate healthcare programmes.
Methods
The Joanna Briggs Institute methodology for scoping reviews was adopted. Eight electronic databases were searched from inception to January 21, 2025. Two authors independently screened and extracted data. The PAGER framework collated, critiqued, and reported the results.
Results
Eight studies were included. ChatGPT was the most frequently employed GenAI technology in SBE of undergraduate healthcare programmes, to enhance the students’ cognitive and affective learning. Study outcomes focused on usability. Five core strategies were synthesized: (a) establish guidelines on GenAI use; (b) enhance GenAI literacy; (c) enhance competency in GenAI prompting in simulation; (d) ensure pedagogical alignment; and (e) conduct pilot tests.
Conclusions
The findings provide insights into GenAI integration in SBE in undergraduate healthcare programmes. Further studies on the benefits of GenAI when applied to SBE are needed to demonstrate its impact on student learning.}
}
@article{LUSETTI20251883,
title = {Applications of generative artificial intelligence in inflammatory bowel disease: A systematic review},
journal = {Digestive and Liver Disease},
volume = {57},
number = {10},
pages = {1883-1889},
year = {2025},
issn = {1590-8658},
doi = {https://doi.org/10.1016/j.dld.2025.04.026},
url = {https://www.sciencedirect.com/science/article/pii/S1590865825007340},
author = {Francesca Lusetti and Stiliano Maimaris and Gianmaria Pio {La Rosa} and Davide Scalvini and Annalisa Schiepatti and Federico Biagi and Alice {De Bernardi} and Gianpiero Manes and Simone Saibeni},
keywords = {Chatgpt, Generative AI, Inflammatory bowel disease},
abstract = {Background and Aims
Inflammatory bowel diseases (IBD) are chronic conditions that can lead to a physical, social, and economic burden. Generative artificial intelligence (AI), particularly ChatGPT, gained attention for its potential to support medical practice. However, concerns remain about the reliability and consistency of its responses. This study systematically reviews the existing evidence on the role of generative AI in IBD.
Materials and methods
We conducted a systematic literature review following PRISMA guidelines. Studies investigating generative AI in IBD care were identified through PubMed and Embase (Jan 2020–Sep 2024).
Results
From 2875 records, 8 studies (2023–2024) met inclusion criteria: 5 on patient education, 2 on decision support, and 1 on research ideation. For patient education, ChatGPT provided clear and accurate responses, with accuracy reaching 84.2 % in a study, though sometimes lacked consistency. In decision support, ChatGPT’s classifications of ulcerative colitis severity aligned with clinician assessments in 80 % of cases and in 87.8 % of cases for guideline-based dysplasia management. For research ideation, ChatGPT generated highly relevant (mean score: 4.9 ± 0.26) and clear (4.8 ± 0.41) questions, but lacked specificity (2.86/5) and originality (1.07/5).
Conclusions
Generative AI shows promise in IBD care, but concerns about accuracy, consistency, and outdated information highlight the need for expert oversight before clinical integration.}
}
@article{LIANG2025103434,
title = {Students’ attitudes toward generative artificial intelligence in academic contexts: A multi-factor analysis},
journal = {International Journal of Educational Development},
volume = {119},
pages = {103434},
year = {2025},
issn = {0738-0593},
doi = {https://doi.org/10.1016/j.ijedudev.2025.103434},
url = {https://www.sciencedirect.com/science/article/pii/S0738059325002329},
author = {Haiying Liang and Xu Mao},
keywords = {Generative artificial intelligence, Higher education, Academic writing, Technology acceptance},
abstract = {As generative artificial intelligence (GAI) tools become increasingly embedded in higher education, understanding the factors shaping students’ attitudes toward these technologies has become critical for effective pedagogical and institutional responses. This study examines how demographic characteristics, usage patterns, perceived GAI literacy, and ethical awareness relate to Chinese undergraduates’ attitudes toward GAI in academic contexts. A cross-sectional survey was conducted with 895 university students from diverse majors. Participants completed a validated GAI Attitude Scale alongside demographic and experiential measures. Descriptive statistics and multiple linear regression analyses were employed to explore how demographic, experiential, and ethical factors relate to students’ attitudes toward GAI. The findings indicate that female students perceived GAI as more useful than male students, while no significant differences were observed across grade levels. Students from non-humanities majors reported more positive attitudes than those in humanities. Regression results further showed that GAI usage frequency and ethical awareness were the strongest predictors of positive attitudes, while demographic factors such as year of study and major became non-significant once other variables were considered. The final model explained 26 % of the variance in overall attitudes. These results suggest that students’ acceptance of GAI is shaped less by demographic background than by their engagement with and ethical awareness of the technology. The study highlights the need for universities to integrate both practical training and ethical guidance into GAI-related teaching and policy.}
}
@article{MUKHERJEE2026104506,
title = {How lack of choice to opt-out of generative artificial intelligence in traditional search engines drives consumer switching intentions: The mechanism of empowerment},
journal = {Journal of Retailing and Consumer Services},
volume = {88},
pages = {104506},
year = {2026},
issn = {0969-6989},
doi = {https://doi.org/10.1016/j.jretconser.2025.104506},
url = {https://www.sciencedirect.com/science/article/pii/S0969698925002851},
author = {Pubali Mukherjee and Varsha Jain},
keywords = {Generative artificial intelligence, GenAI, Generative search experience, Search engine behavior, Consumer empowerment, Switching intentions},
abstract = {The growing integration of generative artificial intelligence (AI) in traditional search interfaces is transforming how consumers search for information online. When AI-generated summaries are at the forefront without allowing users to opt out, their search experience becomes less user-driven and more system-controlled. Yet, its impact on consumer switching intentions is underexplored. Grounded in consumer empowerment and psychological reactance theories, this mixed-method research investigates how the lack of a choice feature to opt out of AI integration drives consumer switching intentions. Analyzing real-world discussions on Reddit, followed by an experiment, our findings reveal that when users lack the choice to disable AI-generated content, they feel less empowered, more intrusive, and irritated, increasing their likelihood of switching. Our findings extend interface design literature by identifying “choice to opt out of AI feature” as a critical design element for GenAI interfaces. While previous research has primarily theorized consumer empowerment in AI-enabled interfaces by focusing on autonomy, power, and control, our findings advance this literature by empirically demonstrating consumer choice as a novel and critical antecedent of empowerment. Further, we contribute to psychological reactance theory by extending it to a permanent, system-level disruption and demonstrate that the scale and permanence of reactance drive switching intentions. We provide actionable recommendations for interface designers to incorporate a toggle switch into GenAI interfaces, enabling users to choose to disable AI features. It suggests that managers may use empowerment as a strategic differentiator of interfaces to prevent consumers from migrating to alternative interfaces.}
}
@article{YEUNG2025103082,
title = {University students' perceptions on how generative artificial intelligence shape learning and research practices: A case study in Hong Kong},
journal = {The Journal of Academic Librarianship},
volume = {51},
number = {5},
pages = {103082},
year = {2025},
issn = {0099-1333},
doi = {https://doi.org/10.1016/j.acalib.2025.103082},
url = {https://www.sciencedirect.com/science/article/pii/S0099133325000783},
author = {Renee Sze Kei Yeung and Ruwen Tian and Dickson K.W. Chiu and Samuel Ping-Man Choi},
keywords = {Generative artificial intelligence, Academic libraries, Student learning, Student research, Quantitative study},
abstract = {The launch of chat-based Generative Artificial Intelligence (GenAI) in November 2022 has garnered significant attention and adoption across various sectors, particularly the academic community. Considering the potential transformative impact of GenAI on university students' learning and research practices, this research examines the patterns of use, perceived benefits, and drawbacks of GenAI among undergraduates and postgraduates at universities in Hong Kong. This research employs the 5E instructional model to systematically investigate the effectiveness of GenAI tools in supporting learning and research among local university students. The 170 valid responses revealed generally positive perceptions of the benefits of using GenAI in learning and research-related activities. However, they also acknowledged its potential drawbacks on ethical issues such as plagiarism and academic dishonesty. In addition, respondents agreed that GenAI could effectively support their learning and research activities despite concerns about potential skill deficits, such as diminished critical thinking and analytical abilities caused by the excessive use of GenAI. These findings highlight the increasingly critical role that academic communities like libraries could play in promoting ethical, effective, and literate use of GenAI technologies through targeted training, tool curation, and research support services.}
}
@article{ELJAOUHARI2025146018,
title = {Integrating generative artificial intelligence into green logistics: A systematic review and policy-oriented research agenda},
journal = {Journal of Cleaner Production},
volume = {519},
pages = {146018},
year = {2025},
issn = {0959-6526},
doi = {https://doi.org/10.1016/j.jclepro.2025.146018},
url = {https://www.sciencedirect.com/science/article/pii/S095965262501368X},
author = {Asmae {El jaouhari} and Ashutosh Samadhiya and Anil Kumar and Sunil Luthra},
keywords = {Green logistics, Sustainable development, Generative artificial intelligence, Systematic literature review, Policy initiatives, Decision-making framework},
abstract = {In light of mounting environmental issues, the logistics industry plays a critical role in promoting sustainability. While generative artificial intelligence (GAI) has the potential to revolutionize green logistics, several barriers still prevent its widespread adoption. In existing literature, little is known about applications, drivers, enablers, critical barriers, and challenges associated with implementing GAI along with green logistics. To fill this gap, this study aims to systematically identify and assess the existing body of knowledge on the GAI and green logistics nexus, drawing on a systematic literature review carried out in compliance with the PRISMA-ScR (Preferred Reporting Items for Systematic Reviews and Meta-Analyses Extension for Scoping Reviews) protocol. The study identifies 34 key GAI-driven green logistics applications, 23 drivers and enablers, and 38 major barriers and challenges. The findings illustrate that GAI-driven green logistics applications, such as risk assessment and mitigation, decision support and real-time environmental response, resilience testing and scenario planning, are essential for developing sustainable logistics ecosystems. Organizational readiness, stakeholder collaboration, and supportive regulatory frameworks emerge as crucial enablers, while lack of digital infrastructure, investment costs, and regulatory gaps constitute significant barriers. The study proposes a decision-making framework to prioritize policy initiatives that could promote GAI adoption in green logistics. This research fills current knowledge gaps and has significant implications for supply chain stakeholders, scholars, and policymakers aiming to support sustainable and cutting-edge logistics systems.}
}
@article{VEHI2025113051,
title = {Generative artificial intelligence in diabetes healthcare},
journal = {iScience},
volume = {28},
number = {8},
pages = {113051},
year = {2025},
issn = {2589-0042},
doi = {https://doi.org/10.1016/j.isci.2025.113051},
url = {https://www.sciencedirect.com/science/article/pii/S2589004225013124},
author = {Josep Vehi and Omer Mujahid and Aleix Beneyto and Ivan Contreras},
keywords = {Health sciences, Diabetology, Artificial intelligence},
abstract = {Summary
The rapid advancement of generative artificial intelligence (AI) has been fueled by breakthroughs in large language models and applications across diverse domains, from creative content to scientific discovery. Its strength lies in modeling, simulating, and generating high-fidelity data. In diabetes care, generative AI enables solutions to challenges such as data scarcity, patient variability, and personalization. This article explores key deep generative models, including variational autoencoders, generative adversarial networks, transformers, and diffusion models applied to tabular, time series, image, and text data. These models enable synthetic patient data generation, dataset augmentation, glucose-insulin dynamics simulation, and the development of virtual coaches and digital twins. Despite these advances, challenges persist, including model instability, high data requirements, and output interpretability. This article reviews the current literature and outlines opportunities, limitations, and ethical considerations for the use of generative AI in diabetes healthcare.}
}
@article{LEVIN2025105216,
title = {Nursing judgment in the age of generative artificial intelligence: A cross-national study on clinical decision-making performance among emergency nurses},
journal = {International Journal of Nursing Studies},
volume = {172},
pages = {105216},
year = {2025},
issn = {0020-7489},
doi = {https://doi.org/10.1016/j.ijnurstu.2025.105216},
url = {https://www.sciencedirect.com/science/article/pii/S0020748925002263},
author = {C. Levin and A. Zaboli and G. Turcato and M. Saban},
keywords = {Clinical decision-making, Generative AI, Emergency nursing, AI decision support, Nursing judgment, AI in healthcare},
abstract = {Background
Clinical decision-making is a core competency in emergency nursing, requiring rapid and accurate assessments. With the growing integration of Generative Artificial Intelligence in healthcare, there is a pressing need to understand its potential as a clinical decision support tool. While Generative Artificial Intelligence models show high accuracy and consistency, their ability to navigate complex, context-sensitive scenarios remains in question.
Objectives
This study aimed to compare the clinical decision-making performance of emergency nurses from Israel and Italy with Generative Artificial Intelligence models (Claude-3.5, ChatGPT-4.0, and Gemini-1.5). It evaluated differences in severity assessment, hospitalization decisions, and test selection, while exploring the influence of demographic and professional characteristics on decision accuracy.
Methods
A prospective observational study was conducted among 82 emergency nurses (49 from Italy, 33 from Israel), each independently evaluating five standardized clinical cases. Their decisions were compared with those generated by Generative Artificial Intelligence models using a structured evaluation rubric. Statistical analyses included ANOVA, chi-square tests, logistic regression, and receiver operating characteristic curve analysis to assess predictive accuracy.
Results
Generative Artificial Intelligence models exhibited higher overall decision accuracy and stronger alignment with expert recommendations. However, notable discrepancies emerged in hospitalization decisions and severity assessments. For example, in Case 2, Generative Artificial Intelligence rated severity as level 1, while Italian and Israeli nurses rated it at 1.98 and 2.23, respectively (P < 0.01, F = 199). In Case 1, only 4.1 % of Italian nurses recommended hospitalization compared to 30.3 % of Israeli nurses, whereas all Generative Artificial Intelligence models advised hospitalization. Nurses showed greater variability in test selection and severity judgments, reflecting their use of clinical intuition and contextual reasoning. Demographics such as age, gender, and years of experience did not significantly predict accuracy.
Conclusions
Generative Artificial Intelligence models demonstrated consistency and expert alignment but lacked the contextual sensitivity vital in emergency care. These results highlight the potential of Generative Artificial Intelligence as a clinical decision-support tool while emphasizing the continued importance of human clinical judgment.}
}
@article{PANDAYSHUKLA2025105088,
title = {Exploring generative artificial intelligence in teacher education},
journal = {Teaching and Teacher Education},
volume = {165},
pages = {105088},
year = {2025},
issn = {0742-051X},
doi = {https://doi.org/10.1016/j.tate.2025.105088},
url = {https://www.sciencedirect.com/science/article/pii/S0742051X25001659},
author = {Priya Panday-Shukla},
keywords = {Generative artificial intelligence (GenAI), Artificial intelligence (AI), Diffusion of Innovation (DOI), Teacher educators, Pre-service teachers},
abstract = {Generative artificial intelligence (GenAI) has the potential to be a powerful tool for educators. However, understanding the key attributes that can influence pre-service teachers and teacher educators’ adoption of GenAI tools remains limited. This collective exploratory case study investigated the perceptions and experiences of 52 pre-service teachers and 21 teacher educators at a U.S. Pacific Northwest university through surveys and focus groups. Findings provide teacher educators and administrators with a deeper understanding of the perceived barriers and facilitators to diffusion and adoption of these tools. The recommendations outline practical approaches to improve key attributes and prepare educators and future teachers.}
}
@article{VERMA2025111478,
title = {Generative artificial intelligence-based modified abstractive cross attention enabled sequence to sequence model for abstractive Hindi text summarization},
journal = {Engineering Applications of Artificial Intelligence},
volume = {158},
pages = {111478},
year = {2025},
issn = {0952-1976},
doi = {https://doi.org/10.1016/j.engappai.2025.111478},
url = {https://www.sciencedirect.com/science/article/pii/S0952197625014800},
author = {Babita Verma and Ani Thomas and Rohit Kumar Verma},
keywords = {Abstractive text summarization, Modified abstractive cross attention, Graph embedding, Generative Artificial Intelligence, Global surrogate technique},
abstract = {Abstractive Text summarization is the process of providing a concise as well as cohesive summary, which encapsulates the vital information from the original text. Although the supervised models now in use are competent, they frequently rely on annotated datasets and create challenges regarding uninterpretability and limited generalization ability. To overcome the limitations, this research proposes a Generative Artificial Intelligence Sequence to sequence the Bidirectional Encoder Representations from the Transformers model to generate concise summaries. During the generation of the output sequence, the model takes into account data from various segments of the input sequence by utilizing a modified abstractive cross-attention technique. Specifically, the Generative Artificial Intelligence assists in removing grammatical mistakes in summaries via the application of the Global Surrogate method, which ensures the clarity and fluency of the output summary. In addition, the encoder-decoder model enables the accurate summary generation process, vastly improving fluency and accuracy. Furthermore, the experimental outcomes show that the Generative Artificial Intelligence Sequence to sequence the Bidirectional Encoder Representations from the Transformers model surpasses the conventional text summarization techniques concerning Bilingual Evaluation Understudy of 0.71 and Metric for Evaluation of Translation with Explicit Ordering of 0.73, which shows that the proposed model generates a meaningful summary from the given text.}
}
@article{ZHENG2025105489,
title = {A generative artificial intelligence-enhanced multiagent approach to empowering collaborative problem solving across different learning domains},
journal = {Computers & Education},
pages = {105489},
year = {2025},
issn = {0360-1315},
doi = {https://doi.org/10.1016/j.compedu.2025.105489},
url = {https://www.sciencedirect.com/science/article/pii/S036013152500257X},
author = {Lanqin Zheng and Zhe Shi and Lei Gao},
keywords = {Cooperative/collaborative learning, Media in education, 21-century abilities},
abstract = {ABSTRACT
Collaborative problem-solving skills are among the most important skills in the 21st century. However, learners exhibit significant deficiencies in terms of their collaborative problem-solving skills. Emerging artificial intelligence (AI) technologies have given rise to transformative opportunities to facilitate collaborative problem solving through the introduction of adaptive learning mechanisms in educational settings. This study proposes a generative artificial intelligence (GenAI)-enhanced multiagent approach that aims to promote collaborative problem solving across different learning domains. The study also examines the effectiveness of this GenAI-enhanced multiagent approach to collaborative problem solving. In total, 234 college students participated in two empirical studies that focused on different tasks but had the same purpose and procedure. Experimental group 1 engaged in collaborative problem-solving with the assistance of a GenAI-enhanced multiagent approach. Experimental group 2 engaged in collaborative problem solving via a chatbot-based approach. The control group engaged in traditional collaborative problem-solving without any support. Data were collected through the pretest, posttest, and collaborative problem-solving process records and interview records. Both quantitative and qualitative methods were employed to analyze the data. The results indicated that compared with chatbot-based and traditional approaches, the GenAI-enhanced multiagent approach had more significant effects on learning achievements, knowledge elaboration, and collaborative problem-solving performance and skills. The implications of these findings are discussed in depth with the goal of advancing the use of GenAI to empower collaborative problem solving.}
}
@article{ALWASHAH2025113802,
title = {Generative artificial intelligence for construction: Use cases, trends, challenges, and opportunities},
journal = {Journal of Building Engineering},
volume = {112},
pages = {113802},
year = {2025},
issn = {2352-7102},
doi = {https://doi.org/10.1016/j.jobe.2025.113802},
url = {https://www.sciencedirect.com/science/article/pii/S235271022502039X},
author = {Zaid Alwashah and Bo Xiao and Hexu Liu and Shane T. Mueller and Xiaoyun Shao},
keywords = {Generative AI, Construction management, Construction education, Mixed review, Smart construction},
abstract = {Recently, generative artificial intelligence (AI) technologies such as Generative Adversarial Networks (GANs), large language models (LLMs), Generative Pre-trained Transformers (GPT), and diffusion models have been increasingly applied to address challenges and inefficiencies within the Architecture, Engineering, Construction (AEC) workflows, particularly in design, planning, and construction management. However, its current research landscape remains fragmented, with limited synthesis of trends and unclear pathways for adoption in the construction industry. To address these gaps, a mixed-method review is conducted, combining bibliometric analysis to quantitatively map research trends with qualitative thematic synthesis for in-depth contextual insights. A total of 148 publications were retrieved from Scopus and Google Scholar (2014–2024). The bibliometric analysis identified 49 high-frequency keywords, grouped into six thematic clusters, characterizing the quantitative research landscape. Complementing this, the qualitative synthesis examined five dominant application domains: (1) proactive safety monitoring and risk prevention, (2) generative AI for sustainable construction, (3) automating design through generative intelligence, (4) construction education, and (5) construction management, within which key research gaps and practical challenges are critically examined. Building upon these insights, the study proposes four-level research roadmap spanning (1) industry-level considerations, (2) organizational and stakeholder perspectives, (3) project-level perspectives, and (4) technological integration. Unlike prior reviews that concentrated on isolated single-model technologies or narrowly defined domains, this study offers a comprehensive, cross-domain analysis of generative AI for construction. By employing a mixed-method review—integrating quantitative bibliometric mapping and qualitative thematic synthesis—it bridges technical, organizational, and implementation perspectives to deliver a holistic understanding of the field. Hence, this review offers clear avenues for future investigation, empowering researchers to expand and refine Generative AI toward achieving a more efficient, resilient, and sustainable construction.}
}
@article{REFOUA2025100702,
title = {The next frontier in mindreading? Assessing generative artificial intelligence (GAI)'s social-cognitive capabilities using dynamic audiovisual stimuli},
journal = {Computers in Human Behavior Reports},
volume = {19},
pages = {100702},
year = {2025},
issn = {2451-9588},
doi = {https://doi.org/10.1016/j.chbr.2025.100702},
url = {https://www.sciencedirect.com/science/article/pii/S2451958825001174},
author = {Elad Refoua and Zohar Elyoseph and Renata Wacker and Isabel Dziobek and Iftach Tsafrir and Gunther Meinlschmidt},
keywords = {Generative artificial intelligence, Social cognition, Theory of mind, Emotion recognition, Multimodal assessment, Generative artificial intelligence and mental health},
abstract = {The integration of Generative Artificial Intelligence (GAI) into human social contexts has raised fundamental questions about machines' capacity to understand and respond to complex emotional and social dynamics. While recent studies have demonstrated GAI's promising capabilities in processing static emotional content, the frontier of dynamic social cognition – where multiple modalities converge to create naturalistic social scenarios – remained largely unexplored. This study advances our understanding by examining the social-cognitive capabilities of Google's Gemini 1.5 Pro model through its performance on the Movie for the Assessment of Social Cognition (MASC), a sophisticated instrument designed to evaluate mentalization abilities using dynamic audiovisual stimuli. We compared the model's performance to a human normative sample (N = 1230) across varying temperature settings (a parameter controlling the level of randomness in the AI's output, where lower values lead to more deterministic responses and higher values increase variability; set at 0, 0.5, and 1). Results revealed that Gemini 1.5 Pro consistently performed above chance across all conditions (all corrected ps < 0.001, Cohen's h range = 1.17–1.41) and significantly outperformed the human sample mean (Z = 2.24, p = .025; Glass's Δ = 0.92, 95 % CI [0.11, 1.72]; Hedges' g = 0.92, 95 % CI [0.12, 1.72]). Analysis of error patterns revealed a distribution between hyper-mentalizing (41.0 %; over-attribution of mental states), hypo-mentalizing (46.2 %; under-attribution of mental states), and non-mentalizing (12.8 %; failure to recognize mental states) errors. These findings extend our understanding of artificial social cognition to complex multimodal processing while raising important questions about the nature of machine-based social understanding. The implications span theoretical considerations in artificial Theory of Mind to practical applications in mental health care and social skills training, though careful consideration is warranted regarding the fundamental differences between human and artificial social cognitive processing.}
}
@article{YU2025116636,
title = {A generative artificial intelligence model for efficient gas sensitivity prediction in materials without parameters from first principle calculation},
journal = {Sensors and Actuators A: Physical},
volume = {391},
pages = {116636},
year = {2025},
issn = {0924-4247},
doi = {https://doi.org/10.1016/j.sna.2025.116636},
url = {https://www.sciencedirect.com/science/article/pii/S092442472500442X},
author = {Qiuchen Yu and Mengjiao Zhao and Qingning Han and Yu Chen and Zijiang Yang and Shasha Gao and Sheng Huang},
keywords = {Gas sensitivity, Doped ZnO, Predictive model, First-principles calculation, Material discovery},
abstract = {High gas sensitivity materials are crucial for the development of high-performance gas sensors. Traditionally, obtaining such materials has relied on trial and error, a process that is time-consuming, resource-intensive and laborious. In this study, an intelligent predictive framework using a generative artificial intelligence model is presented, which predicts the gas sensitivity of target materials with remarkable speed and accuracy. To validate the proposed framework, a material database is constructed using ZnO doped with eight different metal atoms, which serves as representative materials. Subsequently, 25 physical parameters, including crystal structure and electronic structure, are calculated using first-principles calculations. Eight intelligent learning models are then trained to predict sensitivity, with the Extremely Randomized Trees model performing the best, achieving a mean square error of 0.02. By combining feature engineering with generative artificial intelligence models, a novel model based on intrinsic atomic features (radius, electronegativity, first ionization energy) is developed, which enables the prediction of CO gas sensitivity in doped ZnO using the generated 12 key parameters, without any parameters from first principle calculation, thus significantly reducing the time and cost associated with discovering gas-sensitive properties. This predictive framework can be easily extended to other materials, facilitating the functional development of materials.}
}
@article{ZHU2025106855,
title = {Identifying highly correlated determinants influencing student nurses' behavioral intention of using generative artificial intelligence (Generative AI): A network analysis},
journal = {Nurse Education Today},
volume = {154},
pages = {106855},
year = {2025},
issn = {0260-6917},
doi = {https://doi.org/10.1016/j.nedt.2025.106855},
url = {https://www.sciencedirect.com/science/article/pii/S0260691725002928},
author = {Yaqi Zhu and Fule Wen and Jie Wu and Peiyi Huang and Yuanyuan Zhang},
keywords = {Generative artificial intelligence, Nursing students, Network analysis},
abstract = {Aim
This study aims to identify the most critical factors influencing nursing students' behavioral intention to use generative artificial intelligence by developing a network structure.
Background
Generative artificial intelligence is increasingly integrated into nursing education and clinical nursing practice. Studies have explored the factors influencing behavioral intentions toward the use of Artificial Intelligence, but research specific to Generative Artificial Intelligence is still lacking. It's crucial for nursing students to use generative artificial intelligence effectively, especially as clinical environments change rapidly in the digital era. Thus, it is important to identify the key factors that influence their intention to use.
Methods
A cross-sectional study was conducted. 800 participants were recruited from November to December 2023 through convenient sampling. Network analysis was applied in this study to identify the important nodes that are the most critical target goals for improving the behavioral intention of using Generative artificial intelligence by R package.
Results
The network analysis indicated that Artificial Intelligence Relevance, Ethical Awareness About Artificial Intelligence served as central factors in the network of Generative Artificial Intelligence Intention of using (EI = 1.19, 1.06). Artificial Intelligence Literacy was a key bridge node linking the Generative Artificial Intelligence Intention of using with its influencing factor associations (BEI = 0.33).
Conclusions
Generative Artificial Intelligence Relevance, Ethical Awareness about Generative Artificial Intelligence and Generative Artificial Intelligence Literacy serves as potential targets for enhancing nursing students' behavioral intention. Nursing educators and universities could consider targeted and collaborative effort to improve their behavioral intention.}
}
@article{GOLLER2025102746,
title = {This time it’s different – Generative artificial intelligence and occupational choice},
journal = {Labour Economics},
volume = {95},
pages = {102746},
year = {2025},
note = {The European Association for Labour Economists (EALE) Conference 2024, Bergen, Norway, 5-7 September 2024},
issn = {0927-5371},
doi = {https://doi.org/10.1016/j.labeco.2025.102746},
url = {https://www.sciencedirect.com/science/article/pii/S0927537125000703},
author = {Daniel Goller and Christian Gschwendt and Stefan C. Wolter},
keywords = {Artificial intelligence, Occupational choice, Labor supply, Technological change},
abstract = {We show the causal influence of the launch of generative artificial intelligence (AI) in the form of ChatGPT on the search behavior of young people for apprenticeship vacancies. To estimate the short- and medium-term effects, we use a variety of methods, including a difference-in-discontinuity approach exploiting the exogenous nature of the unanticipated launch of ChatGPT in 2022. There is a strong short- and medium-term decline in the intensity of searches for vacancies, indicating a notable reduction in the supply of young people actively seeking apprenticeships and suggesting great uncertainty among the affected cohort. Occupations with a high proportion of cognitive tasks and with high demands on language skills were particularly affected by the decline. Interestingly, the revealed preferences in the search behavior of young job seekers contrasted with previous expert assessments on the automation risks of occupations and aligned with the most recent assessments of the AI and language model exposure of occupations – before these new assessments existed. Notably, while the supply decline did not reduce the number of signed apprenticeship contracts, we find evidence of declining applicant quality, particularly for commercial employees, the most widely offered apprenticeship in Switzerland.}
}
@article{CHAN202585,
title = {Integrating generative artificial intelligence in a writing intensive course for undergraduate nursing students},
journal = {Journal of Professional Nursing},
volume = {57},
pages = {85-91},
year = {2025},
issn = {8755-7223},
doi = {https://doi.org/10.1016/j.profnurs.2025.01.003},
url = {https://www.sciencedirect.com/science/article/pii/S8755722325000109},
author = {Vidya C. Chan},
keywords = {Artificial intelligence, Writing intensive course, Nursing education},
abstract = {While generative artificial intelligence (AI) has been around for many years, it has only recently become available for use by the public. This powerful resource has changed the landscape for higher education and many instructors fear the negative effects it can have on academic integrity and student creativity in the writing process. However, it is certain that AI is here to stay, and it is crucial that educators embrace this technology and teach students to use this resource carefully and wisely. Communication is an essential component in nursing practice and cultivating competent writing skills is a vital aspect of nursing education. However, nursing students struggle with scholarly writing especially at the undergraduate level. Integrating generative artificial intelligence into a writing intensive course offers a unique approach to aid students in improving their writing. In this pilot project, students were given an assignment to actively engage with generative artificial intelligence and critically analyze the response using current nursing literature to support or refute the output. This assignment was used to springboard class discussion on advantages and disadvantages of using artificial intelligence for scholarly writing. This novel approach has the potential to build confidence and competence in novice writers which supports their success in nursing school and in clinical practice.}
}
@article{LIN2025100610,
title = {Generative artificial intelligence: Pioneering a new paradigm for research and education in smart energy systems},
journal = {Energy and AI},
volume = {22},
pages = {100610},
year = {2025},
issn = {2666-5468},
doi = {https://doi.org/10.1016/j.egyai.2025.100610},
url = {https://www.sciencedirect.com/science/article/pii/S2666546825001429},
author = {Xiaojie Lin and Zheng Luo and Liuliu Du-Ikonen and Xueru Lin and Yihui Mao and Haoyu Jiang and Shuai Wang and Chongshuo Yuan and Wei Zhong and Zitao Yu},
keywords = {Smart energy systems, Generative artificial intelligence, Research, Education},
abstract = {Promoting low-carbon energy systems as a centerpiece of global sustainable development goals is essential. As part of this low-carbon transition, smart energy systems have been an active area of research and education, where artificial intelligence (AI) intersects with energy science. It is an emerging area where research and education face new challenges as new knowledge keeps coming in. During this process, generative artificial intelligence (GAI) plays a critical role in education and research activities. However, GAI's impact on smart energy systems research and education is less discussed. Especially, its impact on education is rarely discussed when compared to research. GAI reshapes both the research process and the roles of teachers and students in the course. This perspective offers insights into the ongoing research and education paradigm shifts observed in the smart energy system. This perspective synthesizes existing studies on "GAI for Science" and "GAI for Education" practices in the field of smart energy systems. In research, the impact of GAI is discussed from both macro and micro levels. In education, this perspective examines how a GAI-driven teaching approach addresses the challenges of teaching smart energy systems compared to the traditional approach. This perspective could benefit the discussion of GAI-reshaped research and education in energy science.}
}
@article{SONG2025105157,
title = {A case study of teachers’ generative artificial intelligence integration processes and factors influencing them},
journal = {Teaching and Teacher Education},
volume = {165},
pages = {105157},
year = {2025},
issn = {0742-051X},
doi = {https://doi.org/10.1016/j.tate.2025.105157},
url = {https://www.sciencedirect.com/science/article/pii/S0742051X25002343},
author = {Zicong Song and Jingjing Qin and Fangzhou Jin and Wai Ming Cheung and Chin-Hsi Lin},
keywords = {Teacher, Generative artificial intelligence, Integration, Factors, Transformation},
abstract = {How schoolteachers integrate generative artificial intelligence (GenAI) into their teaching remains underexplored. This case study of 22 teachers from Guangdong delineates four GenAI user types, i.e., cautious adapters, efficiency enhancers, technology enthusiasts, and pedagogical innovators; groups teachers’ GenAI integration into five levels, from low to high; and examines how transformation of GenAI integration is influenced by individual, technological, and environmental factors. These findings extend the Substitution, Augmentation, Modification, and Redefinition (SAMR) model into PSAMR – the “P” stands for “Prohibition” – emphasizing GenAI’s dynamic, controversial nature. They also indicate that, during integration, educators should focus more on human factors than on tools’ functionalities.}
}
@article{ZHANG2026104452,
title = {The effects of generative artificial intelligence on consumers in hospitality and tourism: A systematic review and future research directions},
journal = {International Journal of Hospitality Management},
volume = {133},
pages = {104452},
year = {2026},
issn = {0278-4319},
doi = {https://doi.org/10.1016/j.ijhm.2025.104452},
url = {https://www.sciencedirect.com/science/article/pii/S0278431925003809},
author = {Mengying Zhang and Furui Yi and Dogan Gursoy},
keywords = {Generative Artificial Intelligence, Systematic Review, Consumer Behaviors, Dual Impacts, Tourism Technology},
abstract = {This study provides a comprehensive analysis of the current Generative Artificial Intelligence (GenAI) research landscape at the consumer-level in the hospitality and tourism field through a systematic review of GenAI publications. It explores key motivators and barriers affecting consumer adoption of GenAI, along with its broader influence on consumer behavior. The findings indicate that existing research has largely focused on GenAI’s positive impact on operational efficiency, primarily from the perspectives of industry practitioners, service providers, and technology suppliers. However, critical concerns related to consumer experience, such as ethics, psychology, social dynamics, and security, have received limited attention, despite posing significant risks to the successful adoption and sustainable development of GenAI technologies in hospitality and tourism. Drawing on these insights, the study proposes a future research agenda and highlights its theoretical and practical contributions.}
}
@article{LIU2025105479,
title = {Generative artificial intelligence perspectives on typical landscape types: Can ChatGPT compete with human insight?},
journal = {Landscape and Urban Planning},
volume = {264},
pages = {105479},
year = {2025},
issn = {0169-2046},
doi = {https://doi.org/10.1016/j.landurbplan.2025.105479},
url = {https://www.sciencedirect.com/science/article/pii/S0169204625001860},
author = {Jinxuan Liu and Tianci Zhang and Yongcan Ma and Tianxu Hu and Feng Lin and Huiyi Liang and Danchen Yang and Yinan Pan and Dongyang Gao and Ling Qiu and Tian Gao},
keywords = {ChatGPT, Large language model, Machine perception, Landscape preference, Preference matrix},
abstract = {The emergence of ChatGPT, a prominent generative artificial intelligence (GAI), has raised concerns due to its increasing capability to rival or even surpass human performance across various tasks and domains. However, its alignment with human perception, particularly in emotional and aesthetic dimensions such as landscape preferences, remains uncertain. This study investigated the discrepancies between human and GPT-4 performance in landscape perception and preference, using the Kaplans’ preference matrix as a benchmark. Survey data were collected from 1,333 participants in China, and five typical landscapes i.e. gray, open green, partly open/closed green, closed green, and blue spaces were evaluated. To simulate human-like responses, artificial intelligence (AI) agents using ChatGPT were created with personal attributes mirroring those of the human sample. Results indicated that GPT-4 demonstrated significant divergences from human perception and preference in assessing landscape coherence, complexity, mystery, legibility, and overall preference. While GPT-4 performed comparably well in simpler environments, such as pure single-layer broadleaf forests on flat terrain, it struggled to capture key elements and emotions in more complex or nuanced urban landscapes. Notably, only 2.4 % of ChatGPT’s responses aligned with human perceptions and preferences. These findings highlighted the limitations of current AI in fully replicating human intelligence in landscape perception, emphasizing the continued necessity of human involvement in human-centered landscape design. This study offers insights into the current limitations of ChatGPT and suggests directions for enhancing its application in landscape design.}
}
@article{BELLARY20251217,
title = {Generative artificial intelligence for management education: applications, benefits, challenges and future research directions},
journal = {International Journal of Educational Management},
volume = {39},
number = {5},
pages = {1217-1239},
year = {2025},
issn = {0951-354X},
doi = {https://doi.org/10.1108/IJEM-10-2024-0653},
url = {https://www.sciencedirect.com/science/article/pii/S0951354X25000390},
author = {Sreevatsa Bellary and Sobhan Sarkar and Arindra Nath Mishra},
keywords = {Generative artificial intelligence, Management education, Systematic literature review, Artificial intelligence},
abstract = {Purpose
Generative artificial intelligence (GenAI) has received significant traction in recent years for its ability to generate content based on human inputs. The aim of this study is to examine the existing literature on GenAI in management education by conducting a combination of bibliometric analysis and systematic literature review and provide future research directions, which can help management educators to train management students who are potential future managers.
Design/methodology/approach
Utilizing a total of 141 articles obtained from multiple databases, this study conducts a systematic literature review and synthesizes the existing literature on GenAI across management functions and industries. Further, this study provides future research directions specific to each group that will help in the advancement of context-specific management education.
Findings
The study synthesized the applications, benefits, challenges and future research directions of GenAI across different management domains, including marketing, finance and accounting, operations and human resource management. Overall, the study found that GenAI can promote academic performance enhancement, personalized learning, programming skills development, improved student motivation and effective learning.
Originality/value
The study provides an avenue for management education teachers to train their students in multiple management domains to get a comprehensive idea about the current work on GenAI in that particular domain, using which they can proceed to work in the domain. For management students who are potential emerging managers, the results of the study provide a comprehensive overview of the applications of GenAI across various management verticals, which provides a basis for benchmarking against the applications of GenAI.}
}
@article{CHEN2025101786,
title = {Effectiveness of integrating generative artificial intelligence with virtual reality for maternity communication simulation: A randomized controlled trial},
journal = {Clinical Simulation in Nursing},
volume = {105},
pages = {101786},
year = {2025},
issn = {1876-1399},
doi = {https://doi.org/10.1016/j.ecns.2025.101786},
url = {https://www.sciencedirect.com/science/article/pii/S1876139925001033},
author = {Pao-Ju Chen},
keywords = {Artificial intelligence, Communication skills, Empathy, Maternity, Nursing, Virtual reality},
abstract = {Background
Communication and empathy are equally vital in maternity nursing. However, nursing students often encounter difficulties in clinical communication due to a lack of communication skills training.
Methods
A Natural Language Processing Virtual Reality Communication Simulation (NLP-VRCS) was developed by integrating ChatGPT-based generative artificial intelligence (AI) with virtual reality to assist communication skills training. The empathy, communication confidence, and skills of nursing students trained using the NLP-VRCS (n = 53) were compared to those who received traditional training (n = 52) at baseline (T0), one week (T1), one month (T2), and two months after the training (T3).
Results
After the results were adjusted using generalized estimating equations, the experimental group scores regarding empathy, communication confidence, and communication skills at T1, T2, and T3 were significantly higher than those of the control group.
Conclusion
NLP-VRCS offers personalized training sessions and advice on communication strategies through real-time interactions with a virtual pregnant woman and AI-powered instant assessment and feedback.}
}
@article{AROMAA2025217,
title = {Company perspectives of generative artificial intelligence in industrial work},
journal = {Procedia Computer Science},
volume = {253},
pages = {217-226},
year = {2025},
note = {6th International Conference on Industry 4.0 and Smart Manufacturing},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2025.01.085},
url = {https://www.sciencedirect.com/science/article/pii/S1877050925000936},
author = {Susanna Aromaa and Päivi Heikkilä and Marko Jurvansuu and Selen Pehlivan and Teijo Väärä and Marko Jurmu},
keywords = {Generative artificial intelligence, industry work, manufacturing, human factors, ergonomics, company perspective},
abstract = {The use of artificial intelligence (AI) technologies in the manufacturing industry is rapidly increasing. During this transformation, it can be difficult to understand how AI will change the way work is done. This study explores how generative AI could change manufacturing work. Data collection was conducted using interviews and a questionnaire with seven representatives from three industrial companies. They identified several application areas for GenAI in the industrial work context, such as design, planning, training, problem solving, coding and data management. They also expressed positive attitudes but raised concerns about trust, safety, acceptability and interoperability. Changes in work were identified as being more related to cognitive aspects such as changing the way of thinking and altering the interaction with people and machines. Therefore, human-AI design efforts should focus especially on cognitive ergonomics. Findings from this study can be used in the manufacturing industry when adopting AI, as well as in identifying research topics in the human-AI research community.}
}
@article{CHEN2024104593,
title = {The revolution of generative artificial intelligence in psychology: The interweaving of behavior, consciousness, and ethics},
journal = {Acta Psychologica},
volume = {251},
pages = {104593},
year = {2024},
issn = {0001-6918},
doi = {https://doi.org/10.1016/j.actpsy.2024.104593},
url = {https://www.sciencedirect.com/science/article/pii/S0001691824004712},
author = {Dian Chen and Ying Liu and Yiting Guo and Yulin Zhang},
keywords = {Generative artificial intelligence, ChatGPT, Psychology, Natural language processing, Ethics},
abstract = {In recent years, there have been unparalleled prospects for psychological study due to the swift advancement of generative artificial intelligence (AI) in natural language processing, shown by ChatGPT. This review article looks into the uses and effects of generative artificial intelligence in psychology. We employed a systematic selection process, encompassing papers published between 2015 and 2024 from databases such as Google Scholar, PubMed, and IEEE Xplore, using keywords like “Generative AI in psychology” “ChatGPT and behavior modeling” and “AI in mental health”. First, the paper goes over the fundamental ideas of generative AI and lists its uses in data analysis, behavior modeling, and social interaction simulation. A detailed comparison table has been added to contrast conventional research methodologies with GenAI-based approaches in psychology studies. Next, analyzing the theoretical and ethical issues that generative AI raises for psychological research, it highlights how crucial it is to develop a coherent theoretical framework. This study illustrates the benefits of generative AI in handling vast amounts of data and increasing research efficiency by contrasting traditional research methods with AI-driven methodologies. Regarding particular uses, the study explores how generative AI might be used to simulate social interactions, analyze massive amounts of text, and learn about cognitive processes. Section 5 has been expanded to include discussions on political biases, geographic biases, and other biases. In conclusion, the paper looks forward to the future development of generative AI in psychology research and suggests techniques for improving it. We have included methodological solutions such as the Retrieval Augmented Generation (RAG) approach and human-in-the-loop systems, as well as data privacy solutions like open-source local LLMs. In summary, generative AI has the potential to revolutionize psychological research, but in order to maintain the moral and scientific integrity of the field, ethical and theoretical concerns must be carefully considered before applying the technology.}
}
@article{HAQUE2026108611,
title = {Generative artificial intelligence and large language models in smart healthcare applications: Current status and future perspectives},
journal = {Computational Biology and Chemistry},
volume = {120},
pages = {108611},
year = {2026},
issn = {1476-9271},
doi = {https://doi.org/10.1016/j.compbiolchem.2025.108611},
url = {https://www.sciencedirect.com/science/article/pii/S1476927125002725},
author = {Md. Asraful Haque and Hifzur R. Siddique},
keywords = {Generative AI, LLM, Healthcare applications, Ethical concern, Bias in AI models},
abstract = {With climate change, habitat destruction, and increased population ages, the incidence of both communicable and non-communicable diseases is rising, and managing these has become a growing concern. In recent years, generative artificial intelligence (AI) and large language models (LLMs) have ushered in a transformative era for smart healthcare applications. These models, built on advanced ML architectures like Generative Pre-trained Transformers (GPT) and Bidirectional Encoder Representations from Transformers (BERT), have demonstrated significant capabilities in various medical tasks. This review aims to provide an overview of the potential benefits of generative AI and LLMs in smart healthcare applications, as well as challenges and ethical considerations. A systematic literature review was conducted to identify relevant research papers published in peer-reviewed journals. Databases such as PubMed, PMC, Cochrane Library, Google Scholar, and Web of Science were searched using keywords related to generative AI, LLMs, and healthcare applications. The relevant papers were analyzed to extract key findings and contributions. Generative AI and LLMs are powerful tools that can process and analyze massive amounts of data. Researchers are actively exploring their potential to transform healthcare-powering intelligent virtual health assistants, crafting personalized patient care plans, and facilitating early detection and intervention for medical conditions. With ongoing research and development, the future of generative AI and LLMs in healthcare is promising; however, issues such as bias in AI models, lack of explainability, ethical concerns, and integration difficulties must be addressed.}
}
@article{GAO2025103141,
title = {A study on international scientific journal cover design driven by generative artificial intelligence},
journal = {Displays},
volume = {90},
pages = {103141},
year = {2025},
issn = {0141-9382},
doi = {https://doi.org/10.1016/j.displa.2025.103141},
url = {https://www.sciencedirect.com/science/article/pii/S0141938225001787},
author = {Zhan Gao and Zhenyu Li},
keywords = {Scientific journal cover design, Artificial intelligence, Midjourney, Stable diffusion, Deepseek, VIKOR},
abstract = {The application of generative artificial intelligence technology in the field of visual design is increasingly widespread, particularly showing significant potential in scientific publications. In order to overcome the limitations of traditional journal cover design and enhance the artistic quality and communicative effectiveness of journal covers, this study proposes a method for designing international scientific journal covers driven by artificial intelligence. The method integrates numerous generative artificial intelligence technologies and multi-criteria decision-making methods, applying them to the design practice of food science journals, thereby improving the efficiency of journal cover design and publication. The integrated method first uses the coding method of grounded theory to extract five design dimensions critical to journal cover design and constructs a triple-mapping relationship model of technological translatability, visual expressiveness, and alignment with public cognition and cultural background, providing a research foundation for organizing design elements to align with the journal’s positioning. The DeepSeek large language model is employed to generate creative keywords for the journal cover, which are then translated into descriptive instructions recognizable by Midjourney. Subsequently, Midjourney is used to generate preliminary cover sketches to quickly visualise the creative concept, and the controlnet function of Stable Diffusion is employed to control the outline of the sketch’s line art, followed by experimentation and optimisation across dimensions such as visual style and tonal range. Finally, the VIKOR method is applied to evaluate and rank the six generated cover design proposals. The evaluation criteria encompass scientific content expression, visual aesthetics, and communication and acceptance, across three dimensions with fifteen indicators. The selected design proposals are then subjected to collaborative optimisation between human input and artificial intelligence. The integrated method offers a systematic and innovative framework, enhancing the efficiency, creativity, and visual impact of journal cover design, and provides both theoretical and practical references for future academic publishing.}
}
@article{ZHANG2025104596,
title = {The application of Generative Artificial Intelligence in mental health care: A bibliometric and visualized analysis},
journal = {Asian Journal of Psychiatry},
volume = {110},
pages = {104596},
year = {2025},
issn = {1876-2018},
doi = {https://doi.org/10.1016/j.ajp.2025.104596},
url = {https://www.sciencedirect.com/science/article/pii/S1876201825002394},
author = {Wenyu Zhang and Qian Zhang and Peng Wang and Xiaohua Zhou and Yulan Wu},
keywords = {Generative Artificial Intelligence, Mental health care, Knowledge hotspots, Bibliometric analysis, CiteSpace},
abstract = {Objective
Generative Artificial Intelligence (GAI) has emerged as a promising and innovative technological advancement that can increase access to mental health care services with its powerful natural language processing capabilities. Preliminary findings suggest that GAI has great potential in the field of mental health care. This study aims to elaborate and predict the trajectory of the discipline, identify research hotspots and emerging trends, and provide a comprehensive framework for the application of GAI in mental health care.
Methods
The analyzed papers were obtained from the Web of Science core database and were searched from the beginning of the database to December 14, 2024. Bibliometric and visualization analyses were performed for sources, institutions, countries, author collaboration networks, and keywords. We used Bibliometrix (version 4.4.2), CiteSpace (version 6.4.R1 Basic) and Excel (WPS 6.2.2.8394).
Results
A total of 79 articles published by 118 authors were retrieved from the Web of Science Core Collection database. The number of published articles showed an increasing trend. “JMIR Mental Health” was the journal with the most publications, and the United States, China, and the United Kingdom were the top three contributors and the countries with the most publications. In addition, the high-frequency keywords identified in this study include Artificial Intelligence, Mental Health, Machine Learning, Large Language Models, Natural Language Processing, Care, Depression. Large Language Model, ChatGPT, Challenges.
Conclusions
The application of GAI in the field of mental health care revolves around two main themes: (1) exploring applications in key areas such as emotional support, psychological assessment, and personalized psychological interventions; (2) issues of privacy protection, reliability of generated content, and associated risks. Future research can engage in multidisciplinary collaboration to further optimize the adaptability and standardization of GAI technology applications.}
}
@article{NG2025101222,
title = {Prompt engineering for generative artificial intelligence chatbots in health research: A practical guide for traditional, complementary, and integrative medicine researchers},
journal = {Integrative Medicine Research},
volume = {14},
number = {4},
pages = {101222},
year = {2025},
issn = {2213-4220},
doi = {https://doi.org/10.1016/j.imr.2025.101222},
url = {https://www.sciencedirect.com/science/article/pii/S2213422025001027},
author = {Jeremy Y. Ng},
keywords = {AI chatbots, Prompt engineering, Large language models, Generative artificial intelligence},
abstract = {Generative artificial intelligence (GenAI) chatbots powered by large language models (LLMs) are increasingly used in health research to support a range of academic and clinical activities. While increasingly adopted in biomedical research, their application in traditional, complementary, and integrative medicine (TCIM) remains underexplored. TCIM presents unique challenges, including complex interventions, culturally embedded practices, and variable terminology. This article provides a practical, evidence-informed guide to help TCIM researchers engage responsibly with GenAI chatbots through prompt engineering, the design of clear, structured, and purposeful prompts to improve output relevance and accuracy. The guide outlines strategies to tailor GenAI chatbot interactions to the methodological and epistemological diversity of TCIM. It presents use cases across the research process, including research question development, study design, literature searches, selection of reporting guidelines and appraisal tools, quantitative and qualitative analysis, writing and dissemination, and implementation planning. For each stage, the guide offers examples and best practices while emphasizing that AI-generated content should always serve as a starting point, not a final product, and must be reviewed and verified using credible sources. Potential risks such as hallucinated outputs, embedded bias, and ethical challenges are discussed, particularly in culturally sensitive contexts. Transparency in GenAI chatbot use and researcher accountability are emphasized as essential principles. While GenAI chatbots can expand access to research support and foster innovation in TCIM, they cannot substitute for critical thinking, methodological rigour, or domain-specific expertise. Used responsibly, GenAI chatbots can augment human judgment and contribute meaningfully to the evolution of TCIM scholarship.}
}
@article{ZHAO2025109807,
title = {From invisible to visible: How artificial intelligence facilitates generativity in product architecture},
journal = {International Journal of Production Economics},
pages = {109807},
year = {2025},
issn = {0925-5273},
doi = {https://doi.org/10.1016/j.ijpe.2025.109807},
url = {https://www.sciencedirect.com/science/article/pii/S0925527325002920},
author = {Jianyu Zhao and Yingbo Xu and Bo Zou and Xi Xi and Wei Liu},
keywords = {AI application, Generativity, Layered modular architecture, Artificial intelligence–large language model, New energy vehicle},
abstract = {Artificial intelligence (AI) reshapes the business landscape. The role of AI applications in product innovation has received much attention, yet the impact of AI technologies on the product itself remains insufficient. To address this question, we developed a theoretical framework around the resource-based view and the concept of generativity. We theorize and investigate the impact of AI application on generativity in a product architecture and whether generativity promotes product sales. Using a new energy vehicle (NEV) as a sample, we set a research context of digital manufacturing in which we argue that AI applications facilitate the generation of intelligent functions in NEVs, and intelligent functions promote vehicle sales. We further find that AI–large language model (LLM) adoption weakens the positive relationship between intelligent functions and vehicle sales. We aim to contribute to AI application and generativity studies, and we provide evidence for manufacturers to develop appropriate AI system strategies.}
}
@article{TAN20252015,
title = {Generative Artificial Intelligence (GAI) in Breast Cancer Diagnosis and Treatment: A Systematic Review},
journal = {Computers, Materials and Continua},
volume = {84},
number = {2},
pages = {2015-2060},
year = {2025},
issn = {1546-2218},
doi = {https://doi.org/10.32604/cmc.2025.063407},
url = {https://www.sciencedirect.com/science/article/pii/S1546221825006319},
author = {Xiao Jian Tan and Wai Loon Cheor and Ee Meng Cheng and Chee Chin Lim and Khairul Shakir Ab Rahman},
keywords = {Breast cancer, generative AI, artificial intelligence, deep learning, diagnosis, treatment, oncology},
abstract = {This study systematically reviews the applications of generative artificial intelligence (GAI) in breast cancer research, focusing on its role in diagnosis and therapeutic development. While GAI has gained significant attention across various domains, its utility in breast cancer research has yet to be comprehensively reviewed. This study aims to fill that gap by synthesizing existing research into a unified document. A comprehensive search was conducted following Preferred Reporting Items for Systematic Reviews and Meta-Analyses (PRISMA) guidelines, resulting in the retrieval of 3827 articles, of which 31 were deemed eligible for analysis. The included studies were categorized based on key criteria, such as application types, geographical distribution, contributing organizations, leading journals, publishers, and temporal trends. Keyword co-occurrence mapping and subject profiling further highlighted the major research themes in this field. The findings reveal that GAI models have been applied to improve breast cancer diagnosis, treatment planning, and outcome predictions. Geographical and network analyses showed that most contributions come from a few leading institutions, with limited global collaboration. The review also identifies key challenges in implementing GAI in clinical practice, such as data availability, ethical concerns, and model validation. Despite these challenges, the study highlights GAI’s potential to enhance breast cancer research, particularly in generating synthetic data, improving diagnostic accuracy, and personalizing treatment approaches. This review serves as a valuable resource for researchers and stakeholders, providing insights into current research trends, major contributors, and collaborative networks in GAI-based breast cancer studies. By offering a holistic overview, it aims to support future research directions and encourage broader adoption of GAI technologies in healthcare. Additionally, the study emphasizes the importance of overcoming implementation barriers to fully realize GAI’s potential in transforming breast cancer management.}
}
@article{KIM2025125873,
title = {A physics-driven generative model to accelerate artificial intelligence development for lithium-ion battery diagnostics},
journal = {Applied Energy},
volume = {391},
pages = {125873},
year = {2025},
issn = {0306-2619},
doi = {https://doi.org/10.1016/j.apenergy.2025.125873},
url = {https://www.sciencedirect.com/science/article/pii/S0306261925006038},
author = {Joonhee Kim and Hyosik Moon and Kwanwoong Yoon and Huiyong Chun and Myeongjae Lee and Jeongsik Ko and Soohee Han},
keywords = {Artificial intelligence, Battery diagnosis, Data augmentation, Electrochemical model, Generative model, Lithium-ion battery, Synthetic data},
abstract = {Recent advancements in artificial intelligence (AI) have highlighted the potential of extensive battery cycle data for diagnosing performance degradation in lithium-ion batteries (LIBs). Therefore, related generative models have been developed to rapidly generate a variety of battery data from a small number of real-world experimental measurements. This study proposes a physics-driven generative model (PGM) to produce realistic battery cycle data by reasonably sampling electrochemical parameters in a stochastic manner. PGM captured the fundamental principles of LIBs as electrochemical parameter distributions and then generated the corresponding virtual LIBs, even under conditions that have not been previously applied. This superior generalizable capability was validated by showing that PGM was very effective in detecting the internal short circuits (ISCs) of LIBs. Synthetic data with different ISC degree effects were generated using PGM based only on ISC-free LIBs. The results showed that a neural network trained on the generated synthetic data achieved a detection accuracy of 97.39 % for real physical ISCs, which was comparable to the detection results of a neural network trained using approximately 25 times more real data, including experimental results with ISCs. The proposed PGM is expected to contribute significantly to the rapid advancement of AI-based LIB diagnostics by generating physically meaningful data based on internal electrochemical principles.}
}
@article{HUANG2025104011,
title = {Generative artificial intelligence embedded thermodynamic modeling of gas turbines for adaptive performance matching},
journal = {Thermal Science and Engineering Progress},
volume = {66},
pages = {104011},
year = {2025},
issn = {2451-9049},
doi = {https://doi.org/10.1016/j.tsep.2025.104011},
url = {https://www.sciencedirect.com/science/article/pii/S2451904925008029},
author = {Qinni Huang and Xiwen Gu and Shixi Yang and Rui Xu},
keywords = {Performance modeling, Thermodynamic model, Adaptive performance matching, Gas turbine, Variational autoencoder},
abstract = {Gas turbines (GTs) play a pivotal role in modern energy systems. Accurate thermodynamic modeling is essential for reliable condition monitoring and fault diagnosis. Existing GT performance modeling methods have relatively poor generalization and adaptability under different operating conditions and different units. This paper proposes a generative artificial intelligence (AI) embedded thermodynamic modeling method of GTs for adaptive performance matching. Possible component performance curves are automatically generated by the variational autoencoder in the shape view. Speed-dependent map sampling coefficients of the curves are introduced to realize fast matching of various operating conditions. The proposed method is verified on 2 different types of in-service GTs in the industrial field with mean absolute percentage error 0.5% and 0.54%, respectively. The maximum reduction of performance prediction error is 2.37% compared to traditional methods. The proposed method can realize high-precision GT performance adaptive prediction with good generalization and applicability, thus providing guidance for high efficiency operation control and health management. This paper shows an interpretable and reliable approach for the integration of AI with thermodynamics. Following the proposed generative-embedded modeling paradigm, performance prediction of other complex energy systems can also benefit.}
}
@article{KONG2025100444,
title = {A study of developing administrative Staff's conceptual understanding of generative artificial intelligence through professional Development: Evaluation of a course using tests, surveys and thematic analysis of reflective writings},
journal = {Computers and Education: Artificial Intelligence},
volume = {9},
pages = {100444},
year = {2025},
issn = {2666-920X},
doi = {https://doi.org/10.1016/j.caeai.2025.100444},
url = {https://www.sciencedirect.com/science/article/pii/S2666920X25000840},
author = {Siu Cheung Kong and Wenxi Hu},
keywords = {Administrative staff, Artificial intelligence literacy, Conceptual understanding, Generative artificial intelligence, Professional development},
abstract = {Emerging research underscores the growing importance of artificial intelligence (AI) literacy for administrative staff as AI technologies continue to reshape the labor market. However, there remains a limited study about the curriculum components of AI literacy for administrative staff. This study aims to bridge this gap by designing and evaluating a professional development programme for administrative staff grounded in a four-dimensional AI literacy framework. A total of 62 administrative staff from diverse professional backgrounds participated in a 30-h course on understanding Generative Artificial Intelligence (GenAI) and its applications. Pre- and post-course conceptual tests and acceptance surveys demonstrated significant improvements in participants' conceptual understanding of GenAI as well as acceptance of using GenAI. Additionally, a thematic analysis of participants’ self-reflective writing revealed increased awareness of the importance of developing metacognitive abilities in using GenAI tools, increased acceptance of using AI tools at workplace, and heightened social awareness regarding AI integration in the workplace. This study contributes to both empirical research and theory-building by providing a structured approach to AI literacy development, tailored for administrative professionals. The findings offer a framework for equipping administrative staff with the essential skills needed for AI-integrated workplaces, reducing barriers to AI literacy across diverse sectors.}
}
@article{MACOSCAR2025924,
title = {An assessment of generative artificial intelligence in responding to clinical queries on tapering antidepressants},
journal = {Research in Social and Administrative Pharmacy},
volume = {21},
number = {11},
pages = {924-930},
year = {2025},
issn = {1551-7411},
doi = {https://doi.org/10.1016/j.sapharm.2025.06.107},
url = {https://www.sciencedirect.com/science/article/pii/S1551741125003742},
author = {Maeve {Mac Oscar} and Miriam Boland and Cathal Cadogan},
keywords = {Psychiatry, Tapering, Antidepressants, Artificial intelligence, ChatGPT},
abstract = {Background
A substantial cohort of individuals rely on online resources, such as discussion forums, for support on tapering antidepressants. This study aimed to assess the performance of generative artificial intelligence (AI) in responding to clinical queries on tapering antidepressants.
Methods
Ten queries on tapering antidepressants were developed based on previous research, prescribing guidelines, and online peer support forums. Queries covered areas including reasons for discontinuing antidepressants, tapering methods, withdrawal symptoms, and relapse. Each query was submitted to ChatGPT (OpenAI, San Francisco, CA) using the GPT-4 model as an independent standalone query using standardised prompts. Responses were evaluated in terms of relevance, accuracy, completeness, and clarity by two researchers working independently.
Results
GPT-4 responses to all tapering queries were considered relevant and within scope. Most responses (8/10) incorporated safety netting by emphasising the importance of consulting healthcare professionals before making any medication changes. The overall accuracy, completeness, and clarity of responses compared less favourably. The response to a query on hyperbolic tapering had the least favourable assessment. This was due to inaccuracies as the response incorrectly referred to logarithmic reductions and provided inaccurate examples of fixed dosage reductions. Several instances of AI hallucinations were identified, including fabricated references.
Conclusion
Generative AI is having a transformative impact on healthcare, including how healthcare professionals and patients access information about clinical queries, such as antidepressant tapering. The study findings show that GPT-4 was able to provide relevant and safety-conscious responses on antidepressant tapering. However, performance issues such as inconsistencies and inaccuracies in tapering recommendations highlight the important role that healthcare professionals continue to play in providing patients with clinically trained, professional support in safely managing health-related issues. Further research on developing AI evaluation tools is needed to ensure consistency in the approaches used in evaluating the performance of AI in addressing clinical queries.}
}
@article{MUNIR2025102439,
title = {Pharmacy meets AI: Effect of a drug information activity on student perceptions of generative artificial intelligence},
journal = {Currents in Pharmacy Teaching and Learning},
volume = {17},
number = {10},
pages = {102439},
year = {2025},
issn = {1877-1297},
doi = {https://doi.org/10.1016/j.cptl.2025.102439},
url = {https://www.sciencedirect.com/science/article/pii/S1877129725001601},
author = {Faria Munir and Heather Ipema and Rahul Nohria and Divita Singh},
keywords = {ChatGPT, Artificial intelligence, Drug information, Student perceptions, Generative artificial intelligence, Large language model, Health professional student, Health professional education},
abstract = {Objective
The current study assessed pharmacy students' perceptions about generative AI before and after participation in a ChatGPT-based drug information activity.
Methods
In 2024, students at three colleges of pharmacy completed a baseline and post-activity survey on their perceptions of ChatGPT including its reliability, usefulness, and impact on academic performance and critical thinking. The survey was modified from the TAME-ChatGPT assessment and used a 5-point Likert scale. After the baseline survey, students answered clinically relevant drug information questions on their own using primary or tertiary resources and compared their answers with ChatGPT responses. Independent t-test samples were used to compare baseline and post-activity surveys.
Results
A total of 227 students completed the pre-survey and 203 students completed the post-survey. Students' concerns about the reliability of ChatGPT increased after completing the drug information activity (pre-survey: 3.57 ± 0.96; post-survey: 3.88 ± 1.11; p = 0.002). Students' concerns about reliance on ChatGPT and prevention of critical thinking increased (pre-survey: 3.30 ± 1.34; post-survey: 3.57 ± 1.21; p = 0.031). The following areas decreased after the activity: enthusiasm about ChatGPT as learning and research tool (pre-survey: 3.60 ± 1.02; post-survey: 3.32 ± 1.18; p = 0.008), viewing ChatGPT as an important tool for academic success (pre-survey: 3.40 ± 1.13; post-survey: 3.12 ± 1.23; p = 0.015), and concern regarding being accused of plagiarism when using ChatGPT(pre-survey: 4.12 ± 0.96; post-survey: 3.91 ± 1.10; p = 0.031). Open-ended responses revealed that students largely perceived ChatGPT as unreliable for drug information, citing concerns about accuracy and outdated content. However, some students noted its potential usefulness for non-clinical tasks such as generating ideas, organizing content, or providing general overviews.
Conclusion
After a hands-on ChatGPT-based drug information activity, pharmacy students reported increased concerns about reliability and over-reliance on artificial intelligence-based technology. The results of this study may encourage pharmacy educators to implement classroom activities for active exploration of the benefits and challenges of generative AI.
Contribution to literature
Limited published data describes pharmacy student perceptions of artificial intelligence platforms as a drug information source. There is even less literature with pre- and post-data after implementing an activity in which students gain hands-on experience critiquing an artificial intelligence platform response. Therefore, this study was conducted to evaluate student perceptions after using ChatGPT in the classroom and comparing its performance to their own responses based on information from primary and tertiary literature. The results demonstrate that despite enthusiasm before using ChatGPT, concerns for reliability and hindering thinking increased after a observing the limitations of its performance in answering drug information questions.}
}
@article{SERRASIMON2025103033,
title = {Generative artificial intelligence in advertising. Field applications in Rio de Janeiro and Catalonia},
journal = {Telecommunications Policy},
volume = {49},
number = {8},
pages = {103033},
year = {2025},
issn = {0308-5961},
doi = {https://doi.org/10.1016/j.telpol.2025.103033},
url = {https://www.sciencedirect.com/science/article/pii/S0308596125001302},
author = {Jordi Serra-Simón and Mònica Puntí-Brun and Sílvia Espinosa-Mirabet and Maria Alice {de Faria Nogueira} and Ramón Martín-Guart and Sandro {Tôrres de Azevedo}},
keywords = {AI, GenAI, Advertising agencies, Creativity, Digital media, Rio de Janeiro, Catalonia},
abstract = {The emergence of Artificial Intelligence has revolutionized industries in various productive sectors on an international level. Advertising agencies are not immune to this reality and have also experienced the effects of AI through the advent and widespread use of technologies that enable the design, creation, editing, and writing of content for the advertising industry. This article allows us to measure the impact of the arrival of AI in several advertising agencies, independent and holding companies (such as McCann and Havas Media) in Rio de Janeiro and Catalonia. The research analyses the use and integration of these programs in creative and productive processes based on 25 in-depth interviews with 13 directors and 12 creatives in both regions. The results show that agencies are using generative AI tools, but for different purposes, and that in some cases, AI is related to the advertising creation process, while in others, it is used for tasks related to the design of strategic communication plans or even the design of prototypes and models. Although there is unanimous agreement on the benefits of AI, there are concerns about ethical issues and its use in the finalists' work. This article allows us to glimpse new lines of research related to the implementation of generative AI tools in advertising creativity, customer relationship management, and advertising production.}
}
@article{XIA2025100455,
title = {A systematic review and meta-analysis of the effectiveness of Generative Artificial Intelligence (GenAI) on students’ motivation and engagement},
journal = {Computers and Education: Artificial Intelligence},
volume = {9},
pages = {100455},
year = {2025},
issn = {2666-920X},
doi = {https://doi.org/10.1016/j.caeai.2025.100455},
url = {https://www.sciencedirect.com/science/article/pii/S2666920X25000955},
author = {Qi Xia and Weijia Li and Yiming Yang and Xiaojing Weng and Thomas K.F. Chiu},
keywords = {Meta-analysis, Generative artificial intelligence (GenAI), University students, Motivation and engagement},
abstract = {The rapid development of generative artificial intelligence (GenAI) technologies has revolutionized higher education, enhancing personalized learning and teaching practices. This study conducts a systematic review and meta-analysis to investigate the effects of GenAI on university students' motivation and engagement (cognitive, behavioural, emotional, and agency). By synthesizing experimental studies and applying association rule mining, the study (i) identifies significant positive impacts of GenAI on students' motivation and engagement across diverse educational settings. (ii) key moderating variables, such as subject category, learning strategy, and context of GenAI usage, are shown to influence these effects. (iii) subject category impacts cognitive and emotional engagement, while sample size moderates behavioural engagement. (iv) However, no significant moderating effects were observed on agency engagement. (v) The findings further highlight that individual and small group learning with GenAI, especially using ChatGPT, significantly enhances cognitive and emotional engagement. These findings contribute to the practical application of GenAI in higher education by offering actionable insights into optimizing learning strategies and engagement.}
}
@article{SHARMA2025101249,
title = {Adoption of generative artificial intelligence in management education using unlearning mechanism},
journal = {The International Journal of Management Education},
volume = {23},
number = {3},
pages = {101249},
year = {2025},
issn = {1472-8117},
doi = {https://doi.org/10.1016/j.ijme.2025.101249},
url = {https://www.sciencedirect.com/science/article/pii/S1472811725001193},
author = {Shubham Sharma},
keywords = {Unlearning, Generative artificial intelligence, ChatGPT, Resistance to change, Management education},
abstract = {The unprecedented popularity of Generative Artificial Intelligence (henceforth “GenAI”) tools like ChatGPT and Gemini has the potential to disrupt the education sector in general. The initial reactions from educators have drawn a mixed response about the application of GenAI in management education, where some consider it a ‘watershed’ phenomenon, while others consider it an ‘existential threat’ to the teaching-learning system. Subscribing to the positive view, this paper argues that educators must promote the responsible use of AI-based tools, and imposing any artificial restraint on the application of GenAI technology can be deleterious to students' advancement. This is because GenAI will automate future jobs and create new jobs that do not exist today. As organizations are moving towards skill-based hiring, management education must prepare graduates with the requisite technical and human skills required for future jobs. However, previous studies have invested a lot of attention towards the technical aspect of the integration of GenAI tools by recommending capacity development programs to understand the nuances of new technology. However, they have overlooked the important aspect of adopting technology, i.e., attitudes and behavioral rigidities among educators. For this purpose, we argue that to overcome such a rigid mindset, institutions must focus on an unlearning mechanism comprising three phases: destabilizing triggers, discarding existing practices, and experimenting with new ones to help educators adopt GenAI tools in the education system. This study offers multiple theoretical and practical implications. It is a response to a call from researchers to apply existing theories to inform management scholarship about the implementation of GenAI technology and overcome educators' apprehensions that impede the ethical application of GenAI in management education.}
}
@article{RASHIDI2025100688,
title = {Introduction to Artificial Intelligence and Machine Learning in Pathology and Medicine: Generative and Nongenerative Artificial Intelligence Basics},
journal = {Modern Pathology},
volume = {38},
number = {4},
pages = {100688},
year = {2025},
issn = {0893-3952},
doi = {https://doi.org/10.1016/j.modpat.2024.100688},
url = {https://www.sciencedirect.com/science/article/pii/S0893395224002680},
author = {Hooman H. Rashidi and Joshua Pantanowitz and Matthew G. Hanna and Ahmad P. Tafti and Parth Sanghani and Adam Buchinsky and Brandon Fennell and Mustafa Deebajah and Sarah Wheeler and Thomas Pearce and Ibrahim Abukhiran and Scott Robertson and Octavia Palmer and Mert Gur and Nam K. Tran and Liron Pantanowitz},
keywords = {artificial intelligence, ChatGPT, generative AI, generative pretrained transformer, machine learning, supervised & unsupervised ML},
abstract = {This manuscript serves as an introduction to a comprehensive 7-part review article series on artificial intelligence (AI) and machine learning (ML) and their current and future influence within pathology and medicine. This introductory review provides a comprehensive grasp of this fast-expanding realm and its potential to transform medical diagnosis, workflow, research, and education. Fundamental terminology employed in AI-ML is covered using an extensive dictionary. The article also provides a broad overview of the main domains in the AI-ML field, encompassing both generative and nongenerative (traditional) AI, thereby serving as a primer to the other 6 review articles in this series that describe the details about statistics, regulations, bias, ethical dilemmas, and ML-Ops in AI-ML. The intent of these review articles is to better equip individuals who are or will be working in an AI-enabled health care system.}
}
@article{LI2025105179,
title = {Generative artificial intelligence in tourism management: An integrative review and roadmap for future research},
journal = {Tourism Management},
volume = {110},
pages = {105179},
year = {2025},
issn = {0261-5177},
doi = {https://doi.org/10.1016/j.tourman.2025.105179},
url = {https://www.sciencedirect.com/science/article/pii/S0261517725000494},
author = {Hengyun Li and Jingbo Xi and Cathy H.C. Hsu and Bruce X.B. Yu and Xiang (Kevin) Zheng},
keywords = {Generative artificial intelligence, Integrative review, Tourism, Hospitality, Business, Future research},
abstract = {Rapid technical advances have spurred the potential of generative artificial intelligence (GenAI) in various business settings. However, the tourism industry is in the early stages of understanding and applying GenAI, and comprehensive knowledge is needed. This paper presents a systematic review of the empirical literature, published between 2022 and 2024, related to GenAI in the business and tourism fields. Findings draw a detailed picture of the state of GenAI research. In total, 170 published articles are reviewed based on topics, theories, and methods. Three main topic clusters are identified: 1) antecedents of using GenAI; 2) impacts and applications of GenAI; and 3) technicalities of GenAI. Theoretically, most studies have borrowed foundations from other fields without substantial development. Methodologically, existing research—particularly in tourism—has tended to feature quantitative techniques. This research also compares business and tourism literature based on an antecedents, process and outcomes framework, outlining potential research gaps and opportunities. In addition to synthesizing the current research landscape, this paper presents a multidimensional framework (i.e., theories, contexts, characteristics, and methods – TCCM) that suggests multiple future research questions to inform GenAI studies in tourism.}
}
@article{AGBO2025100266,
title = {Computing education using generative artificial intelligence tools: A systematic literature review},
journal = {Computers and Education Open},
volume = {9},
pages = {100266},
year = {2025},
issn = {2666-5573},
doi = {https://doi.org/10.1016/j.caeo.2025.100266},
url = {https://www.sciencedirect.com/science/article/pii/S2666557325000254},
author = {Friday Joseph Agbo and Chris Olivia and Godsalvation Oguibe and Ismaila Temitayo Sanusi and Godwin Sani},
keywords = {Computing education, Programming, Generative artificial intelligence, Large language model},
abstract = {Recent advances in generative artificial intelligence (GenAI) are revolutionizing computing education, causing paradigm shifts from the traditional teaching and learning technique. Studies are exploring GenAI tools in computing classes from intro to advanced topics with the aim to showcase how to reshape computing education in this new era of GenAI. This study examined the computing education research landscape to unravel how GenAI tools have been used in that domain, what are the characteristics of those studies in terms of computing topics, context, and tools, offering insights into the pros and cons for integrating GenAI in computing education based on the performance indicators reported in the literature. This study employed a systematic literature review approach to identify and analyze 78 relevant articles. The findings of this study show that educators are exploring GenAI tools in computer sciences classes from K-12 through graduate levels. Beyond programming education, GenAI has also been explored in college upper-level computer science courses such as Computer Graphics and Human-Computer Interaction. The performance analysis of these tools are presented in this study, indicating a progressive advancement from when the technology was introduced. This study also discusses learning outcomes, good practices, and potential risks to avoid when exploring GenAI, as reported in the studies, which could guide how computing educators design their instructional strategies using GenAI. This study contributes to broadening the understanding of exploring, adapting, or using GenAI in computer science education and may spark interest among educators who are unwilling to explore GenAI or may not understand how or what strategies to adopt.}
}
@article{LEBLEBICI2025111573,
title = {Generative artificial intelligence for integrated sensing and communication in 6G},
journal = {Computer Networks},
volume = {270},
pages = {111573},
year = {2025},
issn = {1389-1286},
doi = {https://doi.org/10.1016/j.comnet.2025.111573},
url = {https://www.sciencedirect.com/science/article/pii/S1389128625005407},
author = {Merih Leblebici and Ali Çalhan},
keywords = {6G mobile communication, Data link layer, Generative AI, ISAC, Network layer, Physical layer},
abstract = {The advent of sixth generation (6G) networks is poised to redefine wireless communication, promising unprecedented data rates, ultra-low latency, and transformative applications such as holographic communications and real-time digital twins. These advancements hinge on key enabling technologies, including terahertz communication, intelligent reflecting surfaces, and the integration of artificial intelligence (AI). Generative AI (GAI) emerges as a cornerstone of 6G, offering capabilities to overcome challenges such as data scarcity, network optimization, and personalized user experiences. Similarly, integrated sensing and communication (ISAC) stands as a pivotal innovation, merging communication and environmental sensing within a unified system, thereby enhancing spectrum efficiency and operational versatility. This paper examines the convergence of GAI and ISAC as foundational components of 6G. While much of the existing literature focuses on the physical layer, this study also highlights the untapped potential and challenges within the data link and network layers, presenting a comprehensive perspective on the transformative role of GAI and ISAC in next-generation networks.}
}
@article{GMITEREK2025103043,
title = {Generative artificial intelligence in the activities of academic libraries of public universities in Poland},
journal = {The Journal of Academic Librarianship},
volume = {51},
number = {3},
pages = {103043},
year = {2025},
issn = {0099-1333},
doi = {https://doi.org/10.1016/j.acalib.2025.103043},
url = {https://www.sciencedirect.com/science/article/pii/S0099133325000394},
author = {Grzegorz Gmiterek and Sebastian D. Kotuła},
keywords = {Generative artificial intelligence, Artificial intelligence, Academic libraries},
abstract = {The article presents the results of a study conducted, using both survey and content analysis (of the websites and fan pages) of all the libraries of the public universities in Poland to establish their use of generative artificial intelligence. The general findings showed that not all libraries were active in promoting artificial intelligence solutions. Most (57 %) of the libraries supported the inclusion of GAI in the repertoire of library tools, although only 39.3 % dealt with GAI issues. 46 % actively used them despite 50 % of the libraries creating conditions favorable for the use of GAI. Interestingly, 43 % of libraries indicated that they did not think there was a need to use GAI tools with the main reasons given including a lack of staff competencies and the appropriate regulations in the area. For those libraries using GAI or AI, 47 % of them had information about this published on their home pages and 39 % on their fan pages. The most common information found was about the promotion of AI tools, the resources available in the library, organized events (49,67 % of all information) and documents on the subject (36,77 % of the published information).}
}
@article{LIU2025101770,
title = {Leveraging generative artificial intelligence to enhance ICU novice simulation instructors’ case design: A qualitative study},
journal = {Clinical Simulation in Nursing},
volume = {105},
pages = {101770},
year = {2025},
issn = {1876-1399},
doi = {https://doi.org/10.1016/j.ecns.2025.101770},
url = {https://www.sciencedirect.com/science/article/pii/S1876139925000878},
author = {Jingbang Liu and Li Wang and Xuehua He and Yeru Xia and Xiaoyan Gong and Ruijuan Wu and Shan Li and Lili Wu},
keywords = {Case design, ChatGPT, Generative artificial intelligence, Intensive care, Qualitative, Simulation-based Teaching},
abstract = {Background
Generative Artificial Intelligence (Gen AI) is increasingly being integrated into nursing simulation education; however, little is known about how ICU novice simulation instructors experience using Gen AI for case design.
Methods
A descriptive qualitative approach was employed, utilizing semi-structured interviews with 13 ICU novice simulation instructors who participated in a simulation instructor training program incorporating Gen AI for case design. Thematic analysis was used to identify key themes.
Results
Three main themes emerged: (a) Perceived value and benefits; (b) Potential for expansion; and (c) Concerns and limitations.
Conclusion
ICU novice simulation instructors perceive Gen AI as a valuable tool for enhancing case design efficiency and fostering innovative teaching strategies. However, concerns regarding over-reliance on AI, content validation, and ethical considerations must be addressed. Future research should focus on refining AI-assisted simulation case design while maintaining a balance between AI support and instructor-led critical thinking to ensure the quality and sustainability of AI-integrated simulation education.}
}
@article{KHOSRAVI2025100890,
title = {Exploring the potential of generative artificial intelligence in medical image synthesis: opportunities, challenges, and future directions},
journal = {The Lancet Digital Health},
pages = {100890},
year = {2025},
issn = {2589-7500},
doi = {https://doi.org/10.1016/j.landig.2025.100890},
url = {https://www.sciencedirect.com/science/article/pii/S258975002500072X},
author = {Bardia Khosravi and Saptarshi Purkayastha and Bradley J Erickson and Hari M Trivedi and Judy W Gichoya},
abstract = {Summary
Generative artificial intelligence has emerged as a transformative force in medical imaging since 2022, enabling the creation of derivative synthetic datasets that closely resemble real-world data. This Viewpoint examines key aspects of synthetic data, focusing on its advancements, applications, and challenges in medical imaging. Various generative artificial intelligence image generation paradigms, such as physics-informed and statistical models, and their potential to augment and diversify medical research resources are explored. The promises of synthetic datasets, including increased diversity, privacy preservation, and multifunctionality, are also discussed, along with their ability to model complex biological phenomena. Next, specific applications using synthetic data such as enhancing medical education, augmenting rare disease datasets, improving radiology workflows, and enabling privacy-preserving multicentre collaborations are highlighted. The challenges and ethical considerations surrounding generative artificial intelligence, including patient privacy, data copying, and potential biases that could impede clinical translation, are also addressed. Finally, future directions for research and development in this rapidly evolving field are outlined, emphasising the need for robust evaluation frameworks and responsible utilisation of generative artificial intelligence in medical imaging.}
}
@article{PARK2025190,
title = {A 3D preform design method based on a generative artificial intelligence algorithm},
journal = {Journal of Manufacturing Processes},
volume = {144},
pages = {190-208},
year = {2025},
issn = {1526-6125},
doi = {https://doi.org/10.1016/j.jmapro.2025.04.013},
url = {https://www.sciencedirect.com/science/article/pii/S1526612525003962},
author = {Donghwi Park and Joonhee Park and Naksoo Kim},
keywords = {Forging, Preform design, Generative artificial intelligence},
abstract = {This study introduces a novel 3D preform design method that leverages generative artificial intelligence to optimise complex forging geometries. The 3D preform shape is simplified by expressing it in a two-dimensional manner based on the geometric features of the forged shape. A beta-variational autoencoder (β-VAE) serves as the generative model, paired with a surrogate model using deep neural networks (DNN) to explore and optimise preform geometries efficiently. The initial training dataset for the generative model is created using isosurfaces derived from Laplace’s equation. A multi-objective optimisation framework is developed to minimise forging load and flash volume and mitigate underfill and lap defects. Preforms were designed using this method and validated through forging experiments on two target geometries: a brake calliper and an electric vehicle (EV) manifold. The forging results of the optimised preforms were compared with traditional isosurface methods, demonstrating that the proposed method reduces forging load and flash volume while preventing underfill and lap defects. This integrated approach combines advanced computational techniques with practical validation, offering a systematic and adaptable solution for the challenges associated with 3D preform design in forging processes.}
}
@article{BOUEBDALLAH2025100984,
title = {Assessing students’ intention to adopt generative artificial intelligence},
journal = {Journal of Accounting Education},
volume = {72},
pages = {100984},
year = {2025},
issn = {0748-5751},
doi = {https://doi.org/10.1016/j.jaccedu.2025.100984},
url = {https://www.sciencedirect.com/science/article/pii/S0748575125000351},
author = {Najla Bouebdallah and Wissem Ajili {Ben Youssef}},
keywords = {Generative Artificial Intelligence (GenAI), Behavioral Intentions, Management Science Students, UTAUT 3},
abstract = {This study examines the factors that influence the use, adoption, and recommendation of generative artificial intelligence (GenAI) tools among French management science students. Our study extends the Unified Theory of Acceptance and Use of Technology (UTAUT 3) model by including trust, learning value, and empowerment in learning. This extension fills gaps in our understanding of the psychosocial factors influencing the adoption of GenAI tools in higher education. We used a questionnaire and partial least squares structural equation modeling (PLS-SEM) to analyze data collected from 257 French management science students across different institutions. The results show that the most significant factors are performance expectancy, habit, hedonic motivation, and trust. These factors explain 49.3% of the intention to use GenAI tools, 58.7% of the intention to adopt them, and 39.6% of the intention to recommend them. However, other factors had no significant effect on behavioral intentions. This study contributes to the literature on technology acceptance by extending the UTAUT 3 model to an educational context. Additionally, it provides practical recommendations for educators, policymakers, and technology providers to promote the integration of GenAI tools in management science education and prepare students for future professional environments centred on GenAI tools.}
}
@article{ZHANG202586,
title = {Application of generative artificial intelligence in catalysis},
journal = {Chinese Journal of Chemical Engineering},
volume = {84},
pages = {86-95},
year = {2025},
issn = {1004-9541},
doi = {https://doi.org/10.1016/j.cjche.2025.05.013},
url = {https://www.sciencedirect.com/science/article/pii/S1004954125002113},
author = {Tiantong Zhang and Haolin Cheng and Yao Nian and Jinli Zhang and Qingbiao Li and You Han},
keywords = {Generative AI, Neural networks, Catalysis, Catalyst, Characterization technology, Research paradigm},
abstract = {Catalysis has made great contributions to the productivity of human society. Therefore, the pursuit of new catalysts and research on catalytic processes has never stopped. Continuous and in-depth catalysis research significantly increases the complexity of dynamic systems and multivariate optimization, thus posing higher challenges to research methodologies. Recently, the significant advancement of generative artificial intelligence (AI) provides new opportunities for catalysis research. Different from traditional discriminative AI, this state-of-the-art technique generates new samples based on existing data and accumulated knowledge, which endows it with attractive potential for catalysis research — a field featuring a vast exploration space, diverse data types and complex mapping relationships. Generative AI can greatly enhance both the efficiency and innovation capacity of catalysis research, subsequently fostering new scientific paradigms. This perspective covers the basic introduction, unique advantages of this powerful tool, and presents cases of generative AI implemented in various catalysis researches, including catalyst design and optimization, characterization technique enhancement and guidance for new research paradigms. These examples highlight its exceptional efficiency and general applicability. We further discuss the practical challenges in implementation and future development perspectives, ultimately aiming to promote better applications of generative AI in catalysis.}
}
@article{SIAH2025,
title = {Authenticity and academic integrity in Generative Artificial Intelligence (GenAI) use among undergraduate nursing students},
journal = {Journal of Professional Nursing},
year = {2025},
issn = {8755-7223},
doi = {https://doi.org/10.1016/j.profnurs.2025.10.007},
url = {https://www.sciencedirect.com/science/article/pii/S8755722325001668},
author = {Chiew-Jiat Rosalind Siah and Junwei Vincent Lim and Meng Meng Lyu and Tracy Levett-Jones and Ihsan Mattar},
keywords = {Ethics, Generative Artificial Intelligence (GenAI), Education, Students, Nursing},
abstract = {Background
The use of large Generative Artificial Intelligence (GenAI) in higher education is reshaping how students learn. While GenAI offers significant benefits and the potential to improve education, it also poses ethical challenges and may affect students' ability to identify learning gaps and engage with course content.
Purpose
This study aims to explore students' experiences with GenAI related to academic integrity and the authenticity of work, including their awareness and attitudes toward acceptable use.
Method
This study employed a qualitative descriptive approach. The participants were recruited from the Bachelor of Science (Nursing) program in an academic university during the period October 2024 to January 2025.
Results
Fourteen undergraduates in their second- and third-year of study participated in group interviews. The qualitative data analysis revealed five key themes: 1) integration with learning, 2) trust and credibility of GenAI information, 3) ethical considerations, 4) addressing academic integrity, and 5) guidance on using GenAI.
Conclusion
These five key themes underscore the need to better understand the role of GenAI in higher education, particularly in self-directed learning and managing learning activities. With regards to academic integrity, clear guidelines must be put in place for educators to guide the use of GenAI, emphasizing its use as an instrument to augment, and not replace original work.}
}
@article{WANG2025103791,
title = {EFL teachers’ generative artificial intelligence (GenAI) literacy: A scale development and validation study},
journal = {System},
volume = {133},
pages = {103791},
year = {2025},
issn = {0346-251X},
doi = {https://doi.org/10.1016/j.system.2025.103791},
url = {https://www.sciencedirect.com/science/article/pii/S0346251X25002015},
author = {Yongliang Wang and Ali Derakhshan and Farhad Ghiasvand},
keywords = {Generative artificial intelligence (GenAI), EFL teachers, GenAI literacy, Scale development, Scale validation},
abstract = {The application of Generative Artificial Intelligence (GenAI) in second language education (L2) has recently drawn significant scholarly attention. Nonetheless, in the context of English as a foreign language (EFL), the fundamental dimensions of GenAI literacy and its psychometric properties remain poorly defined. Without clarifying the factor structures and dimensionality of GenAI literacy, EFL teachers face challenges in effectively leveraging GenAI in their teaching. To address this gap, our study aimed to develop and validate a GenAI literacy scale for the Chinese EFL context, involving 603 EFL teachers. Specifically, a tentative scale comprising 38 five-point Likert items was administered to participants. Through Exploratory Factor Analysis (EFA) and Confirmatory Factor Analysis (CFA), the final scale was refined, evincing 32 items categorized into five dimensions: “GenAI Knowledge”, “GenAI Use”, “GenAI Evaluation”, “GenAI Design”, and “GenAI Ethics”. Moreover, statistical analysis also verified the scale's convergent validity and reliability in measuring the construct of GenAI literacy. We anticipate that this EFL teachers' GenAI literacy scale will guide teachers and teacher educators in enhancing GenAI capabilities for professional growth. It can also inspire them to innovate teaching with AI tools, thereby offering them fresh insights into GenAI literacy and its sub-components in the rapidly evolving landscape of AI-integrated EFL education.}
}
@article{WANG2025102352,
title = {Integrating Generative Artificial Intelligence techniques into technology function matrix analysis},
journal = {World Patent Information},
volume = {81},
pages = {102352},
year = {2025},
issn = {0172-2190},
doi = {https://doi.org/10.1016/j.wpi.2025.102352},
url = {https://www.sciencedirect.com/science/article/pii/S0172219025000195},
author = {Huei-Yu Wang and Shu-Hao Chang and Chia-Yi Chuang},
keywords = {Technology-function matrices, Generative artificial intelligence, GAI, International patent classification, IPC},
abstract = {This study proposes a novel method for automating the construction of technology-function matrices using generative artificial intelligence (GAI), specifically focusing on quantum technologies. By leveraging GAI to analyze International Patent Classification (IPC) definitions and benchmark reports, we developed a system that rapidly generates technology-function matrices, significantly reducing the time required for manual analysis. The method was applied to 2,399 quantum technology patents from 2023 to March 2024, covering four key areas: secure communications, computing, quantum simulators, and sensors. This approach not only aids government agencies in identifying new technological opportunities but also facilitates the industrialization of potential technologies. By combining GAI with established analytical frameworks, this study contributes to both the theoretical understanding and practical application of patent analysis in emerging fields.}
}

@article{HUNG2025103005,
title = {Factors driving user behavior and value creation with text-to-image generative artificial intelligence (AI): A systems theory perspective},
journal = {Technology in Society},
volume = {83},
pages = {103005},
year = {2025},
issn = {0160-791X},
doi = {https://doi.org/10.1016/j.techsoc.2025.103005},
url = {https://www.sciencedirect.com/science/article/pii/S0160791X25001952},
author = {Chih-Lung Hung and Jen-Her Wu and Po-Chuen Chiang and Qi Li and Yi-Cheng Chen},
keywords = {Text-to-image generative AI, Systems theory, Compatibility, Synergy, User value},
abstract = {The rise of image-generative AI has made it a crucial tool for image creators, gaining popularity in fields such as cartography, design, and photography. As users increasingly rely on AI for image creation, understanding the factors that drive user value becomes essential. Drawing on systems theory, this study proposes a conceptual framework to examine the relationships among integration effort, compatibility, synergy, and value creation. Data from 531 AI image creators supported our hypotheses, revealing that: (1) integration effort significantly enhances both compatibility and synergy; (2) compatibility positively influences synergy; (3) synergy directly and positively impacts user value creation; and (4) synergy serves as a critical mediator in the relationships between the two enablers—compatibility and integration effort—and user value creation, with compatibility also partially mediating the link between integration effort and synergy. These results extend systems theory by integrating it more deeply with the resource-based view and highlighting synergy as a pivotal factor that not only directly drives user value creation but also mediates the effects of compatibility and integration effort. Furthermore, the study empirically confirms that user value can be conceptualized through three key constructs: efficiency, effectiveness, and innovation.}
}
@article{WHITE2025452,
title = {Generative artificial intelligence tools in journal article preparation: A preliminary catalog of ethical considerations, opportunities, and pitfalls*},
journal = {JDS Communications},
volume = {6},
number = {3},
pages = {452-457},
year = {2025},
issn = {2666-9102},
doi = {https://doi.org/10.3168/jdsc.2024-0707},
url = {https://www.sciencedirect.com/science/article/pii/S2666910224002011},
author = {Robin R. White},
abstract = {The launch of generative artificial intelligence (GenAI) tools has catalyzed considerable discussion about the potential impacts of these systems within the scientific article preparation process. This symposium paper seeks to summarize current recommendations on the use of GenAI tools in scientific article preparation, and to provide speculations about the future challenges and opportunities of GenAI use in scientific publishing. Due to the dynamic nature of these tools and the rapid advancement of their sophistication, the most important recommendation is that ongoing engagement and discussion within the scientific community about these issues is critical. When using GenAI tools in scientific article preparation, humans are ultimately accountable and responsible for products produced. Given that accountability, an expert panel convened by the National Academies of Science, Engineering, and Medicine recently proposed principles of GenAI use in science communication, including (1) transparent disclosure and attribution; (2) verification of AI-generated content and analyses; (3) documentation of artificial intelligence (AI)-generated data; (4) a focus on ethics and equity; and (5) continuous monitoring, oversight, and public engagement. In addition to the importance of human accountability, many publishers have established consistent policies suggesting that GenAI tools should not be used for peer reviewing, figure generation or manipulation, or assigned authorship on scientific articles. Along with the potential ethical challenges associated with GenAI use in scientific publishing, there are numerous potential benefits. Herein we summarize example conversations demonstrating the capacity of GenAI tools to support the article preparation process, and an example standard operating procedure for human-AI interaction in article preparation. Finally, diverse broader questions about the impact of GenAI tools on communication, knowledge, and advancement of science are raised for rumination.}
}
@article{ZHANG2026104392,
title = {The double-edged impact of generative artificial intelligence dependence on service innovation in the hospitality industry: A self-regulation perspective},
journal = {International Journal of Hospitality Management},
volume = {132},
pages = {104392},
year = {2026},
issn = {0278-4319},
doi = {https://doi.org/10.1016/j.ijhm.2025.104392},
url = {https://www.sciencedirect.com/science/article/pii/S0278431925003202},
author = {Zhenduo Zhang and Yanyu Dai and Jianing Guo and Haonan Zhang and Yifei Shen and Huan Xiao},
keywords = {Generative artificial intelligence dependence, Problem-solving pondering, Affective rumination, Service innovation, Conscientiousness, Neuroticism},
abstract = {To date, studies on the relationship between generative artificial intelligence (GenAI) dependence and service innovation have yielded inconsistent results. Drawing on self-regulation theory, we examine how and when GenAI dependence promotes or inhibits service innovation in the hospitality industry. Three studies were conducted to examine how GenAI is used in hospitality management and test the conceptual model: a three-wave questionnaire survey (N = 333), a quasi-field experiment (N = 227), and an in-depth interview (N = 11). The results indicate that GenAI dependence promotes service innovation by decreasing affective rumination, and this beneficial indirect path is amplified by employees’ neuroticism. Meanwhile, GenAI dependence inhibits service innovation by decreasing problem-solving pondering, and this unfavourable indirect path is weakened by employees’ conscientiousness. This exploration of when and how the use of GenAI either promotes or inhibits service innovation broadens our understanding of the consequences of GenAI dependence in the hospitality management field.}
}
@article{RAHMAN20243,
title = {Generative artificial intelligence: opportunities, challenges and future avenues for organizational learning},
journal = {Development and Learning in Organizations: An International Journal},
volume = {39},
number = {2},
pages = {3-7},
year = {2024},
issn = {1477-7282},
doi = {https://doi.org/10.1108/DLO-04-2024-0101},
url = {https://www.sciencedirect.com/science/article/pii/S1477728224000534},
author = {Hanfia Rahman and Tripti Singh},
keywords = {Generative artificial intelligence, Organizational learning, Systematic literature review},
abstract = {Purpose
This study provides a comprehensive investigation of the opportunities and challenges associated with generative artificial intelligence (GAI) use in development and learning in organizations. Additionally, it highlights the future avenues in GAI research and provides practical recommendations for policymakers.
Design/methodology/approach
Data for the review was collected from the Web of Science database using the search criteria (“Generative artificial intelligence” OR “artificial intelligence”) AND (“human resource management” OR “human resource development” OR “workplace learning” OR “organizational learning” OR “organizational development” OR “learning organization”) on March 6th, 2024. Filtering results to Management and Business categories yielded 71 articles. After abstract review, 6 unrelated articles were excluded, leaving 65 articles for final analysis.
Findings
The study presents several opportunities of GAI such as applications in personal learning and content generation. Moreover, it unravels several potential challenges of GAI such as quality and accuracy issues and elucidates several future research directions.
Originality/value
Our study is the first literature review that provides and a comprehensive overview of generative artificial intelligence in the context of organizational learning.}
}
@article{CHEN2025S169,
title = {344 - Shaping an Generative Artificial Intelligence Model for Enhancing Early Recognition of Out-of-hospital Cardiac Arrest by Emergency Medical Dispatch Audios and Performance Measurement},
journal = {Resuscitation},
volume = {215},
pages = {S169},
year = {2025},
note = {RESUSCITATION Official Journal of the European Resuscitation Council Abstracts of Resuscitation 2025},
issn = {0300-9572},
doi = {https://doi.org/10.1016/S0300-9572(25)00694-X},
url = {https://www.sciencedirect.com/science/article/pii/S030095722500694X},
author = {Tai-Yuan Chen and Kent You-Shuo Chen and Kah-Meng Chong and Mei-Fen Yang and Zhen-Yi Chen and Chien-Xing Lin and Patrick Chow-In Ko}
}
@article{SIMMS2025106544,
title = {Generative artificial intelligence (AI) literacy in nursing education: A crucial call to action},
journal = {Nurse Education Today},
volume = {146},
pages = {106544},
year = {2025},
issn = {0260-6917},
doi = {https://doi.org/10.1016/j.nedt.2024.106544},
url = {https://www.sciencedirect.com/science/article/pii/S0260691724004544},
author = {Rachel C. Simms},
keywords = {Artificial intelligence, Nursing education, Educational technology, Ethics, Nursing},
abstract = {Introduction
Generative artificial intelligence (AI) is revolutionizing healthcare, necessitating corresponding advancements in nursing education to ensure that future nurses are equipped for a technologically driven environment. This article explores the imperative integration of generative AI literacy in nursing education.
Implications for nurse educators
The article delves into the practical challenges and opportunities presented by generative AI in nursing. It underscores the need for educators to adapt curricula and teaching methods to effectively incorporate generative AI learning, ensuring students are proficient in generative AI technologies and aware of their ethical implications.
Generative AI literacy
Defined as a core educational requirement, this section highlights the skills and knowledge that nurse educators must impart. It encompasses the ability to critically assess AI-generated content, understand the underlying technologies, and responsibly apply this knowledge in clinical settings.
Conclusion
The article concludes by emphasizing the urgency of integrating generative AI literacy into nursing education. It advocates for a proactive approach to curriculum development and calls for global collaboration and standardization in AI education to address the diverse and evolving needs of healthcare.}
}
@article{SUN2025103806,
title = {Enhancing critical language awareness in EAL writing education amid the rise of generative artificial intelligence},
journal = {System},
volume = {134},
pages = {103806},
year = {2025},
issn = {0346-251X},
doi = {https://doi.org/10.1016/j.system.2025.103806},
url = {https://www.sciencedirect.com/science/article/pii/S0346251X25002167},
author = {Yachao Sun and Ge Lan},
keywords = {Generative artificial intelligence, Critical language awareness, English as an additional language, Writing education, Critical AI literacy, Digital literacies},
abstract = {The emergence of generative artificial intelligence (GenAI) tools has presented both opportunities and challenges in English as an Additional Language (EAL) writing education. This mixed-methods exploratory study investigated how Chinese EAL students perceived and used GenAI, and how these attitudes and behaviors reflected their Critical Language Awareness (CLA). Survey data were collected from 320 Chinese undergraduate and graduate students studying in China and abroad, supplemented by in-depth semi-structured interviews with five volunteers. Quantitative findings revealed that, while participants valued GenAI for reducing language barriers and enhancing writing mechanics, they remained wary of issues related to originality, transparency, and ethical accountability. Qualitative analysis further illuminated participants' emerging CLA, evident in their negotiations of power (managing overreliance and misinformation), ideology (navigating dominant academic norms), and social justice (acknowledging cultural biases encoded in GenAI training data). Although students were primarily motivated by pragmatic benefits, such as improved grammar, structure, and efficiency, they also recognized GenAI's potential to perpetuate monolingual, Western-centric perspectives. These results underscore the need to embed CLA principles in GenAI-assisted pedagogy. By encouraging students to critically interrogate GenAI outputs, question linguistic hierarchies, and reflect on sociocultural contexts, educators can better leverage GenAI's affordances while fostering ethical, culturally responsive, and equitable writing practices.}
}
@article{VISSAK2025436,
title = {Applying generative artificial intelligence applications for academic research on firms’ nonlinear internationalization},
journal = {Review of International Business and Strategy},
volume = {35},
number = {4},
pages = {436-484},
year = {2025},
issn = {2059-6014},
doi = {https://doi.org/10.1108/RIBS-10-2024-0120},
url = {https://www.sciencedirect.com/science/article/pii/S2059601425000037},
author = {Tiia Vissak and Lasse Torkkeli},
keywords = {Nonlinear internationalization, De-internationalization, Re-internationalization, Internationalization, Generative artificial intelligence (GenAI) tools, GenAI tools in research},
abstract = {Purpose
This study aims to critically evaluate the applicability of generative artificial intelligence (GenAI) tools for academic research in international business (IB), specifically focusing on the topic of firms’ nonlinear internationalization. It assesses these tools’ key performance dimensions: correctness, hallucinations and thoroughness.
Design/methodology/approach
This research adopts an exploratory approach, examining a comprehensive set of GenAI tools: eight chatbots and four AI-driven applications designed for academic purposes. The evaluation focuses on the capabilities and limitations of these tools in generating accurate research-related content for IB scholars.
Findings
This study finds that while GenAI tools capture some aspects of nonlinear internationalization, they often produce partially accurate and/or biased results. Common issues include providing fictitious sources, incorrect publication data and vague or incorrect answers. Thus, substantial development is still needed for GenAI tools to become reliable for scientific research.
Practical implications
Researchers should use GenAI tools with caution, verifying the accuracy of generated content and citations independently. A cautious approach is crucial to maintain the integrity and quality of academic research.
Social implications
This study raises awareness about ethical and practical challenges of using AI in academia, including issues related to plagiarism and misinformation. It underscores the importance of critical evaluation when using GenAI tools for research.
Originality/value
This paper contributes to the emerging literature on the role of GenAI in academic research by providing a critical assessment of the usability and limitations of current tools in studying complex IB phenomena. By using nonlinear internationalization as an example, it demonstrates how GenAI may support or hinder IB scholarship.}
}
@article{LUO2025,
title = {Generative Artificial Intelligence Tools in Medical Research (GAMER): Protocol for a Scoping Review and Development of Reporting Guidelines},
journal = {JMIR Research Protocols},
volume = {14},
year = {2025},
issn = {1929-0748},
doi = {https://doi.org/10.2196/64640},
url = {https://www.sciencedirect.com/science/article/pii/S1929074825005001},
author = {Xufei Luo and Yih Chung Tham and Mohammad Daher and Zhaoxiang Bian and Yaolong Chen and Janne Estill},
keywords = {generative AI, chatbots, reporting guidelines, transparency, Delphi method, large language models, ChatGPT},
abstract = {Background
The integration of artificial intelligence (AI) has revolutionized medical research, offering innovative solutions for data collection, patient engagement, and information dissemination. Powerful generative AI (GenAI) tools and other similar chatbots have emerged, facilitating user interactions with virtual conversational agents. However, the increasing use of GenAI tools in medical research presents challenges, including ethical concerns, data privacy issues, and the potential for generating false content. These issues necessitate standardization of reporting to ensure transparency and scientific rigor.
Objective
The development of the Generative Artificial Intelligence Tools in Medical Research (GAMER) reporting guidelines aims to establish comprehensive, standardized guidelines for reporting the use of GenAI tools in medical research.
Methods
The GAMER guidelines are being developed following the methodology recommended by the Enhancing the Quality and Transparency of Health Research (EQUATOR) Network, involving a scoping review and expert Delphi consensus. The scoping review searched PubMed, Web of Science, Embase, CINAHL, PsycINFO, and Google Scholar (for the first 200 results) using keywords like “generative AI” and “medical research” to identify reporting elements in GenAI-related studies. The Delphi process involves 30-50 experts with ≥3 years of experience in AI applications or medical research, selected based on publication records and expertise across disciplines (eg, clinicians and data scientists) and regions (eg, Asia and Europe). A 7-point-scale survey will establish consensus on checklist items. The testing phase invites authors to apply the GAMER checklist to GenAI-related manuscripts and provide feedback via a questionnaire, while experts assess reliability (κ statistic) and usability (time taken, 7-point Likert scale). The study has been approved by the Ethics Committee of the Institute of Health Data Science at Lanzhou University (HDS-202406-01).
Results
The GAMER project was launched in July 2023 by the Evidence-Based Medicine Center of Lanzhou University and the WHO Collaborating Centre for Guideline Implementation and Knowledge Translation, and it concluded in July 2024. The scoping review was completed in November 2023. The Delphi process was conducted from October 2023 to April 2024. The testing phase began in March 2025 and is ongoing. The expected outcome of the GAMER project is a reporting checklist accompanied by relevant terminology, examples, and explanations to guide stakeholders in better reporting the use of GenAI tools.
Conclusions
GAMER aims to guide researchers, reviewers, and editors in the transparent and scientific application of GenAI tools in medical research. By providing a standardized reporting checklist, GAMER seeks to enhance the clarity, completeness, and integrity of research involving GenAI tools, thereby promoting collaboration, comparability, and cumulative knowledge generation in AI-driven health care technologies.
International Registered Report Identifier (IRRID)
DERR1-10.2196/64640}
}
@article{VALLEE2026101714,
title = {Generative artificial intelligence in otorhinolaryngology: From innovation to public health transformation},
journal = {Brazilian Journal of Otorhinolaryngology},
volume = {92},
number = {1},
pages = {101714},
year = {2026},
issn = {1808-8694},
doi = {https://doi.org/10.1016/j.bjorl.2025.101714},
url = {https://www.sciencedirect.com/science/article/pii/S1808869425001582},
author = {Alexandre Vallée}
}
@article{HASAN2025874,
title = {Ethical Application of Generative Artificial Intelligence in Medicine},
journal = {Arthroscopy: The Journal of Arthroscopic & Related Surgery},
volume = {41},
number = {4},
pages = {874-885},
year = {2025},
issn = {0749-8063},
doi = {https://doi.org/10.1016/j.arthro.2024.12.011},
url = {https://www.sciencedirect.com/science/article/pii/S074980632401048X},
author = {Sayyida S. Hasan and Matthew S. Fury and Joshua J. Woo and Kyle N. Kunze and Prem N. Ramkumar},
abstract = {Generative artificial intelligence (AI) may revolutionize health care, providing solutions that range from enhancing diagnostic accuracy to personalizing treatment plans. However, its rapid and largely unregulated integration into medicine raises ethical concerns related to data integrity, patient safety, and appropriate oversight. One of the primary ethical challenges lies in generative AI’s potential to produce misleading or fabricated information, posing risks of misdiagnosis or inappropriate treatment recommendations, which underscore the necessity for robust physician oversight. Transparency also remains a critical concern, as the closed-source nature of many large-language models prevents both patients and health care providers from understanding the reasoning behind AI-generated outputs, potentially eroding trust. The lack of regulatory approval for AI as a medical device, combined with concerns around the security of patient-derived data and AI-generated synthetic data, further complicates its safe integration into clinical workflows. Furthermore, synthetic datasets generated by AI, although valuable for augmenting research in areas with scarce data, complicate questions of data ownership, patient consent, and scientific validity. In addition, generative AI’s ability to streamline administrative tasks risks depersonalizing care, further distancing providers from patients. These challenges compound the deeper issues plaguing the health care system, including the emphasis of volume and speed over value and expertise. The use of generative AI in medicine brings about mass scaling of synthetic information, thereby necessitating careful adoption to protect patient care and medical advancement. Given these considerations, generative AI applications warrant regulatory and critical scrutiny. Key starting points include establishing strict standards for data security and transparency, implementing oversight akin to institutional review boards to govern data usage, and developing interdisciplinary guidelines that involve developers, clinicians, and ethicists. By addressing these concerns, we can better align generative AI adoption with the core foundations of humanistic health care, preserving patient safety, autonomy, and trust while harnessing AI’s transformative potential.
Level of Evidence
Level V, expert opinion.}
}
@article{KUMAR2025115160,
title = {Generative artificial intelligence (GenAI) revolution: A deep dive into GenAI adoption},
journal = {Journal of Business Research},
volume = {189},
pages = {115160},
year = {2025},
issn = {0148-2963},
doi = {https://doi.org/10.1016/j.jbusres.2024.115160},
url = {https://www.sciencedirect.com/science/article/pii/S0148296324006647},
author = {Aman Kumar and Amit Shankar and Linda D. Hollebeek and Abhishek Behl and Weng Marc Lim},
keywords = {Artificial intelligence, Generative artificial intelligence, Generative AI, GenAI, Adoption, Behavioral reasoning theory, Mixed methods},
abstract = {This study examines key reasons (for and against) that influence business-to-business (B2B) managers’ intention to adopt generative artificial intelligence (GenAI). We also investigate how GenAI adoption influences firm performance, along with the moderating effect of ethical leadership. Study 1 undertakes a series of in-depth interviews, yielding a set of hypotheses that are tested in Study 2. A total of 277 responses was collected from respondents in the USA, the UK, Canada, India, Australia, Malaysia, and Japan to test the proposed model using structural equation modeling. The findings highlight that need for uniqueness, information completeness, convenience, and deceptiveness significantly impact GenAI adoption. The results also highlight that GenAI adoption boosts firm performance. Finally, ethical leadership was found to moderate the effect of GenAI adoption on firm performance. This study enriches the GenAI, technology adoption, and behavioral reasoning theory literatures while also providing pertinent insights for firms intending to adopt GenAI.}
}
@article{SCHULZEBALHORN2025109121,
title = {Graph-to-SFILES: Control structure prediction from process topologies using generative artificial intelligence},
journal = {Computers & Chemical Engineering},
volume = {199},
pages = {109121},
year = {2025},
issn = {0098-1354},
doi = {https://doi.org/10.1016/j.compchemeng.2025.109121},
url = {https://www.sciencedirect.com/science/article/pii/S0098135425001255},
author = {Lukas {Schulze Balhorn} and Kevin Degens and Artur M. Schweidtmann},
keywords = {Control structure prediction, Graph-to-sequence, Process graph, SFILES 2.0, Generative artificial intelligence},
abstract = {Control structure design is an important but tedious step in P&ID development. Generative artificial intelligence (AI) promises to reduce P&ID development time by supporting engineers. Previous research on generative AI in chemical process design mainly represented processes by sequences. However, graphs offer a promising alternative because of their permutation invariance. We propose the Graph-to-SFILES model, a generative AI method to predict control structures from flowsheet topologies. The Graph-to-SFILES model takes the flowsheet topology as a graph input and returns a control-extended flowsheet as a sequence in the SFILES 2.0 notation. We compare four different graph encoder architectures, one of them being a graph neural network (GNN) proposed in this work. The Graph-to-SFILES model achieves a top-5 accuracy of 73.2% when trained on 10,000 flowsheet topologies. In addition, the proposed GNN performs best among the encoder architectures. Compared to a purely sequence-based approach, the Graph-to-SFILES model improves the top-5 accuracy for a relatively small training dataset of 1,000 flowsheets from 0.9% to 28.4%. However, the sequence-based approach performs better on a large-scale dataset of 100,000 flowsheets. These results highlight the potential of graph-based AI models to accelerate P&ID development in small-data regimes but their effectiveness on industry relevant case studies still needs to be investigated.}
}
@article{YIN2025100227,
title = {A systematic examination of generative artificial intelligence (GenAI) use guidelines in applied linguistics journals},
journal = {Research Methods in Applied Linguistics},
volume = {4},
number = {3},
pages = {100227},
year = {2025},
issn = {2772-7661},
doi = {https://doi.org/10.1016/j.rmal.2025.100227},
url = {https://www.sciencedirect.com/science/article/pii/S2772766125000485},
author = {Shuhui Yin and Carol A. Chapelle},
keywords = {GenAI literacy for research, GenAI use guidelines, Applied linguistics journals, Scholarly publishing},
abstract = {The unannounced appearance of GenAI in 2022 and the speed of its adoption by researchers have left many questions unanswered about its accepted ethical use, with no apparent consensus among applied linguists. In this context, it’s essential for researchers to develop their GenAI literacy for research to engage with GenAI effectively and responsibly. This study contributes to identifying key components of this literacy through examining accepted GenAI uses in research practices. Based on a systematically sampled collection of 170 high-impact journals in applied linguistics, we investigated the scope and nature of GenAI use guidelines provided by 76 journals intended to guide authors. A checklist including four items regarding general statements and 17 items regarding three categories of specific aspects that GenAI guidelines target (authorship, uses, and human responsibility) was identified. Our findings reveal that (1) less than half of the journals provided GenAI use guidelines to guide authors, (2) the number of specific aspects varied across journals, with most falling short of comprehensive coverage, and (3) disagreements were observed about whether AI can be cited and used for manuscript drafting, idea generating, image generating, data generation, data collection, and data analysis and interpretation. Additionally, journals varied in their guidance on how to disclose GenAI uses. We propose recommendations for journals in improving their AI guidelines. Importantly, we introduce and conceptualize the new construct GenAI literacy for research article writing (GenAI-LR) that is important for authors to develop. We provide actionable recommendations accordingly based on our findings.}
}
@article{ALFONZETTI2025e492,
title = {Transforming the Landscape of Clinical Information Retrieval Using Generative Artificial Intelligence: An Application in Machine Fault Analysis},
journal = {Practical Radiation Oncology},
volume = {15},
number = {5},
pages = {e492-e499},
year = {2025},
issn = {1879-8500},
doi = {https://doi.org/10.1016/j.prro.2025.02.006},
url = {https://www.sciencedirect.com/science/article/pii/S187985002500058X},
author = {Tyler Alfonzetti and Junyi Xia},
abstract = {In a radiation oncology clinic, machine downtime can be a serious burden to the entire department. This study investigates using increasingly popular generative artificial intelligence (AI) techniques to assist medical physicists in troubleshooting linear accelerator issues. Google's NotebookLM, supplemented with background information on linear accelerator issues/solutions, was used as a machine troubleshooting assistant for this purpose. Two board-certified medical physicists evaluated the large language model's responses based on hallucination, relevancy, correctness, and completeness. Results indicated that responses improved with increasing source data context and more specific prompt construction. Keeping risk mitigation and the inherent limitations of AI in mind, this work offers a viable, low-risk method to improve efficiency in radiation oncology. This work uses a “Machine Troubleshooting Assistance” application to provide an adaptable example of how radiation oncology clinics can begin using generative AI to enhance clinical efficiency.}
}
@article{MESSNER2025101622,
title = {Quantification of cultural practices and diversity: An empirical experiment with generative artificial intelligence},
journal = {Journal of World Business},
volume = {60},
number = {3},
pages = {101622},
year = {2025},
issn = {1090-9516},
doi = {https://doi.org/10.1016/j.jwb.2025.101622},
url = {https://www.sciencedirect.com/science/article/pii/S1090951625000112},
author = {Wolfgang Messner},
keywords = {Artificial intelligence, Cultural dimensions, Cultural diversity, Culture, Evolution, Generative artificial intelligence (genAI), GLOBE, Hofstede, Large language model (LLM)},
abstract = {Culture is often viewed as a value system that shapes cultural practices. Frameworks like Hofstede, GLOBE, and Schwartz identify and quantify various cultural dimensions; however, these rely on surveys that are criticized for limited country coverage, lack of psychometric robustness, small sample sizes, and cultural biases. This article presents an empirical experiment designed to quantify cultural practices and diversity across 216 countries and territories by prompting large language models using a zero-shot learning strategy. This approach enables subnational and segment-specific analyses, equipping researchers with powerful tools for deeper cultural insights.}
}
@article{METZGER2025103313,
title = {Generative artificial intelligence augmenting SME financial management},
journal = {Technovation},
volume = {147},
pages = {103313},
year = {2025},
issn = {0166-4972},
doi = {https://doi.org/10.1016/j.technovation.2025.103313},
url = {https://www.sciencedirect.com/science/article/pii/S0166497225001452},
author = {Michael Metzger and Seán O'Reilly and Ciarán {Mac an Bhaird}},
keywords = {Financial management, SMEs, Artificial intelligence, Digital technologies, Predictive modelling, Going concern},
abstract = {This study investigates the potential for entrepreneurs to leverage advances in technological innovation, specifically generative Artificial Intelligence (AI), to build management capability to mitigate business and financial risks. Drawing on theories of Technology Affordances and Constraints and the Resource-Based View (RBV) of the firm, recognising that small and medium-sized enterprises (SMEs) are inherently resource-constrained. We examine how AI-generated financial diagnostics can empower SMEs by generating accessible, real-time analysis and insights, thus bolstering the management function and increasing chances of survival and growth. Using a dataset of 1,150 UK SMEs spanning eight years of financial statements, we test a large language model (LLM) prediction assessment and analyse the potential for SMEs to utilise the technology, notwithstanding enterprise-specific constraints. We conclude that AI may be a very effective tool for smaller enterprises to augment the financial management function, although its efficacy hinges on organisational readiness, competence in interpreting data, and the will to act on automated red-flag alerts. These findings offer practical guidance for SMEs seeking to enhance their financial management processes in today's digital era.}
}
@article{HUANG2025445,
title = {Ophthalmology Journals’ Guidelines on Generative Artificial Intelligence: A Comprehensive Analysis},
journal = {American Journal of Ophthalmology},
volume = {271},
pages = {445-454},
year = {2025},
issn = {0002-9394},
doi = {https://doi.org/10.1016/j.ajo.2024.12.021},
url = {https://www.sciencedirect.com/science/article/pii/S0002939424005889},
author = {Wenqiao Huang and Yating Liang and Xianghui Wei and Yi Du},
abstract = {Purpose
The integration of generative artificial intelligence (GAI) into scientific research and academic writing has generated considerable controversy. Currently, standards for using GAI in academic medicine remain undefined. This study aims to conduct a comprehensive analysis of the guidance provided for authors regarding the use of GAI in ophthalmology scientific journals.
Design
Cross-sectional bibliometric analysis.
Participants
A total of 140 ophthalmology journals listed in the Scimago Journal and Country Rankings, regardless of language or origin.
Methods
We systematically searched and screened the 140 ophthalmology journals’ websites on October 19 and 20, 2024, and conducted updates on November 19 and 20, 2024.
Main Outcome Measures
The content of GAI guidelines from the websites of the 140 ophthalmology journals.
Results
Of 140 journals reviewed, 96 (69%) provide explicit guidelines for authors regarding the use of GAI. Among these, nearly all journals agree on 3 key points: (1) 94 journals (98%) have established specific guidelines prohibiting GAI from being listed as an author; (2) 94 journals (98%) emphasize that human authors are responsible for the outputs generated by GAI tools; and (3) all 96 journals require authors to disclose any use of GAI. In addition, 20 journals (21%) specify that their guidelines pertain solely to the writing process with GAI. Furthermore, 92 journals (66%) have developed guidelines concerning GAI-generated images, with 63 journals (68%) permitting their use and 29 (32%) prohibiting them. Among those that prohibit GAI images, 27 journals (93%) allow their use under specific conditions.
Conclusion
Although there is considerable ethical consensus among ophthalmology journals regarding the use of GAI, notable variations exist in terms of permissible use and disclosure practices. Establishing standardized guidelines is essential to safeguard the originality and integrity of scientific research. Researchers must uphold high standards of academic ethics and integrity when using GAI.}
}
@article{SEXTON2024606,
title = {Assessments of Generative Artificial Intelligence as Clinical Decision Support Ought to be Incorporated Into Randomized Controlled Trials of Electronic Alerts for Acute Kidney Injury},
journal = {Mayo Clinic Proceedings: Digital Health},
volume = {2},
number = {4},
pages = {606-610},
year = {2024},
issn = {2949-7612},
doi = {https://doi.org/10.1016/j.mcpdig.2024.09.004},
url = {https://www.sciencedirect.com/science/article/pii/S2949761224001019},
author = {Donal J. Sexton and Conor Judge}
}
@article{TAIWO2025672,
title = {Generative artificial intelligence in construction: A Delphi approach, framework, and case study},
journal = {Alexandria Engineering Journal},
volume = {116},
pages = {672-698},
year = {2025},
issn = {1110-0168},
doi = {https://doi.org/10.1016/j.aej.2024.12.079},
url = {https://www.sciencedirect.com/science/article/pii/S1110016824016776},
author = {Ridwan Taiwo and Idris Temitope Bello and Sulemana Fatoama Abdulai and Abdul-Mugis Yussif and Babatunde Abiodun Salami and Abdullahi Saka and Mohamed El Amine {Ben Seghier} and Tarek Zayed},
keywords = {Generative artificial intelligence, Generative pre-trained transformer, Large language model, Multimodal AI, Retrieval augmented generation, Construction industry, GenAI, RAG, LLM, GPT, ChatGPT},
abstract = {The construction industry plays a crucial role in the global economy, contributing approximately $10 trillion and employing over 220 million workers worldwide, but encounters numerous productivity challenges with only 1 % annual growth compared to 2.8 % for the global economy. These challenges span various processes, including design, planning, procurement, inspection, and maintenance. Generative artificial intelligence (GenAI), capable of producing new and realistic data or content such as text, images, videos, or code from given inputs or existing knowledge, presents innovative solutions to these challenges. While there is an increasing interest in the applications of GenAI in construction, a detailed analysis of its practical uses, advantages, and areas ripe for development is still evolving. This study contributes to this emerging area by offering an insightful analysis of the current state of generative AI in construction. It has three objectives: (1) to identify and categorize the existing and emerging generative AI opportunities and challenges in the construction industry via a Delphi study; (2) to propose a framework enabling construction firms to build customized GenAI solutions; and (3) to illustrate this framework through a case study that employs GenAI model for querying contract documents. Through systematic review and expert consultation, the study identified 76 potential GenAI applications across construction phases and 18 key challenges distributed across domain-specific, technological, adoption, and ethical categories. The case study's findings show that retrieval augmented generation (RAG) improves the baseline large language model (LLM), GPT-4, by 5.2, 9.4, and 4.8 % in terms of quality, relevance, and reproducibility. The study recommends a structured approach to GenAI implementation, emphasizing the need for domain-specific customization, robust validation protocols, and careful consideration of ethical implications. This study equips academics and construction professionals with a comprehensive analysis and practical framework, facilitating the integration of GenAI techniques to enhance productivity, quality, safety, and sustainability across the construction industry.}
}
@article{LI2025,
title = {Comparative Analysis of Generative Artificial Intelligence Systems in Solving Clinical Pharmacy Problems: Mixed Methods Study},
journal = {JMIR Medical Informatics},
volume = {13},
year = {2025},
issn = {2291-9694},
doi = {https://doi.org/10.2196/76128},
url = {https://www.sciencedirect.com/science/article/pii/S2291969425001401},
author = {Lulu Li and Pengqiang Du and Xiaojing Huang and Hongwei Zhao and Ming Ni and Meng Yan and Aifeng Wang},
keywords = {artificial intelligence, DeepSeek-R1, clinical pharmacy, comparative analysis, generative AI},
abstract = {Background
Generative artificial intelligence (AI) systems are increasingly deployed in clinical pharmacy; yet, systematic evaluation of their efficacy, limitations, and risks across diverse practice scenarios remains limited.
Objective
This study aims to quantitatively evaluate and compare the performance of 8 mainstream generative AI systems across 4 core clinical pharmacy scenarios—medication consultation, medication education, prescription review, and case analysis with pharmaceutical care—using a multidimensional framework.
Methods
Forty-eight clinically validated questions were selected via stratified sampling from real-world sources (eg, hospital consultations, clinical case banks, and national pharmacist training databases). Three researchers simultaneously tested 8 different generative AI systems (ERNIE Bot, Doubao, Kimi, Qwen, GPT-4o, Gemini-1.5-Pro, Claude-3.5-Sonnet, and DeepSeek-R1) using standardized prompts within a single day (February 20, 2025). A double-blind scoring design was used, with 6 experienced clinical pharmacists (≥5 years experience) evaluating the AI responses across 6 dimensions: accuracy, rigor, applicability, logical coherence, conciseness, and universality, scored 0‐10 per predefined criteria (eg, −3 for inaccuracy and −2 for incomplete rigor). Statistical analysis used one-way ANOVA with Tukey Honestly Significant Difference (HSD) post hoc testing and intraclass correlation coefficients (ICC) for interrater reliability (2-way random model). Qualitative thematic analysis identified recurrent errors and limitations.
Results
DeepSeek-R1 (DeepSeek) achieved the highest overall performance (mean composite score: medication consultation 9.4, SD 1.0; case analysis 9.3, SD 1.0), significantly outperforming others in complex tasks (P<.05). Critical limitations were observed across models, including high-risk decision errors—75% omitted critical contraindications (eg, ethambutol in optic neuritis) and a lack of localization—90% erroneously recommended macrolides for drug-resistant Mycoplasma pneumoniae (China’s high-resistance setting), while only DeepSeek-R1 aligned with updated American Academy of Pediatrics (AAP) guidelines for pediatric doxycycline. Complex reasoning deficits: only Claude-3.5-Sonnet detected a gender-diagnosis contradiction (prostatic hyperplasia in female); no model identified diazepam’s 7-day prescription limit. Interrater consistency was lowest for conciseness in case analysis (ICC=0.70), reflecting evaluator disagreement on complex outputs. ERNIE Bot (Baidu) consistently underperformed (case analysis: 6.8, SD 1.5; P<.001 vs DeepSeek-R1).
Conclusions
While generative AI shows promise as a pharmacist assistance tool, significant limitations—including high-risk errors (eg, contraindication omissions), inadequate localization, and complex reasoning gaps—preclude autonomous clinical decision-making. Performance stratification highlights DeepSeek-R1’s current advantage, but all systems require optimization in dynamic knowledge updating, complex scenario reasoning, and output interpretability. Future deployment must prioritize human oversight (human-AI co-review), ethical safeguards, and continuous evaluation frameworks.}
}
@article{PAN2025110175,
title = {Enhanced feedback analysis of vertical load reliability parameters for airplane landing gear using an improved generative adversarial network and explainable artificial intelligence techniques},
journal = {Engineering Applications of Artificial Intelligence},
volume = {145},
pages = {110175},
year = {2025},
issn = {0952-1976},
doi = {https://doi.org/10.1016/j.engappai.2025.110175},
url = {https://www.sciencedirect.com/science/article/pii/S0952197625001757},
author = {Weihuang Pan and Yunwen Feng and Cheng Lu and Jiaqi Liu and Jingcui Liang},
keywords = {Landing gear vertical load, Operation reliability, Improved generative adversarial Network, Explainable artificial intelligence, Feedback analysis, Shapley Additive explanations, Data generation},
abstract = {Effective feedback analysis of critical equipment data is essential for improving performance and optimizing design parameters in aviation systems. This study presents a novel framework that integrates an improved generative adversarial network (GAN) with explainable artificial intelligence techniques (XAI) to evaluate the reliability of the vertical load for airplane landing gear. By utilizing limited data from the Quick Access Recorder (QAR), the improved GAN generates extensive synthetic data to expand the dataset and strengthen the analysis. Each parameter's importance and influence on vertical load reliability are then evaluated through the Shapley Additive Explanations (SHAP) method, a key approach in XAI. Validation using landing gear data from a typical civil airplane demonstrates the effectiveness of this method and confirms the viability of explainable artificial intelligence for parametric feedback analysis. The results highlight the impact of each parameter on vertical load reliability, providing valuable insights to support enhanced design and operational efficiency of landing gear.}
}
@article{TAIWO2025100316,
title = {Making waves: Generative artificial intelligence in water distribution networks: Opportunities and challenges},
journal = {Water Research X},
volume = {28},
pages = {100316},
year = {2025},
issn = {2589-9147},
doi = {https://doi.org/10.1016/j.wroa.2025.100316},
url = {https://www.sciencedirect.com/science/article/pii/S2589914725000155},
author = {Ridwan Taiwo and Abdul-Mugis Yussif and Tarek Zayed},
keywords = {Digital water systems, Generative artificial intelligence, Smart water distribution networks, Retrieval-augmented generation, ChatGPT, Reclaimed WDNs, RAG, Multimodal AI},
abstract = {Water distribution networks (WDNs) face increasing challenges from aging infrastructure, population growth, and climate change, necessitating innovative technological solutions. This study examines the integration of Generative Artificial Intelligence (GenAI) in WDNs, including both conventional and reclaimed water systems. Through a comprehensive analysis of current literature and emerging applications, the study identifies key opportunities in near-future applications focusing on enhancing information retrieval through advanced document processing, improving water quality management via real-time monitoring and visualization, implementing predictive maintenance strategies through pattern recognition, and optimizing real-time operational control through adaptive algorithms. Results also demonstrate that GenAI can transform WDN operations through advanced visualization, scenario generation, and adaptive optimization capabilities, particularly in far-future applications such as demand forecasting, emergency response, and network design optimization. The analysis reveals significant challenges, including data quality and availability issues, particularly in non-English speaking regions, scalability constraints in large-scale networks, the critical need for water professionals with hybrid expertise in both traditional engineering and AI systems, and complex regulatory requirements that vary significantly across the globe. The study also explores unique applications in reclaimed WDNs, particularly in quality control, treatment optimization, and stakeholder engagement. These findings provide water utilities, policymakers, and researchers with valuable insights for implementing GenAI technologies while balancing technological advancement with human expertise and social responsibility.}
}
@article{KHOSO2025100627,
title = {Empowering creativity and engagement: The impact of generative artificial intelligence usage on Chines EFL students' language learning experience},
journal = {Computers in Human Behavior Reports},
volume = {18},
pages = {100627},
year = {2025},
issn = {2451-9588},
doi = {https://doi.org/10.1016/j.chbr.2025.100627},
url = {https://www.sciencedirect.com/science/article/pii/S2451958825000429},
author = {Abdul Khalique Khoso and Wang Honggang and Mansoor Ali Darazi},
keywords = {Generative artificial intelligence, Use of ChatGPT, Language learning engagement, EFL student' creativity, EFL students' self-efficacy and tertiary education},
abstract = {Present study examines the impact of Generative Artificial Intelligence (GAI) like Use of ChatGPT on Language Learning Engagement and EFL Students Creativity among Chinese EFL students at the tertiary level in China. Present study aims to investigates the direct effects of Use of ChatGPT on Language Learning Engagement, impact of engagement on EFL students' creativity and the mediating role of engagement between Use of ChatGPT and EFL student ‘creativity thereby, the moderating effect of creative self-efficacy on Language learning engagement and EFL students’ creativity is also investigated. Present study uses quantitative empirical research design and the data were collected from n = 370 EFL students at Yangzhou University of China through a structured survey. Moreover, the analysis for present study was conducted using SPSS and PLS-SEM. The Findings reveal that ChatGPT use positively influences language engagement, enhancing creativity. Language Learning Engagement mediates the relationship between Use of ChatGPT and EFL student’s creativity, while creative self-efficacy significantly moderates the engagement and creativity. These results align with existing research, underscoring the importance of engagement in driving creativity and highlighting the role of self-efficacy in amplifying this effect. The study’s implications suggest that integrating Use of ChatGPT into EFL education can foster both engagement and creative outcomes, providing valuable insights for educators and policy-makers aiming to enhance language learning experiences. Future research could explore additional factors influencing the AI-engagement-creativity dynamic.}
}
@article{YOUNG2025200,
title = {A Hands-Free Approach With Voice to Text and Generative Artificial Intelligence: Streamlining Radiology Reporting},
journal = {Journal of the American College of Radiology},
volume = {22},
number = {2},
pages = {200-203},
year = {2025},
issn = {1546-1440},
doi = {https://doi.org/10.1016/j.jacr.2024.10.004},
url = {https://www.sciencedirect.com/science/article/pii/S154614402400838X},
author = {Austin Young and Katherine E. Wang and Michael X. Jin and Kian Avilla and Kevin Gilotra and Pamela Nguyen and Pablo R. Ros}
}
@article{DORTAGONZALEZ2024102187,
title = {Generative artificial intelligence usage by researchers at work: Effects of gender, career stage, type of workplace, and perceived barriers},
journal = {Telematics and Informatics},
volume = {94},
pages = {102187},
year = {2024},
issn = {0736-5853},
doi = {https://doi.org/10.1016/j.tele.2024.102187},
url = {https://www.sciencedirect.com/science/article/pii/S0736585324000911},
author = {Pablo Dorta-González and Alexis Jorge López-Puig and María Isabel Dorta-González and Sara M. González-Betancor},
keywords = {Artificial intelligence, Use of AI by researchers in the workplace, Challenges in implementing AI, Gender imbalance},
abstract = {The integration of generative artificial intelligence technology into research environments has become increasingly common in recent years, representing a significant shift in the way researchers approach their work. This paper seeks to explore the factors underlying the frequency of use of generative AI amongst researchers in their professional environments. As survey data may be influenced by a bias towards scientists interested in AI, potentially skewing the results towards the perspectives of these researchers, this study uses a regression model to isolate the impact of specific factors such as gender, career stage, type of workplace, and perceived barriers to using AI technology on the frequency of use of generative AI. It also controls for other relevant variables such as direct involvement in AI research or development, collaboration with AI companies, geographic location, and scientific discipline. Our results show that researchers who face barriers to AI adoption experience an 11 % increase in tool use, while those who cite insufficient training resources experience an 8 % decrease. Female researchers experience a 7 % decrease in AI tool usage compared to men, while advanced career researchers experience a significant 19 % decrease. Researchers associated with government advisory groups are 45 % more likely to use AI tools frequently than those in government roles. Researchers in for-profit companies show an increase of 19 %, while those in medical research institutions and hospitals show an increase of 16 % and 15 %, respectively. This paper contributes to a deeper understanding of the mechanisms driving the use of generative AI tools amongst researchers, with valuable implications for both academia and industry.}
}
@article{ZHANG2025100040,
title = {Generative artificial intelligence (AI) in built environment design and planning – A state-of-the-art review},
journal = {Progress in Engineering Science},
volume = {2},
number = {1},
pages = {100040},
year = {2025},
issn = {2950-4252},
doi = {https://doi.org/10.1016/j.pes.2024.100040},
url = {https://www.sciencedirect.com/science/article/pii/S2950425224000409},
author = {Haolan Zhang and Ruichuan Zhang},
keywords = {Generative artificial intelligence (AI), Built environment design, Deep learning, Data-driven design, Benchmarking},
abstract = {Despite numerous studies on adopting, implementing, and developing generative design approaches within the architectural, engineering, and construction (AEC) sectors, there remains a limited understanding of the capabilities and constraints of generative artificial intelligence (AI) in specific applications for built environment design and planning. This review paper aims to bridge this gap by providing a systematic review guided by a framework encompassing three main related application areas in building development – site layout, interior, and exterior design, and three main categories of generative AI algorithms – rule-based AI and expert systems, optimization and metaheuristics, and machine learning algorithms, with a focus on state-of-the-art deep learning algorithms. We collected, reviewed, and analyzed 179 state-of-the-art studies in the past decade, consolidating siloed knowledge of user-centric design constraints and objectives, hybrid generative AI methods, data sources for development and testing, as well as benchmarking methods and metrics for assessing design performance, thereby providing a comprehensive understanding of the efficacy of generative AI technologies across diverse design contexts.}
}
@article{ZHOU2025103953,
title = {Government adoption of generative artificial intelligence and ambidextrous innovation},
journal = {International Review of Economics & Finance},
volume = {98},
pages = {103953},
year = {2025},
issn = {1059-0560},
doi = {https://doi.org/10.1016/j.iref.2025.103953},
url = {https://www.sciencedirect.com/science/article/pii/S1059056025001169},
author = {Zhikai Zhou and Dewen Liu and Zhongjie Chen and Martin Pancho},
keywords = {Generative artificial intelligence, TOE framework, Technology adoption, Organizational ambidextrous innovation},
abstract = {Every information technological revolution has brought about new possibilities for governmental organizational innovation, and the rapid development of Generative artificial intelligence (Gen-AI) is poised to profoundly impact government governance models and public service supply methods. Understanding the factors influencing government adoption of Gen-AI, and analyzing the impact of such adoption on governmental organizational innovation behavior, have emerged as urgent and cutting-edge topics. Based on the Technology-Organization-Environment (TOE) framework and the ambidextrous organization theory, this study systematically analyzes the three-layered driving factors that influence government organizations' adoption of Gen-AI, and examines the impact of Gen-AI on exploratory and exploitative innovation within government organizations. Furthermore, it delves into the influence mechanisms of technology adoption on different innovation behaviors from the meso-institutional and micro-implementation perspectives. At the theoretical level, this study constructs a conceptual framework for understanding the adoption of Gen-AI technology, extends the application scope of the TOE theory and enhances its explanatory power, while also providing new insights into the complexity of technology-enabled organizational innovation. At the practical level, it offers a more strategic perspective and profound implications for government organizations to maintain innovative vitality and achieve sustainable development amidst the wave of intelligent transformation.}
}
@article{DING2025100866,
title = {Tracking the carbon footprint of global generative artificial intelligence},
journal = {The Innovation},
volume = {6},
number = {5},
pages = {100866},
year = {2025},
issn = {2666-6758},
doi = {https://doi.org/10.1016/j.xinn.2025.100866},
url = {https://www.sciencedirect.com/science/article/pii/S2666675825000694},
author = {Zhaohao Ding and Jianxiao Wang and Yiyang Song and Xiaokang Zheng and Guannan He and Xiupeng Chen and Tiance Zhang and Wei-Jen Lee and Jie Song}
}
@article{TRIPATHI2025,
title = {Toward Pediatric Patient–Friendly Education Material Using Generative Artificial Intelligence},
journal = {Journal of the American College of Radiology},
year = {2025},
issn = {1546-1440},
doi = {https://doi.org/10.1016/j.jacr.2025.07.009},
url = {https://www.sciencedirect.com/science/article/pii/S1546144025004041},
author = {Satvik Tripathi and Dana Alkhulaifat and Hansel J. Otero and Tessa S. Cook}
}
@article{ROBINSON2025212,
title = {Generative Artificial Intelligence in Academic Surgery: Ethical Implications and Transformative Potential},
journal = {Journal of Surgical Research},
volume = {307},
pages = {212-220},
year = {2025},
issn = {0022-4804},
doi = {https://doi.org/10.1016/j.jss.2024.12.059},
url = {https://www.sciencedirect.com/science/article/pii/S0022480425000216},
author = {Jamie R. Robinson and Anne Stey and David F. Schneider and Anai N. Kothari and Brenessa Lindeman and Haytham M. Kaafarani and Krista L. Haines},
keywords = {AI, Artificial intelligence, ChatGPT, Generative AI, Large language models},
abstract = {Artificial intelligence (AI) is rapidly being used in medicine due to its advanced capabilities in image and video recognition, clinical decision support, surgical education, and administrative task automation. Large language models such as OpenAI’s Generative Pretrained Transformer (GPT)-4 and Google’s Bard have particularly revolutionized text generation, offering substantial benefits for the academic surgeon, including aiding in manuscript and grant writing. However, integrating AI into academic surgery necessitates addressing ethical concerns such as bias, transparency, and intellectual property. This paper provides guidelines and recommendations based on current literature around the opportunities and ethical challenges of AI in academic surgery. We discuss the underlying mechanisms of large language models, their potential biases, and the importance of responsible usage. Furthermore, we explore the ethical implications of AI in clinical documentation, highlighting improved efficiency and necessary privacy concerns. This review also addresses the critical issue of intellectual property dilemmas posed by AI-generated innovations in university settings. Finally, we propose guidelines for the responsible adoption of AI in academic and clinical environments, stressing the need for transparency, ethical training, and robust governance frameworks to ensure AI enhances, rather than undermines, academic integrity and patient care.}
}
@article{WANG2024102744,
title = {Green entrepreneurship success in the age of generative artificial intelligence: The interplay of technology adoption, knowledge management, and government support},
journal = {Technology in Society},
volume = {79},
pages = {102744},
year = {2024},
issn = {0160-791X},
doi = {https://doi.org/10.1016/j.techsoc.2024.102744},
url = {https://www.sciencedirect.com/science/article/pii/S0160791X24002926},
author = {Shaofeng Wang and Hao Zhang},
keywords = {Generative artificial intelligence, Green entrepreneurship, Knowledge management, Green innovation, Government support, Resource orchestration theory},
abstract = {This study investigates the integral role of generative artificial intelligence (GAI) in enhancing green entrepreneurship success, focusing on the interconnected dynamics of GAI adoption, green knowledge management, innovation, and government support. Despite the growing interest in GAI, existing research lacks an understanding of how GAI fosters green entrepreneurship success, particularly in green knowledge management and innovation pathways. Utilizing a robust theoretical framework grounded in resource orchestration and knowledge management theories, we examine the influence of GAI on acquiring and applying green knowledge and its subsequent impact on fostering green innovation. The study examines how government funding moderates these correlations. Employing PLS-SEM and fsQCA, the research elucidates complex interrelationships and causal paths. The findings reveal that GAI significantly enhances green knowledge management capabilities, which drives green innovation and entrepreneurship success. Additionally, government support plays a crucial role in amplifying these effects. This study contributes to technological change and social transformation discourse, offering practical insights for decision-makers and stakeholders in green entrepreneurship and policy-making.}
}
@article{YANG2025,
title = {Reinforcement learning-based generative artificial intelligence for novel pesticide design},
journal = {Journal of Advanced Research},
year = {2025},
issn = {2090-1232},
doi = {https://doi.org/10.1016/j.jare.2025.02.030},
url = {https://www.sciencedirect.com/science/article/pii/S2090123225001286},
author = {Ruoqi Yang and Biao Li and Jin Dong and Zhuomei Cai and Hongyan Lin and Fan Wang and Guangfu Yang},
keywords = {Generative model, Reinforcement learning, Pesticide design, 4-hydroxyphenylpyruvate dioxygenase},
abstract = {Introduction
Pesticides play a pivotal role in ensuring food security, and the development of green pesticides is an inevitable trend in global agricultural progress. Although deep learning-based generative models have revolutionized de novo drug design in pharmaceutical research, their application in pesticide research and development remains unexplored.
Objectives
This study aims to pioneer the application of generative artificial intelligence to pesticide design by proposing a reinforcement learning-based framework for obtaining pesticide-like molecules with high binding affinity.
Methods
This framework comprises two key components: PestiGen-G, which systematically explores the pesticide-like chemical space using a character-based generative model coupled with the REINFORCE algorithm; and PestiGen-S, which combines a fragment-based generative model with the Monte Carlo Tree Search algorithm to generate molecules that stably bind to the specific target protein.
Results
Experimental results show that the molecules generated by PestiGen have superior pesticide-likeness and binding affinity compared to those generated by existing methods. In addition, we employ an active learning strategy to reduce the false-positive rate of the generated molecules. Finally, through collaboration with domain experts, we successfully designed a novel 4-hydroxyphenylpyruvate dioxygenase inhibitor (YH23768) with favorable enzyme inhibition and herbicidal potency.
Conclusion
This proof-of-concept study highlights the utility of PestiGen as a valuable tool for pesticide design. The web server based on the model is freely available at https://dpai.ccnu.edu.cn/PestiGen/.}
}
@article{LIU2025114513,
title = {A friend or a foe? The effect of generative artificial intelligence on creator contributions on original work sharing platforms},
journal = {Decision Support Systems},
volume = {197},
pages = {114513},
year = {2025},
issn = {0167-9236},
doi = {https://doi.org/10.1016/j.dss.2025.114513},
url = {https://www.sciencedirect.com/science/article/pii/S0167923625001149},
author = {Shan Liu and Wenxuan Hu and Baojun Gao},
keywords = {Generative artificial intelligence, Copyright infringement, Original work sharing platform, Crowding out, Protective motivation theory},
abstract = {While generative artificial intelligence (GAI) is increasingly used to create content, it is often criticized for collecting and training private data and induces potential copy infringement issue. This dilemma leaves a question of whether GAI increases or decreases creators' work sharing. Drawn on protection motivation theory, this study examines how the launch of a GAI system affects creators' contributions on an original work sharing platform. We discover that GAI poses a threat to drawing-category creators, leading to a significant crowding-out effect on their contributions. Specifically, compared with that of non-drawing-category creators, the work sharing of drawing-category creators decreases by 19.64 % and 14.29 % within a short period after the launch and removal of the GAI system, respectively. We discover that creators' protective behavior is driven by GAI-related copyright infringement. Compared with creators without copyright protection, those with copyright protection are more inclined to cease contributions or even leave the platform. We further find that among copyright-protected creators, top creators, evidenced by their acquisition of a large number of supporters or platform honor titles, exhibit more pronounced responses to protect their works due to their higher coping efficacy. Notably, this threat reduces creators' sharing behavior or even lead to their exit from the platform. Nevertheless, such reduction is likely to gradually recover once the threat subsides. Overall, our findings have important implications for whether and how platform managers adopt GAI systems, especially in an original work sharing context.}
}
@article{RODLER20241496,
title = {Generative artificial intelligence in surgery},
journal = {Surgery},
volume = {175},
number = {6},
pages = {1496-1502},
year = {2024},
issn = {0039-6060},
doi = {https://doi.org/10.1016/j.surg.2024.02.019},
url = {https://www.sciencedirect.com/science/article/pii/S0039606024001193},
author = {Severin Rodler and Conner Ganjavi and Pieter {De Backer} and Vasileios Magoulianitis and Lorenzo Storino Ramacciotti and Andre Luis {De Castro Abreu} and Inderbir S. Gill and Giovanni E. Cacciamani},
abstract = {Generative artificial intelligence is able to collect, extract, digest, and generate information in an understandable way for humans. As the first surgical applications of generative artificial intelligence are applied, this perspective paper aims to provide a comprehensive overview of current applications and future perspectives for the application of generative artificial intelligence in surgery, from preoperative planning to training. Generative artificial intelligence can be used before surgery for planning and decision support by extracting patient information and providing patients with information and simulation regarding the procedure. Intraoperatively, generative artificial intelligence can document data that is normally not captured as intraoperative adverse events or provide information to help decision-making. Postoperatively, GAIs can help with patient discharge and follow-up. The ability to provide real-time feedback and store it for later review is an important capability of GAIs. GAI applications are emerging as highly specialized, task-specific tools for tasks such as data extraction, synthesis, presentation, and communication within the realm of surgery. GAIs have the potential to play a pivotal role in facilitating interaction between surgeons and artificial intelligence.}
}
@article{HERZBERG2025102363,
title = {Assessing the standard-essentiality of 5G technology patents by means of generative artificial intelligence},
journal = {World Patent Information},
volume = {81},
pages = {102363},
year = {2025},
issn = {0172-2190},
doi = {https://doi.org/10.1016/j.wpi.2025.102363},
url = {https://www.sciencedirect.com/science/article/pii/S0172219025000304},
author = {Andre Herzberg},
abstract = {In telecommunication technology, identifying standard-essential patents (SEPs) plays a crucial role in the management of intellectual property. This technology is regulated by technical standards that are largely based on the content of SEPs. These patents are declared standard-essential by their owners because they contain elements of a technical standard. The declaration process leaves room for over- and under-declaration, which entails risks for organizations. This paper focuses on the question of how generative artificial intelligence can be used to assess the standard-essentiality of 5G technology patents. For this purpose, the standard-essentiality is assessed using different prompts with four Large Language Models (LLMs) in two variants. In the first variant, the LLM results are generated by a rather simple prompt and compared with an approach based on unsupervised and supervised machine learning. The result shows that large LLMs are capable of assessing the standard-essentiality. In the second variant, the best-performing LLM is selected and the prompt is expanded to include selected parts of a technical standard. While the assessment results remain largely the same, the LLM is now able to explain in which detail a patent is part of a standard. This has several implications for patent evaluation, licensing and litigation strategies.}
}
@article{KOKABI2025100619,
title = {Ionic Cell Microscopy: A new modality for visualizing cells using microfluidic impedance cytometry and generative artificial intelligence},
journal = {Biosensors and Bioelectronics: X},
volume = {24},
pages = {100619},
year = {2025},
issn = {2590-1370},
doi = {https://doi.org/10.1016/j.biosx.2025.100619},
url = {https://www.sciencedirect.com/science/article/pii/S2590137025000469},
author = {Mahtab Kokabi and Gulam M. Rather and Mehdi Javanmard},
keywords = {Cancer imaging, Impedance cytometry, Microfluidic device, Label-free diagnostics, Generative AI},
abstract = {This study introduces a novel approach to cancer cell imaging by integrating microfluidic sensor technology with artificial intelligence (AI). We developed a custom microfluidic device with polydimethylsiloxane (PDMS) microchannels and integrated electrodes to capture electrical impedance data. The device was fabricated using photolithography, electron beam evaporation, and lift-off techniques. Instead of traditional imaging methods, electrical impedance signals were used to reconstruct cell images. A generative AI model with eight hidden layers processed 191 impedance values to accurately reconstruct the shapes of cancer cells and control beads. Our approach successfully reconstructed images of MDA-MB-231 breast cancer cells, HeLa cells, and beads, achieving 91 % accuracy on the test dataset. Validation using the Structural Similarity Index (SSI) and Mean Structural Similarity Index (MSSIM) produced scores of 0.97 for breast cancer cells and 0.93 for beads, confirming the high precision of this method. This label-free, impedance-based imaging offers a promising solution for cancer diagnostics by accurately reconstructing cell shapes and distinguishing cell types, particularly in point-of-care applications.}
}
@article{ZHAO2025103055,
title = {Unlocking ancient wisdom with modern tools: A new approach to the revitalization of ancient texts based on generative artificial intelligence},
journal = {The Journal of Academic Librarianship},
volume = {51},
number = {3},
pages = {103055},
year = {2025},
issn = {0099-1333},
doi = {https://doi.org/10.1016/j.acalib.2025.103055},
url = {https://www.sciencedirect.com/science/article/pii/S0099133325000515},
author = {YueYan Zhao and WenJie Zhou},
keywords = {Generative artificial intelligence, Chinese classics, Multi-granularity knowledge deconstruction, Knowledge services},
abstract = {In the fields of library science and information science, the gap between the obscure language of ancient texts and the cognitive abilities of the average reader is the primary obstacle to the widespread dissemination of the rich wisdom in traditional cultural heritage. The rapid development of generative artificial intelligence technology has provided the conditions for researchers to transition from sequential organization of bibliographic references to the deconstruction and reorganization of knowledge elements. This study, reveals the intrinsic relationship patterns between multi-granularity knowledge in ancient texts from perspectives such as logical relationships, frame semantic associations, hierarchical structures, and feature associations, and constructs a multidimensional knowledge representation model for ancient texts. Furthermore, a YAML prompt template was designed by integrating large language models with the deconstruction of multi-granularity knowledge elements from ancient texts, and experiments were conducted using the Chinese classic “Records of the Grand Historian: Biographies.” The results indicate that the method developed in this study for the deconstruction and reorganization of knowledge elements in ancient texts exhibits notable characteristics such as multi-granularity, cross-document application, refinement, multiple perspectives, efficiency improvement, and scalability, demonstrating potential for application in the field of knowledge services for ancient texts.}
}
@article{FENG2024100090,
title = {Latest developments of generative artificial intelligence and applications in ophthalmology},
journal = {Asia-Pacific Journal of Ophthalmology},
volume = {13},
number = {4},
pages = {100090},
year = {2024},
issn = {2162-0989},
doi = {https://doi.org/10.1016/j.apjo.2024.100090},
url = {https://www.sciencedirect.com/science/article/pii/S2162098924000914},
author = {Xiaoru Feng and Kezheng Xu and Ming-Jie Luo and Haichao Chen and Yangfan Yang and Qi He and Chenxin Song and Ruiyao Li and You Wu and Haibo Wang and Yih Chung Tham and Daniel Shu Wei Ting and Haotian Lin and Tien Yin Wong and Dennis Shun-chiu Lam},
keywords = {Generative artificial intelligence, Ophthalmology, Risk management, Clinical workflow, AI in medical research},
abstract = {The emergence of generative artificial intelligence (AI) has revolutionized various fields. In ophthalmology, generative AI has the potential to enhance efficiency, accuracy, personalization and innovation in clinical practice and medical research, through processing data, streamlining medical documentation, facilitating patient-doctor communication, aiding in clinical decision-making, and simulating clinical trials. This review focuses on the development and integration of generative AI models into clinical workflows and scientific research of ophthalmology. It outlines the need for development of a standard framework for comprehensive assessments, robust evidence, and exploration of the potential of multimodal capabilities and intelligent agents. Additionally, the review addresses the risks in AI model development and application in clinical service and research of ophthalmology, including data privacy, data bias, adaptation friction, over interdependence, and job replacement, based on which we summarized a risk management framework to mitigate these concerns. This review highlights the transformative potential of generative AI in enhancing patient care, improving operational efficiency in the clinical service and research in ophthalmology. It also advocates for a balanced approach to its adoption.}
}
@article{ECKHARDT2025100987,
title = {Livestock behaviour forecasting via generative artificial intelligence},
journal = {Smart Agricultural Technology},
volume = {11},
pages = {100987},
year = {2025},
issn = {2772-3755},
doi = {https://doi.org/10.1016/j.atech.2025.100987},
url = {https://www.sciencedirect.com/science/article/pii/S2772375525002205},
author = {Regina Eckhardt and Reza Arablouei and Aaron Ingham and Kieren McCosker and Heinz Bernhardt},
keywords = {Accelerometer data, Cattle behaviour, Data imputation, Generative AI, Precision agriculture},
abstract = {Recent advancements in sensor technology and generative artificial intelligence (AI) are transforming precision livestock farming by enhancing behaviour monitoring and predictive analytics. This study examines the effectiveness of Transformer-type generative AI models in predicting cattle behaviour profiles and imputing missing data from collar accelerometer readings collected during two trials in Queensland, Australia, in 2022 and 2023, alongside climatic data. Each trial involved 60 cattle equipped with collars that classified six core behaviours: grazing, ruminating, walking, resting, drinking, and other over five-second time windows. Hourly behaviour profiles were constructed for each animal and experiment day by aggregating the behaviour predictions over every calendar hour, representing the time spent on each behaviour within each hour. Subsequently, four Transformer-type models (i.e., standard Transformer, Informer, Reformer, and Autoformer) were trained on the hourly behaviour profile data to predict behaviour profiles of the next 24 hours for each animal. Among the considered models, Autoformer showed the highest predictive accuracy when including climate data, achieving a mean absolute error (MAE) of <5.5 min, while the next best model had an MAE of approximately 6 min. For imputing missing data, the standard Transformer outperformed traditional imputation methods, with an MAE of <30 min over 24 hours, compared to 40 to 70 min for traditional methods (mean, median, and linear interpolation). These results highlight the potential of generative AI, particularly Autoformer and Transformer, to enhance predictive accuracy and data imputation in livestock management, thereby supporting regulatory guidance for data-driven decision-making and improved farming practices.}
}
@article{HAMADA2025174,
title = {In silico design of smaller size enzymatic protein by generative artificial intelligence (ProtGPT2)},
journal = {Journal of Bioscience and Bioengineering},
volume = {140},
number = {3},
pages = {174-179},
year = {2025},
issn = {1389-1723},
doi = {https://doi.org/10.1016/j.jbiosc.2025.06.009},
url = {https://www.sciencedirect.com/science/article/pii/S1389172325001598},
author = {Hiroyuki Hamada and Tamon Matsuzawa and Taizo Hanai},
keywords = {Generative artificial intelligence, Protein language model, ProtGPT2, Amino acid sequence design, Smaller size protein, Malate dehydrogenase},
abstract = {The construction of small proteins by removing amino acid subsequences that are not involved in function, activity, or structure is crucial for bioprocessing and drug development. Traditional design methods often focus on reconstructing functional motifs, but they face challenges in stabilizing structure and reproducing function. In this study, we aimed to develop a design method for small proteins using ProtGPT2, a model that generates protein sequences based on function and structure. First, amino acid sequence data of malate dehydrogenase (MDH) was collected, and ProtGPT2 was fine-tuned (ProtGPT2 for MDH). The chain length and perplexity (ppl) of the generated sequences were evaluated, producing shorter sequences than the natural ones. The validity of the generated sequences was assessed using both population and individual analyses. Population analysis, including multiple sequence alignment (MSA) and t-distributed stochastic neighbor embedding (tSNE), revealed that ProtGPT2 for MDH identified functional motifs of MDH and incorporated them into the generated sequences. Additionally, tSNE showed that the generated sequences were highly similar to natural MDH sequences. In individual analysis, 10 randomly selected sequences were evaluated using BLAST, AlphaFold2, and InterPro. BLAST indicated that 9 sequences were novel MDH variants. AlphaFold2 confirmed that their 3D structures were highly similar to known MDH structures. InterPro identified domains and active sites in 2 sequences, suggesting that they were novel, small MDH variants. In conclusion, ProtGPT2 for MDH has the potential to design amino acid sequence candidates for small MDHs. The validity and utility of the model will be established through future experimental efforts.}
}
@article{BIRKUN2025110680,
title = {Generative artificial intelligence-mediated counselling on first aid for seizures: The performance of publicly available chatbot versus its customised version},
journal = {Epilepsy & Behavior},
volume = {171},
pages = {110680},
year = {2025},
issn = {1525-5050},
doi = {https://doi.org/10.1016/j.yebeh.2025.110680},
url = {https://www.sciencedirect.com/science/article/pii/S1525505025004202},
author = {Alexei A. Birkun and Yekaterina Kosova and Anton Rudenko},
keywords = {Cardiopulmonary resuscitation, Epilepsy, First aid, Generative Artificial Intelligence, Large language models, Natural language processing, Seizures},
abstract = {Background
The potential application of cutting-edge generative artificial intelligence chatbots in the capacity of emergency consultants is gaining growing attention. This study aimed to analyse the quality of advice on first aid for seizures generated by a commercially developed chatbot in comparison with its customised version.
Methods
The baseline version of ChatGPT (model GPT-4o) and the same chatbot customised using a specialised knowledge base and prompt engineering were tested in four scenarios mimicking bystander requests for instructions on how to help a victim with seizures. The scenarios included ongoing seizures and postictal states, with or without consciousness and breathing. A checklist-based evaluation was conducted.
Results
In total, 120 user-to-chatbot dialogues were generated (2 chatbots × 15 dialogues × 4 scenarios). The baseline chatbot always failed to consider the victim’s state, including whether the seizures are continuing, or if the victim in the postictal period is conscious and breathing normally. Its advice was non-selective and inaccurate, with frequent omissions of key recommendations on first aid and suggestions of inadequate measures. The customised chatbot-generated guidance was consistently tailored to the victim’s condition, significantly more precise and completely safe. Depending on the scenario, the mean percentage of chatbot responses that fulfilled the checklist items was 14–49 % for the baseline chatbot and 77–92 % for the customised version (p ≤ 0.039).
Conclusions
Whereas the publicly available version of the chatbot is not acceptable for first aid counselling, its expert-informed customisation ensures high accuracy and safety of generated advice. Further research in this field is advisable.}
}
@article{BAHARMAND20251486,
title = {Leveraging Generative Artificial Intelligence to Address Data Management Challenges in Humanitarian Operations},
journal = {IFAC-PapersOnLine},
volume = {59},
number = {10},
pages = {1486-1491},
year = {2025},
note = {11th IFAC Conference on Manufacturing Modelling, Management and Control MIM 2025},
issn = {2405-8963},
doi = {https://doi.org/10.1016/j.ifacol.2025.09.250},
url = {https://www.sciencedirect.com/science/article/pii/S2405896325010110},
author = {Hossein Baharmand},
keywords = {Generative AI, humanitarian operations, decision-making, resource allocation, case study},
abstract = {Integrating generative artificial intelligence (Gen-AI) into humanitarian operations presents a transformative opportunity to enhance decision-making and resource allocation. This paper explores how Gen-AI can address data management challenges in humanitarian contexts, thereby supporting decision-making and resource allocation in humanitarian operations. We examine the practical benefits and challenges of implementing this technology by studying three pilot projects: the Humanitarian Data Insights Project, the UNHCR and Arm partnership, and the WFP’s voice-to-text project. The findings highlight the potential of Gen-AI to streamline data processes, enhance accuracy, and facilitate real-time insights while also addressing concerns related to bias, data privacy, and accountability. The paper concludes with recommendations for humanitarian organizations to effectively leverage Gen-AI, emphasizing the importance of relevant data governance, AI literacy, and cross-sector collaboration. This study contributes to the growing body of knowledge on applying advanced technologies in humanitarian operations, offering insights for future research and practical implementation.}
}
@article{SALARI2025100652,
title = {Impacts of generative artificial intelligence on the future of labor market: A systematic review},
journal = {Computers in Human Behavior Reports},
volume = {18},
pages = {100652},
year = {2025},
issn = {2451-9588},
doi = {https://doi.org/10.1016/j.chbr.2025.100652},
url = {https://www.sciencedirect.com/science/article/pii/S2451958825000673},
author = {Nader Salari and Mahan Beiromvand and Amin Hosseinian-Far and Javad Habibi and Fateme Babajani and Masoud Mohammadi},
keywords = {Job market, AI, ChatGPT, Labor market, GenAI},
abstract = {Background
Generative AI (GenAI) has the ability to autonomously collect and process data to generate contents, inform decisions, solve problems, and perform tasks that typically require human reasoning. This Systematic Review is conducted to examine the impacts of GenAI on the future of employment, focusing on concerns about rising unemployment, and the positive and negative perspectives outlined within exiting studies. The findings from this review can help identify research gaps, guide organizational planning, and improve AI governance frameworks and policies.
Methods
To identify relevant studies, the PubMed, Scopus, Web of Science, Embase, ScienceDirect and Google Scholar databases and repositories were systematically searched using the keywords: ‘Future of work’, ‘Job market’, ‘Generative AI’, ‘Generative AI’, and ‘ChatGPT’. Additionally, the reference lists of the identified related articles were reviewed for grey literature.
Results
Following the PRISMA guidelines, a total of 14 articles were selected for analysis. Selected studies have examined the positive and negative viewpoints on GenAI, together with pertinent challenges and opportunities. Accordingly, GenAI, when compliant with security and ethical issues, has the potential to increase efficiency whilst reducing costs and time.
Conclusion
Considering the rapid growth and adoption of AI technologies, examining the impacts of GenAI on the future of labor market is crucial. GenAI is likely to create new roles in some sectors yet reduce opportunities in others. A nuanced assessment of the impacts, and ongoing monitoring are vital for effective preparation and adaptation to the evolving work landscape in the presence of advanced AI technologies.}
}
@article{TONG2025103629,
title = {A rapidly structured aircraft concept design method based on generative artificial intelligence},
journal = {Chinese Journal of Aeronautics},
volume = {38},
number = {10},
pages = {103629},
year = {2025},
issn = {1000-9361},
doi = {https://doi.org/10.1016/j.cja.2025.103629},
url = {https://www.sciencedirect.com/science/article/pii/S1000936125002353},
author = {Yao TONG and Mingqiang LUO and Shangqing REN and Zheng ZHANG and Chenguang XING and Ziliang DU},
keywords = {Aircraft, Conceptual design, Generative artificial intelligence, Large language model, Prompt engineering},
abstract = {Aircraft conceptual design is a critical step in the development and research of aircraft, involving complex processes and multiple disciplines. Improving the efficiency of aircraft conceptual design while ensuring quality is an important challenge. Intelligent technologies such as neural networks have played significant roles in areas like aerodynamics and structural analysis. However, due to issues such as high data demands and difficulties in transfer learning, their application in the conceptual design phase has been limited. The rise of generative artificial intelligence, exemplified by Large Language Model (LLM), offers a new approach to this problem. Therefore, this study proposes a methodology for generating aircraft conceptual design solutions based on LLMs and develops a prototype system. First, four of the current best-performing general-purpose LLMs are selected for deployment as foundational models. Then, based on the general prompt framework of LLMs, schema for aircraft conceptual design solutions, and real-world design cases, task prompts for generating aircraft conceptual design solutions are crafted, resulting in three types of prompts: Full-Instruction, 1-Shot, and 5-Shot. Finally, the prototype system is utilized to design conceptual solutions, and the model-generated solutions are compared with those designed by engineers from both objective and subjective perspectives. The experimental results indicate that LLMs demonstrate conceptual design capabilities comparable to those of engineers, exhibiting strong generalization ability and potential for innovative design.}
}
@article{RONKSLEYPAVIA2025100437,
title = {A scoping literature review of generative artificial intelligence for supporting neurodivergent school students},
journal = {Computers and Education: Artificial Intelligence},
volume = {9},
pages = {100437},
year = {2025},
issn = {2666-920X},
doi = {https://doi.org/10.1016/j.caeai.2025.100437},
url = {https://www.sciencedirect.com/science/article/pii/S2666920X25000773},
author = {Michelle Ronksley-Pavia and Lan Nguyen and Elizabeth Wheeley and Judy Rose and Michelle M. Neumann and Chris Bigum and David L. Neumann},
keywords = {Artificial intelligence, Generative AI, GenAI, Neurodiversity, School, Personalized learning, Teachers},
abstract = {While Generative Artificial Intelligence (GenAI) platforms like ChatGPT have gained significant traction in education, their specific applications for neurodivergent learners remain largely unmapped. Through systematic searching of academic databases and grey literature between 2020 and 2024, this scoping literature review examined the emerging landscape of GenAI applications in supporting neurodivergent students (e.g., those with ADHD, autism, dyslexia, gifted, twice-exceptional) within K-12 educational contexts. Twenty-one relevant sources were identified, discussing GenAI usage with neurodivergent students, the analysis revealed discussion of several predominant applications, including personalized learning, administrative assistance for educators, and development of individualized education plans. The review identified both promising approaches and significant concerns. Benefits included GenAI's potential to provide real-time, personalized support for students as well as reducing administrative burdens for educators. However, notable concerns emerged regarding information accuracy, over-reliance on AI, privacy considerations, and the need for human oversight. The limited empirical evidence base was particularly striking, with only nine studies providing original research data. The review identified critical gaps in current understanding, particularly regarding GenAI's effectiveness across different neurodivergent conditions and curriculum areas, and little evidence of approaches detailed in ways that educators could use. This scoping review demonstrates the need for robust empirical research examining GenAI usage in learning for neurodivergent students. These insights are timely and crucial for educators, researchers, and policymakers working to harness GenAI's potential in supporting neurodivergent learners within inclusive educational environments.}
}
@article{EHMKE2025222,
title = {Self-perceived knowledge, skills, and attitude of nursing faculty on generative artificial intelligence in nursing education: A descriptive, cross-sectional study},
journal = {Teaching and Learning in Nursing},
volume = {20},
number = {3},
pages = {222-227},
year = {2025},
issn = {1557-3087},
doi = {https://doi.org/10.1016/j.teln.2025.01.029},
url = {https://www.sciencedirect.com/science/article/pii/S1557308725000447},
author = {Sabrina D. Ehmke and Jenny Bridges and Sarah E. Patel},
keywords = {Artificial intelligence, Nursing education, Nursing faculty},
abstract = {Background
AI is transforming health and education, offering innovative solutions to workflow and curriculum challenges. However, faculty members lack familiarity with AI, limiting their ability to prepare students for AI-driven healthcare.
Aim
Our study investigated nursing faculty's knowledge, skills, and attitudes toward integrating Artificial Intelligence (AI) into education, examining differences by degree type and the influence of policies or syllabi on AI integration.
Methods
A descriptive, cross-sectional study assessed faculty's self-perceptions of knowledge, skills, and attitudes regarding AI in education. Data were gathered via a survey of nursing faculty from diverse institutions.
Results
Findings revealed gaps in AI knowledge and skills linked to educational level and institutional policy development. Doctorly prepared-faculty reported higher perceived knowledge and skills, while BS-prepared faculty had higher attitudes toward AI. Faculty involved in AI policy or syllabus development perceived greater knowledge, skills, and attitudes.
Conclusion
Faculty education and policy support are critical for integrating AI into education. Institutions should invest in faculty development and ethical AI adoption, using case studies, simulation, and decision-support tools to enhance curriculum and healthcare outcomes.}
}
@article{BARROSO2025501667,
title = {Application of generative artificial intelligence chatbots in the field of anesthesia},
journal = {Revista Española de Anestesiología y Reanimación (English Edition)},
volume = {72},
number = {6},
pages = {501667},
year = {2025},
issn = {2341-1929},
doi = {https://doi.org/10.1016/j.redare.2025.501667},
url = {https://www.sciencedirect.com/science/article/pii/S2341192925001179},
author = {A. Barroso and R. Casans}
}
@article{TEO2024100091,
title = {Cybersecurity in the generative artificial intelligence era},
journal = {Asia-Pacific Journal of Ophthalmology},
volume = {13},
number = {4},
pages = {100091},
year = {2024},
issn = {2162-0989},
doi = {https://doi.org/10.1016/j.apjo.2024.100091},
url = {https://www.sciencedirect.com/science/article/pii/S2162098924000926},
author = {Zhen Ling Teo and Chrystie Wan Ning Quek and Joy Le Yi Wong and Daniel Shu Wei Ting},
keywords = {Generative Artificial Intelligence, ChatGPT, Cybersecurity, Privacy risks, Large language model},
abstract = {Generative Artificial Intelligence (GenAI) are algorithms capable of generating original content. The ability of GenAI to learn and generate novel outputs alike human cognition has taken the world by storm and ushered in a new era. In this review, we explore the role of GenAI in healthcare, including clinical, operational, and research applications, and delve into the cybersecurity risks of this technology. We discuss risks such as data privacy risks, data poisoning attacks, the propagation of bias, and hallucinations. In this review, we recommend risk mitigation strategies to enhance cybersecurity in GenAI technologies and further explore the use of GenAI as a tool in itself to enhance cybersecurity across the various AI algorithms. GenAI is emerging as a pivotal catalyst across various industries including the healthcare domain. Comprehending the intricacies of this technology and its potential risks will be imperative for us to fully capitalise on the benefits that GenAI can bring.}
}
@article{ZHAO2025102299,
title = {From interface to inference: mapping the impact of generative artificial intelligence affordances on user risk perception},
journal = {Telematics and Informatics},
volume = {101},
pages = {102299},
year = {2025},
issn = {0736-5853},
doi = {https://doi.org/10.1016/j.tele.2025.102299},
url = {https://www.sciencedirect.com/science/article/pii/S0736585325000619},
author = {Haoyu Zhao and Zhengbiao Han and Shuqi Yin and Nan yang and Preben Hansen},
keywords = {Perceived affordances, User risk perception, Generative artificial intelligence, Human-computer interaction},
abstract = {A deep understanding of Generative Artificial Intelligence (GAI) is crucial not only for technological development but also for formulating effective risk response strategies. However, previous studies have mainly focused on how individual factors affect GAI risk perception while the technical functions and features that are the root causes of user concerns regarding GAI remain unclear. To address this gap, the current study, grounded in affordance theory, explored how perceived affordances of GAI influenced user risk perceptions across six dimensions: information, security, technical, social, ethical, and legal. A hierarchical regression analysis was conducted on a survey of 1,031 GAI users to examine the impact of interactivity, agency, and security affordances on these risk dimensions. The results indicate that higher perceptions of affordances such as bandwidth, synchrony, and transparency are significantly associated with lower risk perceptions across all dimensions. Notably, women reported higher perceived risks than men in most categories, whereas age and GAI usage experience did not significantly affect these perceptions. These findings highlight the importance of enhancing user control, transparency, and privacy protections in GAI system design to effectively mitigate perceived risks. This study contributes to the literature by providing a multidimensional analysis of risk perception in the context of GAI, offering practical insights for the development of inclusive, transparent, and user-centered artificial intelligence systems.}
}
@article{PALLOTTINO2025109919,
title = {Applications and perspectives of Generative Artificial Intelligence in agriculture},
journal = {Computers and Electronics in Agriculture},
volume = {230},
pages = {109919},
year = {2025},
issn = {0168-1699},
doi = {https://doi.org/10.1016/j.compag.2025.109919},
url = {https://www.sciencedirect.com/science/article/pii/S0168169925000250},
author = {Federico Pallottino and Simona Violino and Simone Figorilli and Catello Pane and Jacopo Aguzzi and Giacomo Colle and Eugenio {Nerio Nemmi} and Alessandro Montaghi and Damianos Chatzievangelou and Francesca Antonucci and Lavinia Moscovini and Alessandro Mei and Corrado Costa and Luciano Ortenzi},
keywords = {GAI, GAN, NLP, LLMs, ChatGPT, Microsoft Copilot},
abstract = {Artificial Intelligence (AI) applications related to agriculture have recently gained in use and attention. They are indeed valuable tools for interpreting data, improving production chains, and optimizing the use of natural resources. Among AI models, the most recent and promising area is represented by Generative Artificial Intelligence (GAI). After an initial description of its general model architectures, this work aims to review its practical uses and potentials in the following individual sectors: agriculture, precision farming, and animal farming, as well as interdisciplinary applications. The literature search was carried out using the SCOPUS, Google Scholar, and Web of Science databases. GAI holds immense potential for revolutionizing agriculture, offering solutions ranging from precision farming to pest management and supply chain optimization. Though some applications can extend beyond efficiency gains, and hallucinations occurrence i.e. false output information presented as fact, remains an open issue, GAI can be decisive for tasks like improving training datasets, refining models, and facilitating time series analysis. This review extensively describes the vital importance of these tasks for agriculture, precision and animal farming, caused by the rise of new technologies. As a result, by embracing and responsibly implementing GAI applications, it is possible to create a more sustainable and resilient future for agriculture and precision farming. GAI have the capacity to extract specific information from big data systems, offering huge potential to meet a growing global population demand and consequent environmental challenges for the future.}
}
@article{CHENG2025104194,
title = {From emotion to reflection: leveraging EmotionPrompt strategy to empower self-determination in decision-making with generative artificial intelligence},
journal = {Information & Management},
volume = {62},
number = {7},
pages = {104194},
year = {2025},
issn = {0378-7206},
doi = {https://doi.org/10.1016/j.im.2025.104194},
url = {https://www.sciencedirect.com/science/article/pii/S0378720625000977},
author = {Xusen Cheng and Lu Gao and Xin (Robert) Luo},
keywords = {Human–AI interaction, EmotionPrompt, Regulatory focus theory, Cognitive reappraisal, Psychological empowerment},
abstract = {Communication and reflection abilities are critical in managing strategic cooperation between humans and Generative Artificial Intelligence (GAI), especially when facing conflict in decision-making. This study introduces two variations of EmotionPrompt strategies, drawing on regulatory focus theory, to explore both individuals' perceptions of GAI ability and their empowerment in self-competence when handling disagreements. An experiment between humans and GAI chatbots in determining product promotion strategy showed that emotional prompts impact individuals' reappraisals of both chatbots and their own performance profoundly, cultivating self-determination in the final decision. Importantly, EmotionPrompt with promotion orientation can increase the perceived flexibility of chatbot decision-makers, facilitating individual self-enhancement and trust in GAI competence. In contrast, the prevention-oriented EmotionPrompt appears to constrain individuals' judgments and decision-making processes, as evidenced by the increased occurrence of inhibit words and anxiety emotions in their reflections. These findings provide novel perspectives on implementing specific regulatory-oriented EmotionPrompt strategies in GAI to address opinion conflicts in decision-making with humans.}
}
@article{BOSCO2025,
title = {Designing a Multimodal and Culturally Relevant Alzheimer Disease and Related Dementia Generative Artificial Intelligence Tool for Black American Informal Caregivers: Cognitive Walk-Through Usability Study},
journal = {JMIR Aging},
volume = {8},
year = {2025},
issn = {2561-7605},
doi = {https://doi.org/10.2196/60566},
url = {https://www.sciencedirect.com/science/article/pii/S2561760525000027},
author = {Cristina Bosco and Ege Otenen and John {Osorio Torres} and Vivian Nguyen and Darshil Chheda and Xinran Peng and Nenette M Jessup and Anna K Himes and Bianca Cureton and Yvonne Lu and Carl V Hill and Hugh C Hendrie and Priscilla A Barnes and Patrick C Shih},
keywords = {multimodality, artificial intelligence, AI, generative AI, usability, black, African American, cultural, Alzheimer's, dementia, caregivers, mobile app, interaction, cognition, user opinion, geriatrics, smartphone, mHealth, digital health, aging},
abstract = {Background
Many members of Black American communities, faced with the high prevalence of Alzheimer disease and related dementias (ADRD) within their demographic, find themselves taking on the role of informal caregivers. Despite being the primary individuals responsible for the care of individuals with ADRD, these caregivers often lack sufficient knowledge about ADRD-related health literacy and feel ill-prepared for their caregiving responsibilities. Generative AI has become a new promising technological innovation in the health care domain, particularly for improving health literacy; however, some generative AI developments might lead to increased bias and potential harm toward Black American communities. Therefore, rigorous development of generative AI tools to support the Black American community is needed.
Objective
The goal of this study is to test Lola, a multimodal mobile app, which, by relying on generative AI, facilitates access to ADRD-related health information by enabling speech and text as inputs and providing auditory, textual, and visual outputs.
Methods
To test our mobile app, we used the cognitive walk-through methodology, and we recruited 15 informal ADRD caregivers who were older than 50 years and part of the Black American community living within the region. We asked them to perform 3 tasks on the mobile app (ie, searching for an article on brain health, searching for local events, and finally, searching for opportunities to participate in scientific research in their area), then we recorded their opinions and impressions. The main aspects to be evaluated were the mobile app’s usability, accessibility, cultural relevance, and adoption.
Results
Our findings highlight the users’ need for a system that enables interaction with different modalities, the need for a system that can provide personalized and culturally and contextually relevant information, and the role of community and physical spaces in increasing the use of Lola.
Conclusions
Our study shows that, when designing for Black American older adults, a multimodal interaction with the generative AI system can allow individuals to choose their own interaction way and style based upon their interaction preferences and external constraints. This flexibility of interaction modes can guarantee an inclusive and engaging generative AI experience.}
}
@article{DERAKHSHAN2025102114,
title = {EFL students’ perceptions about the role of generative artificial intelligence (GAI)-mediated instruction in their emotional engagement and goal orientation: A motivational climate theory (MCT) perspective in focus},
journal = {Learning and Motivation},
volume = {90},
pages = {102114},
year = {2025},
issn = {0023-9690},
doi = {https://doi.org/10.1016/j.lmot.2025.102114},
url = {https://www.sciencedirect.com/science/article/pii/S0023969025000219},
author = {Ali Derakhshan},
keywords = {Achievement goal theory, Emotional engagement, Generative artificial intelligence (GAI), Goal orientation, L2 education, Motivational climate theory (MCT), Self-determination theory (SDT)},
abstract = {Research on the contributions of generative artificial intelligence (GAI) technologies to second language (L2) education has soared in the past couple of years. However, there is limited evidence pertaining to the impact of AI-mediated instruction on postgraduate students’ psycho-affective factors and the overall learning climate in English as a foreign language (EFL) context. To address this gap, the present study drew on motivational climate theory (MCT) to explore postgraduate EFL students’ perceptions of the role of GAI technologies in their emotional engagement and goal orientation. To do so, an interview was conducted with 30 postgraduate students using maximum variation sampling. The results of the inductive thematic analysis revealed that AI-mediated instruction had affected both the emotional engagement and goal orientation of the students. In particular, it was found that GAI tools fostered emotional engagement by ‘enlightening teacher-student classroom relationships’, ‘making the overall classroom culture/climate engaging, motivating, and updated’, ‘improving teachers’ action, instruction, and feedback quality’, ‘providing a personalized, interactive, and autonomy supporting education’, and ‘taping into learner-specific idiosyncrasies and individual differences’. Furthermore, GAI tools affected the students’ goal orientation by ‘facilitating the mastery of course content’, ‘setting personalized and achievable goals’, ‘fostering students’ performance comparison in the classroom’, and ‘providing a reflective and adaptive learning environment’. The findings are discussed and implications are provided for EFL teachers, students, teacher educators, and policymakers concerning the interplay of GAI, emotions, goal orientation, and motivational climate.}
}
@article{JIN2025100467,
title = {Mechanisms of enhancing learning with unequal preparation: An experimental study on generative artificial intelligence use and proficiency in programming learning},
journal = {Computers and Education: Artificial Intelligence},
volume = {9},
pages = {100467},
year = {2025},
issn = {2666-920X},
doi = {https://doi.org/10.1016/j.caeai.2025.100467},
url = {https://www.sciencedirect.com/science/article/pii/S2666920X25001079},
author = {Yuan Jin and Wei He and Jun Shen and Jingyun Hu},
keywords = {Generative artificial intelligence (GenAI), Learning preparation, GenAI proficiency, Learning outcomes, Experimental study},
abstract = {Prior learning preparation, encompassing learners' prior knowledge, resources, and readiness for learning new material, plays a critical role in a new learning process. Unequal learning preparation commonly exists among learners with varying socioeconomic and academic backgrounds, and can further exacerbate the educational divide. By reducing learning cost and providing less prepared learners with personalized delivery of information and knowledge, Generative Artificial Intelligence (GenAI) may help mitigate disparities in learning preparation. In this study, we investigate the roles of learners' use of GenAI in their learning processes, considering varying levels of learners’ prior learning preparation and proficiency in GenAI use. Specifically, we examine the effects of the use of GenAI tools on learning outcomes through its impacts on perceived informational benefit, learning cost, and knowledge fit in the focal learning process, moderated by learning preparation and GenAI proficiency of learners. Based on an experiment in a programming learning context, we find that although GenAI use significantly reduces learning cost, especially for less prepared learners, the cost reduction effect has not been translated into improved learning outcomes. We find no significant moderating effects of learning preparation on how GenAI use affects informational benefit and knowledge fit, further showing that GenAI tools have not yet been effectively utilized to help less prepared learners or reduce the educational divide. As indicated by the significant moderating roles of GenAI proficiency, to fully leverage the power of GenAI, improving GenAI proficiency can be crucial to ensure learning effectiveness for learners with different levels of learning preparation.}
}
@article{MABWE2025820,
title = {Generative artificial intelligence chatbots in investment decision-making: a phantom menace or a new hope?},
journal = {Foresight},
volume = {27},
number = {4},
pages = {820-863},
year = {2025},
issn = {1463-6689},
doi = {https://doi.org/10.1108/FS-06-2024-0122},
url = {https://www.sciencedirect.com/science/article/pii/S1463668925000082},
author = {Kumbirai Mabwe and Nasir Aminu and Stanislav Hristov Ivanov and Diyan Dimov},
keywords = {Generative AI, ChatGPT, Bard, Gemini, Bing, Large language models, Chatbots, Investment recommendations},
abstract = {Purpose
This study aims to investigate the relevance, accuracy, specificity and justification of investment recommendations of generative artificial intelligence (GenAI) chatbots for different investment capitals and countries (UK and Bulgaria).
Design/methodology/approach
A two-stage mixed methods approach was used. Prompts were queried into OpenAI’s ChatGPT, Microsoft Bing and Google Bard (now Gemini). Finance and investment practitioners and finance and investment lecturers assessed the chatbots’ recommendations through an online questionnaire using a five-point Likert scale. The Chi-squared test, Wilcoxon-signed ranks test, Mann–Whitney U test and Friedman test were used for data analysis to compare GenAIs’ recommendations for the UK and Bulgaria across different amounts of investment capital and to assess the consistency of the chatbots.
Findings
GenAI chatbots’ responses were found to perform medium-to-high in terms of relevance, accuracy, specificity and justification. For the UK sample, the amount of investment had a marginal effect but prompt timing had an interesting impact. Unlike the British sample, the GenAI application, prompt timing and investment amount did not significantly influence the Bulgarian respondents’ evaluations. While the mean responses of the British sample were slightly higher, these differences were not statistically significant, indicating that ChatGPT, Bing and Bard performed similarly in both the UK and Bulgaria.
Originality/value
The study assesses the relevance, accuracy, specificity and justification of GenAI chatbots’ investment recommendations for two different periods, investment amounts and countries.}
}
@article{YE2024102851,
title = {Privacy and personal data risk governance for generative artificial intelligence: A Chinese perspective},
journal = {Telecommunications Policy},
volume = {48},
number = {10},
pages = {102851},
year = {2024},
issn = {0308-5961},
doi = {https://doi.org/10.1016/j.telpol.2024.102851},
url = {https://www.sciencedirect.com/science/article/pii/S0308596124001484},
author = {Xiongbiao Ye and Yuhong Yan and Jia Li and Bo Jiang},
keywords = {Generative AI, Privacy and personal data protection, Risk governance, Chinese law},
abstract = {The rapid development of generative artificial intelligence (AI) has attracted global attention and posed challenges to existing data governance frameworks. The increased technical complexity and expanded scale of data usage not only make it more difficult to regulate AI but also present challenges for the current legal system. This article, which takes ChatGPT's training data and working principles as a starting point, examines specific privacy risks, data leakage risks, and personal data risks posed by generative AI. It also analyzes the latest practices in privacy and personal data protection in China. This article finds that while China's governance on privacy and personal data protection takes a macro-micro integration approach and a private-and-public law integration approach, there are shortcomings in the legal system. Given that the current personal data protection system centered on individual control is unsuitable for the modes of data processing by generative AI, and that private law is insufficient in safeguarding data privacy, urgent institutional innovation is needed to achieve the objective of “trustworthy AI.”}
}
@article{JIN2025105248,
title = {High heels, compass, spider-man, or drug? Metaphor analysis of generative artificial intelligence in academic writing},
journal = {Computers & Education},
volume = {228},
pages = {105248},
year = {2025},
issn = {0360-1315},
doi = {https://doi.org/10.1016/j.compedu.2025.105248},
url = {https://www.sciencedirect.com/science/article/pii/S0360131525000168},
author = {Fangzhou Jin and Lanfang Sun and Yunqiu Pan and Chin-Hsi Lin},
keywords = {Artificial intelligence, Writing, Metaphor analysis, Cross-cultural skills, Interdisciplinary knowledge},
abstract = {This research employed metaphor analysis to explore 277 postgraduate students' perceptions of the role of generative artificial intelligence (GenAI) in academic writing. All participants were international students, from a total of 14 countries and regions, studying in the United Kingdom. Data collection was carried out in two phases. The first was a survey comprising demographic and metaphor-related questions, and the second involved metaphor checking, in which participants provided screenshots of their interactions with GenAI. The data, which were analyzed both qualitatively and quantitatively, yielded 53 unique metaphors for the concept of GenAI in academic writing. We divided these into four conceptual categories in what we term the 4T Pyramid Model: Technical Support (representative metaphor: high-heeled shoes), Text Development (compass), Transformative Potential (Spider-Man), and Threat (drug). The respondents' academic disciplines influenced their perceptions of GenAI, but overall, the results suggest that most viewed it as transformative, i.e., more than just a writing tool. This study's innovative methodology integrating metaphor analysis with real user interactions offers a framework, aligned with Bloom's Taxonomy, that reveals the multi-level benefits and potential risks of GenAI. It also provides actionable insights for AI literacy education, including strategies for effective prompt design.}
}
@article{CRUMBLY2025103129,
title = {A classification framework for generative artificial intelligence for social good},
journal = {Technovation},
volume = {139},
pages = {103129},
year = {2025},
issn = {0166-4972},
doi = {https://doi.org/10.1016/j.technovation.2024.103129},
url = {https://www.sciencedirect.com/science/article/pii/S0166497224001792},
author = {Jack Crumbly and Raktim Pal and Nezih Altay},
keywords = {Artificial intelligence (AI), Generative artificial intelligence (GenAI), Social good, Classification},
abstract = {Many policy makers and corporate leaders are adjusting their strategies to harness the power of GenAI. There are numerous debates on how GenAI would fundamentally change existing business models. However, there is not much discussion on roles of generative AI in the domain of social good. Broader views covering potential opportunities of GenAI to enable diverse initiatives in the social good space are largely missing. We intend to reduce the gap by developing a classification framework that should allow researchers gauge the potential impact of GenAI for social good initiatives. Through case analysis, we assess how value-added abilities of GenAI may influence various social good initiatives. We adopt/develop two loosely connected classification frameworks that are grounded in task-technology fit (TTF) theory. Subsequently, we investigate how our analyses of GenAI initiatives utilizing different dimensions of these two frameworks may be synthesized to provide appropriate explanation for potential success of GenAI for social good. We develop five propositions that will provide guidance to practitioners and researchers. The theoretically grounded analysis of 21 GenAI for social good use cases based on the two classification frameworks, and the resulting propositions are the original contributions of this paper to the AI for social good literature.}
}
@article{CALLARI2025266,
title = {Can generative artificial intelligence productivity tools support workplace learning? A qualitative study on employee perceptions in a multinational corporation},
journal = {Journal of Workplace Learning},
volume = {37},
number = {3},
pages = {266-283},
year = {2025},
issn = {1366-5626},
doi = {https://doi.org/10.1108/JWL-11-2024-0258},
url = {https://www.sciencedirect.com/science/article/pii/S1366562625000026},
author = {Tiziana C. Callari and Lucia Puppione},
keywords = {Organisational socialisation, Meaningful work, Formal and informal learning, Incidental learning, Sociotechnical capital},
abstract = {Purpose
The purpose of this study was to explore employees’ perceptions and firsthand experiences of the impact of generative artificial intelligence (AI) productivity tools, specifically Microsoft 365 Copilot, on individual and collective learning processes within a multinational corporation. In doing so, the study provides insights into how these tools can shape workplace learning dynamics, fostering both individual skill development and collaborative knowledge-sharing practices.
Design/methodology/approach
The authors collected responses from 357 participants through a survey that included both multiple-choice and open-ended questions. This study focuses exclusively on the qualitative responses. The reflexive thematic analysis method was used to capture and interpret employees’ perceptions of the role of Microsoft 365 Copilot – a generative AI-powered assistant integrated into the Microsoft 365 suite of applications (e.g., Word, Excel, PowerPoint, Outlook, Teams) – in enhancing their work and learning opportunities in the workplace.
Findings
The results highlight four key themes contributing to workplace learning. At the individual level, Task Support illustrates the extent to which generative AI productivity tools transform work practices and facilitate both formal and informal learning pathways, while Meaningful Work underscores the tools’ role in enhancing employees’ foundational knowledge through enriched information. At the organisational level, organisational culture suggests the importance of fostering a supportive environment for AI integration, while organisational socialisation highlights its influence on team cohesion and the informal knowledge-sharing processes essential for effective collaboration within and among team members.
Practical implications
The results of this study offer actionable insights for organisations integrating generative AI productivity tools in the workplace. Understanding employees’ perceptions of the role of AI in workplace learning can inform the design of targeted training programmes that promote individual skill development and foster collaborative knowledge sharing. Furthermore, a supportive organisational culture that positions AI as a complementary resource can improve employee engagement, reduce resistance to new technologies and encourage a growth-oriented mindset, ultimately driving both personal and organisational development.
Originality/value
This study shifts the narrative around the role of AI in the workplace by examining how generative AI productivity tools can enhance workplace learning at both individual and organisational levels, rather than focusing solely on their potential to disrupt work through displacement and automation. By positioning AI-based applications as complementary to human work, this approach highlights their potential as enablers of skill development, knowledge sharing and job enrichment, fostering a more adaptive and learning-oriented work environment.}
}
@article{NING2024e848,
title = {Generative artificial intelligence and ethical considerations in health care: a scoping review and ethics checklist},
journal = {The Lancet Digital Health},
volume = {6},
number = {11},
pages = {e848-e856},
year = {2024},
issn = {2589-7500},
doi = {https://doi.org/10.1016/S2589-7500(24)00143-2},
url = {https://www.sciencedirect.com/science/article/pii/S2589750024001432},
author = {Yilin Ning and Salinelat Teixayavong and Yuqing Shang and Julian Savulescu and Vaishaanth Nagaraj and Di Miao and Mayli Mertens and Daniel Shu Wei Ting and Jasmine Chiat Ling Ong and Mingxuan Liu and Jiuwen Cao and Michael Dunn and Roger Vaughan and Marcus Eng Hock Ong and Joseph Jao-Yiu Sung and Eric J Topol and Nan Liu},
abstract = {Summary
The widespread use of Chat Generative Pre-trained Transformer (known as ChatGPT) and other emerging technology that is powered by generative artificial intelligence (GenAI) has drawn attention to the potential ethical issues they can cause, especially in high-stakes applications such as health care, but ethical discussions have not yet been translated into operationalisable solutions. Furthermore, ongoing ethical discussions often neglect other types of GenAI that have been used to synthesise data (eg, images) for research and practical purposes, which resolve some ethical issues and expose others. We did a scoping review of the ethical discussions on GenAI in health care to comprehensively analyse gaps in the research. To reduce the gaps, we have developed a checklist for comprehensive assessment and evaluation of ethical discussions in GenAI research. The checklist can be integrated into peer review and publication systems to enhance GenAI research and might be useful for ethics-related disclosures for GenAI-powered products and health-care applications of such products and beyond.}
}
@article{SUPPAN2025,
title = {Performance of 3 Conversational Generative Artificial Intelligence Models for Computing Maximum Safe Doses of Local Anesthetics: Comparative Analysis},
journal = {JMIR AI},
volume = {4},
year = {2025},
issn = {2817-1705},
doi = {https://doi.org/10.2196/66796},
url = {https://www.sciencedirect.com/science/article/pii/S2817170525000419},
author = {Mélanie Suppan and Pietro Elias Fubini and Alexandra Stefani and Mia Gisselbaek and Caroline Flora Samer and Georges Louis Savoldelli},
keywords = {local anesthetic, dose calculation, toxicity, performance, conversational generative artificial intelligence, artificial intelligence, anesthesiology, comparative analysis, anesthetics, LA, generative artificial intelligence, ChatGPT, Copilot, Gemini, artificial intelligence models, machine learning, neural network, LLM, NLP, natural language processing, large language model, AI, ML},
abstract = {Background
Generative artificial intelligence (AI) is showing great promise as a tool to optimize decision-making across various fields, including medicine. In anesthesiology, accurately calculating maximum safe doses of local anesthetics (LAs) is crucial to prevent complications such as local anesthetic systemic toxicity (LAST). Current methods for determining LA dosage are largely based on empirical guidelines and clinician experience, which can result in significant variability and dosing errors. AI models may offer a solution, by processing multiple parameters simultaneously to suggest adequate LA doses.
Objective
This study aimed to evaluate the efficacy and safety of 3 generative AI models, ChatGPT (OpenAI), Copilot (Microsoft Corporation), and Gemini (Google LLC), in calculating maximum safe LA doses, with the goal of determining their potential use in clinical practice.
Methods
A comparative analysis was conducted using a 51-item questionnaire designed to assess LA dose calculation across 10 simulated clinical vignettes. The responses generated by ChatGPT, Copilot, and Gemini were compared with reference doses calculated using a scientifically validated set of rules. Quantitative evaluations involved comparing AI-generated doses to these reference doses, while qualitative assessments were conducted by independent reviewers using a 5-point Likert scale.
Results
All 3 AI models (Gemini, ChatGPT, and Copilot) completed the questionnaire and generated responses aligned with LA dose calculation principles, but their performance in providing safe doses varied significantly. Gemini frequently avoided proposing any specific dose, instead recommending consultation with a specialist. When it did provide dose ranges, they often exceeded safe limits by 140% (SD 103%) in cases involving mixtures. ChatGPT provided unsafe doses in 90% (9/10) of cases, exceeding safe limits by 198% (SD 196%). Copilot’s recommendations were unsafe in 67% (6/9) of cases, exceeding limits by 217% (SD 239%). Qualitative assessments rated Gemini as “fair” and both ChatGPT and Copilot as “poor.”
Conclusions
Generative AI models like Gemini, ChatGPT, and Copilot currently lack the accuracy and reliability needed for safe LA dose calculation. Their poor performance suggests that they should not be used as decision-making tools for this purpose. Until more reliable AI-driven solutions are developed and validated, clinicians should rely on their expertise, experience, and a careful assessment of individual patient factors to guide LA dosing and ensure patient safety.}
}
@article{SILALAHI2025102995,
title = {Can generative artificial intelligence drive sustainable behavior? A consumer-adoption model for AI-driven sustainability recommendations},
journal = {Technology in Society},
volume = {83},
pages = {102995},
year = {2025},
issn = {0160-791X},
doi = {https://doi.org/10.1016/j.techsoc.2025.102995},
url = {https://www.sciencedirect.com/science/article/pii/S0160791X2500185X},
author = {Andri Dayarana K. Silalahi},
keywords = {Generative AI, Sustainable behavior, User trust, Elaboration likelihood model, Cognitive engagement, Pro-environmental adoption},
abstract = {Generative AI (GAI) has the potential to promote sustainable behavior through personalized recommendations; yet its effectiveness hinges on user trust—an issue that remains under-explored in the literature. Existing studies often focus on specific domains without addressing broader trust-building mechanisms or the cognitive and motivational factors needed for sustained engagement. This study investigates how trust shapes the adoption of GAI-driven sustainability recommendations by integrating the Elaboration Likelihood Model (ELM) and Expectancy-Value Theory (EVT) into a single framework. Using data from sustainability-oriented users, we examine how central route constructs-perceived information quality and utility-peripheral route constructs-anthropomorphism and interaction quality-enhance trust, while perceived information complexity and perceived risk moderate these relationships. Our findings indicate that high-quality, useful information enhances trust through cognitive engagement, whereas anthropomorphic design and interaction quality reinforce trust via the heuristic route. However, excessive complexity and privacy concerns undermine trust, highlighting the need for clearer communication and data transparency. This study broadens theoretical understanding by extending ELM and EVT to the context of GAI-driven sustainability efforts, providing an integrated framework that encompasses cognitive and motivational trust drivers. These insights fill gaps in technology adoption research and offer practical guidance for developing GAI platforms that effectively support pro-environmental behavior change.}
}
@article{HUANG2025100526,
title = {Generative spatial artificial intelligence for sustainable smart cities: A pioneering large flow model for urban digital twin},
journal = {Environmental Science and Ecotechnology},
volume = {24},
pages = {100526},
year = {2025},
issn = {2666-4984},
doi = {https://doi.org/10.1016/j.ese.2025.100526},
url = {https://www.sciencedirect.com/science/article/pii/S2666498425000043},
author = {Jeffrey Huang and Simon Elias Bibri and Paul Keel},
keywords = {Sustainable smart cities, Generative artificial intelligence, Generative spatial artificial intelligence, Foundation models, Large flow model, Urban digital twin, Urban planning and design},
abstract = {Rapid urbanization, alongside escalating resource depletion and ecological degradation, underscores the critical need for innovative urban development solutions. In response, sustainable smart cities are increasingly turning to cutting-edge technologies—such as Generative Artificial Intelligence (GenAI), Foundation Models (FMs), and Urban Digital Twin (UDT) frameworks—to transform urban planning and design practices. These transformative tools provide advanced capabilities to analyze complex urban systems, optimize resource management, and enable evidence-based decision-making. Despite recent progress, research on integrating GenAI and FMs into UDT frameworks remains scant, leaving gaps in our ability to capture complex urban flows and multimodal dynamics essential to achieving environmental sustainability goals. Moreover, the lack of a robust theoretical foundation and real-world operationalization of these tools hampers comprehensive modeling and practical adoption. This study introduces a pioneering Large Flow Model (LFM), grounded in a robust foundational framework and designed with GenAI capabilities. It is specifically tailored for integration into UDT systems to enhance predictive analytics, adaptive learning, and complex data management functionalities. To validate its applicability and relevance, the Blue City Project in Lausanne City is examined as a case study, showcasing the ability of the LFM to effectively model and analyze urban flows—namely mobility, goods, energy, waste, materials, and biodiversity—critical to advancing environmental sustainability. This study highlights how the LFM addresses the spatial challenges inherent in current UDT frameworks. The LFM demonstrates its novelty in comprehensive urban modeling and analysis by completing impartial city data, estimating flow data in new locations, predicting the evolution of flow data, and offering a holistic understanding of urban dynamics and their interconnections. The model enhances decision-making processes, supports evidence-based planning and design, fosters integrated development strategies, and enables the development of more efficient, resilient, and sustainable urban environments. This research advances both the theoretical and practical dimensions of AI-driven, environmentally sustainable urban development by operationalizing GenAI and FMs within UDT frameworks. It provides sophisticated tools and valuable insights for urban planners, designers, policymakers, and researchers to address the complexities of modern cities and accelerate the transition towards sustainable urban futures.}
}
@article{LEE2025104317,
title = {Readability, quality and accuracy of generative artificial intelligence chatbots for commonly asked questions about labor epidurals: a comparison of ChatGPT and Bard},
journal = {International Journal of Obstetric Anesthesia},
volume = {61},
pages = {104317},
year = {2025},
issn = {0959-289X},
doi = {https://doi.org/10.1016/j.ijoa.2024.104317},
url = {https://www.sciencedirect.com/science/article/pii/S0959289X24003297},
author = {D. Lee and M. Brown and J. Hammond and M. Zakowski},
keywords = {Labor analgesia, Epidural, Pregnancy, Generative Artificial Intelligence, Patient educational materials},
abstract = {Introduction
Over 90% of pregnant women and 76% expectant fathers search for pregnancy health information. We examined readability, accuracy and quality of answers to common obstetric anesthesia questions from the popular generative artificial intelligence (AI) chatbots ChatGPT and Bard.
Methods
Twenty questions for generative AI chatbots were derived from frequently asked questions based on professional society, hospital and consumer websites. ChatGPT and Bard were queried in November 2023. Answers were graded for accuracy by four obstetric anesthesiologists. Quality was measured using Patient Education Materials Assessment Tool for Print (PEMAT). Readability was measured using six readability indices. Accuracy, quality and readability were compared using independent t-test.
Results
Bard readability scores were high school level, significantly easier than ChatGPT’s college level by all scoring metrics (P <0.001). Bard had significantly longer answers (P <0.001), yet with similar accuracy of Bard (85% ± 10) and ChatGPT (87% ± 14) (P=0.5). PEMAT understandability scores were no statistically significantly different (P=0.06). Actionability by PEMAT scores for Bard was significantly higher (22% vs. 9%) than ChatGPT (P=0.007)
Conclusion
Answers to questions about “labor epidurals” should be accurate, high quality, and easy to read. Bard at high school reading level, was well above the goal 4th to 6th grade level suggested for patient materials. Consumers, health care providers, hospitals and governmental agencies should be aware of the quality of information generated by chatbots. Chatbots should meet the standards for readability and understandability of health-related questions, to aid public understanding and enhance shared decision-making.}
}
@article{ALKHATIB2024102676,
title = {How can generative artificial intelligence improve digital supply chain performance in manufacturing firms? Analyzing the mediating role of innovation ambidexterity using hybrid analysis through CB-SEM and PLS-SEM},
journal = {Technology in Society},
volume = {78},
pages = {102676},
year = {2024},
issn = {0160-791X},
doi = {https://doi.org/10.1016/j.techsoc.2024.102676},
url = {https://www.sciencedirect.com/science/article/pii/S0160791X24002240},
author = {Ayman wael Al-khatib and Moh'd Anwer AL-Shboul and Mais Khattab},
keywords = {Generative artificial intelligence, Innovation ambidexterity, Digital supply chain, Manufacturing firms, Performance, Hybrid analysis, Jordan},
abstract = {Artificial intelligence capabilities (AIC) can influence supply chain management (SCM) in multiple ways. This study explores how generative artificial intelligence capabilities (GAIC) could affect digital supply chain performance (DSCP) through ambidexterity innovation (AMI), which includes both elements, exploratory and exploitative innovations in the manufacturing firms (MFs) in Jordan as a developing and emerging economy. This study adopted a quantitative methodology for the data collection process applying a cross-sectional approach through testing deductive-hypotheses techniques. 263 valid surveys were used for analysis using hybrid analysis measurements (i.e., PLS-SEM, and CB-SEM). Further, it was applied data reliability, convergent validity, and discriminant validity tests. Additionally, examined the mediating effect of exploratory innovation (EXPI), and exploitative innovation (EXTI) on DSCP. The study findings assured that the proposed direct and indirect causal associations illustrated in the study model were accepted due to that all associations between the dimensions s were statistically significant. The findings of the GAIC supported a positive relationship between GAIC and the DSCP, GAIC on EXPI and EXTI, and EXPI and EXTI on DSCP respectively. Furthermore, the mediating effect of EXPI and EXTI is statistically significant, which was confirmed. This study developed a conceptual model to merge GAIC, AMI, and DSCP. This study provides new outcomes that bridge the existing research gap in the literature by testing the mediation model with a focus on the MF benefits of GAIC to improve levels of EXPI, EXTI, and DSCP in Jordan as a developing and emerging economy. Furthermore, this study is considered unique, as it was the first study in Jordan, and through applying hybrid analysis measurements using both PLS-SEM and CB-SEM methods.}
}
@article{MARZOUK2025118228,
title = {Editorial: Generative Artificial Intelligence for Predictive Simulations and Decision-Making in Science and Engineering},
journal = {Computer Methods in Applied Mechanics and Engineering},
volume = {445},
pages = {118228},
year = {2025},
issn = {0045-7825},
doi = {https://doi.org/10.1016/j.cma.2025.118228},
url = {https://www.sciencedirect.com/science/article/pii/S0045782525005006},
author = {Youssef Marzouk and Benjamin Peherstorfer}
}
@article{WHEATLEY2024102942,
title = {Comparing generative artificial intelligence tools to voice assistants using reference interactions},
journal = {The Journal of Academic Librarianship},
volume = {50},
number = {5},
pages = {102942},
year = {2024},
issn = {0099-1333},
doi = {https://doi.org/10.1016/j.acalib.2024.102942},
url = {https://www.sciencedirect.com/science/article/pii/S0099133324001034},
author = {Amanda Wheatley and Sandy Hervieux},
keywords = {Artificial intelligence, Voice assistants, Generative AI, Reference},
abstract = {This study investigates the ability of voice assistants and generative AI tools to respond to reference questions traditionally received by academic librarians. The authors created a sample of 25 questions based on queries received on the virtual reference service at their institution. They then created a rubric to evaluate the quality of the answers that the AI powered tools provided. The authors determined that the tools understand reference questions well and provide relevant answers but that the quality of the references provided, and the accuracy of the answers can be lacking. They suggest that more research needs to be done to understand the place of AI powered tools in reference services.}
}
@article{SALAH2024101872,
title = {The good, the bad, and the GPT: Reviewing the impact of generative artificial intelligence on psychology},
journal = {Current Opinion in Psychology},
volume = {59},
pages = {101872},
year = {2024},
issn = {2352-250X},
doi = {https://doi.org/10.1016/j.copsyc.2024.101872},
url = {https://www.sciencedirect.com/science/article/pii/S2352250X2400085X},
author = {Mohammed Salah and Fadi Abdelfattah and Hussam {Al Halbusi}},
keywords = {Generative artificial intelligence, Psychology, Ethical considerations, Therapeutic personalization, Natural language processing},
abstract = {This review explores the impact of Generative Artificial Intelligence (GenAI)—a technology capable of autonomously creating new content, ideas, or solutions by learning from extensive data—on psychology. GenAI is changing research methodologies, diagnostics, and treatments by enhancing diagnostic accuracy, personalizing therapeutic interventions, and providing deeper insights into cognitive processes. However, these advancements come with significant ethical concerns, including privacy, bias, and the risk of depersonalization in therapy. By focusing on the current capabilities of GenAI, this study aims to provide a balanced understanding and guide the ethical integration of AI into psychological practices and research. We argue that while GenAI presents profound opportunities, its integration must be approached cautiously using robust ethical frameworks.}
}
@article{BUI2025101392,
title = {Exploring value co-creation and co-destruction between consumers & generative artificial intelligence (GAI) in travel},
journal = {Tourism Management Perspectives},
volume = {58},
pages = {101392},
year = {2025},
issn = {2211-9736},
doi = {https://doi.org/10.1016/j.tmp.2025.101392},
url = {https://www.sciencedirect.com/science/article/pii/S2211973625000571},
author = {Hien Thu Bui and Viachaslau Filimonau and Hakan Sezerel},
keywords = {Emerging technology, Generative artificial intelligence, Travel assistance, Value co-creation, Value co-destruction, ChatGPT},
abstract = {Little is known about the (dis)benefits of using generative artificial intelligence (GAI) with travel-related purposes, which hinders an understanding of the value co-created and co-destructed in the process of its use by tourists. This mixed methods study explored and examined the key factors in value co-creation and co-destruction when using a popular GAI's conversational interface, ChatGPT, in tourism. The results indicate that the key perceived utility of ChatGPT is in travel planning and time saving, and the main perceived shortcomings are its limited knowledge and inaccurate responses. The study pinpoints the importance of refining and developing GAI collaboratively by all tourism stakeholders given that perceived value co-creation outweighs value co-destruction.}
}
@article{KAPLAN2025106080,
title = {New generative artificial intelligence model: ScholarGPT’s performance on dental avulsion},
journal = {International Journal of Medical Informatics},
volume = {204},
pages = {106080},
year = {2025},
issn = {1386-5056},
doi = {https://doi.org/10.1016/j.ijmedinf.2025.106080},
url = {https://www.sciencedirect.com/science/article/pii/S1386505625002977},
author = {Taibe Tokgöz Kaplan},
keywords = {Artificial intelligence, ChatGPT, Dental avulsion, Gemini, Large Language Models, ScholarGPT},
abstract = {Background
This study aims to evaluate the performance of ScholarGPT, a Large Language Model (LLM) developed for academic purposes, on questions related to dental avulsion. In addition, to analyze and compare it with the results of the previous study evaluating the performance of ChatGPT and Gemini.
Method
A total of 22 technical questions (11 multiple-choice questions (MCQs), 11 true/false (T/F)) were posed to the ScholarGPT. ScholarGPT responses were assessed using a modified Global Quality Scale (GQS). Responses were randomized using an online randomizer (www.randomizer.org) before scoring. A single researcher carried out the assessments at three different times, two weeks apart, and a new randomization was performed before each scoring.
Results
When the answers given by ScholarGPT according to the question groups were analyzed by the Mann-Whitney U test, the mean value was found to be 4.64 for MCQ questions and 4.82 for T/F questions. ScholarGPT provided similarly high-quality and consistent answers in both question types (p = 0.590). When the performance of ScholarGPT was compared with Gemini and ChatGPT via the Friedman test, the mean score of ScholarGPT responses was significantly higher than both ChatGPT and Gemini (mean difference with Gemini = 0.75; mean difference with ChatGPT = 1.62, p < 0.001). ScholarGPT produced statistically significantly more consistent and higher-quality responses than ChatGPT and Gemini.
Conclusion
ScholarGPT showed high performance on technical questions related to dental avulsion and produced more consistent and higher-quality answers than ChatGPT and Gemini. According to the findings, LLMs based on academic databases can provide more accurate and reliable information. In the future, through the development of LLMs specific to the branches of dentistry, artificial intelligence systems can produce higher quality and consistent information.}
}
@article{CAMPELLONE2025,
title = {Safety and User Experience of a Generative Artificial Intelligence Digital Mental Health Intervention: Exploratory Randomized Controlled Trial},
journal = {Journal of Medical Internet Research},
volume = {27},
year = {2025},
issn = {1438-8871},
doi = {https://doi.org/10.2196/67365},
url = {https://www.sciencedirect.com/science/article/pii/S1438887125007381},
author = {Timothy R Campellone and Megan Flom and Robert M Montgomery and Lauren Bullard and Maddison C Pirner and Aaron Pavez and Michelle Morales and Devin Harper and Catherine Oddy and Tom O'Connor and Jade Daniels and Stephanie Eaneff and Valerie L Forman-Hoffman and Casey Sackett and Alison Darcy},
keywords = {generative AI, digital mental health intervention, user experience, RCT, randomized, controlled trials, randomized controlled trial, chatbots, artificial intelligence, AI, user relationship, user satisfaction, user safety, user, exploratory, relationship, satisfaction, safety, generative, DMHI, mental health, digital health},
abstract = {Background
General awareness and exposure to generative artificial intelligence (AI) have increased recently. This transformative technology has the potential to create a more dynamic and engaging user experience in digital mental health interventions (DMHIs). However, if not appropriately used and controlled, it can introduce risks to users that may result in harm and erode trust. At the time of conducting this trial, there had not been a rigorous evaluation of an approach to safely implementing generative AI in a DMHI.
Objective
This study aims to explore the user relationship, experience, safety, and technical guardrails of a DMHI using generative AI compared with a rules-based intervention.
Methods
We conducted a 2-week exploratory randomized controlled trial (RCT) with 160 adult participants randomized to receive a generative AI (n=81) or rules-based (n=79) version of a conversation-based DMHI. Self-report measures of the user relationship (client satisfaction, working alliance bond, and accuracy of empathic listening and reflection) and experience (engagement metrics, adverse events, and technical guardrail success) were collected. Descriptions and validation of technical guardrails for handling user inputs (eg, detecting potentially concerning language and off-topic responses) and model outputs (eg, not providing medical advice and not providing a diagnosis) are provided, along with examples to illustrate how they worked. Safety monitoring was conducted throughout the trial for adverse events, and the success of technical guardrails created for the generative arm was assessed post trial.
Results
In general, the majority of measures of user relationship and experience appeared to be similar in both the generative and rules-based arms. The generative arm appeared to be more accurate at detecting and responding to user statements with empathy (98% accuracy vs 69%). There were no serious or device-related adverse events, and technical guardrails were shown to be 100% successful in posttrial review of generated statements. A majority of participants in both groups reported an increase in positive sentiment (62% and 66%) about AI at the end of the trial.
Conclusions
This trial provides initial evidence that, with the right guardrails and process, generative AI can be successfully used in a digital mental health intervention (DMHI) while maintaining the user experience and relationship. It also provides an initial blueprint for approaches to technical and conversational guardrails that can be replicated to build a safe DMHI.
Trial Registration
ClinicalTrials.gov NCT05948670; https://clinicaltrials.gov/study/NCT05948670}
}
@article{NG2025101222,
title = {Prompt engineering for generative artificial intelligence chatbots in health research: A practical guide for traditional, complementary, and integrative medicine researchers},
journal = {Integrative Medicine Research},
volume = {14},
number = {4},
pages = {101222},
year = {2025},
issn = {2213-4220},
doi = {https://doi.org/10.1016/j.imr.2025.101222},
url = {https://www.sciencedirect.com/science/article/pii/S2213422025001027},
author = {Jeremy Y. Ng},
keywords = {AI chatbots, Prompt engineering, Large language models, Generative artificial intelligence},
abstract = {Generative artificial intelligence (GenAI) chatbots powered by large language models (LLMs) are increasingly used in health research to support a range of academic and clinical activities. While increasingly adopted in biomedical research, their application in traditional, complementary, and integrative medicine (TCIM) remains underexplored. TCIM presents unique challenges, including complex interventions, culturally embedded practices, and variable terminology. This article provides a practical, evidence-informed guide to help TCIM researchers engage responsibly with GenAI chatbots through prompt engineering, the design of clear, structured, and purposeful prompts to improve output relevance and accuracy. The guide outlines strategies to tailor GenAI chatbot interactions to the methodological and epistemological diversity of TCIM. It presents use cases across the research process, including research question development, study design, literature searches, selection of reporting guidelines and appraisal tools, quantitative and qualitative analysis, writing and dissemination, and implementation planning. For each stage, the guide offers examples and best practices while emphasizing that AI-generated content should always serve as a starting point, not a final product, and must be reviewed and verified using credible sources. Potential risks such as hallucinated outputs, embedded bias, and ethical challenges are discussed, particularly in culturally sensitive contexts. Transparency in GenAI chatbot use and researcher accountability are emphasized as essential principles. While GenAI chatbots can expand access to research support and foster innovation in TCIM, they cannot substitute for critical thinking, methodological rigour, or domain-specific expertise. Used responsibly, GenAI chatbots can augment human judgment and contribute meaningfully to the evolution of TCIM scholarship.}
}
@article{SOLORZANOREQUEJO2024102157,
title = {Fostering creativity in engineering design through constructive dialogues with generative artificial intelligence},
journal = {Cell Reports Physical Science},
volume = {5},
number = {9},
pages = {102157},
year = {2024},
issn = {2666-3864},
doi = {https://doi.org/10.1016/j.xcrp.2024.102157},
url = {https://www.sciencedirect.com/science/article/pii/S2666386424004429},
author = {William {Solórzano Requejo} and Francisco {Franco Martínez} and Carlos {Aguilar Vega} and Rodrigo {Zapata Martínez} and Adrián {Martínez Cendrero} and Andrés {Díaz Lantada}},
keywords = {artificial intelligence, engineering design, creativity promotion, biohybrid materials, medical devices, product design, architected materials: architectural structures},
abstract = {Summary
Artificial intelligence (AI) is progressively reshaping the way that researchers design and study highly complex systems. In this perspective, we introduce an engineering design methodology aimed at fostering creativity through “constructive dialogues with a generative AI” and exemplify its potential through a set of methodically developed case studies. This creativity promotion approach starts with computer-aided design (CAD) models of lattices, metamaterials, and architected materials, which are provided as initial inputs to a generative AI through a chat. Then, the conversation starts with researchers asking the generative AI to modify the provided CAD model images by incorporating new elements, placing them in quasi-real-life environments, or adapting the provided designs to the structures of new products. To illustrate the methodology, a varied set of selected case studies of constructive dialogues leading to highly innovative designs are provided, bridging the gap between tissue engineering scaffolds and building architectures, biohybrid materials and product design, and innovative structures and medical devices, to cite a few.}
}
@article{BARAKCORREN2025102242,
title = {From Text to Data: Automatically Extracting Data From Catheterization Reports Using Generative Artificial Intelligence},
journal = {Journal of the Society for Cardiovascular Angiography & Interventions},
volume = {4},
number = {3, Part B},
pages = {102242},
year = {2025},
note = {The Role of Artificial Intelligence in Cardiovascular Interventions},
issn = {2772-9303},
doi = {https://doi.org/10.1016/j.jscai.2024.102242},
url = {https://www.sciencedirect.com/science/article/pii/S2772930324016247},
author = {Yuval Barak-Corren and Mudit Gupta and Jessica Tang and Christopher L. Smith and Ryan Callahan and Yoav Dori and Jonathan J. Rome and Matthew J. Gillespie and Michael L. O’Byrne},
keywords = {artificial intelligence, generative artificial intelligence, health informatics, interventional cardiology, natural language processing, pediatric cardiology}
}
@article{MESSER2025100108,
title = {How do people react to political bias in generative artificial intelligence (AI)?},
journal = {Computers in Human Behavior: Artificial Humans},
volume = {3},
pages = {100108},
year = {2025},
issn = {2949-8821},
doi = {https://doi.org/10.1016/j.chbah.2024.100108},
url = {https://www.sciencedirect.com/science/article/pii/S2949882124000689},
author = {Uwe Messer},
keywords = {Artificial intelligence, Alignment, Political orientation, Bias, Acceptance, Large language model},
abstract = {Generative Artificial Intelligence (GAI) such as Large Language Models (LLMs) have a concerning tendency to generate politically biased content. This is a challenge, as the emergence of GAI meets politically polarized societies. Therefore, this research investigates how people react to biased GAI-content based on their pre-existing political beliefs and how this influences the acceptance of GAI. In three experiments (N = 513), it was found that perceived alignment between user's political orientation and bias in generated content (in text and images) increases acceptance and reliance on GAI. Participants who perceived alignment were more likely to grant GAI access to sensitive smartphone functions and to endorse the use in critical domains (e.g., loan approval; social media moderation). Because users see GAI as a social actor, they consider perceived alignment as a sign of greater objectivity, thus granting aligned GAI access to more sensitive areas.}
}
@article{CURRIE2025103,
title = {Gender bias in text-to-image generative artificial intelligence depiction of Australian paramedics and first responders},
journal = {Australasian Emergency Care},
volume = {28},
number = {2},
pages = {103-109},
year = {2025},
issn = {2588-994X},
doi = {https://doi.org/10.1016/j.auec.2024.11.003},
url = {https://www.sciencedirect.com/science/article/pii/S2588994X24000757},
author = {Geoffrey Currie and Johnathan Hewis and Phillip Ebbs},
keywords = {First responder, Generative artificial intelligence, Diversity, Inclusivity},
abstract = {Introduction
In Australia, almost 50 % of paramedics are female yet they remain under-represented in stereotypical depictions of the profession. The potentially transformative value of generative artificial intelligence (AI) may be limited by stereotypical errors, misrepresentations and bias. Increasing use of text-to-image generative AI, like DALL-E 3, could reinforce gender and ethnicity biases and, therefore, is important to objectively evaluate.
Method
In March 2024, DALL-E 3 was utilised via GPT-4 to generate a series of individual and group images of Australian paramedics, ambulance officers, police officers and firefighters. In total, 82 images were produced including 60 individual-character images, and 22 multiple-character group images. All 326 depicted characters were independently analysed by three reviewers for apparent gender, age, skin tone and ethnicity.
Results
Among first responders, 90.8 % (N = 296) were depicted as male, 90.5 % (N = 295) as Caucasian, 95.7 % (N = 312) as a light skin tone, and 94.8 % (N = 309) as under 55 years of age. For paramedics and police the gender distribution was a statistically significant variation from that of actual Australian workforce data (all p < 0.001). Among the images of individual paramedics and ambulance officers (N = 32), DALL-E 3 depicted 100 % as male, 100 % as Caucasian and 100 % with light skin tone.
Conclusion
Gender and ethnicity bias is a significant limitation for text-to-image generative AI using DALL-E 3 among Australian first responders. Generated images have a disproportionately high misrepresentation of males, Caucasians and light skin tones that are not representative of the diversity of paramedics in Australia today.}
}
@article{GARCIAMORENO2025113415,
title = {Artificial intelligence-aided generative design of non-imaging secondary reflector for linear Fresnel concentrating collector},
journal = {Solar Energy},
volume = {292},
pages = {113415},
year = {2025},
issn = {0038-092X},
doi = {https://doi.org/10.1016/j.solener.2025.113415},
url = {https://www.sciencedirect.com/science/article/pii/S0038092X25001781},
author = {Jorge Moreno García-Moreno and Alaric Christian Montenon and Mihalis A. Nicolaou and Wojciech Lipiński and Kypros Milidonis},
keywords = {Concentrated solar thermal, Non-imaging optics, Linear Fresnel reflector, Artificial intelligence, Generative design, NSGA-II},
abstract = {In this article, an AI-aided generative design workflow is presented for the geometrical optimisation of secondary reflectors of linear Fresnel concentrating collectors. The geometry of the secondary reflector is based on principles of non-imaging optics, for which the exact analytical solution is derived for a specific linear Fresnel system acting as a validation test case. The artificial intelligence-aided generative design workflow is then applied on the same system and the optimal geometry generated is compared against the analytical solution. It is shown that the secondary reflector geometry obtained from the artificial intelligence-aided generative design workflow approaches the shape of the one obtained using the analytical solution and can outperform the latter with respect to the magnitude of radiative power intercepted by the receiver and radiative flux distribution at the receiver aperture.}
}
@article{COHEN2025111646,
title = {Generative artificial intelligence and academic writing: friend or foe?},
journal = {Journal of Clinical Epidemiology},
volume = {179},
pages = {111646},
year = {2025},
issn = {0895-4356},
doi = {https://doi.org/10.1016/j.jclinepi.2024.111646},
url = {https://www.sciencedirect.com/science/article/pii/S0895435624004025},
author = {Jérémie F. Cohen and David Moher},
keywords = {Artificial Intelligence, Large language models, Medical writing, Publication ethics, Research ethics, Research integrity},
abstract = {This viewpoint examines the use of generative AI models in medical writing, discusses the opportunities and threats they represent, and highlights avenues for improvement and future research.}
}
@article{SOLAIMAN2024102028,
title = {Generative artificial intelligence (GenAI) and decision-making: Legal & ethical hurdles for implementation in mental health},
journal = {International Journal of Law and Psychiatry},
volume = {97},
pages = {102028},
year = {2024},
issn = {0160-2527},
doi = {https://doi.org/10.1016/j.ijlp.2024.102028},
url = {https://www.sciencedirect.com/science/article/pii/S0160252724000773},
author = {Barry Solaiman},
keywords = {Generative artificial intelligence (GenAI), Mental health, Psychiatry, Ethics, Law, Healthcare},
abstract = {This article argues that significant risks are being taken with using GenAI in mental health that should be assessed urgently. It recommends that guidelines for using generative artificial intelligence (GenAI) in mental health care must be established promptly. Currently, clinicians using chatbots without appropriate approval risk undermining legal protections for patients. This could harm the patient and undermine the standards of the profession, undermining trust in an area where human involvement in decision-making is critical. To explore these concerns, this paper is divided into three parts. First, it examines the needs of patients in mental health. Second, it explores the potential benefits of GenAI in mental health and highlights the risks of its use as it pertains to patient needs. Third, it notes the ethical and legal concerns around data use and medical liability that require careful attention. The impact of the European Union's (EU) Artificial Intelligence Act (AI-Act) is also considered. It will be seen that these laws are insufficient in the context of mental health. As such, the paper recommends that guidelines should be developed to help resolve the existing legal gaps until codified rules are established.}
}
@article{HIROSAWA2025,
title = {Utility of Generative Artificial Intelligence for Japanese Medical Interview Training: Randomized Crossover Pilot Study},
journal = {JMIR Medical Education},
volume = {11},
year = {2025},
issn = {2369-3762},
doi = {https://doi.org/10.2196/77332},
url = {https://www.sciencedirect.com/science/article/pii/S2369376225000996},
author = {Takanobu Hirosawa and Masashi Yokose and Tetsu Sakamoto and Yukinori Harada and Kazuki Tokumasu and Kazuya Mizuta and Taro Shimizu},
keywords = {artificial intelligence, generative artificial intelligence, medical interview training, mock patient, simulation education},
abstract = {Background
The medical interview remains a cornerstone of clinical training. There is growing interest in applying generative artificial intelligence (AI) in medical education, including medical interview training. However, its utility in culturally and linguistically specific contexts, including Japanese, remains underexplored. This study investigated the utility of generative AI for Japanese medical interview training.
Objective
This pilot study aimed to evaluate the utility of generative AI as a tool for medical interview training by comparing its performance with that of traditional face-to-face training methods using a simulated patient.
Methods
We conducted a randomized crossover pilot study involving 20 postgraduate year 1‐2 physicians from a university hospital. Participants were randomly allocated into 2 groups. Group A began with an AI-based station on a case involving abdominal pain, followed by a traditional station with a standardized patient presenting chest pain. Group B followed the reverse order, starting with the traditional station for abdominal pain and subsequently within the AI-based station for the chest pain scenario. In the AI-based stations, participants interacted with a GPT-configured platform that simulated patient behaviors. GPTs are customizable versions of ChatGPT adapted for specific purposes. The traditional stations involved face-to-face interviews with a simulated patient. Both groups used identical, standardized case scenarios to ensure uniformity. Two independent evaluators, blinded to the study conditions, assessed participants’ performances using 6 defined metrics: patient care and communication, history taking, physical examination, accuracy and clarity of transcription, clinical reasoning, and patient management. A 6-point Likert scale was used for scoring. The discrepancy between the evaluators was resolved through discussion. To ensure cultural and linguistic authenticity, all interviews and evaluations were conducted in Japanese.
Results
AI-based stations scored lower across most categories, particularly in patient care and communication, than traditional stations (4.48 vs 4.95; P=.009). However, AI-based stations demonstrated comparable performance in clinical reasoning, with a nonsignificant difference (4.43 vs 4.85; P=.10).
Conclusions
The comparable performance of generative AI in clinical reasoning highlights its potential as a complementary tool in medical interview training. One of its main advantages lies in enabling self-learning, allowing trainees to independently practice interviews without the need for simulated patients. Nonetheless, the lower scores in patient care and communication underline the importance of maintaining traditional methods that capture the nuances of human interaction. These findings support the adoption of hybrid training models that combine generative AI with conventional approaches to enhance the overall effectiveness of medical interview training in Japan.
Trial Registration
UMIN-CTR UMIN000053747; https://center6.umin.ac.jp/cgi-open-bin/ctr_e/ctr_view.cgi?recptno=R000061336}
}
@article{REASON2025,
title = {The “Artificial Intelligence Statistician”: Utilizing Generative Artificial Intelligence to Select an Appropriate Model and Execute Network Meta-Analyses},
journal = {Value in Health},
year = {2025},
issn = {1098-3015},
doi = {https://doi.org/10.1016/j.jval.2025.08.001},
url = {https://www.sciencedirect.com/science/article/pii/S1098301525025112},
author = {Tim Reason and Yunchou Wu and Cheryl Jones and Emma Benbow and Kasper Johannesen and Bill Malcolm},
keywords = {automated analysis, health technology assessment (HTA), joint clinical assessments (JCAs), large language models (LLMs), network meta-analysis (NMA)},
abstract = {Objectives
This exploratory study aimed to develop a large language model (LLM)-based process to automate components of network meta-analysis (NMA), including model selection, analysis, output evaluation, and results interpretation. Automating these tasks with LLMs can enhance efficiency, consistency, and scalability in health economics and outcomes research, while ensuring that analyses adhere to established guidelines required by health technology assessment agencies. Improvements in efficiency and scalability may potentially become relevant as the European Union Health Technology Assessment Regulation comes into force, given anticipated analysis requirements and timelines.
Methods
Using Claude 3.5 Sonnet (V2), a process was designed to automate statistical model selection, NMA output evaluation, and results interpretation based on an “analysis-ready” data set. Validation was assessed by replicating examples from the National Institute for Health and Care Excellence Technical Support Document (TSD2), replicating results of non-Decision Support Unit-published NMAs, and generating comprehensive outputs (eg, heterogeneity, inconsistency, and convergence).
Results
The automated LLM-based process produced accurate results. Compared with TSD2 examples, differences were minimal, within expectations (given differences in sampling frameworks used), and comparable to those observed between estimates produced by the R vignettes against TSD2. Similar consistency was noted for non-Decision Support Unit-published NMA examples. Additionally, the LLM process generated and interpreted comprehensive NMA outputs.
Conclusions
This exploratory study demonstrates the feasibility of LLMs to automate key components of NMAs, determining the requisite NMA framework based only on input data. Further exploring these capabilities could clarify their role in streamlining NMA workflows.}
}
@article{RASHIDI2025100687,
title = {Generative Artificial Intelligence in Pathology and Medicine: A Deeper Dive},
journal = {Modern Pathology},
volume = {38},
number = {4},
pages = {100687},
year = {2025},
issn = {0893-3952},
doi = {https://doi.org/10.1016/j.modpat.2024.100687},
url = {https://www.sciencedirect.com/science/article/pii/S0893395224002679},
author = {Hooman H. Rashidi and Joshua Pantanowitz and Alireza Chamanzar and Brandon Fennell and Yanshan Wang and Rama R. Gullapalli and Ahmad Tafti and Mustafa Deebajah and Samer Albahra and Eric Glassy and Matthew G. Hanna and Liron Pantanowitz},
keywords = {ChatGPT, diffusion, generative adversarial network, generative artificial intelligence, generative pretrained transformer, multiagent},
abstract = {This review article builds upon the introductory piece in our 7-part series, delving deeper into the transformative potential of generative artificial intelligence (Gen AI) in pathology and medicine. The article explores the applications of Gen AI models in pathology and medicine, including the use of custom chatbots for diagnostic report generation, synthetic image synthesis for training new models, data set augmentation, hypothetical scenario generation for educational purposes, and the use of multimodal along with multiagent models. This article also provides an overview of the common categories within Gen AI models, discussing open-source and closed-source models, as well as specific examples of popular models such as GPT-4, Llama, Mistral, DALL-E, Stable Diffusion, and their associated frameworks (eg, transformers, generative adversarial networks, diffusion-based neural networks), along with their limitations and challenges, especially within the medical domain. We also review common libraries and tools that are currently deemed necessary to build and integrate such models. Finally, we look to the future, discussing the potential impact of Gen AI on health care, including benefits, challenges, and concerns related to privacy, bias, ethics, application programming interface costs, and security measures.}
}
@article{KHANIFAR2025100069,
title = {Generative artificial intelligence in soil science},
journal = {Soil Advances},
volume = {4},
pages = {100069},
year = {2025},
issn = {2950-2896},
doi = {https://doi.org/10.1016/j.soilad.2025.100069},
url = {https://www.sciencedirect.com/science/article/pii/S2950289625000375},
author = {Javad Khanifar}
}
@article{DUAN2025103719,
title = {The transformative roles of generative artificial intelligence in vision techniques for structural health monitoring: A state-of-the-art review},
journal = {Advanced Engineering Informatics},
volume = {68},
pages = {103719},
year = {2025},
issn = {1474-0346},
doi = {https://doi.org/10.1016/j.aei.2025.103719},
url = {https://www.sciencedirect.com/science/article/pii/S1474034625006123},
author = {Shundi Duan and Xiao Tan and Pengwei Guo and Yurong Guo and Yi Bao},
keywords = {Generative artificial intelligence, Structural health monitoring, Image restoration, Data augmentation, Multi-modal generative AI, Large language model},
abstract = {As urbanization accelerates, aging infrastructure demands more advanced inspection methods for structural health monitoring. The growing integration of artificial intelligence (AI) and computer vision technologies has significantly enhanced damage detection accuracy while simultaneously reducing inspection time and operational costs. Despite these advantages, the adoption of AI-based technologies in infrastructure maintenance remains limited due to challenges related to data. One major issue is the lack of comprehensive, task-specific annotated datasets. Another is the poor quality of images captured by drones or mobile devices, which are often affected by noise, blurring, and inconsistent lighting. Although recent advances in generative AI offer promising support for structural health monitoring, it remains unclear which models are best suited for specific tasks. This study examines the use of generative AI in structural health monitoring, focusing on key challenges such as limited datasets and low-quality image restoration. The review covers a range of generative AI technologies, outlining their principles, strengths, limitations, and representative applications to support the selection of appropriate tools for specific tasks. Generative AI models enable accurate image segmentation and structural anomaly detection using limited training data. The paper also explores new opportunities for integrating multi-modal generative AI to enhance human–computer interaction in support of structural health monitoring. A framework is proposed to streamline the use of generative AI technologies for data augmentation, image restoration, damage inspection, and human–computer interaction in structural health monitoring.}
}
@article{FLEURENCE2025175,
title = {Generative Artificial Intelligence for Health Technology Assessment: Opportunities, Challenges, and Policy Considerations: An ISPOR Working Group Report},
journal = {Value in Health},
volume = {28},
number = {2},
pages = {175-183},
year = {2025},
issn = {1098-3015},
doi = {https://doi.org/10.1016/j.jval.2024.10.3846},
url = {https://www.sciencedirect.com/science/article/pii/S1098301524067548},
author = {Rachael L. Fleurence and Jiang Bian and Xiaoyan Wang and Hua Xu and Dalia Dawoud and Mitchell Higashi and Jagpreet Chhatwal},
keywords = {artificial intelligence, economic modeling methods, generative AI, large language models, real world evidence, systematic reviews},
abstract = {Objectives
To provide an introduction to the uses of generative artificial intelligence (AI) and foundation models, including large language models, in the field of health technology assessment (HTA).
Methods
We reviewed applications of generative AI in 3 areas: systematic literature reviews, real-world evidence, and health economic modeling.
Results
(1) Literature reviews: generative AI has the potential to assist in automating aspects of systematic literature reviews by proposing search terms, screening abstracts, extracting data, and generating code for meta-analyses; (2) real-world evidence: generative AI can facilitate automating processes and analyze large collections of real-world data, including unstructured clinical notes and imaging; (3) health economic modeling: generative AI can aid in the development of health economic models, from conceptualization to validation. Limitations in the use of foundation models and large language models include challenges surrounding their scientific rigor and reliability, the potential for bias, implications for equity, as well as nontrivial concerns regarding adherence to regulatory and ethical standards, particularly in terms of data privacy and security. Additionally, we survey the current policy landscape and provide suggestions for HTA agencies on responsibly integrating generative AI into their workflows, emphasizing the importance of human oversight and the fast-evolving nature of these tools.
Conclusions
Although generative AI technology holds promise with respect to HTA applications, it is still undergoing rapid developments and improvements. Continued careful evaluation of their applications to HTA is required. Both developers and users of research incorporating these tools, should familiarize themselves with their current capabilities and limitations.}
}
@article{TADOKORO2025663,
title = {On the effective co-creation of CAD models by leveraging generative artificial intelligence},
journal = {Procedia CIRP},
volume = {134},
pages = {663-668},
year = {2025},
note = {58th CIRP Conference on Manufacturing Systems 2025},
issn = {2212-8271},
doi = {https://doi.org/10.1016/j.procir.2025.02.181},
url = {https://www.sciencedirect.com/science/article/pii/S2212827125005608},
author = {Fuwa Tadokoro and Angkush Kumar Ghosh and Sharifu Ura},
keywords = {Computer-Aided Design, Generative Artificial Intelligence, Co-creation, Prompt Tuning, Modular Decomposition, Information, Complexity},
abstract = {Collaboration between humans and generative artificial intelligence (GenAI) can result in effective problem-solving methods for smart manufacturing. From this point of view, this study presents how to solve computer-aided design (CAD) problems using GenAI-human collaboration, where a GenAI tool generates structured code (syntax) for CAD while a designer articulates the design intent (semantics). The focus is to see how the information type, model complexity, and prompt structure collectively affect the collaboration. A set of case studies demonstrate that a modular modeling approach with low-level information improves prompt efficiency and modeling accuracy, especially in complex scenarios. This strategy also enables novice and expert users to collaborate with GenAI in solving challenging real-world CAD tasks effectively. The findings support the development of advanced human-AI co-creation systems and encourage future research in areas such as reverse engineering, multi-part assemblies, and collaborative CAD workflows coupled with complex design constraints.}
}
@article{CHENG2025101497,
title = {Online reviews generated by generative artificial intelligence versus human: A study of perceived differences and user adoption behavior},
journal = {Electronic Commerce Research and Applications},
volume = {71},
pages = {101497},
year = {2025},
issn = {1567-4223},
doi = {https://doi.org/10.1016/j.elerap.2025.101497},
url = {https://www.sciencedirect.com/science/article/pii/S1567422325000225},
author = {Xusen Cheng and Ang Zeng and Bo Yang and Yu Liu and Xiaoping Zhang},
keywords = {generative artificial intelligence (GAI), GAI-generated reviews, human-generated reviews, willingness to use GAI},
abstract = {Companies in various industries are attempting to integrate Generative Artificial Intelligence (GAI) into their existing businesses. In the e-commerce domain, GAI has shown tremendous potential in generating online reviews. However, existing literature has paid less attention to how consumers respond to GAI-generated reviews versus human-generated reviews. Moreover, little research has explored whether and why consumers are willing to use GAI to generate online reviews. By conducting two experiments, this study investigates how consumers respond differently to GAI-generated reviews versus human-generated reviews and identifies potential factors that influence consumers’ willingness to use GAI to generate reviews. Findings indicate that although there is no significant difference in consumers’ perceptions between human-generated and GAI-generated reviews in terms of review credibility, review richness, and review usefulness, only half of the participants are willing to use GAI to generate reviews. Further analysis results suggest that individuals who consider GAI unethical tend to avoid using GAI. Those with high personal innovativeness are more willing to use GAI to generate online reviews. Our findings deepen the understanding of consumer attitudes toward GAI-generated reviews and provide implications for the deployment of GAI in the online review system.}
}
@article{DEEB20241724,
title = {The emerging role of generative artificial intelligence in transplant medicine},
journal = {American Journal of Transplantation},
volume = {24},
number = {10},
pages = {1724-1730},
year = {2024},
issn = {1600-6135},
doi = {https://doi.org/10.1016/j.ajt.2024.06.009},
url = {https://www.sciencedirect.com/science/article/pii/S1600613524003824},
author = {Maya Deeb and Anirudh Gangadhar and Madhumitha Rabindranath and Khyathi Rao and Michael Brudno and Aman Sidhu and Bo Wang and Mamatha Bhat},
keywords = {artificial intelligence, deep learning, generative adversarial networks, large language models, machine learning, natural language processing, variational autoencoders},
abstract = {Generative artificial intelligence (AI), a subset of machine learning that creates new content based on training data, has witnessed tremendous advances in recent years. Practical applications have been identified in health care in general, and there is significant opportunity in transplant medicine for generative AI to simplify tasks in research, medical education, and clinical practice. In addition, patients stand to benefit from patient education that is more readily provided by generative AI applications. This review aims to catalyze the development and adoption of generative AI in transplantation by introducing basic AI and generative AI concepts to the transplant clinician and summarizing its current and potential applications within the field. We provide an overview of applications to the clinician, researcher, educator, and patient. We also highlight the challenges involved in bringing these applications to the bedside and need for ongoing refinement of generative AI applications to sustainably augment the transplantation field.}
}
@article{PARK2024428,
title = {Generative artificial intelligence in nursing: A scoping review},
journal = {Collegian},
volume = {31},
number = {6},
pages = {428-436},
year = {2024},
issn = {1322-7696},
doi = {https://doi.org/10.1016/j.colegn.2024.10.004},
url = {https://www.sciencedirect.com/science/article/pii/S1322769624000696},
author = {Ga Eun Park and Hyeryeon Kim and U Ri Go},
keywords = {Generative artificial intelligence, Artificial intelligence, ChatGPT, Nursing, Nurses, Healthcare, Machine learning},
abstract = {ABSTRACT
Background
Generative artificial intelligence (AI) is rapidly transforming multiple sectors, with significant potential to revolutionise nursing through advancements in education, practice, and research. However, the application of generative AI in nursing remains underexplored, highlighting the need for a comprehensive review of its current impact and future implications.
Aim
To investigate the current state and implications of generative AI in nursing education, practice, and research.
Methods
This scoping review was conducted following the methodological frameworks of Arksey and O’Malley, refined by Levac and colleagues. The databases searched for articles published between January 2020 and April 2024 included PubMed, Embase, CINAHL, PsycINFO, Cochrane Library, and IEEE Xplore.
Findings
A total of 4858 articles were identified, with 23 included in this review. Most of the selected studies were published in 2024 (n = 19/23), primarily conducted in the United States (n = 8/23), and largely consisted of quantitative descriptive studies (n = 14/22). ChatGPT was the most frequently used tool, appearing in 95.7% of the studies (n = 22/23). The articles addressed various nursing domains, including nursing education (n = 12/23), practice (n = 10/23), and research (n = 1/23). Both the benefits and concerns associated with this technology were identified.
Discussion
Generative AI shows great promise for transforming nursing education, practice, and research; however, its integration is still in the early stages.
Conclusion
To fully leverage the benefits of generative AI, nursing professionals must address the challenges associated with AI and lead its ethical adoption. Rigorous research and proactive leadership are crucial to realising the potential of generative AI in nursing.}
}
@article{ALBUSAIDI2024100630,
title = {Redefining boundaries in innovation and knowledge domains: Investigating the impact of generative artificial intelligence on copyright and intellectual property rights},
journal = {Journal of Innovation & Knowledge},
volume = {9},
number = {4},
pages = {100630},
year = {2024},
issn = {2444-569X},
doi = {https://doi.org/10.1016/j.jik.2024.100630},
url = {https://www.sciencedirect.com/science/article/pii/S2444569X24001690},
author = {Adil S. Al-Busaidi and Raghu Raman and Laurie Hughes and Mousa Ahmed Albashrawi and Tegwen Malik and Yogesh K. Dwivedi and Thuraiya {Al- Alawi} and Mohammed AlRizeiqi and Gareth Davies and Mark Fenwick and Parul Gupta and Shashikala Gurpur and Apeksha Hooda and Paulius Jurcys and Daryl Lim and Nicola Lucchi and Tanvi Misra and Ramakrishnan Raman and Anuragini Shirish and Paul Walton},
keywords = {ChatGPT, Generative artificial intelligence, GenAI, Generative scholar, Innovation, Intellectual property (IP) Risks, Large language models (LLMs), Misuse case analysis, Personality rights},
abstract = {The rapid integration of generative AI (GenAI) into industries and society has prompted a re-evaluation of copyright and intellectual property rights (IPR) frameworks. GenAI's ability to produce original content using data from human-created sources raises critical ethical and legal concerns. Current copyright and IPR frameworks, designed around human authorship, are insufficient to address these challenges. This study, using a multi-perspective approach, explores GenAI's disruptive potential in replicating or transforming copyrighted materials, challenging established IPR norms. Findings highlight gaps in legislation and the opacity of GenAI platforms. To address these issues, this study presents a Dynamic Ethical Framework linked to a future global fair use policy, aiming to guide responsible GenAI development and use. By incorporating insights from domain experts, this study contextualizes emerging challenges and potential solutions within broader societal and technological trends. That said, this study calls for international collaboration and further research to reform IPR related laws and frameworks, ensuring they remain relevant and equitable in a GenAI-driven era.}
}
@article{LIU20251202,
title = {Environmental Assessment and Improvement of Factory Building Designs based on Generative Artificial Intelligence},
journal = {Procedia CIRP},
volume = {135},
pages = {1202-1207},
year = {2025},
note = {32nd CIRP Conference on Life Cycle Engineering (LCE2025)},
issn = {2212-8271},
doi = {https://doi.org/10.1016/j.procir.2024.12.119},
url = {https://www.sciencedirect.com/science/article/pii/S2212827125004184},
author = {Shengyu Liu and Sipke Hoekstra and Sebastian Thiede},
keywords = {Generative Artificial Intelligence, Life Cycle Assessment, Factory},
abstract = {The paper explores an innovative approach to evaluate the environmental impact of factory buildings at early design stages. Generative design, a cutting-edge computational technique, is employed to generate multiple factory building design alternatives based on user and case specific boundary conditions, e.g. related to material flow and space restrictions. This paper aims to integrate generative design principles with environmental assessment metrics to improve factory buildings for minimal environmental footprint, e.g. driven through energy demand. Thus, a framework that combines the generative factory design approach with key environmental assessment parameters is introduced. The effectiveness of generative design in enhancing the environmental performance of factory buildings is demonstrated with a case study. A comparative analysis of different designs highlights main influencing factors, as well as trade-offs and synergies between different manufacturing system performances and environmental oriented objectives. With that, the paper underlines the value of generative design as a transformative tool in sustainable factory design and provides actionable insights for architects, engineers, and policymakers aiming to develop greener industrial facilities.}
}
@article{LIEBSCHER2025e106,
title = {Testing the Implementation and Acceptance of Generative Artificial Intelligence to Augment Vascular Surgery Journal Club},
journal = {Journal of Vascular Surgery},
volume = {82},
number = {4},
pages = {e106},
year = {2025},
issn = {0741-5214},
doi = {https://doi.org/10.1016/j.jvs.2025.06.096},
url = {https://www.sciencedirect.com/science/article/pii/S0741521425014764},
author = {Sean Liebscher and Rhea Puthumana and Mead Ferris and Daniel Bertges}
}
@article{KONG2024100328,
title = {Examining teachers’ behavioural intention of using generative artificial intelligence tools for teaching and learning based on the extended technology acceptance model},
journal = {Computers and Education: Artificial Intelligence},
volume = {7},
pages = {100328},
year = {2024},
issn = {2666-920X},
doi = {https://doi.org/10.1016/j.caeai.2024.100328},
url = {https://www.sciencedirect.com/science/article/pii/S2666920X24001310},
author = {Siu Cheung Kong and Yin Yang and Chunyu Hou},
keywords = {Artificial intelligence literacy, Generative artificial intelligence tools, Teacher development, Teaching and learning, Extended technology acceptance model},
abstract = {The rapid development of generative artificial intelligence (GenAI) tools has given rise to a growing discussion of the potential challenges and benefits that the use of these technologies may present in the field of education. This study examines the acceptance of the use of GenAI tools for teaching and learning among primary and secondary school teachers in Hong Kong. It uses an extension of the technology acceptance model (TAM) with a modified framework that incorporates two key factors: self-efficacy and subjective norm. Data were collected from a sample of 367 primary and secondary school teachers in Hong Kong using questionnaires containing items for six constructs: self-efficacy, perceived usefulness, perceived ease of use, attitude towards using, subjective norm, and behavioural intention. The results show that fostering teachers' self-efficacy, perceived usefulness, and attitude is essential for successfully increasing their behavioural intention to use GenAI tools. Subjective norm was also found to influence teachers' behavioural intention. To enhance teachers' effective use of GenAI for teaching, teacher development programmes should focus on equipping teachers with comprehensive conceptual knowledge and skills and an understanding of the application of these tools to teaching and learning. Policy support to create a conducive environment for the use of GenAI in teaching and learning would also be beneficial. The study has theoretical implications in its extension of the TAM model as well as implications for enhancing teachers’ AI literacy and developing pedagogies for the meaningful use of GenAI tools for teaching and learning in K–12 settings.}
}
@article{RASHIDI2025100663,
title = {Statistics of Generative Artificial Intelligence and Nongenerative Predictive Analytics Machine Learning in Medicine},
journal = {Modern Pathology},
volume = {38},
number = {3},
pages = {100663},
year = {2025},
issn = {0893-3952},
doi = {https://doi.org/10.1016/j.modpat.2024.100663},
url = {https://www.sciencedirect.com/science/article/pii/S0893395224002436},
author = {Hooman H. Rashidi and Bo Hu and Joshua Pantanowitz and Nam Tran and Silvia Liu and Alireza Chamanzar and Mert Gur and Chung-Chou H. Chang and Yanshan Wang and Ahmad Tafti and Liron Pantanowitz and Matthew G. Hanna},
keywords = {BiLingual Evaluation Understudy, accuracy, precision, F1 score, receiver operating characteristic area under the curve, perplexity},
abstract = {The rapidly evolving landscape of artificial intelligence (AI) and machine learning (ML) in medicine has prompted medical professionals to increasingly familiarize themselves with related topics. This also demands grasping the underlying statistical principles that govern their design, validation, and reproducibility. Uniquely, the practice of pathology and medicine produces vast amount of data that can be exploited by AI/ML. The emergence of generative AI, especially in the area of large language models and multimodal frameworks, represents approaches that are starting to transform medicine. Fundamentally, generative and traditional (eg, nongenerative predictive analytics) ML techniques rely on certain common statistical measures to function. However, unique to generative AI are metrics such as, but not limited to, perplexity and BiLingual Evaluation Understudy score that provide a means to determine the quality of generated samples that are typically unfamiliar to most medical practitioners. In contrast, nongenerative predictive analytics ML often uses more familiar metrics tailored to specific tasks as seen in the typical classification (ie, confusion metrics measures, such as accuracy, sensitivity, F1 score, and receiver operating characteristic area under the curve) or regression studies (ie, root mean square error and R2). To this end, the goal of this review article (as part 4 of our AI review series) is to provide an overview and a comparative measure of statistical measures and methodologies used in both generative AI and traditional (ie, nongenerative predictive analytics) ML fields along with their strengths and known limitations. By understanding their similarities and differences along with their respective applications, we will become better stewards of this transformative space, which ultimately enables us to better address our current and future needs and challenges in a more responsible and scientifically sound manner.}
}
@article{JANG2024102175,
title = {When, What, and how should generative artificial intelligence explain to Users?},
journal = {Telematics and Informatics},
volume = {93},
pages = {102175},
year = {2024},
issn = {0736-5853},
doi = {https://doi.org/10.1016/j.tele.2024.102175},
url = {https://www.sciencedirect.com/science/article/pii/S0736585324000790},
author = {Soobin Jang and Haeyoon Lee and Yujin Kim and Daeho Lee and Jungwoo Shin and Jungwoo Nam},
keywords = {Generative AI, Conversational user interface, Explainable AI, Conjoint analysis},
abstract = {With the commercialization of ChatGPT, generative artificial intelligence (AI) has been applied almost everywhere in our lives. However, even though generative AI has become a daily technology that anyone can use, most non-majors need to know the process and reason for the results because it can be misused due to lack of sufficient knowledge and misunderstanding. Therefore, this study investigated users’ preferences for when, what, and how generative AI should provide explanations about the process of generating and the reasoning behind the results, using conjoint method and mixed logit analysis. The results show that users are most sensitive to the timing of providing eXplainable AI (XAI), and that users want additional information only when they ask for explanations during the process of using generative AI. The results of this study will help shape the XAI design of future generative AI from a user perspective and improve usability.}
}
@article{ICHIKAWA2025,
title = {Generative Artificial Intelligence in Medical Education—Policies and Training at US Osteopathic Medical Schools: Descriptive Cross-Sectional Survey},
journal = {JMIR Medical Education},
volume = {11},
year = {2025},
issn = {2369-3762},
doi = {https://doi.org/10.2196/58766},
url = {https://www.sciencedirect.com/science/article/pii/S2369376225000236},
author = {Tsunagu Ichikawa and Elizabeth Olsen and Arathi Vinod and Noah Glenn and Karim Hanna and Gregg C Lund and Stacey Pierce-Talsma},
keywords = {artificial intelligence, medical education, faculty development, policy, AI, training, United States, school, university, college, institution, osteopathic, osteopathy, curriculum, student, faculty, administrator, survey, cross-sectional},
abstract = {Background
Interest has recently increased in generative artificial intelligence (GenAI), a subset of artificial intelligence that can create new content. Although the publicly available GenAI tools are not specifically trained in the medical domain, they have demonstrated proficiency in a wide range of medical assessments. The future integration of GenAI in medicine remains unknown. However, the rapid availability of GenAI with a chat interface and the potential risks and benefits are the focus of great interest. As with any significant medical advancement or change, medical schools must adapt their curricula to equip students with the skills necessary to become successful physicians. Furthermore, medical schools must ensure that faculty members have the skills to harness these new opportunities to increase their effectiveness as educators. How medical schools currently fulfill their responsibilities is unclear. Colleges of Osteopathic Medicine (COMs) in the United States currently train a significant proportion of the total number of medical students. These COMs are in academic settings ranging from large public research universities to small private institutions. Therefore, studying COMs will offer a representative sample of the current GenAI integration in medical education.
Objective
This study aims to describe the policies and training regarding the specific aspect of GenAI in US COMs, targeting students, faculty, and administrators.
Methods
Web-based surveys were sent to deans and Student Government Association (SGA) presidents of the main campuses of fully accredited US COMs. The dean survey included questions regarding current and planned policies and training related to GenAI for students, faculty, and administrators. The SGA president survey included only those questions related to current student policies and training.
Results
Responses were received from 81% (26/32) of COMs surveyed. This included 47% (15/32) of the deans and 50% (16/32) of the SGA presidents (with 5 COMs represented by both the deans and the SGA presidents). Most COMs did not have a policy on the student use of GenAI, as reported by the dean (14/15, 93%) and the SGA president (14/16, 88%). Of the COMs with no policy, 79% (11/14) had no formal plans for policy development. Only 1 COM had training for students, which focused entirely on the ethics of using GenAI. Most COMs had no formal plans to provide mandatory (11/14, 79%) or elective (11/15, 73%) training. No COM had GenAI policies for faculty or administrators. Eighty percent had no formal plans for policy development. Furthermore, 33.3% (5/15) of COMs had faculty or administrator GenAI training. Except for examination question development, there was no training to increase faculty or administrator capabilities and efficiency or to decrease their workload.
Conclusions
The survey revealed that most COMs lack GenAI policies and training for students, faculty, and administrators. The few institutions with policies or training were extremely limited in scope. Most institutions without current training or policies had no formal plans for development. The lack of current policies and training initiatives suggests inadequate preparedness for integrating GenAI into the medical school environment, therefore, relegating the responsibility for ethical guidance and training to the individual COM member.}
}
@article{RIANTO2025104427,
title = {Generative artificial intelligence for fire scenario analysis in complex building design layouts},
journal = {Fire Safety Journal},
volume = {155},
pages = {104427},
year = {2025},
issn = {0379-7112},
doi = {https://doi.org/10.1016/j.firesaf.2025.104427},
url = {https://www.sciencedirect.com/science/article/pii/S0379711225000918},
author = {Shandy Rianto and Yanfu Zeng and Xinyan Huang and Xinzheng Lu},
keywords = {Intelligent design, Fire safety engineering, Generative AI, Building fire simulation, Computational fluid dynamics},
abstract = {Performance-based fire safety design requires thoroughly evaluating building fire scenarios to ensure comprehensive fire safety. However, conventional Computational Fluid Dynamics (CFD) fire simulations are computationally intensive and time-consuming, limiting the number of scenarios that can be practically analyzed. This study addresses these challenges by using generative artificial intelligence (AI) to predict fire scenes in realistic multi-room building layouts, characterized by complex shapes and intricate wall partitions. Three generative AI models for image generation are employed for this purpose: GAN-based pix2pix and pix2pixHD, as well as the diffusion model. These models were trained on an extensive dataset of CFD fire simulations to generate near-ceiling smoke movement and temperature distribution outcomes. When tested on new unseen building layouts, these models demonstrated remarkable accuracy and provided near real-time assessments. The diffusion model achieved the highest accuracy (>94 %) while requiring the more computational time. The high performance of these models highlights the potential of using generative AI to enhance fire safety engineering by enabling faster and more comprehensive fire risk assessments.}
}
@article{MONZON2025,
title = {Leveraging Generative Artificial Intelligence to Improve Motivation and Retrieval in Higher Education Learners},
journal = {JMIR Medical Education},
volume = {11},
year = {2025},
issn = {2369-3762},
doi = {https://doi.org/10.2196/59210},
url = {https://www.sciencedirect.com/science/article/pii/S2369376225000352},
author = {Noahlana Monzon and Franklin Alan Hays},
keywords = {educational technology, retrieval practice, flipped classroom, cognitive engagement, personalized learning, generative artificial intelligence, higher education, university education, learners, instructors, curriculum structure, learning, technologies, innovation, academic misconduct, gamification, self-directed, socio-economic disparities, interactive approach, medical education, chatGPT, machine learning, AI, large language models},
abstract = {Generative artificial intelligence (GenAI) presents novel approaches to enhance motivation, curriculum structure and development, and learning and retrieval processes for both learners and instructors. Though a focus for this emerging technology is academic misconduct, we sought to leverage GenAI in curriculum structure to facilitate educational outcomes. For instructors, GenAI offers new opportunities in course design and management while reducing time requirements to evaluate outcomes and personalizing learner feedback. These include innovative instructional designs such as flipped classrooms and gamification, enriching teaching methodologies with focused and interactive approaches, and team-based exercise development among others. For learners, GenAI offers unprecedented self-directed learning opportunities, improved cognitive engagement, and effective retrieval practices, leading to enhanced autonomy, motivation, and knowledge retention. Though empowering, this evolving landscape has integration challenges and ethical considerations, including accuracy, technological evolution, loss of learner’s voice, and socioeconomic disparities. Our experience demonstrates that the responsible application of GenAI’s in educational settings will revolutionize learning practices, making education more accessible and tailored, producing positive motivational outcomes for both learners and instructors. Thus, we argue that leveraging GenAI in educational settings will improve outcomes with implications extending from primary through higher and continuing education paradigms.}
}
@article{BLEASE2025,
title = {Generative Artificial Intelligence in Primary Care: Qualitative Study of UK General Practitioners’ Views},
journal = {Journal of Medical Internet Research},
volume = {27},
year = {2025},
issn = {1438-8871},
doi = {https://doi.org/10.2196/74428},
url = {https://www.sciencedirect.com/science/article/pii/S1438887125010520},
author = {Charlotte Blease and Carolina {Garcia Sanchez} and Cosima Locher and Brian McMillan and Jens Gaab and John Torous},
keywords = {generative AI, general practice, primary care, large language models, education, training, online survey questionnaire, qualitative research., artificial intelligence},
abstract = {Background
The potential for generative artificial intelligence (GenAI) to assist with clinical tasks is the subject of ongoing debate within biomedical informatics and related fields.
Objective
This study aimed to explore general practitioners’ (GPs’) opinions about GenAI on primary care.
Methods
In January 2025, we conducted a web-based survey of 1005 UK GPs’ experiences and opinions of GenAI in clinical practice. This study involved a qualitative inductive descriptive analysis of a written response (“comments”) to an open-ended question in the survey. After analysis, the interpretation of themes was also informed by the technology acceptance model.
Results
Out of 1005 respondents, 611 GPs (61%) provided written comments in response to the free text question, totaling 7990 words. Comments were classified into 3 major themes and 8 subthemes in relation to GenAI in clinical practice. The major themes were (1) unfamiliarity, (2) ambivalence and anxiety, and (3) role in clinical tasks. “Unfamiliarity” encompassed a lack of experience and knowledge, and the need for training on GenAI. “Ambivalence and anxiety” included mixed expectations among GPs in relation to these tools, beliefs about diminished human connection, and skepticism about AI accountability. Finally, commenting on the role of GenAI in clinical tasks, GPs believed it would help with documentation. However, respondents questioned AI’s clinical judgment and raised concerns about operational uncertainty concerning these tools. Female GPs were more likely to leave comments than male GPs, with 53% (324/611) of female GPs providing feedback compared to 41.1% (162/394) who did not. Chi-square tests confirmed this difference ((χ²₂= 14.6, P=.001). In addition, doctors who left comments were significantly more likely to have used GenAI in clinical practice compared with those who did not. Among all respondents, 71.7% (438/611) had not used GenAI. However, noncommenters were even less likely to have used it, with 80.7% (318/394) reporting no use. A chi-square test confirmed this difference (χ²₁=10.0, P=.002).
Conclusions
This study provides timely insights into UK GPs’ perspectives on the role, impact, and limitations of GenAI in primary care. However, the study has limitations. The qualitative data analyzed originates from a self-selected subset of respondents who chose to provide free-text comments, and these participants were more likely to have used GenAI tools in clinical practice. However, the substantial number of comments offers valuable insights into the diverse views held by GPs regarding GenAI. Furthermore, the majority of our respondents reported limited experience and training with these tools; however, many GPs perceived potential benefits of GenAI and ambient AI for documentation. Notably, 2 years after the widespread introduction of GenAI, GPs’ persistent lack of understanding and training remains a critical concern. More extensive qualitative work would provide a more in-depth understanding of GPs’ views.}
}

@article{HABER2024,
title = {The Artificial Third: A Broad View of the Effects of Introducing Generative Artificial Intelligence on Psychotherapy},
journal = {JMIR Mental Health},
volume = {11},
year = {2024},
issn = {2368-7959},
doi = {https://doi.org/10.2196/54781},
url = {https://www.sciencedirect.com/science/article/pii/S2368795924000544},
author = {Yuval Haber and Inbar Levkovich and Dorit Hadar-Shoval and Zohar Elyoseph},
keywords = {psychoanalysis, generative artificial intelligence, psychotherapy, large language models, narcissism, narcissist, narcissistic, perception, perceptions, critical thinking, transparency, autonomy, mental health, interpersonal, LLM, LLMs, language model, language models, artificial intelligence, generative, AI, ethic, ethics, ethical},
abstract = {This paper explores a significant shift in the field of mental health in general and psychotherapy in particular following generative artificial intelligence’s new capabilities in processing and generating humanlike language. Following Freud, this lingo-technological development is conceptualized as the “fourth narcissistic blow” that science inflicts on humanity. We argue that this narcissistic blow has a potentially dramatic influence on perceptions of human society, interrelationships, and the self. We should, accordingly, expect dramatic changes in perceptions of the therapeutic act following the emergence of what we term the artificial third in the field of psychotherapy. The introduction of an artificial third marks a critical juncture, prompting us to ask the following important core questions that address two basic elements of critical thinking, namely, transparency and autonomy: (1) What is this new artificial presence in therapy relationships? (2) How does it reshape our perception of ourselves and our interpersonal dynamics? and (3) What remains of the irreplaceable human elements at the core of therapy? Given the ethical implications that arise from these questions, this paper proposes that the artificial third can be a valuable asset when applied with insight and ethical consideration, enhancing but not replacing the human touch in therapy.}
}
@article{PARK20242355,
title = {Has generative artificial intelligence solved inverse materials design?},
journal = {Matter},
volume = {7},
number = {7},
pages = {2355-2367},
year = {2024},
issn = {2590-2385},
doi = {https://doi.org/10.1016/j.matt.2024.05.017},
url = {https://www.sciencedirect.com/science/article/pii/S259023852400242X},
author = {Hyunsoo Park and Zhenzhu Li and Aron Walsh},
abstract = {Summary
The directed design and discovery of compounds with pre-determined properties is a long-standing challenge in materials research. We provide a perspective on progress toward achieving this goal using generative models for chemical compositions and crystal structures based on a set of powerful statistical techniques drawn from the artificial intelligence community. We introduce the central concepts underpinning generative models of crystalline materials. Coverage is provided of early implementations for inorganic crystals based on generative adversarial networks and variational autoencoders through to ongoing progress involving autoregressive and diffusion models. The influence of the choice of chemical representation and the generative architecture is discussed, along with metrics for quantifying the quality of the hypothetical compounds produced. While further developments are required to enable realistic predictions drawn from richer structure and property datasets, generative artificial intelligence is already proving to be complementary to traditional materials design strategies.}
}
@article{WAISBERG20251,
title = {Generative artificial intelligence in ophthalmology},
journal = {Survey of Ophthalmology},
volume = {70},
number = {1},
pages = {1-11},
year = {2025},
issn = {0039-6257},
doi = {https://doi.org/10.1016/j.survophthal.2024.04.009},
url = {https://www.sciencedirect.com/science/article/pii/S0039625724000444},
author = {Ethan Waisberg and Joshua Ong and Sharif Amit Kamran and Mouayad Masalkhi and Phani Paladugu and Nasif Zaman and Andrew G. Lee and Alireza Tavakkoli},
keywords = {Generative adversarial networks, Deep learning, ChatGPT, GPT4, Artificial ophthalmic image synthesis, AI, Machine learning},
abstract = {Generative artificial intelligence (AI) has revolutionized medicine over the past several years. A generative adversarial network (GAN) is a deep learning framework that has become a powerful technique in medicine, particularly in ophthalmology for image analysis. In this paper we review the current ophthalmic literature involving GANs, and highlight key contributions in the field. We briefly touch on ChatGPT, another application of generative AI, and its potential in ophthalmology. We also explore the potential uses for GANs in ocular imaging, with a specific emphasis on 3 primary domains: image enhancement, disease identification, and generating of synthetic data. PubMed, Ovid MEDLINE, Google Scholar were searched from inception to October 30, 2022, to identify applications of GAN in ophthalmology. A total of 40 papers were included in this review. We cover various applications of GANs in ophthalmic-related imaging including optical coherence tomography, orbital magnetic resonance imaging, fundus photography, and ultrasound; however, we also highlight several challenges that resulted in the generation of inaccurate and atypical results during certain iterations. Finally, we examine future directions and considerations for generative AI in ophthalmology.}
}
@article{CHARLES2025177508,
title = {AI in action: Changes to student perceptions when using generative artificial intelligence for the creation of a multimedia project-based assessment},
journal = {European Journal of Pharmacology},
volume = {998},
pages = {177508},
year = {2025},
issn = {0014-2999},
doi = {https://doi.org/10.1016/j.ejphar.2025.177508},
url = {https://www.sciencedirect.com/science/article/pii/S0014299925002626},
author = {Kellie A. Charles and Arsalan Yousuf and Han Chow Chua and Slade Matthews and Joanna Harnett and Tina Hinton},
keywords = {Science education, Pharmacology education, Artificial intelligence, AI, ChatGPT},
abstract = {Introduction
New modes of assessments are needed to evaluate of the authenticity of student learning in an artificial intelligence (AI) world. In mid-2023, we piloted a new assessment type; a collaborative group multimedia assessment with AI allowance. The aim of the research study was to explore the experiences of students using AI in a multimedia assessment. We further aimed to determine whether these use cases changed student perceptions of the ways AI can be used in learning and assessment.
Methods
Students enrolled in a capstone Pharmacology interdisciplinary unit (n = 40) were included in an exploratory, qualitative case study methodology. Thematic analysis using an AI role-based conceptual framework was used to explore student perceptions of AI use prior to and during their projects from logbooks documenting the assessment process.
Results
AI was initially perceived by students as having a personal tutor-style role, which aligned with the taxonomy with AI acting as an Arbiter (49 %), Oracle (41 %) and Quant (10 %). In contrast to their earlier perceptions, AI was only used in a limited manner in the early stages of assessment in the idea generation in the role as an Oracle (86 %) or in data analytic purposes as a Quant (14 %), (n = 14 cases in 5 groups). No student group used AI to generate written text for the final assessment.
Discussion
Tension between perceived and actual use of AI is indicative of the uncertainty faced by students with the allowance of AI within assessments. Clear guidance for educators and students about how to assess the AI-supported learning process is needed to ensure the integrity of the assessment system.}
}
@article{DEMIREL2025101127,
title = {Late gadolinium enhancement cardiovascular magnetic resonance with generative artificial intelligence},
journal = {Journal of Cardiovascular Magnetic Resonance},
volume = {27},
number = {1},
pages = {101127},
year = {2025},
issn = {1097-6647},
doi = {https://doi.org/10.1016/j.jocmr.2024.101127},
url = {https://www.sciencedirect.com/science/article/pii/S1097664724011542},
author = {Omer Burak Demirel and Fahime Ghanbari and Christopher W. Hoeger and Connie W. Tsao and Adele Carty and Long H. Ngo and Patrick Pierce and Scott Johnson and Kathryn Arcand and Jordan Street and Jennifer Rodriguez and Tess E. Wallace and Kelvin Chow and Warren J. Manning and Reza Nezafat},
keywords = {Late gadolinium enhancement, Highly accelerated, Deep learning},
abstract = {ABSTRACT
Background
Late gadolinium enhancement (LGE) cardiovascular magnetic resonance (CMR) imaging enables imaging of scar/fibrosis and is a cornerstone of most CMR imaging protocols. CMR imaging can benefit from image acceleration; however, image acceleration in LGE remains challenging due to its limited signal-to-noise ratio. In this study, we sought to evaluate a rapid two-dimensional (2D) LGE imaging protocol using a generative artificial intelligence (AI) algorithm with inline reconstruction.
Methods
A generative AI-based image enhancement was used to improve the sharpness of 2D LGE images acquired with low spatial resolution in the phase-encode direction. The generative AI model is an image enhancement technique built on the enhanced super-resolution generative adversarial network. The model was trained using balanced steady-state free-precession cine images, readily used for LGE without additional training. The model was implemented inline, allowing the reconstruction of images on the scanner console. We prospectively enrolled 100 patients (55 ± 14 years, 72 males) referred for clinical CMR at 3T. We collected three sets of LGE images in each subject, with in-plane spatial resolutions of 1.5 × 1.5-3-6 mm2. The generative AI model enhanced in-plane resolution to 1.5 × 1.5 mm2 from the low-resolution counterparts. Images were compared using a blur metric, quantifying the perceived image sharpness (0 = sharpest, 1 = blurriest). LGE image sharpness (using a 5-point scale) was assessed by three independent readers.
Results
The scan times for the three imaging sets were 15 ± 3, 9 ± 2, and 6 ± 1 s, with inline generative AI-based images reconstructed time of ∼37 ms. The generative AI-based model improved visual image sharpness, resulting in lower blur metric compared to low-resolution counterparts (AI-enhanced from 1.5 × 3 mm2 resolution: 0.3 ± 0.03 vs 0.35 ± 0.03, P < 0.01). Meanwhile, AI-enhanced images from 1.5 × 3 mm2 resolution and original LGE images showed similar blur metric (0.30 ± 0.03 vs 0.31 ± 0.03, P = 1.0) Additionally, there was an overall 18% improvement in image sharpness between AI-enhanced images from 1.5 × 3 mm2 resolution and original LGE images in the subjective blurriness score (P < 0.01).
Conclusion
The generative AI-based model enhances the image quality of 2D LGE images while reducing the scan time and preserving imaging sharpness. Further evaluation in a large cohort is needed to assess the clinical utility of AI-enhanced LGE images for scar evaluation, as this proof-of-concept study does not provide evidence of an impact on diagnosis.}
}
@article{ZHAO2024100043,
title = {Advancing microplastic analysis in the era of artificial intelligence: From current applications to the promise of generative AI},
journal = {Nexus},
volume = {1},
number = {4},
pages = {100043},
year = {2024},
issn = {2950-1601},
doi = {https://doi.org/10.1016/j.ynexs.2024.100043},
url = {https://www.sciencedirect.com/science/article/pii/S295016012400041X},
author = {Bu Zhao and Ruth E. Richardson and Fengqi You},
keywords = {microplastics, artificial intelligence, machine learning, deep learning, generative AI},
abstract = {Summary
The proliferation of microplastics (MPs) in aquatic and terrestrial environments poses significant threats to ecosystems and human health. Over the past 20 years, significant efforts have been dedicated to understanding the distribution, sources, and impacts of MPs. However, traditional methods for the detection and analysis of MPs rely on labor-intensive and time-consuming techniques, often lacking the needed precision. Recently, artificial intelligence (AI) has emerged as a transformative tool in environmental science, offering innovative solutions to enhance the efficiency and accuracy of MP analysis. Despite significant scientific advancements, there is a lack of critical review that consolidates the key applications of AI in MP analysis, synthesizes knowledge gained, and navigates for future research directions. This review is the first to thoroughly explore the exciting role of AI across the entire life cycle of MP analysis—from collection to characterization, dynamic modeling, impact assessment, and management of MP pollution. Specifically, AI-driven autonomous drones and robotics have emerged as promising solutions to revolutionize MP collection practices. Computer vision systems provide robust solutions for the identification and quantification of MPs in diverse environmental matrices. Additionally, data-driven modeling using machine-learning and deep-learning techniques facilitates accurate evaluation of MP pollution levels and their impacts, facilitating the design of effective management strategies. Despite these advancements, several knowledge gaps remain, including data scarcity and quality issues; the readiness of the AI models; and model interpretability, transparency, and reproducibility issues. Addressing these gaps requires the development of standardized protocols for improved data infrastructure, the adoption of more advanced and groundbreaking AI tools (such as generative AI), and the encouraging of multidisciplinary collaborations. Through these efforts, AI has the potential to revolutionize MP research, leading to a more comprehensive and effective response to MP pollution.}
}
@article{GOFMAN2025S260,
title = {HTA74 Transforming Global Value Dossier (GVD) Drafting: Creation with a Generative Artificial Intelligence (Gen AI)-Driven Coauthoring Accelerator},
journal = {Value in Health},
volume = {28},
number = {6, Supplement 1},
pages = {S260},
year = {2025},
issn = {1098-3015},
doi = {https://doi.org/10.1016/j.jval.2025.04.1085},
url = {https://www.sciencedirect.com/science/article/pii/S1098301525012100},
author = {Larisa Gofman and Jevin G. Meyerink and Sheetal Sharma}
}
@article{BARCAUI2023100101,
title = {Who is better in project planning?Generative artificial intelligence or project managers?},
journal = {Project Leadership and Society},
volume = {4},
pages = {100101},
year = {2023},
issn = {2666-7215},
doi = {https://doi.org/10.1016/j.plas.2023.100101},
url = {https://www.sciencedirect.com/science/article/pii/S2666721523000224},
author = {André Barcaui and André Monat},
keywords = {Generative, Artificial intelligence, Project management},
abstract = {This paper presents a comparative study of generative artificial intelligence (AI), specifically the GPT-4 model, and a human project manager in the context of a project plan development. The study's objective was to analyze the content and structure of a project plan prepared by this disruptive new technology and its human counterpart, focusing on the digital technology sector. Through a primarily qualitative methodology, the study scrutinizes critical aspects of each part of the project plan, including scope preparation, schedule development, cost estimation, resources evaluation, quality planning, stakeholder mapping, communication planning, and risk analysis. The results indicate unique strengths and weaknesses for both AI-generated and human-generated project plans, revealing them as complementary in the project planning process. It also emphasizes the continued importance of human expertise in refining AI outputs and harnessing the full potential of AI through the process known as prompt engineering. In conclusion, this study illustrates the potential synergy between human experience and AI in project planning, suggesting the careful integration of human and AI capabilities is key to developing robust and trustworthy project plans.}
}
@article{ARCEURRIZA2025104234,
title = {From familiarity to acceptance: The impact of Generative Artificial Intelligence on consumer adoption of retail chatbots},
journal = {Journal of Retailing and Consumer Services},
volume = {84},
pages = {104234},
year = {2025},
issn = {0969-6989},
doi = {https://doi.org/10.1016/j.jretconser.2025.104234},
url = {https://www.sciencedirect.com/science/article/pii/S096969892500013X},
author = {Marta Arce-Urriza and Raquel Chocarro and Mónica Cortiñas and Gustavo Marcos-Matás},
keywords = {Generative artificial intelligence, Chatbot adoption, Retail technology, Consumer familiarity, Privacy risk, Service robot acceptance model (SRAM)},
abstract = {This study investigates the influence of Generative Artificial Intelligence (GenAI) on consumer adoption of retail chatbots, focusing on how GenAI impacts key adoption determinants, the role of familiarity and assessing its effects across different stages of the customer journey. We conducted two waves of surveys, one pre- and one post-GenAI integration, to compare consumer perceptions across three customer service tasks. Using the Service Robot Acceptance Model (SRAM) as a framework, we found that GenAI enhances consumer perceptions of chatbot usefulness, human-likeness, and familiarity, thereby increasing adoption intentions. However, trust remains largely unchanged, and privacy concerns have risen post-GenAI. Additionally, the relationships remain stable across customer journey stages, with familiarity playing a key role. Our findings extend SRAM to the retail context with GenAI, offering new insights into the temporal stability of chatbot adoption factors. It underscores familiarity's dual role (direct and indirect) in fostering adoption, while highlighting that GenAI impacts specific aspects of consumer interaction. These findings provide insights for retailers to leverage GenAI-powered chatbots to enhance customer engagement and satisfaction.}
}
@article{GUPTA2024100232,
title = {Adoption and impacts of generative artificial intelligence: Theoretical underpinnings and research agenda},
journal = {International Journal of Information Management Data Insights},
volume = {4},
number = {1},
pages = {100232},
year = {2024},
issn = {2667-0968},
doi = {https://doi.org/10.1016/j.jjimei.2024.100232},
url = {https://www.sciencedirect.com/science/article/pii/S2667096824000211},
author = {Ruchi Gupta and Kiran Nair and Mahima Mishra and Blend Ibrahim and Seema Bhardwaj},
keywords = {ChatGPT, Adoption, Generative AI, Chatbots},
abstract = {Large language models (LLMs) have received considerable interest in the field of natural language processing (NLP) owing to their remarkable ability to generate clear, consistent, and contextually relevant materials. Among the numerous LLMs, ChatGPT (Generative Pre-trained Transformer for Chatbots) is emerging as a prominent prospective tool for developing conversational agents such as chatbots. However, there is a need for a clear conceptual understanding of ChatGPT's potential implications for the industry and its role in marketing. This study explores the adoption of ChatGPT in marketing and examines theories that may influence its adoption by marketers and consumers, as well as its implications for marketers. This study discusses how ChatGPT may allow for more personalized and engaging content, better customer experience, and improved ROI. However, adoption also brings challenges, including ethical considerations and the need for new skill development. This study also discusses future research opportunities for the adoption of ChatGPT and other generative artificial intelligence technologies in marketing. The goal is to provide insights for organizations that consider implementing these technologies, and to contribute to the literature on the adoption of Artificial Intelligence (AI) and the use of Generative AI in marketing.}
}
@article{MOULAEI2024105474,
title = {Generative artificial intelligence in healthcare: A scoping review on benefits, challenges and applications},
journal = {International Journal of Medical Informatics},
volume = {188},
pages = {105474},
year = {2024},
issn = {1386-5056},
doi = {https://doi.org/10.1016/j.ijmedinf.2024.105474},
url = {https://www.sciencedirect.com/science/article/pii/S1386505624001370},
author = {Khadijeh Moulaei and Atiye Yadegari and Mahdi Baharestani and Shayan Farzanbakhsh and Babak Sabet and Mohammad {Reza Afrash}},
keywords = {Generative artificial intelligence, Health, Artificial intelligence},
abstract = {Background
Generative artificial intelligence (GAI) is revolutionizing healthcare with solutions for complex challenges, enhancing diagnosis, treatment, and care through new data and insights. However, its integration raises questions about applications, benefits, and challenges. Our study explores these aspects, offering an overview of GAI's applications and future prospects in healthcare.
Methods
This scoping review searched Web of Science, PubMed, and Scopus . The selection of studies involved screening titles, reviewing abstracts, and examining full texts, adhering to the PRISMA-ScR guidelines throughout the process.
Results
From 1406 articles across three databases, 109 met inclusion criteria after screening and deduplication. Nine GAI models were utilized in healthcare, with ChatGPT (n = 102, 74 %), Google Bard (Gemini) (n = 16, 11 %), and Microsoft Bing AI (n = 10, 7 %) being the most frequently employed. A total of 24 different applications of GAI in healthcare were identified, with the most common being “offering insights and information on health conditions through answering questions” (n = 41) and “diagnosis and prediction of diseases” (n = 17). In total, 606 benefits and challenges were identified, which were condensed to 48 benefits and 61 challenges after consolidation. The predominant benefits included “Providing rapid access to information and valuable insights” and “Improving prediction and diagnosis accuracy”, while the primary challenges comprised “generating inaccurate or fictional content”, “unknown source of information and fake references for texts”, and “lower accuracy in answering questions”.
Conclusion
This scoping review identified the applications, benefits, and challenges of GAI in healthcare. This synthesis offers a crucial overview of GAI's potential to revolutionize healthcare, emphasizing the imperative to address its limitations.}
}
@article{ASAD2024490,
title = {ChatGPT as artificial intelligence-based generative multimedia for English writing pedagogy: challenges and opportunities from an educator’s perspective},
journal = {International Journal of Information and Learning Technology},
volume = {41},
number = {5},
pages = {490-506},
year = {2024},
issn = {2056-4880},
doi = {https://doi.org/10.1108/IJILT-02-2024-0021},
url = {https://www.sciencedirect.com/science/article/pii/S2056488024000131},
author = {Muhammad Mujtaba Asad and Shafaque Shahzad and Syed Hassan Ali Shah and Fahad Sherwani and Norah Mansour Almusharraf},
keywords = {Artificial intelligence, ChatGPT, English language, English writing pedagogy, Composing, Generative multimedia, Personalized learning},
abstract = {Purpose
This paper holds considerable importance in the educational dynamics specifically ChatGPT as generative multimedia in English language writing pedagogy and presents a unique lens, as it uses a narrative literature review to view this cutting-edge topic. This paper compiles the knowledge and information already available regarding the views and integration of ChatGPT in English writing pedagogy. This review attempts to determine the potential that ChatGPT provides for improving pedagogical practices and facilitating individualized learning by looking at the experiences and viewpoints of educators. Simultaneously, it addresses the crucial challenges educators must overcome to optimize the advantages of artificial intelligence (AI) while preserving academic fairness and honesty. The ultimate goal of this paper is to offer a nuanced understanding of ChatGPT’s role in education, especially in English language writing pedagogy, educating researchers, teachers and policymakers on how to integrate generative multimedia successfully AI into teaching and learning and aiding in the creation of inclusive and more effective teaching strategies.
Design/methodology/approach
The review was done using a narrative approach by analyzing the latest international and national studies, research papers, blog posts, newspaper articles and documentaries, and by collecting the data, facts, figures and pictures. This narrative literature review approach provides a contextual understanding of how different English language teachers view ChatGPT in English writing pedagogy allowing for a comprehensive synthesis of data about its opportunities and challenges as well. It also helps in finding patterns and gaps in the body of knowledge, directing future studies and emphasizing areas that require more research, which is important for this new cutting-edge invention. The narrative approach, in contrast to systematic reviews, enables a detailed qualitative analysis that is necessary for delving into complex topics. This review offers useful insights into the prospects and practical challenges of integrating ChatGPT in English language writing pedagogy by concentrating on the experiences of teachers. The narrative literature review is a useful and relevant means of comprehending and using AI in educational settings since its ultimate goal is to synthesize current knowledge and provide practical recommendations for teachers, students, administrators and, last but not least, policymakers for the effective integration of ChatGPT as generative multimedia specifically in the English language writing pedagogy.
Findings
Grounded on findings, it is essential to mention here that ChatGPT holds immense value in terms of English language writing pedagogy. The findings deal with the three research questions: each research question has a main theme followed by sub-themes about the views of teachers on ChatGPT integration into English writing pedagogy, its benefits and, last but not least, challenges; however, very few traces of AI have been found in the early most downloaded Language learning apps, but ChatGPT covers it all with the features like personalized learning, contextually adaptable feedback, human-like conversational skills and preparation of standard tests, which make ChatGPT stand apart and stand tall in the race of new AI inventions. On the contrary, the paper identifies vital challenges associated with ChatGPT. First, there is a severe concern that students’ creativity may be at risk. Second, the concern of data privacy is a critical consideration. Finally, dealing with the trust issue of English language teachers regarding the use of ChatGPT for English language writing pedagogy and, last but not least, the paper also talks about low digital literacy as an additional challenge to integrating ChatGPT in educational settings. The incorporation of ChatGPT is not only a new trend but also a door to future AI wonders, so the education community needs to make the most of it.
Practical implications
The paper has broad implications that address multiple aspects of educational theory, practice, policy and future research when incorporating AI systems such as ChatGPT into English language writing pedagogy. The findings imply that ChatGPT can result in more dynamic and customized learning experiences, which has important implications for improving English language writing pedagogy with the integration of ChatGPT. AI can help teachers customize lessons to each student’s needs, which could increase student engagement in writing classes and improve learning results. Additionally, for the school administration and policymakers, the integration of ChatGPT depends upon access to smooth internet connection and other resources needed for effective learning of the students. Policymakers can develop policies as per the changing needs of the hour by providing professional development training to the teachers for the incorporation of AI inventions such as ChatGPT for English language writing pedagogy. Furthermore, the research also highlights significant ethical and policy issues, especially those dealing with academic integrity. Policies by the administration and teachers must be developed to stop students from misusing ChatGPT and to guarantee that AI tools are applied morally and responsibly in educational contexts because students can utilize the tool to complete assignments in an unethical manner.
Originality/value
This narrative literature review is unique as it provides insights into the new invention of OpenAI ChatGPT from the education perspective, specifically about the teaching of English language writing pedagogy, and offers some exciting revelations that have not been done previously.}
}
@article{BEWERSDORFF2025102601,
title = {Taking the next step with generative artificial intelligence: The transformative role of multimodal large language models in science education},
journal = {Learning and Individual Differences},
volume = {118},
pages = {102601},
year = {2025},
issn = {1041-6080},
doi = {https://doi.org/10.1016/j.lindif.2024.102601},
url = {https://www.sciencedirect.com/science/article/pii/S1041608024001948},
author = {Arne Bewersdorff and Christian Hartmann and Marie Hornberger and Kathrin Seßler and Maria Bannert and Enkelejda Kasneci and Gjergji Kasneci and Xiaoming Zhai and Claudia Nerdel},
keywords = {Artificial Intelligence, Large Language Models (LLMs), ChatGPT, Multimodal learning, Cognitive Theory of Multimedia Learning, Science education},
abstract = {The integration of Artificial Intelligence (AI), particularly Large Language Model (LLM)-based systems, in education has shown promise in enhancing teaching and learning experiences. However, the advent of Multimodal Large Language Models (MLLMs) like GPT-4 Vision, capable of processing multimodal data including text, sound, and visual inputs, opens a new era of enriched, personalized, and interactive learning landscapes in education. This paper derives a theoretical framework for integrating MLLMs into multimodal learning. This framework serves to explore the transformative role of MLLMs in central aspects of science education by presenting exemplary innovative learning scenarios. Possible applications for MLLMs range from content creation to tailored support for learning, fostering engagement in scientific practices, and providing assessments and feedback. These applications are not limited to text-based and uni-modal formats but can be multimodal, thus increasing personalization, accessibility, and potential learning effectiveness. Despite the many opportunities, challenges such as data protection and ethical considerations become salient, calling for robust frameworks to ensure responsible integration. This paper underscores the necessity for a balanced approach in implementing MLLMs, where the technology complements rather than supplants the educators' roles, ensuring an effective and ethical use of AI in science education. It calls for further research to explore the nuanced implications of MLLMs for educators and to extend the discourse beyond science education to other disciplines. Through developing a theoretical framework for the integration of MLLMs into multimodal learning and exploring the associated potentials, challenges, and future implications, this paper contributes to a preliminary examination of the transformative role of MLLMs in science education and beyond.}
}
@article{ASSAD2024677,
title = {Enhancing sustainability in manufacturing through cognitive digital twins powered by generative artificial intelligence},
journal = {Procedia CIRP},
volume = {130},
pages = {677-682},
year = {2024},
note = {57th CIRP Conference on Manufacturing Systems 2024 (CMS 2024)},
issn = {2212-8271},
doi = {https://doi.org/10.1016/j.procir.2024.10.147},
url = {https://www.sciencedirect.com/science/article/pii/S2212827124013040},
author = {Fadi Assad and John Patsavellas and Konstantinos Salonitis},
keywords = {ChatGPT, Cognitive manufacturing, digital twin, generative artificial intelligence, Internet of Things, sustainable manufacturing},
abstract = {The rise of Industry 4.0 has brought new advancements in manufacturing, with a focus on integrating digital technologies to optimise processes and increase sustainability. Cognitive Digital Twins (CDTs) are emerging as a powerful paradigm in this area. They leverage advanced analytics, artificial intelligence (AI), and machine learning to create dynamic, real-time representations of physical manufacturing systems. This paper explores how CDTs can improve sustainability within the manufacturing sector. It proposes integrating generative artificial intelligence (GenAI) into the platforms that operate these digital twins to grant them cognitive capabilities. The work introduces a method for mapping and integrating energy consumption data to an Internet of Things (IoT) platform that includes the digital twin and a generative AI language model, such as ChatGPT. This proposed approach serves as a stepping stone towards unlocking the full potential of CDTs. It empowers manufacturers to achieve higher levels of sustainability and environmental responsibility.}
}
@article{MAYOL2025109496,
title = {Generative artificial intelligence and scientific publishing: Turning noise into trust},
journal = {Surgery},
volume = {183},
pages = {109496},
year = {2025},
issn = {0039-6060},
doi = {https://doi.org/10.1016/j.surg.2025.109496},
url = {https://www.sciencedirect.com/science/article/pii/S0039606025003484},
author = {Julio Mayol and Caitlin W. Hicks and Steven D. Wexner}
}
@article{RAWLINSON2025,
title = {Generative Artificial Intelligence to Automate the Adaptation of Excel Health Economic Models and Word Technical Reports},
journal = {Value in Health},
year = {2025},
issn = {1098-3015},
doi = {https://doi.org/10.1016/j.jval.2025.05.020},
url = {https://www.sciencedirect.com/science/article/pii/S109830152502399X},
author = {William Rawlinson and Siguroli Teitsson and Tim Reason and Bill Malcolm and Andy Gimblett and Sven L. Klijn},
keywords = {artificial intelligence, large language models},
abstract = {Objectives
In health economics and outcomes research (HEOR), many repetitive tasks could be performed by large language models (LLMs), including adapting Excel-based health economic models and associated Word technical reports to a new setting. However, it is vital to develop robust methods so that the LLM delivers at least human-level accuracy.
Methods
We developed LLM-based pipelines to automate parameter value adaptations for Excel-based models and subsequent reporting of the model results. Chain-of-thought prompting, ensemble shuffling, and task decomposition were used to enhance the accuracy of the LLM-generated content. We tested the pipelines by adapting 3 Excel-based models (2 cost-effectiveness models [CEMs] and 1 budget impact model [BIM]) and their associated technical reports. The quality of reporting was evaluated by 2 expert health economists.
Results
The accuracy of parameter value adaptations was 100% (147 of 147), 100% (207 of 207), and 98.7% (158 of 160) for the 2 CEMs and 1 budget impact model, respectively. The parameter value adaptations were performed without human intervention in 195 seconds, 245 seconds, and 189 seconds. For parameter value adaptations, the application programming interface costs associated with running the pipeline were $13.36, $6.48, and $2.65. The accuracy of report adaptations was 94.4% (17 of 18), 100% (54 of 54), and 95.1% (39 of 41), respectively. The report adaptations were performed in 128 seconds, 336 seconds, and 286 seconds. For report adaptations, the application programming interface costs associated with running the pipeline were $1.53, $4.24, and $4.05.
Conclusions
LLM-based toolchains have the potential to accurately and rapidly perform routine adaptations of Excel-based CEMs and technical reports at a low cost. This could expedite health technology assessments and improve patient access to new treatments.}
}
@article{RESELFOLKERSMA2025S1749,
title = {A0902 – Evaluation of the quality of the responses regarding Lower Urinary Tract Symptoms (LUTS) of different generative Artificial Intelligence (AI) App in comparison with UrologuIA (generative AI App developed by urologists and urogynecologists)},
journal = {European Urology},
volume = {87},
pages = {S1749},
year = {2025},
note = {Abstracts EAU25 - 40th Annual EAU Congress},
issn = {0302-2838},
doi = {https://doi.org/10.1016/j.eururo.2025.09.4082},
url = {https://www.sciencedirect.com/science/article/pii/S0302283825045919},
author = {L. {Resel Folkersma} and B. {Padilla Fernández} and C. {González Enguita} and J.L. Gago and M. {García Sanz} and P. {Blasco Hernández} and R. Vozmediano and S. Arlandis and S. Zubillaga and J. {Medina Polo}}
}
@article{GARCIA20253136,
title = {Generative artificial intelligence in human resource management: a critical reflection on impacts, resilience and roles},
journal = {International Journal of Contemporary Hospitality Management},
volume = {37},
number = {9},
pages = {3136-3158},
year = {2025},
issn = {0959-6119},
doi = {https://doi.org/10.1108/IJCHM-01-2025-0159},
url = {https://www.sciencedirect.com/science/article/pii/S0959611925000452},
author = {R.L. Fernando Garcia and Linchi Kwok},
keywords = {Critical reflection, Artificial intelligence, Generative AI, Human resource management, Information technology, Employee lifecycle},
abstract = {Purpose
This study aims to address three questions: RQ1 – What significant changes has generative artificial intelligence (GenAI) brought to human resource (HR) functions? RQ2 – How can HR professionals sustain a critical role in an organization when GenAI is transforming traditional HR functions? RQ3 – What research questions can be addressed to support organizations and HR professionals in a new GenAI-empowered work environment?
Design/methodology/approach
As a critical reflection of the authors’ corporate HR experience and research expertise, a narrative review of purposefully selective relevant literature, industry white papers and news updates across the six stages of the employee lifecycle was carried out to answer RQ1. A provoking reflection was further synthesized to answer RQ2 and RQ3.
Findings
Three categories of HR duties (those likely and unlikely to be replaced by GenAI and those likely to emerge due to GenAI implications) were synthesized, leading to the advancement of three propositions. Recommendations for HR professionals, organizations and future research were summarized.
Research limitations/implications
This paper presents a series of specific research questions, inspiring new research ideas that help organizations improve HR work with GenAI-empowered tools while mitigating its negative impacts.
Practical implications
This paper proposes detailed recommendations to help HR professionals maintain their critical roles within the organization. In addition to hospitality and tourism businesses, for-profit or nonprofit organizations across all sectors can refer to the answers to RQ1 to restructure their HR departments.
Social implications
Beyond the HR profession, this work signals a broader societal shift in job functions and structures, urging individuals and organizations to rethink what is needed in the new GenAI-empowered work environments. It also raises awareness of the need for human oversight and responsible AI governance in redesigning future work and organizational structures.
Originality/value
This paper synthesizes GenAI’s significant impact on various HR functions across the six stages of the employee lifecycle. It offers specific practical recommendations and research ideas to help organizations leverage GenAI’s power in HR operations.}
}
@article{HIDAYATULLAH2025100213,
title = {Exploring community pharmacist's psychological intentions to adopt generative artificial intelligence (GenAI) chatbots for patient information, education, and counseling},
journal = {Neuroscience Informatics},
volume = {5},
number = {3},
pages = {100213},
year = {2025},
issn = {2772-5286},
doi = {https://doi.org/10.1016/j.neuri.2025.100213},
url = {https://www.sciencedirect.com/science/article/pii/S2772528625000287},
author = {Hafidz Ihsan Hidayatullah and Muhammad Taufiq Saifullah and Muhammad Thesa Ghozali and Ayesha Aziz},
keywords = {Artificial intelligence, Communal pharmacy, Social intention, Procreative AI, Technology acceptance},
abstract = {Generative AI (GenAI) chatbots, driven by advanced machine learning algorithms, are emerging as transformative tools for enhancing patient education, information dissemination, and counseling (EIC) in healthcare. This study investigated the psychological determinants of community pharmacists' intentions to adopt GenAI chatbots using the Extended Technology Acceptance Model (ETAM). A cross-sectional survey of 240 licensed community pharmacists across several Indonesian provinces assessed key constructs, including self-efficacy (SE), perceived usefulness (PU), perceived ease of use (PEU), attitude toward technology (ATT), trust (TT), and behavioral intention (BI). Structural equation modeling revealed that SE significantly influenced PU (β=0.37) and PEU (β=0.57), indicating that confidence in using technology positively affects perceived utility and usability. PU further predicted ATT (β=0.39) and BI (β=0.236), emphasizing the motivational role of perceived benefits. Trust emerged as a crucial mediator, channeling favorable attitudes into actionable behavioral intentions (indirect β=0.148). The model demonstrated strong fit indices (χ2=263.09, RMSEA = 0.019, GFI = 0.915, CFI = 0.991), supporting the psychological framework. These findings highlight the importance of fostering trust, improving perceived usability, and enhancing self-efficacy through targeted training to promote GenAI chatbot adoption. Future research should explore longitudinal behavioral changes and contextual influences to support sustainable AI integration in pharmacy practice.}
}
@article{LUSETTI2025S250,
title = {T.06.3 APPLICATIONS OF GENERATIVE ARTIFICIAL INTELLIGENCE IN INFLAMMATORY BOWEL DISEASE: A SYSTEMATIC REVIEW},
journal = {Digestive and Liver Disease},
volume = {57},
pages = {S250-S251},
year = {2025},
note = {Abstracts of the 31st National Congress of Digestive Diseases, FISMAD},
issn = {1590-8658},
doi = {https://doi.org/10.1016/S1590-8658(25)00603-6},
url = {https://www.sciencedirect.com/science/article/pii/S1590865825006036},
author = {F. Lusetti and S. Maimaris and G.P. {La Rosa} and D. Scalvini and A. Schiepatti and F. Biagi and G. Manes and S. Saibeni}
}
@incollection{SMITH2026421,
title = {Chapter 16 - Generative artificial intelligence for research translation in environmental toxicology and the ethical considerations∗},
editor = {Zhoumeng Lin and Wei-Chun Chou},
booktitle = {Machine Learning and Artificial Intelligence in Toxicology and Environmental Health},
publisher = {Academic Press},
pages = {421-432},
year = {2026},
isbn = {978-0-443-30010-3},
doi = {https://doi.org/10.1016/B978-0-443-30010-3.00013-1},
url = {https://www.sciencedirect.com/science/article/pii/B9780443300103000131},
author = {Ted Smith},
keywords = {Artificial intelligence (AI), ChatGPT, Environmental health, Generative AI, Large language model (LLM), Plain language summaries (PLS), Prompt development},
abstract = {This chapter explores the potential of generative artificial intelligence (AI) for increasing the accessibility of the toxicological research published for the scientific community for nonspecialist audiences who may need this information for a wide range of important purposes. Translating and summarizing, in plain language, the specialized terminology, intricate statistical models, and interdisciplinary knowledge inherent in this field presents significant challenges which have historically been addressed with human intermediaries and their associated cost and time. Freely available chat-enabled large language models offer the ability to automatically generate a range of cost-effective plain language summaries. These capabilities are accompanied by several limitations such as oversimplification and the risk of inaccuracies which must be considered. Also considered are the ethical considerations such as the need to emphasize transparency, cultural sensitivities, and mitigation of bias in generative AI outputs. The importance of human quality assurance in maintaining scientific accuracy, context, and public trust is critical to responsible applications of this approach. By advocating for a balanced approach that leverages AI's scalability while preserving scientific rigor, this chapter promotes the thoughtful integration of AI in environmental toxicology research translation, ultimately envisioning its role in enhancing public understanding, informing policy, and fostering equitable access to scientific knowledge. An illustrative case exercise provides a step-by-step process for creating these summaries.}
}
@article{MORTLOCK2024100481,
title = {Generative artificial intelligence (Gen-AI) in pharmacy education: Utilization and implications for academic integrity: A scoping review},
journal = {Exploratory Research in Clinical and Social Pharmacy},
volume = {15},
pages = {100481},
year = {2024},
issn = {2667-2766},
doi = {https://doi.org/10.1016/j.rcsop.2024.100481},
url = {https://www.sciencedirect.com/science/article/pii/S2667276624000787},
author = {R. Mortlock and C. Lucas},
keywords = {Artificial intelligence, Academic integrity, ChatGPT, Pharmacy education, Machine learning},
abstract = {Introduction
Generative artificial intelligence (Gen-AI), exemplified by the widely adopted ChatGPT, has garnered significant attention in recent years. Its application spans various health education domains, including pharmacy, where its potential benefits and drawbacks have become increasingly apparent. Despite the growing adoption of Gen-AI such as ChatGPT in pharmacy education, there remains a critical need to assess and mitigate associated risks. This review exploresthe literature and potential strategies for mitigating risks associated with the integration of Gen-AI in pharmacy education.
Aim
To conduct a scoping review to identify implications of Gen-AI in pharmacy education, identify its use and emerging evidence, with a particular focus on strategies which mitigate potential risks to academic integrity.
Methods
A scoping review strategy was employed in accordance with the PRISMA-ScR guidelines. Databases searched includedPubMed, ERIC [Education Resources Information Center], Scopus and ProQuestfrom August 2023 to 20 February 2024 and included all relevant records from 1 January 2000 to 20 February 2024 relating specifically to LLM use within pharmacy education. A grey literature search was also conducted due to the emerging nature of this topic. Policies, procedures, and documents from institutions such as universities and colleges, including standards, guidelines, and policy documents, were hand searched and reviewed in their most updated form. These documents were not published in the scientific literature or indexed in academic search engines.
Results
Articles (n = 12) were derived from the scientific data bases and Records (n = 9) derived from the grey literature. Potential use and benefits of Gen-AI within pharmacy education were identified in all included published articles however there was a paucity of published articles related the degree of consideration to the potential risks to academic integrity. Grey literature recordsheld the largest proportion of risk mitigation strategies largely focusing on increased academic and student education and training relating to the ethical use of Gen-AI as well considerations for redesigning of current assessments likely to be a risk for Gen-AI use to academic integrity.
Conclusion
Drawing upon existing literature, this review highlights the importance of evidence-based approaches to address the challenges posed by Gen-AI such as ChatGPT in pharmacy education settings. Additionally, whilst mitigation strategies are suggested, primarily drawn from the grey literature, there is a paucity of traditionally published scientific literature outlining strategies for the practical and ethical implementation of Gen-AI within pharmacy education. Further research related to the responsible and ethical use of Gen-AI in pharmacy curricula; and studies related to strategies adopted to mitigate risks to academic integrity would be beneficial.}
}
@article{ABUMALLOH2024104128,
title = {Impact of generative artificial intelligence models on the performance of citizen data scientists in retail firms},
journal = {Computers in Industry},
volume = {161},
pages = {104128},
year = {2024},
issn = {0166-3615},
doi = {https://doi.org/10.1016/j.compind.2024.104128},
url = {https://www.sciencedirect.com/science/article/pii/S0166361524000563},
author = {Rabab Ali Abumalloh and Mehrbakhsh Nilashi and Keng Boon Ooi and Garry Wei Han Tan and Hing Kai Chan},
keywords = {Generative AI models, ChatGPT, Citizen Data science, Retail firms, Industrial growth, Industrial and innovation},
abstract = {Generative Artificial Intelligence (AI) models serve as powerful tools for organizations aiming to integrate advanced data analysis and automation into their applications and services. Citizen data scientists—individuals without formal training but skilled in data analysis—combine domain expertise with analytical skills, making them invaluable assets in the retail sector. Generative AI models can further enhance their performance, offering a cost-effective alternative to hiring professional data scientists. However, it is unclear how AI models can effectively contribute to this development and what challenges may arise. This study explores the impact of generative AI models on citizen data scientists in retail firms. We investigate the strengths, weaknesses, opportunities, and threats of these models. Survey data from 268 retail companies is used to develop and validate a new model. Findings highlight that misinformation, lack of explainability, biased content generation, and data security and privacy concerns in generative AI models are major factors affecting citizen data scientists’ performance. Practical implications suggest that generative AI can empower retail firms by enabling advanced data science techniques and real-time decision-making. However, firms must address drawbacks and threats in generative AI models through robust policies and collaboration between domain experts and AI developers.}
}
@incollection{FU2024,
title = {Generative artificial intelligence in operations},
booktitle = {Reference Module in Social Sciences},
publisher = {Elsevier},
year = {2024},
isbn = {978-0-443-15785-1},
doi = {https://doi.org/10.1016/B978-0-443-28993-4.00057-3},
url = {https://www.sciencedirect.com/science/article/pii/B9780443289934000573},
author = {Yingxuan Fu and Hing Kai Chan and Zhao Cai},
keywords = {Generative AI, , Generative adversarial network, Large language model, Transformer, Variational autoencoder},
abstract = {The rise of generative artificial intelligence (AI) may present a significant opportunity for a profound revolution in operations and supply chain management. However, such technological advancement is accompanied by a scholarly discourse that navigates the balance between its promising abilities and challenges. This chapter provides an overview of generative AI in operations and supply chain management. It begins by expositing its fundamental technical concepts and role alongside existing AI technologies. Subsequently, it delves into potential applications and challenges in implementing generative AI in operations. A future research agenda and takeaways for practitioners and Operations Management (OM) researchers are proposed at the end.}
}
@article{COHEN2025100405,
title = {A comparative analysis of generative artificial intelligence responses from leading chatbots to questions about endometriosis},
journal = {AJOG Global Reports},
volume = {5},
number = {1},
pages = {100405},
year = {2025},
issn = {2666-5778},
doi = {https://doi.org/10.1016/j.xagr.2024.100405},
url = {https://www.sciencedirect.com/science/article/pii/S2666577824000996},
author = {Natalie D. Cohen and Milan Ho and Donald McIntire and Katherine Smith and Kimberly A. Kho},
keywords = {chatbots, endometriosis education, health information technology, large language models, patient education, patient information},
abstract = {Introduction
The use of generative artificial intelligence (AI) has begun to permeate most industries, including medicine, and patients will inevitably start using these large language model (LLM) chatbots as a modality for education. As healthcare information technology evolves, it is imperative to evaluate chatbots and the accuracy of the information they provide to patients and to determine if there is variability between them.
Objective
This study aimed to evaluate the accuracy and comprehensiveness of three chatbots in addressing questions related to endometriosis and determine the level of variability between them.
Study Design
Three LLMs, including Chat GPT-4 (Open AI), Claude (Anthropic), and Bard (Google) were asked to generate answers to 10 commonly asked questions about endometriosis. The responses were qualitatively compared to current guidelines and expert opinion on endometriosis and rated on a scale by nine gynecologists. The grading scale included the following: (1) Completely incorrect, (2) mostly incorrect and some correct, (3) mostly correct and some incorrect, (4) correct but inadequate, (5) correct and comprehensive. Final scores were averaged between the nine reviewers. Kendall's W and the related chi-square test were used to evaluate the reviewers’ strength of agreement in ranking the LLMs’ responses for each item.
Results
Average scores for the 10 answers amongst Bard, Chat GPT, and Claude were 3.69, 4.24, and 3.7, respectively. Two questions showed significant disagreement between the nine reviewers. There were no questions the models could answer comprehensively or correctly across the reviewers. The model most associated with comprehensive and correct responses was ChatGPT. Chatbots showed an improved ability to accurately answer questions about symptoms and pathophysiology over treatment and risk of recurrence.
Conclusion
The analysis of LLMs revealed that, on average, they mainly provided correct but inadequate responses to commonly asked patient questions about endometriosis. While chatbot responses can serve as valuable supplements to information provided by licensed medical professionals, it is crucial to maintain a thorough ongoing evaluation process for outputs to provide the most comprehensive and accurate information to patients. Further research into this technology and its role in patient education and treatment is crucial as generative AI becomes more embedded in the medical field.}
}
@article{AWIDI2024100226,
title = {Comparing expert tutor evaluation of reflective essays with marking by generative artificial intelligence (AI) tool},
journal = {Computers and Education: Artificial Intelligence},
volume = {6},
pages = {100226},
year = {2024},
issn = {2666-920X},
doi = {https://doi.org/10.1016/j.caeai.2024.100226},
url = {https://www.sciencedirect.com/science/article/pii/S2666920X24000274},
author = {Isaiah T. Awidi}
}
@article{SINGH2024100531,
title = {Characterizing generative artificial intelligence applications: Text-mining-enabled technology roadmapping},
journal = {Journal of Innovation & Knowledge},
volume = {9},
number = {3},
pages = {100531},
year = {2024},
issn = {2444-569X},
doi = {https://doi.org/10.1016/j.jik.2024.100531},
url = {https://www.sciencedirect.com/science/article/pii/S2444569X24000702},
author = {Shiwangi Singh and Surabhi Singh and Sascha Kraus and Anuj Sharma and Sanjay Dhir},
keywords = {Generative AI, Technology roadmapping, Patents, Text-mining, Structural topic modeling, Patent data mining},
abstract = {This study aims to identify generative AI (GenAI) applications and develop a roadmap for the near, mid, and far future. Structural topic modeling (STM) is used to discover latent semantic patterns and identify the key application areas from a text corpus comprising 2,398 patents published between 2017 and 2023. The study identifies six latent topics of GenAI application, including object detection and identification; medical applications; intelligent conversational agents; image generation and processing; financial and information security applications; and cyber-physical systems. Emergent topic terms are listed for each topic, and inter-topic correlations are explored to understand the thematic structures and summarize the semantic relationships among GenAI application areas. Finally, a technology roadmap is developed for each identified application area for the near, mid, and far future. This study provides valuable insights into the evolving GenAI landscape and helps practitioners make strategic business decisions based on the GenAI roadmap.}
}
@article{ZHANG2025S-318,
title = {1299: GENERATIVE ARTIFICIAL INTELLIGENCE FOR DYNAMIC RISK ASSESSMENT TO PREDICT TRAJECTORIES IN PATIENTS WITH ACUTE GASTROINTESTINAL BLEEDING IN THE INTENSIVE CARE UNIT},
journal = {Gastroenterology},
volume = {169},
number = {1, Supplement },
pages = {S-318},
year = {2025},
issn = {0016-5085},
doi = {https://doi.org/10.1016/S0016-5085(25)01677-4},
url = {https://www.sciencedirect.com/science/article/pii/S0016508525016774},
author = {Xi Zhang and Jun Yup Kim and Yuan Pu and Andrew J. Loza and Alexander Tong and Dennis Shung}
}
@article{KANAKALA2024103175,
title = {Generative artificial intelligence for small molecule drug design},
journal = {Current Opinion in Biotechnology},
volume = {89},
pages = {103175},
year = {2024},
issn = {0958-1669},
doi = {https://doi.org/10.1016/j.copbio.2024.103175},
url = {https://www.sciencedirect.com/science/article/pii/S0958166924001113},
author = {Ganesh Chandan Kanakala and Sriram Devata and Prathit Chatterjee and Udaykumar Deva Priyakumar},
abstract = {In recent years, the rapid advancement of generative artificial intelligence (GenAI) has revolutionized the landscape of drug design, offering innovative solutions to potentially expedite the discovery of novel therapeutics. GenAI encompasses algorithms and models that autonomously create new data, including text, images, and molecules, often mirroring characteristics of existing datasets. This comprehensive review delves into the realm of GenAI for drug design, emphasizing recent advancements and methodologies that have propelled the field forward. Specifically, we focus on three prominent paradigms: transformers, diffusion models, and reinforcement learning algorithms, which have been exceptionally impactful in the last few years. By synthesizing insights from a myriad of studies and developments, we elucidate the potential of these approaches in accelerating the drug discovery process. Through a detailed analysis, we explore the current state and future directions of GenAI in the context of drug design, highlighting its transformative impact on pharmaceutical research and development.}
}
@article{RAJARAM2024629,
title = {Generative artificial intelligence in small and medium enterprises: Navigating its promises and challenges},
journal = {Business Horizons},
volume = {67},
number = {5},
pages = {629-648},
year = {2024},
note = {SPECIAL ISSUE: WRITTEN BY CHATGPT},
issn = {0007-6813},
doi = {https://doi.org/10.1016/j.bushor.2024.05.008},
url = {https://www.sciencedirect.com/science/article/pii/S0007681324000685},
author = {Kumaran Rajaram and Patrick Nicolas Tinguely},
keywords = {Generative artificial intelligence, Small and medium enterprises, AI management, Competitiveness, Digital innovation},
abstract = {The latest technological developments in generative artificial intelligence (GenAI) offer powerful capabilities to small and medium enterprises (SMEs) as they facilitate the democratization of scalability and creativity. With little technical expertise or financial resources, SMEs can leverage this technology to streamline work processes and unleash innovation, improving their product offerings and long-term competitiveness. In this article, we discuss how SMEs can navigate both the promises and challenges of GenAI and offer a roadmap for deploying the technology. We then introduce a sailing metaphor that reveals key strategic dimensions for GenAI deployment: competency of employees, effective leadership and work values, organizational culture, collaboration and cooperation, and relationships with third parties. We conclude with practical recommendations for successfully deploying GenAI in SMEs.}
}
@article{TOROUS2025683,
title = {Assessing generative artificial intelligence for mental health},
journal = {The Lancet},
volume = {406},
number = {10504},
pages = {683},
year = {2025},
issn = {0140-6736},
doi = {https://doi.org/10.1016/S0140-6736(25)01237-1},
url = {https://www.sciencedirect.com/science/article/pii/S0140673625012371},
author = {John Torous and Eric J Topol}
}
@article{ZHAO2024191,
title = {Employees’ perception of generative artificial intelligence and the dark side of work outcomes},
journal = {Journal of Hospitality and Tourism Management},
volume = {61},
pages = {191-199},
year = {2024},
issn = {1447-6770},
doi = {https://doi.org/10.1016/j.jhtm.2024.10.007},
url = {https://www.sciencedirect.com/science/article/pii/S1447677024001207},
author = {Hairong Zhao and Bocong Yuan and Yang Song},
keywords = {, , },
abstract = {Artificial intelligence (as well as generative AI) has been increasingly applied in the tourism and hospitality industry and has an important impact on the work behavior of practitioners. Drawing from the transactional theory of stress and coping, this study is to clarify the mechanism of potential negative impact of AI on the work outcomes of tourism and hospitality practitioners who use generative AI (GenAI) to assist their work. This study conducts in-depth interviews and thematic analysis to explore how the use of GenAI affects negative work behaviors among tourism and hospitality practitioners. The results show that employees’ technical fear towards AI is negatively associated with their sense of realism, self-investment, and habitual perception, but positively associated with the perceived threat of job intelligence to employment. Moreover, the technical fear towards AI can be positively associated with their transgression behavior. The findings of this study can be illuminating for helping tourism and hospitality organizations develop sustainable and healthy workplace guidelines.}
}
@article{CHO2025101418,
title = {Exploring international students' perceptions of adopting generative artificial intelligence (GenAI) technologies in learning},
journal = {Social Sciences & Humanities Open},
volume = {11},
pages = {101418},
year = {2025},
issn = {2590-2911},
doi = {https://doi.org/10.1016/j.ssaho.2025.101418},
url = {https://www.sciencedirect.com/science/article/pii/S2590291125001457},
author = {Changwhan Cho and Duke Ofosu-Anim},
abstract = {This study explores international students' perceptions of GenAI technologies in higher education, focusing on how gender and age influence their willingness to adopt. A survey of 122 international graduate students from a private university in South Korea showed that the students are generally familiar with GenAI and its uses in learning. However, its usage varied in frequency. The study also finds that male students are more likely to use GenAI than female students. Additionally, the study revealed age-related differences in the willingness of international students to adopt GenAI, with younger students showing more interest and willingness than older students. However, despite the differences in interest levels in adopting GenAI among genders and ages, the study revealed that overall, there is a general willingness among international students to learn and apply GenAI technologies to their studies. The South Korean education system can be reformed to accommodate the emerging and growing relevance of GenAI in education by developing ethical capacities that will enhance learning while addressing students’ concerns.}
}
@article{WALLER2025102227,
title = {Reliable answers to patients’ questions: A fundamental need in any patient education tool, especially generative artificial intelligence},
journal = {Journal of Nuclear Cardiology},
volume = {47},
pages = {102227},
year = {2025},
issn = {1071-3581},
doi = {https://doi.org/10.1016/j.nuclcard.2025.102227},
url = {https://www.sciencedirect.com/science/article/pii/S1071358125001011},
author = {Alfonso H. Waller and Baoqiong Liu},
keywords = {Artificial intelligence, Generative artificial intelligence, ChatGPT, Nuclear stress, Fluorodeoxyglucose, Positron emission tomography}
}
@article{MOUSSA2025202990,
title = {Validation of a generative artificial intelligence tool for the critical appraisal of articles on the epidemiology of mental health: Its application in the Middle East and North Africa},
journal = {Journal of Epidemiology and Population Health},
volume = {73},
number = {2},
pages = {202990},
year = {2025},
issn = {2950-4333},
doi = {https://doi.org/10.1016/j.jeph.2025.202990},
url = {https://www.sciencedirect.com/science/article/pii/S2950433325001843},
author = {Cheima Moussa and Sarah Altayyar and Marion Vergonjeanne and Thibaut Gelle and Pierre-Marie Preux},
keywords = {Artificial intelligence, ChatGPT, Critical appraisal, Mental health, MENA},
abstract = {Mental health disorders have a high disability-adjusted life years in the Middle East and North Africa. This rise has led to a surge in related publications, prompting researchers to use AI tools like ChatGPT to reduce time spent on routine tasks. Our study aimed to validate an AI-assisted critical appraisal (CA) tool by comparing it with human raters. We developed customized GPT models using ChatGPT-4. These models were tailored to evaluate studies using the Newcastle-Ottawa Scale (NOS) or the Jadad Scale in one model, while another model evaluated STROBE or CONSORT guidelines. Our results showed a moderate to good agreement between human CA and our GPTs for the NOS for cohort, case control and cross-sectional studies and for the Jadad scale, with an ICC of 0.68 [95 %CI: 0.24–0.82], 0.69 [95 %CI: 0.31–0.88], 0.76 [95 %CI: 0.47–0.90] and 0.84 [95 %CI: 0.57–0.94] respectively. There was also a moderate to substantial agreement between the two methods for STROBE in cross sectional, cohort, case control studies, and for CONSORT in trial design, with a K of 0.63 [95 %CI: 0.56–0.70], 0.57 [95 %CI: 0.47–0.66], 0.48 [95 %CI: 0.38–0.50] and 0.70 [95 %CI: 0.63–0.77] respectively. Our custom GPT models produced hallucinations in 6.5 % and 4.9 % of cases, respectively. Human raters took an average of 19.6 ± 4.3 min per article, whereas our customized GPTs took only 1.4. ChatGPT could be a useful tool for handling repetitive tasks yet its effective application relies on the critical expertise of researchers.}
}
@article{JIANG2024102883,
title = {When generative artificial intelligence meets multimodal composition: Rethinking the composition process through an AI-assisted design project},
journal = {Computers and Composition},
volume = {74},
pages = {102883},
year = {2024},
issn = {8755-4615},
doi = {https://doi.org/10.1016/j.compcom.2024.102883},
url = {https://www.sciencedirect.com/science/article/pii/S8755461524000598},
author = {Jialei Jiang},
keywords = {Generative artificial intelligence, Multimodal composition process, Adobe Firefly, DALL·E, Wicked problems, Design, Writing studies},
abstract = {This study explores the integration of generative artificial intelligence (GenAI) design technologies, including Adobe Firefly and DALL·E, into the teaching and learning of multimodal composition. Through focus group discussions and case studies, this paper demonstrates the potential of GenAI in reshaping the various stages of the composition process, including invention, designing, and revising. The findings reveal that GenAI technologies have the potential to enhance students’ multimodal composition practices and offer alternative solutions to the wicked problems encountered during the design process. Specifically, GenAI facilitates invention by offering design inspirations and enriches designing by expanding, removing, and editing the student-produced design contents. The students in this study also shared their critical stance on the revision process by modifying and iterating their designs after their uses of GenAI. Through showcasing both the opportunities and challenges of GenAI technologies, this paper contributes to the ongoing scholarly conversations on multimodal composition and pedagogy. Moreover, the paper offers implications for the future research and teaching of GenAI-assisted multimodal composition projects, with the aim of encouraging thoughtful integration of GenAI technologies to foster critical AI literacy among college composition students.}
}
@article{ALLEN2025S64,
title = {OS03-09 Surveying the Landscape: A Modular Generative Artificial Intelligence Workflow to Identify NAMs for Systemic Toxicity},
journal = {Toxicology Letters},
volume = {411},
pages = {S64},
year = {2025},
note = {Abstracts of the 59th Congress of the European Societies of Toxicology (EUROTOX 2025) TOXICOLOGY ADDRESSES SOCIETY'S REAL LIFE RISKS FOR SUSTAINABLE HEALTH AND WELL BEING},
issn = {0378-4274},
doi = {https://doi.org/10.1016/j.toxlet.2025.07.180},
url = {https://www.sciencedirect.com/science/article/pii/S0378427425017631},
author = {D. Allen and E. Martin and J. Hamm and J. Wignall and K. To and T. Feiler and C. Lemeris and P. Kukic},
abstract = {To identify the areas of systemic toxicity with the greatest need, and which present the best opportunities for human-relevant model (i.e., new approach methodologies [NAMs]) development, standardization, and implementation, we conducted a landscape analysis to collect information on ongoing efforts in the NAMs space. This type of analysis traditionally requires the collection, manual review, summary, and synthesis of an extensive literature base that requires hundreds of hours to complete. To increase both speed and efficiency, we utilized a reproducible workflow that incorporates multiple computational tools including generative artificial intelligence (GenAI) to quickly summarize a large literature database. Our integrated approach coupled subject matter expertise with sorting and extraction algorithms to provide a comprehensive overview of the state of the science for NAMs used for, or potentially useful for, the assessment of systemic toxicity of cosmetics. To identify potentially relevant studies, we conducted a literature search with keywords related to NAMs across three major topic areas: in silico, in chemico, and in vitro. We prioritized studies by coupling supervised clustering, topic extraction and keyword analysis algorithms. These methods led to the prioritization of 8,418 studies. To identify relevant studies, subject matter experts were employed in conjunction with active machine learning to identify relevant studies that were then summarized via GenAI. Given the objective was to provide sufficient coverage of the landscape to both address pragmatic, near-term needs, as well as shaping the future of how safety assessments are performed, we designed prompts to characterize the current and past systematic efforts directed towards developing and refining NAMs, including both success stories, scientific and technical challenges, and roadblocks to wider adoption. Our analysis identified 3,010 peer-reviewed publications and 38 consortium websites cataloguing NAMs that were applicable to the cosmetics regulatory process, from hazard-focused endpoints to exposure-based waiving of studies altogether. Additionally, they covered the full spectrum of maturity, from those approaches that show promise at the research and development phase to fully validated approaches ready for immediate regulatory use. To the extent available, we identified the molecular/cellular endpoints associated with each NAM and the reference dataset that was used to develop and/or evaluate usefulness and limitations across a total of 60,960 endpoints. The landscape also captured opportunities to validate mature NAMs to support their regulatory use and market adoption. These results will support the development and identification of NAMs to be included in frameworks for assessing systemic toxicity potential.}
}
@article{COSCI2025112113,
title = {Generative artificial intelligence: A hot topic to face with},
journal = {Journal of Psychosomatic Research},
volume = {192},
pages = {112113},
year = {2025},
issn = {0022-3999},
doi = {https://doi.org/10.1016/j.jpsychores.2025.112113},
url = {https://www.sciencedirect.com/science/article/pii/S0022399925000777},
author = {Fiammetta Cosci and Antonina Mikocka-Walus}
}
@article{SUN2025103974,
title = {A methodological exploration of generative artificial intelligence (AI) for efficient qualitative analysis on hotel guests’ delightful experiences},
journal = {International Journal of Hospitality Management},
volume = {124},
pages = {103974},
year = {2025},
issn = {0278-4319},
doi = {https://doi.org/10.1016/j.ijhm.2024.103974},
url = {https://www.sciencedirect.com/science/article/pii/S027843192400286X},
author = {Hala Sun and MiRan Kim and Soyeon Kim and Laee Choi},
keywords = {Artificial Intelligence, ChatGPT, Customer, Delight grounded theory, Hospitality industry, Qualitative content analysis},
abstract = {This study explores the use of generative artificial intelligence (AI), specifically ChatGPT, in analyzing qualitative data on hotel guests’ delightful experiences. To assess the utility and trustworthiness of ChatGPT as a supplementary tool, we compared human coding, guided by Grounded Theory and Qualitative Content Analysis method, with AI-augmented coding using developed prompts in analyzing survey data. Our findings reveal that the majority of ChatGPT's themes and codes of customer delight closely match those identified by human coders, suggesting its potential to streamline data analysis. However, there are also notable differences, as human coders emphasized customer-to-customer interactions and safety and security, which were not identified by ChatGPT. The research contributes to hospitality literature by establishing a methodology for using ChatGPT in qualitative analysis, highlighting its efficiency in analyzing comments and open-ended survey data.}
}
@article{FELICETTI2024100545,
title = {Artificial intelligence and project management: An empirical investigation on the appropriation of generative Chatbots by project managers},
journal = {Journal of Innovation & Knowledge},
volume = {9},
number = {3},
pages = {100545},
year = {2024},
issn = {2444-569X},
doi = {https://doi.org/10.1016/j.jik.2024.100545},
url = {https://www.sciencedirect.com/science/article/pii/S2444569X24000842},
author = {Alberto Michele Felicetti and Antonio Cimino and Alberto Mazzoleni and Salvatore Ammirato},
keywords = {Project managers, Generative artificial intelligence, Chatgpt, Appropriation Theory, Structural Equation Modeling},
abstract = {The integration of generative AI tools, such as chatbots, into project management is revolutionizing the field. This paper explores how project managers are adopting and adapting these tools, specifically focusing on ChatGPT, for enhanced project management. Using Adaptive Structuration Theory, the study examines project managers' appropriation of generative AI. It considers factors like Innovation Attitude, Peer Influence, and Task-Technology Fit, employing a survey of Italian project managers. The approach adopted to analyze data is based on Partial Least Square - Structural Equation Modeling. The research confirms the significance of the hypothesized antecedents in AI tool appropriation. Innovation Attitude and Peer Influence are shown to positively impact the creative and 'unfaithful' use of AI in project management. Task-Technology Fit is crucial for effective AI integration, impacting both creative behaviour and unfaithful appropriation. The study highlights the role of an innovative mindset, peer dynamics, and task compatibility in the effective use of AI tools in project management. It suggests potential areas for future research, including exploring cultural and organizational contexts and the rapid evolution of AI technologies.}
}
@article{BONNET2024,
title = {Unfolding the Potential of Generative Artificial Intelligence:},
journal = {International Journal of Knowledge Management},
volume = {21},
number = {1},
year = {2024},
issn = {1548-0666},
doi = {https://doi.org/10.4018/IJKM.368223},
url = {https://www.sciencedirect.com/science/article/pii/S154806662500013X},
author = {Severin Bonnet and Frank Teuteberg},
keywords = {Generative AI Chatbots, Artificial Intelligence, AI Based Chatbots, Academic Research, ChatGPT},
abstract = {ABSTRACT
Scholars are increasingly using generative artificial intelligence (AI) chatbots, like ChatGPT, in research, though concerns remain about ethics, data privacy, bias, and intellectual property. This study adopts a design science research approach to explore how generative AI chatbots can support academic teaching and research, bridging theory and practice. A literature review and expert interviews identified key requirements and design principles that support virtues such as uniqueness, generalizability, and reproducibility. We also introduce a prototype, “AcademiaBot,” to demonstrate these principles in action. Our findings suggest that AI chatbots can significantly aid scholarly work if users are informed and ethical concerns are addressed. Responsible usage can help AI augment human research efforts without compromising integrity. This study provides valuable design knowledge, ensuring AI-based chatbots remain a beneficial tool for scholars.}
}
@article{RASHID2025S268,
title = {MT14 Role of Generative Artificial Intelligence in Assisting Systematic Review Process in Health Research: A Systematic Review},
journal = {Value in Health},
volume = {28},
number = {6, Supplement 1},
pages = {S268},
year = {2025},
issn = {1098-3015},
doi = {https://doi.org/10.1016/j.jval.2025.04.1124},
url = {https://www.sciencedirect.com/science/article/pii/S1098301525012495},
author = {Muhammed Rashid and Cheng Su Yi and Suwapat Lawin and Pongsapat Limhensin and Suppachai Insuk and Sajesh K. Veettil and Nai Ming Lai and Xiangyang Ye and Nathorn Chaiyakunapruk and Teerapon Dhippayom}
}
@article{ZHAO2025108654,
title = {“Positive” or “Threatened”? The impact of the features in generative artificial intelligence on continued behavior},
journal = {Computers in Human Behavior},
volume = {168},
pages = {108654},
year = {2025},
issn = {0747-5632},
doi = {https://doi.org/10.1016/j.chb.2025.108654},
url = {https://www.sciencedirect.com/science/article/pii/S0747563225001013},
author = {Li Zhao and Yun Xu and Sheng-kai Zhou},
keywords = {Artificial intelligence generated content (AIGC), Positive awe, Threatened awe, Continued usage intention},
abstract = {Artificial intelligence technologies have empowered marketers with advanced tools and insights, fostering unparalleled efficiency and personalization decision-making. To provide marketers with targeted and actionable guidance, this study investigated the behavioral mechanisms underlying the adoption of artificial intelligence-generated content (AIGC) technology. Specifically, it examined the influence of AIGC features (accuracy, competence, anthropomorphism, and interactivity) and the distinct psychological mechanisms of awe on users' behavioral intentions. A mixed-methods approach was employed, combining quantitative data (N = 860) with qualitative research (user reviews). The analysis revealed that the awe experience significantly influences AIGC users' preferences to continue using the technology. Positive awe had a significant positive effect, while threatened awe had a comparatively weaker negative effect. The four features (accuracy, competence, anthropomorphism, and interactivity) of AIGC contribute significantly to its users' continued usage intention. Notably, positive awe induced by competence, anthropomorphism, and interactivity significantly outweighed threatened awe, with the exception of accuracy. The findings reveal that the unique features of AIGC not only evoke users’ perceived awe but also strengthen their intentions to continue using the technology.}
}
@article{KENOPURUM2025S301,
title = {MSR139 Application of Generative Artificial Intelligence for Extracting Structured Data from Unstructured Bladder Cancer Pathology Reports},
journal = {Value in Health},
volume = {28},
number = {6, Supplement 1},
pages = {S301},
year = {2025},
issn = {1098-3015},
doi = {https://doi.org/10.1016/j.jval.2025.04.1290},
url = {https://www.sciencedirect.com/science/article/pii/S1098301525014159},
author = {Jennifer Ken-Opurum and Sidharth Singh and P. Pranav and Rahul Bhonsle and Shekhar Thumake and Heather Marino and Luke Dunlap}
}
@article{YANG2025104877,
title = {The impact of TPACK on teachers’ willingness to integrate generative artificial intelligence (GenAI): The moderating role of negative emotions and the buffering effects of need satisfaction},
journal = {Teaching and Teacher Education},
volume = {154},
pages = {104877},
year = {2025},
issn = {0742-051X},
doi = {https://doi.org/10.1016/j.tate.2024.104877},
url = {https://www.sciencedirect.com/science/article/pii/S0742051X24004104},
author = {Yiming Yang and Qi Xia and Chuanbin Liu and Thomas K.F. Chiu},
keywords = {TPACK, Negative emotions, Self-determination theory (SDT), Generative artificial intelligence (GenAI), Teachers' willingness},
abstract = {Understanding teachers' willingness to integrate generative AI (WIAI) is essential in the current dilemma where students' adoption rate is faster than teachers'. Therefore, this study aims to identify factors affecting teachers' WIAI and their interactions from the perspectives of needs satisfaction and emotion. We used regression analyses to analyze data collected from 1348 teachers online. The results supported that TPACK positively influences teachers' WIAI, but this effect is weakened by negative emotions, while needs satisfaction for competence and relatedness buffers the negative effect more effectively than autonomy. These highlight the role of emotional and psychological support in fostering teachers’ adoptions.}
}
@article{KARELL2025101966,
title = {Synthetic duality: A framework for analyzing generative artificial intelligence's representation of social reality},
journal = {Poetics},
volume = {108},
pages = {101966},
year = {2025},
issn = {0304-422X},
doi = {https://doi.org/10.1016/j.poetic.2024.101966},
url = {https://www.sciencedirect.com/science/article/pii/S0304422X24001049},
author = {Daniel Karell and Jeffrey Sachs and Ryan Barrett},
keywords = {Duality, Mondo-Breiger, Socio-semantic networks, Large language models, Generative artificial intelligence},
abstract = {The development of generative artificial intelligence (genAI) has caused concern about its potential risks, including how its ability to generate human-like texts could affect our shared perception of the social world. Yet, it remains unclear how best to assess and understand genAI's influence on our understanding of social reality. Building on insights into the representation of social worlds within texts, we introduce a framework for analyzing genAI's content and its consequences for perceptions of social reality. We demonstrate this “synthetic duality” framework in two parts. First, we show that genAI can create, with minimal guidance, reasonable portrayals of actors and ascribe relational meaning to those actors – virtual social worlds within texts, or “Mondo-Breigers”. Second, we examine how these synthetic documents with interior social worlds affect readers’ view of social reality. We find that they change individuals’ perceptions of actors depicted in the documents, likely by updating individuals’ expectations about the actors and their meanings. However, additional exploratory analyses suggest it is texts’ style, not their construction of “Mondo-Breigers”, that might be influencing people's perceptions. We end with a discussion of theoretical and methodological implications, including how genAI may unsettle structural notions of individuality. Namely, reimagining the duality of individuals and groups could help theorize growing homogeneity in an increasingly genAI-informed world.}
}
@article{RUIZ2025206,
title = {71361968-2415 - Is the use of Generative-Artificial Intelligence suitable for diagnosing Maxillofacial Pathologies?},
journal = {International Journal of Oral and Maxillofacial Surgery},
volume = {54},
pages = {206},
year = {2025},
note = {ICOMS Singapore 2025},
issn = {0901-5027},
doi = {https://doi.org/10.1016/j.ijom.2025.04.562},
url = {https://www.sciencedirect.com/science/article/pii/S0901502725006769},
author = {O. Peña Ruiz and J. Castellanos and J. Sifuentes-Cervantes and M. Villarroel-Dorrego and F. Bermudez}
}
@article{GANJOO2024,
title = {Beyond boundaries: exploring a generative artificial intelligence assignment in graduate, online science courses},
journal = {Journal of Microbiology & Biology Education},
volume = {25},
number = {3},
year = {2024},
issn = {1935-7877},
doi = {https://doi.org/10.1128/jmbe.00127-24},
url = {https://www.sciencedirect.com/science/article/pii/S1935787724000893},
author = {Rohini Ganjoo and James Rankin and Benjamin Lee and Lisa Schwartz},
keywords = {generative artificial intelligence, graduate courses, assignment, online education, health professional education},
abstract = {ABSTRACT

Generative artificial intelligence (GAI) offers increased accessibility and personalized learning, though the potential for inaccuracies, biases, and unethical use is concerning. We present a newly developed research paper assignment that required students to utilize GAI. The assignment was implemented within three online, asynchronous graduate courses for medical laboratory sciences. Student learning was assessed using a rubric, which rated students’ effective integration and evaluation of GAI-generated content against peer-reviewed research articles, thus demonstrating their critical thinking and synthesis skills, among other metrics. Overall rubric scores were high, suggesting that learning outcomes were met. After field testing, we administered a 16-item survey about GAI utilization, contribution to learning, and ethical concerns. Data (n = 32) were analyzed, and free-response answers were thematically coded. While 93.8% of respondents found the GAI-generated content to be “very good” or “excellent,” 28.1% found inaccuracies, and 68.8% “strongly agreed” or “agreed” that GAI should be allowed to be used as a tool to complete academic assignments. Interestingly, however, only 28.1% “strongly agreed” or “agreed” that GAI may be used for assignments if not explicitly authorized by the instructor. Though GAI allowed for more efficient completion of the project and better understanding of the topic, students noted concerns about academic integrity and the lack of citations in GAI responses. The assignment can easily be modified for different learning preferences and course environments. Raising awareness among students and faculty about the ethical use and limitations of GAI is crucial in today’s evolving pedagogical landscape.}
}
@article{CURRIE2025423,
title = {Generative Artificial Intelligence Biases, Limitations and Risks in Nuclear Medicine: An Argument for Appropriate Use Framework and Recommendations},
journal = {Seminars in Nuclear Medicine},
volume = {55},
number = {3},
pages = {423-436},
year = {2025},
note = {Artificial Intelligence},
issn = {0001-2998},
doi = {https://doi.org/10.1053/j.semnuclmed.2024.05.005},
url = {https://www.sciencedirect.com/science/article/pii/S0001299824000461},
author = {Geoffrey M. Currie and K. Elizabeth Hawk and Eric M. Rohren},
abstract = {Generative artificial intelligence (AI) algorithms for both text-to-text and text-to-image applications have seen rapid and widespread adoption in the general and medical communities. While limitations of generative AI have been widely reported, there remain valuable applications in patient and professional communities. Here, the limitations and biases of both text-to-text and text-to-image generative AI are explored using purported applications in medical imaging as case examples. A direct comparison of the capabilities of four common text-to-image generative AI algorithms is reported and recommendations for the most appropriate use, DALL-E 3, justified. The risks use and biases are outlined, and appropriate use guidelines framed for use of generative AI in nuclear medicine. Generative AI text-to-text and text-to-image generation includes inherent biases, particularly gender and ethnicity, that could misrepresent nuclear medicine. The assimilation of generative AI tools into medical education, image interpretation, patient education, health promotion and marketing in nuclear medicine risks propagating errors and amplification of biases. Mitigation strategies should reside inside appropriate use criteria and minimum standards for quality and professionalism for the application of generative AI in nuclear medicine.}
}
@article{KANAPARTHY2025,
title = {Real-World Evidence Synthesis of Digital Scribes Using Ambient Listening and Generative Artificial Intelligence for Clinician Documentation Workflows: Rapid Review},
journal = {JMIR AI},
volume = {4},
year = {2025},
issn = {2817-1705},
doi = {https://doi.org/10.2196/76743},
url = {https://www.sciencedirect.com/science/article/pii/S2817170525000808},
author = {Naga Sasidhar Kanaparthy and Yenny Villuendas-Rey and Tolulope Bakare and Zihan Diao and Mark Iscoe and Andrew Loza and Donald Wright and Conrad Safranek and Isaac V Faustino and Alexandria Brackett and Edward R Melnick and R Andrew Taylor},
keywords = {digital scribes, artificial intelligence in medicine, clinical documentation, speech recognition software, patient-clinician communication},
abstract = {Background
As physicians spend up to twice as much time on electronic health record tasks as on direct patient care, digital scribes have emerged as a promising solution to restore patient-clinician communication and reduce documentation burden—making it essential to study their real-world impact on clinical workflows, efficiency, and satisfaction.
Objective
This study aimed to synthesize evidence on clinician efficiency, user satisfaction, quality, and practical barriers associated with the use of digital scribes using ambient listening and generative artificial intelligence (AI) in real-world clinical settings.
Methods
A rapid review was conducted to evaluate the real-world evidence of digital scribes using ambient listening and generative AI in clinical practice from 2014 to 2024. Data were collected from Ovid MEDLINE, Embase, Web of Science–Core Collection, Cochrane CENTRAL and Reviews, and PubMed Central. Predefined eligibility criteria focused on studies addressing clinical implementation, excluding those centered solely on technical development or model validation. The findings of each study were synthesized and analyzed through the QUEST human evaluation framework for quality and safety and the Systems Engineering Initiative for Patient Safety (SEIPS) 3.0 model to assess integration into clinicians’ workflows and experience.
Results
Of the 1450 studies identified, 6 met the inclusion criteria. These studies included an observational study, a case report, a peer-matched cohort study, and survey-based assessments conducted across academic health systems, community settings, and outpatient practices. The major themes noted were as follows: (1) they decreased self-reported documentation times, with associated increased length of notes; (2) physician burnout measured using standardized scales was unaffected, but physician engagement improved; (3) physician productivity, assessed via billing metrics, was unchanged; and (4) the studies fell short when compared to standardized frameworks.
Conclusions
Digital scribes show promise in reducing documentation burden and enhancing clinician satisfaction, thereby supporting workflow efficiency. However, the currently available evidence is sparse. Future real-world, multifaceted studies are needed before AI scribes can be recommended unequivocally.}
}
@article{PELLEGRINO2025S126,
title = {OC.02.7 CONVERSATIONAL LARGE LANGUAGE MODEL GENERATIVE ARTIFICIAL INTELLIGENCE CHATBOT CHATGPT-4 FOR COLONOSCOPY BOSTON BOWEL PREPARATION SCORING: AN AI-TO-HEAD HUMAN-BLINDED CONCORDANCE ANALYSIS ON A LARGE VOLUME OF ENDOSCOPIC FRAMES},
journal = {Digestive and Liver Disease},
volume = {57},
pages = {S126-S127},
year = {2025},
note = {Abstracts of the 31st National Congress of Digestive Diseases, FISMAD},
issn = {1590-8658},
doi = {https://doi.org/10.1016/S1590-8658(25)00382-2},
url = {https://www.sciencedirect.com/science/article/pii/S1590865825003822},
author = {R. Pellegrino and G. Palladino and G. Imperio and A. Federico and A.G. Gravina}
}
@article{LI2025S280,
title = {MSR33 Automated Extraction of Kaplan-Meier Survival Curves Using Generative Artificial Intelligence and Computer Vision},
journal = {Value in Health},
volume = {28},
number = {6, Supplement 1},
pages = {S280},
year = {2025},
issn = {1098-3015},
doi = {https://doi.org/10.1016/j.jval.2025.04.1185},
url = {https://www.sciencedirect.com/science/article/pii/S1098301525013105},
author = {Ying Li and Augustine Annan and Majid R. Mojarad and Jingcheng Du and Yingxin Xu}
}
@article{MCDONALD2025100121,
title = {Generative artificial intelligence in higher education: Evidence from an analysis of institutional policies and guidelines},
journal = {Computers in Human Behavior: Artificial Humans},
volume = {3},
pages = {100121},
year = {2025},
issn = {2949-8821},
doi = {https://doi.org/10.1016/j.chbah.2025.100121},
url = {https://www.sciencedirect.com/science/article/pii/S2949882125000052},
author = {Nora McDonald and Aditya Johri and Areej Ali and Aayushi Hingle Collier},
abstract = {The release of ChatGPT in November 2022 prompted a massive uptake of generative artificial intelligence (GenAI) across higher education institutions (HEIs). In response, HEIs focused on regulating its use, particularly among students, before shifting towards advocating for its productive integration within teaching and learning. Since then, many HEIs have increasingly provided policies and guidelines to direct GenAI. This paper presents an analysis of documents produced by 116 US universities classified as as high research activity or R1 institutions providing a comprehensive examination of the advice and guidance offered by institutional stakeholders about GenAI. Through an extensive analysis, we found a majority of universities (N = 73, 63%) encourage the use of GenAI, with many offering detailed guidance for its use in the classroom (N = 48, 41%). Over half the institutions provided sample syllabi (N = 65, 56%) and half (N = 58, 50%) provided sample GenAI curriculum and activities that would help instructors integrate and leverage GenAI in their teaching. Notably, the majority of guidance focused on writing activities focused on writing, whereas references to code and STEM-related activities were infrequent, and often vague, even when mentioned (N = 58, 50%). Finally, more than half of institutions talked about the ethics of GenAI on a broad range of topics, including Diversity, Equity and Inclusion (DEI) (N = 60, 52%). Based on our findings we caution that guidance for faculty can become burdensome as policies suggest or imply substantial revisions to existing pedagogical practices.}
}
@article{ERIKSEN2024100016,
title = {Generative artificial intelligence for increasing accessibility of patient information videos in ophthalmology},
journal = {AJO International},
volume = {1},
number = {1},
pages = {100016},
year = {2024},
issn = {2950-2535},
doi = {https://doi.org/10.1016/j.ajoint.2024.100016},
url = {https://www.sciencedirect.com/science/article/pii/S2950253524000169},
author = {Nathalie S. Eriksen and Moug Al-Bakri and Kirstine B. Boysen and Oliver N. Klefter and Diana C. Schmidt and Kirsten Reinwaldt and Jakob Grauslund and Lars M. Holm and Yousif Subhi},
keywords = {Artificial intelligence, Accessibility, Patient information videos},
abstract = {Purpose
Patient information videos are excellent for conveying information on eye health. Language barriers lead to inaccessibility for ethnic minorities. So far, overcoming language barriers have been very expensive, but in this short communications paper, we share our experiences with an inexpensive generative artificial intelligence-based translation system for videos.
Design
Explorative study.
Methods
We developed a patient information video on a very common and broadly relevant issue: how to use eye drops. The original video was made in Danish. We used HeyGen (HeyGen, Los Angeles, California, USA) to translate the video into three categories according to distance from Danish according to comparative linguistics: highly related (English and German), remotely related (French and Polish), and no recognizable relationship (Arabic and Turkish). Ophthalmologists with high proficiency in Danish and each of these languages evaluated and commented on the accuracy of the translations.
Results
All translations resulted in a recognizable clone of the original individual with synchronized lip movements and understandable language. We observed certain inaccuracies in the translation, however, these differed across languages without a specific pattern. Inconsistencies in formal/informal pronouns were observed across languages. But overall, the general information was conveyed across all languages.
Conclusion
Modern generative artificial intelligence-based translation tools can help tearing down language barriers and improve accessibility of patient information videos in ophthalmology.}
}
@article{YOGARATNAM2025100226,
title = {What Becomes of the Human Touch in the Age of Generative Artificial Intelligence?},
journal = {Mayo Clinic Proceedings: Digital Health},
volume = {3},
number = {2},
pages = {100226},
year = {2025},
issn = {2949-7612},
doi = {https://doi.org/10.1016/j.mcpdig.2025.100226},
url = {https://www.sciencedirect.com/science/article/pii/S2949761225000331},
author = {Kishwen Kanna {Yoga Ratnam}}
}
@article{WANG2025100996,
title = {A systematic literature review on the application of generative artificial intelligence (GAI) in teaching within higher education: Instructional contexts, process, and strategies},
journal = {The Internet and Higher Education},
volume = {65},
pages = {100996},
year = {2025},
issn = {1096-7516},
doi = {https://doi.org/10.1016/j.iheduc.2025.100996},
url = {https://www.sciencedirect.com/science/article/pii/S1096751625000053},
author = {Peijun Wang and Yuhui Jing and Shusheng Shen},
keywords = {GAI, Higher education, Systematic literature review, Chatgpt, Instructional strategies},
abstract = {Represented by ChatGPT, Generative Artificial Intelligence (GAI) is revolutionizing the field of education. Despite a series of related studies and reviews around GAI, existing reviews predominantly focus on macro-level discussions covering overall development trends, core issues, opportunities and risks. There has been a lack of systematic reviews from a meso-level perspective examining the application of GAI in classroom teaching within higher education. This study employs a systematic literature review method, examining 139 articles from Web of Science, EBSCO, and Scopus databases. Findings include: (1)In terms of disciplines and types of GAI applications, engineering, health and medicine, and language are the most popular, while humanities, social sciences, basic sciences, mathematics, sports sciences, and interdisciplinary fields have fewer applications. Based on Strobel's classification of GAI(2024), it is found that Generators, Reimaginators, and Assistants are the most widely applied types of GAI. In contrast, Synthesizers and Enablers are less commonly utilized. Regarding the adoption trends across disciplines, engineering and language have a diverse range of GAI product types applied, whereas health and medicine has fewer types of GAI products in use. Due to smaller sample sizes, the analysis of GAI product types in the remaining six disciplines is also relatively limited. (2)In terms of the application of GAI across different disciplines, a small portion of GAI applications reflect distinctive disciplinary characteristics. Regarding the roles mapped out by the application of GAI, based on Xu and Ouyang's classification(2022), instructors or students predominantly perceive GAI as “New Subject” or “Direct Mediator", with less emphasis on the role of “Supplement Assistant”. Regarding the integration into the classroom, as assessed through the SAMR framework, most GAI applications are in the Augmentation level. There are also some in the Substitution and Modification levels, while applications in the Redefinition level are relatively rare. (3)In terms of the selection of instructional strategies under GAI applications, there are 18 types of strategies across four orientations, primarily emphasizing constructive and reflective orientations. Strategies focusing on didactic and authentic orientiations are less frequently utilized. Regarding the roles GAI plays as reflected in instructional strategies, it predominantly assumes roles as “New Subject” and “Direct Mediator", with the role of “Supplementary Assistant” yet to be explored. Finally, this study evaluated the instructional application research of GAI from three dimensions: GAI product type and applied discipline, discipline-specific application and integration level, instructional strategies and GAI role, and put forward relevant research suggestions.}
}
@article{ABDALLAH2025,
title = {Generative Artificial Intelligence Models for Developing Neuroimaging Markers of Psychiatric Disorders},
journal = {Biological Psychiatry},
year = {2025},
issn = {0006-3223},
doi = {https://doi.org/10.1016/j.biopsych.2025.05.002},
url = {https://www.sciencedirect.com/science/article/pii/S0006322325011849},
author = {Chadi G. Abdallah and David {van Dijk}}
}
@article{ALEXANDER2025101416,
title = {Exploring Generative Artificial Intelligence to Enhance Reflective Writing in Pharmacy Education},
journal = {American Journal of Pharmaceutical Education},
volume = {89},
number = {6},
pages = {101416},
year = {2025},
issn = {0002-9459},
doi = {https://doi.org/10.1016/j.ajpe.2025.101416},
url = {https://www.sciencedirect.com/science/article/pii/S0002945925000610},
author = {Kaitlin M. Alexander and Margeaux Johnson and Michelle Z. Farland and Amy Blue and Emily K. Bald},
keywords = {Artificial intelligence, Reflective writing, Reflection techniques, Self-assessment, Pharmacy education},
abstract = {The integration of generative artificial intelligence (AI) holds the potential to impact teaching and learning. In this commentary, we explore the opportunity for AI to enhance reflective writing (RW) among student pharmacists. AI-guided RW has the potential to strengthen students’ reflective capacity, deepen their autobiographical memory, and develop their self-confidence. This commentary presents examples of how AI can be utilized to enrich RW and includes a sample prompt aimed at facilitating student self-reflection. We explore how integrating AI-facilitated RW assignments into the pharmacy curriculum can help students develop detailed examples for self-reflection and gain exposure to the potential uses of AI in their professional development and career advancement.}
}
@article{LEE2025,
title = {Use of a Medical Communication Framework to Assess the Quality of Generative Artificial Intelligence Replies to Primary Care Patient Portal Messages: Content Analysis},
journal = {JMIR Formative Research},
volume = {9},
year = {2025},
issn = {2561-326X},
doi = {https://doi.org/10.2196/71966},
url = {https://www.sciencedirect.com/science/article/pii/S2561326X25005220},
author = {Natalie S Lee and Nathan Richards and Jodi Grandominico and Robert M Cronin and Amanda K Hendricks and Ravi S Tripathi and Daniel E Jonas},
keywords = {communication, artificial intelligence, primary care, electronic health record, patient portal, health communication},
abstract = {Background
There is growing interest in applying generative artificial intelligence (GenAI) to respond to electronic patient portal messages, particularly in primary care where message volumes are highest. However, evaluations of GenAI as an inbox communication tool are limited. Qualitative analysis of when and how often GenAI responses achieve communication goals can inform estimates of impact and guide continuous improvement.
Objective
This study aims to evaluate GenAI responses to primary care messages using a medical communication framework.
Methods
This was a descriptive quality improvement study of 201 GenAI replies to a purposively sampled, diverse pool of real primary care patient messages in a large midwestern academic medical center. Two physician reviewers (NSL and NR) used a hybrid deductive-inductive approach to qualitatively identify and define themes, guided by constructs from the “best practice” medical communication framework. After achieving thematic saturation, the reviewers assessed the presence or absence of identified communication themes, both independently and collaboratively. Discrepant observations were reconciled via discussion. Frequencies of identified themes were tallied.
Results
Themes in strengths and limitations emerged across 5 communication domains. In the domain of rapport building, expressing respect and restating key phrases were strengths, while inappropriate or inadequate rapport building statements were limitations. For information gathering, questions that built toward a plan or elicited patient needs were strengths, while questions that were out of place or redundant were limitations. For information delivery, accurate content delivered clearly and professionally was a strength, but delivery of inaccurate content was an observed limitation. GenAI responses could facilitate next steps by outlining choices or providing instruction, but sometimes those next steps were inappropriate or premature. Finally, in responding to emotion, strengths were that emotions were named and validated, while inadequate or absent acknowledgment of emotion was a limitation. Overall, 26.4% (53/201) of all messages displayed communication strengths without limitations, 27.4% (55/201) had limitations without strengths, and the remaining 46.3% (93/201) had both. Strengths outnumbered limitations in rapport building (87/201, 43.3% vs 35/201, 17.4%) and facilitating next steps (73/201, 36.3% vs 39/201, 19.4%). Limitations outnumbered strengths in the remaining domains of information delivery (89/201, 44.3% vs 43/201, 21.4%), information gathering (60/201, 29.9% vs 43/201, 21.4%), and responding to emotion (7/201, 8.5% vs 9/201, 4.5%).
Conclusions
GenAI response quality on behalf of primary care physicians and advanced practice providers may vary by communication function. Expressions of respect or descriptions of common next steps may be appropriate, but gathering and delivering appropriate information, or responding to emotion, may be limited. While communication standards were often met, they were also often compromised. Understanding these strengths and limitations can inform decisions about whether, when, and how to apply GenAI as a tool for primary care inbox communication.}
}
@article{CHENG2025100374,
title = {Asking generative artificial intelligence the right questions improves writing performance},
journal = {Computers and Education: Artificial Intelligence},
volume = {8},
pages = {100374},
year = {2025},
issn = {2666-920X},
doi = {https://doi.org/10.1016/j.caeai.2025.100374},
url = {https://www.sciencedirect.com/science/article/pii/S2666920X25000141},
author = {Yixin Cheng and Yizhou Fan and Xinyu Li and Guanliang Chen and Dragan Gašević and Zachari Swiecki},
keywords = {Generative AI, ChatGPT, Question asking, Help seeking, Epistemic network analysis, Mediation analysis},
abstract = {Generative Artificial Intelligence (GenAI) tools are widely used by learners and this trend is poised to continue. However, little is known about whether and how GenAI use impacts learning and performance. This study aimed to investigate the effect of GenAI on performance by examining a key affordance of GenAI—seeking help via question asking. We compared the questions that learners asked GenAI versus a human tutor online during a writing task. Using quantitative ethnographic methods, we found that: (a) participants in the GenAI condition asked significantly more questions compared to those in the Tutor condition; (b) GenAI participants tended to ask one-off questions, while Tutor participants tended to have longer conversational exchanges; (c) GenAI participants tended to question pragmatically, asking direct questions about conceptual and procedural knowledge, while Tutor participants tended to make indirect request for feedback; (d) question asking, as measured by epistemic network analysis, mediated the relationship between experimental condition and performance—the more pragmatic the questions, and thus the more like questions in the GenAI condition, the better the performance; and (e) questions in the GenAI condition were driven by social coordination and knowledge deficits, while questions in the Tutor condition were driven by social coordination and establishing common ground. These findings suggest learners may be less hesitant to admit knowledge deficits and more willing to repair them when interacting with GenAI compared to human tutors. Thus, GenAI can be a useful educational tool when improved performance is the goal and human tutoring may benefit from creating a space where learners are more comfortable revealing a lack of knowledge.}
}
@article{BUGHIN2024658,
title = {What drives the corporate payoffs of using generative artificial intelligence?},
journal = {Structural Change and Economic Dynamics},
volume = {71},
pages = {658-668},
year = {2024},
issn = {0954-349X},
doi = {https://doi.org/10.1016/j.strueco.2024.09.011},
url = {https://www.sciencedirect.com/science/article/pii/S0954349X24001413},
author = {Jacques Bughin},
keywords = {AI, Generative AI, Productivity impact, Capabilities, Entropy},
abstract = {Artificial Intelligence, a set of technologies that aim to replicate human cognitive functions, has seen remarkable improvements over the last decade. In particular, generative AI (GenAI), a subset of AI able to generate content tasks based on Large Language Models (LLM), has recently gained momentum. Based on an extensive analysis of generative AI use cases in large enterprises, we find that Gen AI shows strong labor productivity improvements across metrics such as throughput time, unit cost, and task effectiveness. However, the distribution of gains is asymmetric in favor of a few companies. While the current distribution of gains does not provide evidence of a power law effect, the current asymmetry reflects differences in AI resources/capabilities across companies - mainly data access, AI talent, or AI governance.}
}
@article{INAM2024102387,
title = {A review of top cardiology and cardiovascular medicine journal guidelines regarding the use of generative artificial intelligence tools in scientific writing},
journal = {Current Problems in Cardiology},
volume = {49},
number = {3},
pages = {102387},
year = {2024},
issn = {0146-2806},
doi = {https://doi.org/10.1016/j.cpcardiol.2024.102387},
url = {https://www.sciencedirect.com/science/article/pii/S0146280624000264},
author = {Maha Inam and Sana Sheikh and Abdul Mannan Khan Minhas and Elizabeth M. Vaughan and Chayakrit Krittanawong and Zainab Samad and Carl J. Lavie and Adeel Khoja and Melaine D'Cruze and Leandro Slipczuk and Farhana Alarakhiya and Azra Naseem and Adil H. Haider and Salim S. Virani},
keywords = {Artificial Intelligence, Editorial Policies, ChatGPT, Large Language Models, Machine Learning, Scientific Writing, Cardiology, SCImago},
abstract = {Background
Generative Artificial Intelligence (AI) tools have experienced rapid development over the last decade and are gaining increasing popularity as assistive models in academic writing. However, the ability of AI to generate reliable and accurate research articles is a topic of debate. Major scientific journals have issued policies regarding the contribution of AI tools in scientific writing.
Methods
We conducted a review of the author and peer reviewer guidelines of the top 25 Cardiology and Cardiovascular Medicine journals as per the 2023 SCImago rankings. Data were obtained though reviewing journal websites and directly emailing the editorial office. Descriptive data regarding journal characteristics were coded on SPSS. Subgroup analyses of the journal guidelines were conducted based on the publishing company policies.
Results
Our analysis revealed that all scientific journals in our study permitted the documented use of AI in scientific writing with certain limitations as per ICMJE recommendations. We found that AI tools cannot be included in the authorship or be used for image generation, and that all authors are required to assume full responsibility of their submitted and published work. The use of generative AI tools in the peer review process is strictly prohibited.
Conclusion
Guidelines regarding the use of generative AI in scientific writing are standardized, detailed, and unanimously followed by all journals in our study according to the recommendations set forth by international forums. It is imperative to ensure that these policies are carefully followed and updated to maintain scientific integrity.}
}
@article{ALNASER2025102122,
title = {Geographic prompting and content fidelity in generative Artificial Intelligence: A multi-model study of demographics and imaging equipment in AI-generated videos and images of Canadian medical radiation technologists},
journal = {Journal of Medical Imaging and Radiation Sciences},
volume = {56},
number = {6},
pages = {102122},
year = {2025},
issn = {1939-8654},
doi = {https://doi.org/10.1016/j.jmir.2025.102122},
url = {https://www.sciencedirect.com/science/article/pii/S1939865425002711},
author = {Yousif Al-Naser and Sonali Sharma and Ken Niure and Kevin Ibach and Faisal Khosa and Charlotte J. Yong-Hing},
keywords = {Artificial intelligence, Medical radiation technologist, Generative ai, Demographics},
abstract = {Background
As generative AI tools increasingly produce medical imagery and videos for education, marketing, and communication, concerns have arisen about the accuracy and equity of these representations. Existing research has identified demographic biases in AI-generated depictions of healthcare professionals, but little is known about their portrayal of Medical Radiation Technologists (MRTs), particularly in the Canadian context.
Methods
This study evaluated 690 AI-generated outputs (600 images and 90 videos) created by eight leading text-to-image and text-to-video models using the prompt ``Image [or video] of a Canadian Medical Radiation Technologist.'' Each image and video was assessed for demographic characteristics (gender, race/ethnicity, age, religious representation, visible disabilities), and the presence and accuracy of imaging equipment. These were compared to real-world demographic data on Canadian MRTs (n = 20,755).
Results
Significant demographic discrepancies were observed between AI-generated content and real-world data. AI depictions included a higher proportion of visible minorities (as defined by Statistics Canada) (39% vs. 20.8%, p < 0.001) and males (41.4% vs. 21.2%, p < 0.001), while underrepresenting women (58.5% vs. 78.8%, p < 0.001). Age representation skewed younger than actual workforce demographics (p < 0.001). Equipment representation was inconsistent, with 66% of outputs showing CT/MRI and only 4.3% showing X-rays; 26% included inaccurate or fictional equipment.
Conclusion
Generative AI models frequently produce demographically and contextually inaccurate depictions of MRTs, misrepresenting workforce diversity and clinical tools. These inconsistencies pose risks for educational accuracy, public perception, and equity in professional representation. Improved model training and prompt sensitivity are needed to ensure reliable and inclusive AI-generated medical content.
Résumé
Alors que les outils d'IA générative produisent de plus en plus d'images et de vidéos médicales à des fins éducatives, promotionnelles et communicationnelles, des inquiétudes ont été soulevées quant à l'exactitude et à l'équité de ces représentations. Les recherches existantes ont mis en évidence des biais démographiques dans les représentations générées par l'IA des professionnels de la santé, mais on en sait peu sur leur représentation des technologues en radiation médicale (TRM), en particulier dans le contexte canadien.
Méthodologie
Cette étude a évalué 690 productions générées par l'IA (600 images et 90 vidéos) créées par huit modèles de pointe de conversion de texte en image et de texte en vidéo à partir de la commande « Image [ou vidéo] d'un technologue en radiation médicale canadien ». Chaque image et vidéo a été évaluée en fonction de caractéristiques démographiques (sexe, race/ethnicité, âge, représentation religieuse, handicaps visibles) et de la présence et de l'exactitude des équipements d'imagerie. Ces données ont été comparées aux données démographiques réelles sur les TRM canadiens (n = 20 755).
Résultats
Des écarts démographiques significatifs ont été observés entre le contenu généré par l'IA et les données réelles. Les représentations générées par l'IA comprenaient une proportion plus élevée de minorités visibles (telles que définies par Statistique Canada) (39 % contre 20,8 %, p < 0001) et d'hommes (41,4 % contre 21,2 %, p < 0001), tandis que les femmes étaient sous-représentées (58,5 % contre 78,8 %, p < 0001). La représentation des âges était plus jeune que la démographie réelle de la main-d'œuvre (p < 0001). La représentation des équipements était incohérente, 66 % des résultats montrant des appareils de TDM/IRM et seulement 4,3 % des radiographies; 26 % comprenaient des équipements inexacts ou fictifs.
Conclusion
les modèles d'IA générative produisent souvent des représentations démographiques et contextuelles inexactes des TRM, donnant une image faussée de la diversité de la main-d'œuvre et des outils cliniques. Ces incohérences posent des risques pour l'exactitude pédagogique, la perception du public et l'équité dans la représentation professionnelle. Une amélioration de la formation des modèles et une sensibilité immédiate sont nécessaires pour garantir un contenu médical fiable et inclusif généré par l'IA.}
}
@article{KOOLI2025104476,
title = {Generative artificial intelligence addiction syndrome: A new behavioral disorder?},
journal = {Asian Journal of Psychiatry},
volume = {107},
pages = {104476},
year = {2025},
issn = {1876-2018},
doi = {https://doi.org/10.1016/j.ajp.2025.104476},
url = {https://www.sciencedirect.com/science/article/pii/S1876201825001194},
author = {Chokri Kooli and Youssef Kooli and Eya Kooli},
keywords = {Generative AI Addiction, Behavioral Addiction, Artificial Intelligence Dependency, Digital Addiction, Cognitive and Emotional Well-being, AI and Mental Health, Human-AI Interaction}
}
@article{FOSSOWAMBA2025103235,
title = {Generative artificial intelligence and the challenges to adding value ethically},
journal = {Technovation},
volume = {144},
pages = {103235},
year = {2025},
issn = {0166-4972},
doi = {https://doi.org/10.1016/j.technovation.2025.103235},
url = {https://www.sciencedirect.com/science/article/pii/S0166497225000677},
author = {Samuel {Fosso Wamba} and Maciel M. Queiroz and Krithika Randhawa and Gaurav Gupta},
keywords = {Generative AI, Gen-AI, LLMs, Ethical tensions, Business value, Innovation},
abstract = {Generative Artificial Intelligence (Gen-AI) is reshaping business models, innovation processes, and organizational strategies across industries. This editorial highlights its transformative potential through multiple lenses, including business model adaptation, strategic agility, social impact, creative industries, and ethical governance. The special issue “Generative artificial intelligence and the challenges to adding value ethically” presents diverse perspectives on how firms leverage Gen-AI to gain competitive advantage, drive value creation, and enhance resilience while addressing regulatory, ethical, and operational challenges. The accepted papers examine Gen-AI-driven shifts in entrepreneurship, decision-making, and digital ecosystems using quantitative, qualitative, and mixed-method approaches. Their findings point out both the opportunities and tensions of Gen-AI adoption, highlighting the need for responsible governance, strategic alignment, and human-AI collaboration. By integrating multidisciplinary perspectives, this collection offers a rigorous foundation for scholars, practitioners, and policymakers to understand how Gen-AI can be harnessed to drive sustainable and strategic innovation in an evolving and challenging digital landscape.}
}
@article{HERMANN2024114720,
title = {Artificial intelligence and consumer behavior: From predictive to generative AI},
journal = {Journal of Business Research},
volume = {180},
pages = {114720},
year = {2024},
issn = {0148-2963},
doi = {https://doi.org/10.1016/j.jbusres.2024.114720},
url = {https://www.sciencedirect.com/science/article/pii/S0148296324002248},
author = {Erik Hermann and Stefano Puntoni},
keywords = {Artificial intelligence, Consumer behavior, Algorithms, Predictive AI, Generative AI},
abstract = {Since the introduction of ChatGPT, the leading example of Generative Artificial Intelligence (GenAI), the research community and the general public have been captivated by GenAI’s remarkable advances in performance, and its ability to both imitate and, in some respects, surpass human capabilities. This paper offers a comprehensive analysis of the impact of AI on consumer behavior, focusing on the two pivotal phases of AI development over the past 15 years. We start by reviewing the extensively researched, yet still growing, field of algorithmic predictions and decision-making, alongside the varied positive and negative consumer reactions it elicits. Subsequently, we delve into the just emerging field of GenAI. Here, we differentiate between Convergent Thinking GenAI, which is more domain-specific and geared towards pre-defined task completion, and Divergent Thinking GenAI, which is more domain-general and oriented towards new task fulfillment. For each of these realms, we identify key areas for future investigation.}
}
@article{RAPP2025103375,
title = {How do people experience the images created by generative artificial intelligence? An exploration of people's perceptions, appraisals, and emotions related to a Gen-AI text-to-image model and its creations},
journal = {International Journal of Human-Computer Studies},
volume = {193},
pages = {103375},
year = {2025},
issn = {1071-5819},
doi = {https://doi.org/10.1016/j.ijhcs.2024.103375},
url = {https://www.sciencedirect.com/science/article/pii/S1071581924001587},
author = {Amon Rapp and Chiara {Di Lodovico} and Federico Torrielli and Luigi {Di Caro}},
keywords = {AI, Generative AI, Stable diffusion, User experience, Anthropomorphising, Humanness, Uncanny valley},
abstract = {Generative Artificial Intelligence (Gen-AI) has rapidly advanced in recent years, potentially producing enormous impacts on industries, societies, and individuals in the near future. In particular, Gen-AI text-to-image models allow people to easily create high-quality images possibly revolutionizing human creative practices. Despite their increasing use, however, the broader population's perceptions and understandings of Gen-AI-generated images remain understudied in the Human-Computer Interaction (HCI) community. This study investigates how individuals, including those unfamiliar with Gen-AI, perceive Gen-AI text-to-image (Stable Diffusion) outputs. Study findings reveal that participants appraise Gen-AI images based on their technical quality and fidelity in representing a subject, often experiencing them as either prototypical or strange: these experiences may raise awareness of societal biases and evoke unsettling feelings that extend to the Gen-AI itself. The study also uncovers several “relational” strategies that participants employ to cope with concerns related to Gen-AI, contributing to the understanding of reactions to uncanny technology and the (de)humanization of intelligent agents. Moreover, the study offers design suggestions on how to use the anthropomorphizing of the text-to-image model as design material, and the Gen-AI images as support for critical design sessions.}
}
@article{LENGUYEN2024138836,
title = {Generative artificial intelligence and optimisation framework for concrete mixture design with low cost and embodied carbon dioxide},
journal = {Construction and Building Materials},
volume = {451},
pages = {138836},
year = {2024},
issn = {0950-0618},
doi = {https://doi.org/10.1016/j.conbuildmat.2024.138836},
url = {https://www.sciencedirect.com/science/article/pii/S0950061824039783},
author = {Khuong {Le Nguyen} and Minhaz Uddin and Thong M. Pham},
keywords = {Concrete mixture design, Machine learning approach, Generative AI, Compressive strength prediction, Multi-objective optimisation},
abstract = {This research presents a generative Artificial Intelligence (AI) and design framework that integrates machine learning (ML) and optimisation methodologies to discover new concrete mixture designs. Unlike traditional ML models that predict based on existing data, this framework innovatively generates new concrete mix designs that meet specific requirements such as strength, cost-efficiency, and reduced embodied CO2. To propose a powerful and reliable generative AI model, several advanced ML algorithms were considered, e.g., CatBoost, XGBoost, and LGBM. These models were trained on a unique dataset consisting of 4,936 data points collected from five different batching plants and have not been published yet. Bayesian Optimisation was employed to fine-tune model hyperparameters, resulting in the most effective models attaining R2 values of 0.94 and 0.89 for raw and grouped data, respectively. To verify the trained generative AI model, a case study was conducted, in which the model was requested to provide designs of a mix with pre-determined strength and optimised cost and embodied CO2. The mix designs generated by the framework were successfully validated through experimental tests, corroborating the predictive outcomes. The research culminated in the development of a web application, a tool crafted to streamline the concrete mixture design and optimisation process. This generative AI design framework can be applied to many other aspects of material design and engineering problems.}
}
@article{MARIANI2024114542,
title = {Generative artificial intelligence in innovation management: A preview of future research developments},
journal = {Journal of Business Research},
volume = {175},
pages = {114542},
year = {2024},
issn = {0148-2963},
doi = {https://doi.org/10.1016/j.jbusres.2024.114542},
url = {https://www.sciencedirect.com/science/article/pii/S0148296324000468},
author = {Marcello Mariani and Yogesh K. Dwivedi},
keywords = {Generative artificial intelligence, Delphi study, Management, Innovation},
abstract = {This study outlines the future research opportunities related to Generative Artificial Intelligence (GenAI) in innovation management. To this end, it combines a review of the academic literature with the results of a Delphi study involving leading innovation management scholars. Ten major research themes emerged that can guide future research developments at the intersection of GenAI and innovation management: 1) Gen AI and innovation types; 2) GenAI, dominant designs and technology evolution; 3) Scientific and artistic creativity and GenAI-enabled innovations; 4) GenAI-enabled innovations and intellectual property; 5) GenAI and new product development; 6) Multimodal/unimodal GenAI and innovation outcomes; 7) GenAI, agency and ecosystems; 8) Policymakers, lawmakers and anti-trust authorities in the regulation of GenAI-enabled innovation; 9) Misuse and unethical use of GenAI leading to biased innovation; and 10) Organizational design and boundaries for GenAI-enabled innovation. The paper concludes by discussing how these themes can inform theoretical development in innovation management studies.}
}
@article{SHIN2025108662,
title = {Artificial intelligence versus clinical judgement: how accurately do generative models reflect CNS guidelines for chiari malformation?},
journal = {Clinical Neurology and Neurosurgery},
volume = {248},
pages = {108662},
year = {2025},
issn = {0303-8467},
doi = {https://doi.org/10.1016/j.clineuro.2024.108662},
url = {https://www.sciencedirect.com/science/article/pii/S0303846724005493},
author = {David Shin and Hyunah Park and Isabel Shaffrey and Vahe Yacoubian and Taha M. Taka and Justin Dye and Olumide Danisa},
keywords = {Artificial intelligence, Chatgpt, Chiari malformation, Guidelines},
abstract = {Objective
This study investigated the response and readability of generative artificial intelligence (AI) models to questions and recommendations proposed by the 2023 Congress of Neurological Surgeons (CNS) guidelines for Chiari 1 malformation.
Methods
Thirteen questions were generated from CNS guidelines and asked to Perplexity, ChatGPT 4o, Microsoft Copilot, and Google Gemini. AI answers were divided into two categories, "concordant" and "non-concordant," according to their alignment with current CNS guidelines. Non-concordant answers were sub-categorized as “insufficient” or “over-conclusive.” Responses were evaluated for readability via the Flesch-Kincaid Grade Level, Gunning Fog Index, SMOG (Simple Measure of Gobbledygook) Index, and Flesch Reading Ease test.
Results
Perplexity displayed the highest concordance rate of 69.2 %, with non-concordant responses classified as 0 % insufficient and 30.8 % over-conclusive. ChatGPT 4o had the lowest concordance rate at 23.1 %, with 0 % insufficient and 76.9 % over-conclusive classifications. Copilot showed a 61.5 % concordance rate, with 7.7 % insufficient and 30.8 % over-conclusive. Gemini demonstrated a 30.8 % concordance rate, with 7.7 % insufficient and 61.5 % as over-conclusive. Flesch-Kincaid Grade Level scores ranged from 14.48 (Gemini) to 16.48 (Copilot), Gunning Fog Index scores varied between 16.18 (Gemini) and 18.8 (Copilot), SMOG Index scores ranged from 16 (Gemini) to 17.54 (Copilot), and Flesch Reading Ease scores were low across all models, with Gemini showing the highest mean score of 21.3.
Conclusion
Perplexity and Copilot emerged as the best-performing for concordance, while ChatGPT and Gemini displayed the highest over-conclusive rates. All responses showcased high complexity and difficult readability. While AI can be valuable in certain aspects of clinical practice, the low concordance rates show that AI should not replace clinician judgement.}
}
@article{MARTIKAINEN2025,
title = {Evaluation of Generative Artificial Intelligence Implementation Impacts in Social and Health Care Language Translation: Mixed Methods Case Study},
journal = {JMIR Formative Research},
volume = {9},
year = {2025},
issn = {2561-326X},
doi = {https://doi.org/10.2196/73658},
url = {https://www.sciencedirect.com/science/article/pii/S2561326X25006420},
author = {Miia Martikainen and Kari Smolander and Johan Sanmark and Enni Sanmark},
keywords = {generative artificial intelligence, large language model, ChatGPT, pretrained language model, language translation, machine translation evaluation, public social and health care},
abstract = {Background
Generative artificial intelligence (GAI) is expected to enhance the productivity of the public social and health care sector while maintaining, at minimum, current standards of quality and user experience. However, empirical evidence on GAI impacts in practical, real-life settings remains limited.
Objective
This study investigates productivity, machine translation quality, and user experience impacts of the GPT-4 language model in an in-house language translation services team of a large well-being services county in Finland.
Methods
A mixed methods study was conducted with 4 in-house translators between March and June 2024. Quantitative data of 908 translation segments were collected in real-life conditions using the computer-assisted language translation software Trados (RWS) to assess productivity differences between machine and human translation. Quality was measured using 4 automatic metrics (human-targeted translation edit rate, Bilingual Evaluation Understudy, Metric for Evaluation of Translation With Explicit Ordering, and Character n-gram F-score) applied to 1373 GAI-human segment pairs. User experience was investigated through 5 semistructured interviews, including the team supervisor.
Results
The findings indicate that, on average, postediting machine translation is 14% faster than translating texts from scratch (2.75 vs 2.40 characters per second, P=.03), and up to 37% faster when the number of segments is equalized across translators. However, productivity varied notably between individuals, with improvements ranging from −2% to 102%. Regarding translation quality, 11% (141/1261) of Finnish-Swedish and 16% (18/112) of Finnish-English GAI outputs were accepted without edits. Average human-targeted translation edit rate scores were 55 (Swedish) and 46 (English), indicating that approximately half of the words required editing. Bilingual Evaluation Understudy scores averaged 43 for Swedish and 38 for English, suggesting good translation quality. Metric for Evaluation of Translation With Explicit Ordering and Character n-gram F-scores reached 63 and 68 for Swedish and 59 and 57 for English, respectively. All metrics have been converted to an equivalent scale from 0 to 100, with 100 reflecting a perfect match. Interviewed translators expressed mixed reviews on productivity gains but generally perceived value in using GAI, especially for repetitive, generic content. Identified challenges included inconsistent or incorrect terminology, lack of document-level context, and limited system customization.
Conclusions
Based on this case study, GPT-4–based GAI shows measurable potential to enhance translation productivity and quality within an in-house translation team in the public social and health care sector. However, its effectiveness appears to be influenced by factors, such as translator postediting skills, workflow design, and organizational readiness. These findings suggest that, in similar contexts, public social and health care organizations could benefit from investing in translator training, optimizing technical integration, redesigning workflows, and implementing effective change management. Future research should examine larger translator teams to assess the generalizability of these results and further explore how translation quality and user experience can be improved through domain-specific customization.}
}
@article{LUO2025e117,
title = {Transparent reporting of generative artificial intelligence use in systematic reviews},
journal = {Journal of the American Academy of Dermatology},
volume = {93},
number = {3},
pages = {e117-e118},
year = {2025},
issn = {0190-9622},
doi = {https://doi.org/10.1016/j.jaad.2025.03.101},
url = {https://www.sciencedirect.com/science/article/pii/S0190962225022078},
author = {Xufei Luo and Yaolong Chen},
keywords = {cutaneous squamous cell carcinoma, generative AI, reporting guideline, systematic review}
}
@article{LIU2024124511,
title = {Generative artificial intelligence and data augmentation for prognostic and health management: Taxonomy, progress, and prospects},
journal = {Expert Systems with Applications},
volume = {255},
pages = {124511},
year = {2024},
issn = {0957-4174},
doi = {https://doi.org/10.1016/j.eswa.2024.124511},
url = {https://www.sciencedirect.com/science/article/pii/S0957417424013782},
author = {Shen Liu and Jinglong Chen and Yong Feng and Zongliang Xie and Tongyang Pan and Jingsong Xie},
keywords = {Fault diagnosis, Generative artificial intelligence, Data augmentation, Data generation, Prognostics and health management},
abstract = {Intelligent fault diagnosis, detection, and prognostics (DDP) for complex equipment prognostics and health management (PHM) have achieved remarkable breakthroughs. Equipment in industrial scenarios often operates in normal conditions, resulting in missing anomalies, limited failures, and incomplete degradation paths. Thus the limited information on the state of the equipment collected from sensor readings severely hinders the cognitive capabilities of discriminative artificial intelligence (AI) for PHM. Data augmentation and generation (DA&G) techniques, represented by generative AI, have shown great promise in overcoming the limitations of PHM application scenarios. Research on DA&G has yielded significant achievements, but a comprehensive review in the mechanical field is still lacking. To this end, this paper provides a comprehensive review of DA&G techniques aimed at solving the DDP problems, which are divided into three categories insights of data, mechanism, and features. The data-based randomized approach applies controlled randomness for augmentation. The mechanism-based domain-specific techniques advocate for exploring relationships between the physical entity and monitoring data for generating by reasoned inference. The feature-based generative model aims to identify the latent space of data and subsequently resample it. Finally, the paper explores strategies for evaluating DA&G and provides a deep insight into the challenges and opportunities of DA&G techniques.}
}
@article{DAS2025102546,
title = {Generative artificial intelligence, integrative bioinformatics, and single-cell analysis reveal Alzheimer’s genetic and immune landscape},
journal = {Molecular Therapy Nucleic Acids},
volume = {36},
number = {2},
pages = {102546},
year = {2025},
issn = {2162-2531},
doi = {https://doi.org/10.1016/j.omtn.2025.102546},
url = {https://www.sciencedirect.com/science/article/pii/S2162253125001003},
author = {Arpita Das and Manojit Bhattacharya and Ali Saber Abdelhameed and Sang-Soo Lee and Chiranjib Chakraborty},
keywords = {Bioinformatics, GenAI, single-cell analysis, Alzheimer’s disease, genetic and immune landscape},
abstract = {The research aims to understand Alzheimer’s genetic and immune landscapes using the amalgamation of three technologies: artificial intelligence (GenAI), integrative bioinformatics, and single-cell analysis. First, the study aims to identify and characterize the significant genes associated with Alzheimer’s disease (AD) using three GenAI models (GPT‑4o, Gemini model, and DeepSeek). After the genes were accumulated from GenAI models, 27 genes associated with AD were recoded. Furthermore, they were analyzed using integrative bioinformatics methods. Similarly, the immune landscape of AD using single-cell analysis was also explored, which reveals a high percentage of effector CD8+ T cells (33.42%) and naive T cells (45.95%). The single-cell study found that effector memory T cells have two subsets. It also found that the macrophage population has started to spread and dendritic cells have decreased in Alzheimer’s patients. The single-cell gene expression study reveals the top ten highly expressed genes (NDUFV2, CAT, MRPS34, PBX3, THOC2, CCDC57, PBXIP1, SDHAF3, PPP4C, and MAP3K8). The clonal frequency indicates that CD8+ T and naive T cell populations show the highest clonal frequency in healthy and AD individuals and are further noted them in the clonotype cell proportion study. Following our GenAI and single-cell profiling strategy, future studies will help in quickly understanding the genetic and immune basis of many diseases.}
}
@article{KOHNKE2025108600,
title = {Enhancing the emotional aspects of language education through generative artificial intelligence (GenAI): A qualitative investigation},
journal = {Computers in Human Behavior},
volume = {167},
pages = {108600},
year = {2025},
issn = {0747-5632},
doi = {https://doi.org/10.1016/j.chb.2025.108600},
url = {https://www.sciencedirect.com/science/article/pii/S0747563225000470},
author = {Lucas Kohnke and Benjamin Luke Moorhouse},
keywords = {GenAI, Motivation, Emotions, Positive psychology},
abstract = {This qualitative study investigates the impact of generative artificial intelligence (GenAI) on the emotional engagement, motivation and well-being of first-year university students in Hong Kong. We conducted semi-structured interviews with 21 students and three instructors to explore their perceptions of how GenAI influences the affective dimensions of language learning. The data were analyzed using manual coding and inductive thematic analysis to identify key themes. The findings revealed that GenAI generally enhances students’ motivation, reduces anxiety and stress, and fosters an emotionally supportive learning environment. However, challenges related to cultural context and technical issues were also identified. The study highlights the pivotal role of instructors in shaping students’ experiences with GenAI and underscores the need for ongoing support and professional development. It also demonstrates the importance of cultural sensitivity, technological infrastructure and balance. The study is valuable for those who aim to harness GenAI while preserving the irreplaceable human elements of teaching. It contributes to the growing body of knowledge on integrating AI in language learning.}
}
@article{CHEAH2025100363,
title = {Integrating generative artificial intelligence in K-12 education: Examining teachers’ preparedness, practices, and barriers},
journal = {Computers and Education: Artificial Intelligence},
volume = {8},
pages = {100363},
year = {2025},
issn = {2666-920X},
doi = {https://doi.org/10.1016/j.caeai.2025.100363},
url = {https://www.sciencedirect.com/science/article/pii/S2666920X25000037},
author = {Yin Hong Cheah and Jingru Lu and Juhee Kim},
keywords = {Generative artificial intelligence, In-service teachers, Preparedness, Practices, Barriers, K-12 education},
abstract = {Despite the growing body of research on developing K-12 teachers' generative AI (GenAI) knowledge and skills, its integration into daily teaching practices remains underexplored. Using a snowball sampling method, this study examined the preparedness, practices, and barriers encountered by 89 U.S. teachers in the state of Idaho. Participants were predominantly White, female teachers serving in rural schools. A mixed-methods analysis of survey responses revealed that teachers were generally underprepared for integrating GenAI, with fewer than half incorporating it into their educational practices. Unlike the widespread classroom integration patterns observed with general educational technologies, teachers in this study tended to use GenAI for out-of-classroom duties (i.e., lesson preparation, assessment, and administrative tasks) rather than for real-time teaching and learning. These preferences could be attributed to key barriers teachers faced, including doubts about GenAI's ability to manage risks (i.e., technology value beliefs), reduced human interaction in instruction (i.e., pedagogical beliefs), ethical considerations, and the absence of policies and guidance. This study highlights the need to develop support systems and targeted policies to facilitate teachers' GenAI integration, offering implications for Idaho's education system and the broader U.S. context.}
}
@article{LEE2024102846,
title = {Generating TRIZ-inspired guidelines for eco-design using Generative Artificial Intelligence},
journal = {Advanced Engineering Informatics},
volume = {62},
pages = {102846},
year = {2024},
issn = {1474-0346},
doi = {https://doi.org/10.1016/j.aei.2024.102846},
url = {https://www.sciencedirect.com/science/article/pii/S1474034624004944},
author = {C.K.M. Lee and Jingying Liang and K.L. Yung and K.L. Keung},
keywords = {Eco-design, TRIZ, Large Language Models, Generative AI},
abstract = {Environmental considerations are emerging as stimuli for innovation during the eco-design ideation process. Integrating TRIZ (Teoriya Resheniya Izobretatelskikh Zadatch─Theory of Inventive Problem Solving) methodology into eco-design offers a structured problem-solving approach to address sustainability challenges. However, developing innovative designs requires expertise in TRIZ concepts and access to resources, which makes it a time-consuming process and can limit its application for eco-design innovation quickly. This study leverages the analytical and generative capabilities of large language models (LLMs) to enhance the TRIZ methodology and automate the ideation process in eco-design. An intelligent tool, “Eco-innovate Assistant,” is designed to provide users with eco-innovative solutions with design sketches. Its effectiveness is validated and evaluated through comparative studies. The findings demonstrate the potential of LLMs in automating design processes, catalyzing a transformation in AI-driven innovation and ideation in eco-design.}
}
@article{SHLOBIN2024e769,
title = {Ethical Incorporation of Artificial Intelligence into Neurosurgery: A Generative Pretrained Transformer Chatbot-Based, Human-Modified Approach},
journal = {World Neurosurgery},
volume = {187},
pages = {e769-e791},
year = {2024},
issn = {1878-8750},
doi = {https://doi.org/10.1016/j.wneu.2024.04.165},
url = {https://www.sciencedirect.com/science/article/pii/S1878875024007381},
author = {Nathan A. Shlobin and Max Ward and Harshal A. Shah and Ethan D.L. Brown and Daniel M. Sciubba and David Langer and Randy S. D'Amico},
keywords = {Bioethics, ChatGPT, Deep learning, Machine learning, Medical ethics, Neurologic surgery},
abstract = {Introduction
Artificial intelligence (AI) has become increasingly used in neurosurgery. Generative pretrained transformers (GPTs) have been of particular interest. However, ethical concerns regarding the incorporation of AI into the field remain underexplored. We delineate key ethical considerations using a novel GPT-based, human-modified approach, synthesize the most common considerations, and present an ethical framework for the involvement of AI in neurosurgery.
Methods
GPT-4, ChatGPT, Bing Chat/Copilot, You, Perplexity.ai, and Google Bard were queried with the prompt “How can artificial intelligence be ethically incorporated into neurosurgery?”. Then, a layered GPT-based thematic analysis was performed. The authors synthesized the results into considerations for the ethical incorporation of AI into neurosurgery. Separate Pareto analyses with 20% threshold and 10% threshold were conducted to determine salient themes. The authors refined these salient themes.
Results
Twelve key ethical considerations focusing on stakeholders, clinical implementation, and governance were identified. Refinement of the Pareto analysis of the top 20% most salient themes in the aggregated GPT outputs yielded 10 key considerations. Additionally, from the top 10% most salient themes, 5 considerations were retrieved. An ethical framework for the use of AI in neurosurgery was developed.
Conclusions
It is critical to address the ethical considerations associated with the use of AI in neurosurgery. The framework described in this manuscript may facilitate the integration of AI into neurosurgery, benefitting both patients and neurosurgeons alike. We urge neurosurgeons to use AI only for validated purposes and caution against automatic adoption of its outputs without neurosurgeon interpretation.}
}
@article{REN2024100073,
title = {Rapid estimation of γ' solvus temperature for composition design of Ni-based superalloy via physics-informed generative artificial intelligence},
journal = {Journal of Alloys and Metallurgical Systems},
volume = {6},
pages = {100073},
year = {2024},
issn = {2949-9178},
doi = {https://doi.org/10.1016/j.jalmes.2024.100073},
url = {https://www.sciencedirect.com/science/article/pii/S2949917824000208},
author = {Yunfei Ren and Tao Hu and Songzhe Xu and Chaoyue Chen and Weidong Xuan and Zhongming Ren},
keywords = {Ni-based superalloy, γ' Solvus temperature, Composition deviation index, Generative artificial intelligence, Thermodynamic calculation},
abstract = {The exceptional high-temperature mechanical properties of Ni-based superalloys are mainly stemmed from the L12 γ' phase, therefore it is crucial to discover Ni-based superalloys with high γ' solvus temperatures. Utilizing generative artificial intelligence, we have developed a framework to swiftly evaluate the γ' solvus temperature and tailor Ni-based superalloys, accelerating the process of discovering Ni-based superalloys. Physics-informed artificial neural network emerged as the optimal choice for reverse engineering, outperforming other models with an R2 score of 0.917 and a mean absolute error of 15 K. In the reverse design process, 20,000 virtual alloy samples were generated based on divide-and-conquer variational autoencoder which divides the dataset into distinct clusters by K-means algorithm provides a structured representation of the alloy composition space, thereby facilitating a more nuanced understanding of its inherent complexities. In a specific alloy design example, 563 samples were identified through screening based on criteria like γ' solvus temperature, composition deviation index, price, and density. Thermodynamic calculations were used to further screen Ni-based superalloys with exceptional high-temperature properties. The showcase of BA alloy discovery through generative artificial intelligence demonstrates the potential of our research to steer the creation of novel compositions for Ni-based superalloys with outstanding high-temperature properties.}
}
@article{HEINKE2024100089,
title = {A review of ophthalmology education in the era of generative artificial intelligence},
journal = {Asia-Pacific Journal of Ophthalmology},
volume = {13},
number = {4},
pages = {100089},
year = {2024},
issn = {2162-0989},
doi = {https://doi.org/10.1016/j.apjo.2024.100089},
url = {https://www.sciencedirect.com/science/article/pii/S2162098924000902},
author = {Anna Heinke and Niloofar Radgoudarzi and Bonnie B. Huang and Sally L. Baxter},
keywords = {Generative AI, Large Language Models (LLMs), Ophthalmology Education, Artificial Intelligence (AI)},
abstract = {Purpose
To explore the integration of generative AI, specifically large language models (LLMs), in ophthalmology education and practice, addressing their applications, benefits, challenges, and future directions.
Design
A literature review and analysis of current AI applications and educational programs in ophthalmology.
Methods
Analysis of published studies, reviews, articles, websites, and institutional reports on AI use in ophthalmology. Examination of educational programs incorporating AI, including curriculum frameworks, training methodologies, and evaluations of AI performance on medical examinations and clinical case studies.
Results
Generative AI, particularly LLMs, shows potential to improve diagnostic accuracy and patient care in ophthalmology. Applications include aiding in patient, physician, and medical students’ education. However, challenges such as AI hallucinations, biases, lack of interpretability, and outdated training data limit clinical deployment. Studies revealed varying levels of accuracy of LLMs on ophthalmology board exam questions, underscoring the need for more reliable AI integration. Several educational programs nationwide provide AI and data science training relevant to clinical medicine and ophthalmology.
Conclusions
Generative AI and LLMs offer promising advancements in ophthalmology education and practice. Addressing challenges through comprehensive curricula that include fundamental AI principles, ethical guidelines, and updated, unbiased training data is crucial. Future directions include developing clinically relevant evaluation metrics, implementing hybrid models with human oversight, leveraging image-rich data, and benchmarking AI performance against ophthalmologists. Robust policies on data privacy, security, and transparency are essential for fostering a safe and ethical environment for AI applications in ophthalmology.}
}
@article{SOLAIMAN2024102028,
title = {Generative artificial intelligence (GenAI) and decision-making: Legal & ethical hurdles for implementation in mental health},
journal = {International Journal of Law and Psychiatry},
volume = {97},
pages = {102028},
year = {2024},
issn = {0160-2527},
doi = {https://doi.org/10.1016/j.ijlp.2024.102028},
url = {https://www.sciencedirect.com/science/article/pii/S0160252724000773},
author = {Barry Solaiman},
keywords = {Generative artificial intelligence (GenAI), Mental health, Psychiatry, Ethics, Law, Healthcare},
abstract = {This article argues that significant risks are being taken with using GenAI in mental health that should be assessed urgently. It recommends that guidelines for using generative artificial intelligence (GenAI) in mental health care must be established promptly. Currently, clinicians using chatbots without appropriate approval risk undermining legal protections for patients. This could harm the patient and undermine the standards of the profession, undermining trust in an area where human involvement in decision-making is critical. To explore these concerns, this paper is divided into three parts. First, it examines the needs of patients in mental health. Second, it explores the potential benefits of GenAI in mental health and highlights the risks of its use as it pertains to patient needs. Third, it notes the ethical and legal concerns around data use and medical liability that require careful attention. The impact of the European Union's (EU) Artificial Intelligence Act (AI-Act) is also considered. It will be seen that these laws are insufficient in the context of mental health. As such, the paper recommends that guidelines should be developed to help resolve the existing legal gaps until codified rules are established.}
}
@article{GUNTUKA2024140,
title = {Application of Generative Artificial Intelligence in Minimizing Cyber Attacks on Vehicular Networks},
journal = {Procedia Computer Science},
volume = {251},
pages = {140-149},
year = {2024},
note = {15th International Conference on Emerging Ubiquitous Systems and Pervasive Networks / 14th International Conference on Current and Future Trends of Information and Communication Technologies in Healthcare EUSPN/ICTH 2024},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2024.11.094},
url = {https://www.sciencedirect.com/science/article/pii/S1877050924033283},
author = {Sony Guntuka and Elhadi Shakshuki},
keywords = {Cyber attacks, GenAI, Vehicular Networks},
abstract = {This paper explores the innovative applications of Generative Artificial Intelligence (GenAI) for strengthening the cybersecurity of vehicular networks. With the advent of intelligent transport systems and autonomous vehicles, the cybersecurity landscape has evolved significantly, which necessitating new strategies to tackle sophisticated threats. GenAI provides advanced capabilities for automating defenses, enhancing threat intelligence, and fostering dynamic security frameworks in vehicular networks. However, the incorporation of GenAI also introduces new risks, requiring robust ethical, legal, and technical oversight. This research paper outlines the current state of GenAI in vehicular network cybersecurity, showcases the Vehicular Threat Intelligence Flowchart (VTIF), focuses on the threat detection rule algorithm in VTIF, highlights the potential benefits and challenges, and proposes future research directions for developing resilient and ethical cybersecurity mechanisms.}
}
@article{ANDERSEN2025102813,
title = {Generative Artificial Intelligence (GenAI) in the research process – A survey of researchers’ practices and perceptions},
journal = {Technology in Society},
volume = {81},
pages = {102813},
year = {2025},
issn = {0160-791X},
doi = {https://doi.org/10.1016/j.techsoc.2025.102813},
url = {https://www.sciencedirect.com/science/article/pii/S0160791X2500003X},
author = {Jens Peter Andersen and Lise Degn and Rachel Fishberg and Ebbe K. Graversen and Serge P.J.M. Horbach and Evanthia Kalpazidou Schmidt and Jesper W. Schneider and Mads P. Sørensen},
keywords = {Generative Artificial Intelligence (GenAI), Research process, Research practice, use cases, Research integrity},
abstract = {This study explores the use of generative AI (GenAI) and research integrity assessments of use cases by researchers, including PhD students, at Danish universities. Conducted through a survey sent to all Danish researchers from January to February 2024, the study received 2534 responses and evaluated 32 GenAI use cases across five research phases: idea generation, research design, data collection, data analysis, and writing/reporting. Respondents reported on their own and colleagues' GenAI usage. They also assessed whether the practices in the use cases were considered good research practice. Through an explorative factor analysis, we identified three clusters of perception: "GenAI as a work horse", "GenAI as a language assistant only", and "GenAI as a research accelerator". The findings further show varied opinions on GenAI's research integrity implications. Language editing and data analysis were generally viewed positively, whereas experiment design and peer review tasks faced more criticism. Controversial areas included image creation/modification and synthetic data, with comments highlighting the need for critical and reflexive use of GenAI. Usage differed by main research area, with technical and quantitative sciences reporting slightly higher usage and more positive assessments. Junior researchers used GenAI more than senior colleagues, while no significant gender differences were observed. The study underscores the need for adaptable, discipline-specific guidelines for GenAI use in research, developed collaboratively with experts to align with diverse research practices and minimize ethical and practical misalignment.}
}
@article{LAW2024100174,
title = {Application of generative artificial intelligence (GenAI) in language teaching and learning: A scoping literature review},
journal = {Computers and Education Open},
volume = {6},
pages = {100174},
year = {2024},
issn = {2666-5573},
doi = {https://doi.org/10.1016/j.caeo.2024.100174},
url = {https://www.sciencedirect.com/science/article/pii/S2666557324000156},
author = {Locky Law},
keywords = {Generative AI, AI, Language education, Scoping review, Content generation, ChatGPT},
abstract = {This scoping literature review examines the application of Generative Artificial Intelligence (GenAI), a disruptive technology, in language teaching and learning. Since its launch in November 2022, GenAI has captured global attention with OpenAI's ChatGPT, powered by the generative pre-trained transformer-3 (GPT-3) large-language model. The emergence of GenAI holds immense implications across various domains, including language education. This review aims to provide an overview of the current state of research and identify research gaps and future directions in this emerging field. The review follows the PRISMA-ScR guidelines and includes eligible publications published between 2017 and July 2023. Four electronic databases were searched and 41 of the 224 initial papers were eventually selected for review. The findings reveal key terms related to GenAI in language education, the most researched language study and education levels, areas of research, attitudes towards GenAI, and the potential benefits and challenges of GenAI application. The review highlights several research gaps, including the need for more empirical studies to assess the effectiveness and impact of GenAI tools, discussion of ethical considerations, targeted interventions for specific language skills, and stakeholder engagement in responsible integration. Educators are encouraged to incorporate GenAI tools into their teaching practices while remaining vigilant about potential risks. Continuous professional development for educators is crucial to ensure informed decision-making and effective integration of GenAI tools. This scoping review contributes to the existing knowledge on the use of GenAI in language education and informs future research and practice in this disruptive and rapidly evolving field.}
}
@article{GHANBARI2025101901,
title = {Free-breathing single-beat exercise cardiovascular magnetic resonance with generative artificial intelligence for evaluation of volumetric and functional cardiac indices: A reproducibility study},
journal = {Journal of Cardiovascular Magnetic Resonance},
volume = {27},
number = {1},
pages = {101901},
year = {2025},
issn = {1097-6647},
doi = {https://doi.org/10.1016/j.jocmr.2025.101901},
url = {https://www.sciencedirect.com/science/article/pii/S1097664725000638},
author = {Fahime Ghanbari and Alexander Schulz and Manuel A. Morales and Jennifer Rodriguez and Jordan A. Street and Kathryn Arcand and Scott Johnson and Patrick Pierce and Christopher W. Hoeger and Connie W. Tsao and Warren J. Manning and Reza Nezafat},
keywords = {Exercise-CMR, Free-breathing single-beat cine, Biventricular volumetric and functional indices},
abstract = {Background
Exercise cardiovascular magnetic resonance (Ex-CMR) can reveal pathophysiologies not evident at rest by quantifying biventricular volume and function during or immediately after exercise. However, achieving reproducible Ex-CMR measurements is challenging due to limited spatial and temporal resolution. This study aimed to develop and evaluate a free-breathing, high-spatiotemporal-resolution single-beat Ex-CMR cine enhanced by generative artificial intelligence. We assessed image analysis reproducibility, scan-rescan reproducibility, and impact of the reader's experience on the analysis.
Methods
Imaging was performed on a 3T CMR system using a free-breathing, highly accelerated, multi-slice, single-beat cine sequence (in-plane spatiotemporal resolution of 1.9 × 1.9 mm² and 37 ms, respectively). High acceleration was achieved by combining compressed sensing reconstruction with a resolution-enhancement generative adversarial inline neural network. Ex-CMR was performed using a supine ergometer positioned immediately outside the magnet bore. Single-beat cine images were acquired at rest and immediately post-exercise. In a prospective study, the protocol was evaluated in 141 subjects. A structured image analysis workflow was implemented. Four expert readers, with or without prior training in single-beat Ex-CMR, independently rated all images for diagnostic and image quality. The subjective assessment used two 3-point Likert scales. Biventricular parameters were calculated. Inter- and intra-observer reproducibility were assessed. Fifteen healthy subjects were re-imaged 1 year later for scan-rescan reproducibility. Reproducibility was assessed using intraclass correlation coefficient (ICC), with agreement evaluated via Bland-Altman analysis, linear regression, and Pearson correlation.
Results
Free-breathing, single-beat Ex-CMR cine enabled imaging of the beating heart within 30 ± 6 s, with technically successful scans in 96% (136/141) of subjects. Post-exercise single-beat cine images were assessed as diagnostic in 98% (133/136), 96% (131/136), 82% (112/136), and 65% (89/136) of cases by four readers (ordered by descending years of Ex-CMR experience). Good image quality was reported in 74% (100/136) to 80% (109/136) of subjects. Biventricular parameters were successfully measured in all subjects, demonstrating good to excellent inter-observer reproducibility. Scan/rescan reproducibility over 1 year, assessed by two independent readers, showed excellent inter-visit ICCs (0.96–1.0) and strong correlations (R² ≥ 0.92, p < 0.001 for left ventricle; R² ≥ 0.95, p < 0.001 for right ventricle).
Conclusion
Single-beat Ex-CMR enabled evaluation of biventricular volumetric and functional indices with excellent reproducibility.}
}
@article{CHUNG2025S-173,
title = {742: RANDOMIZED CONTROLLED TRIAL EVALUATING THE EFFICACY OF HUMAN-GENERATIVE ARTIFICIAL INTELLIGENCE TEAMING ON TECHNOLOGY ACCEPTANCE, USABILITY, AND TRUST: THE GUT-GPT SIMULATION STUDY},
journal = {Gastroenterology},
volume = {169},
number = {1, Supplement },
pages = {S-173},
year = {2025},
issn = {0016-5085},
doi = {https://doi.org/10.1016/S0016-5085(25)01346-0},
url = {https://www.sciencedirect.com/science/article/pii/S0016508525013460},
author = {Sunny Chung and Niroop Rajashekar and Yuan Pu and Yeo Eun Shin and Mauro Giuffrè and Colleen Chan and Kisung You and Theo Saarinen and Allen Hsiao and Jasjeet Sekhon and Ambrose Wong and Leigh Evans and Terika McCall and Rene F. Kizilcec and Loren Laine and Dennis Shung}
}
@article{CHAN2025102733,
title = {Generative artificial intelligence in a VUCA world: the ‘Lived Experiences’ of Southeast Asian teachers’ use of AI in higher education},
journal = {International Journal of Educational Research},
volume = {133},
pages = {102733},
year = {2025},
issn = {0883-0355},
doi = {https://doi.org/10.1016/j.ijer.2025.102733},
url = {https://www.sciencedirect.com/science/article/pii/S088303552500206X},
author = {Nee Nee Chan and Richard Peter Bailey and Mabel Hwee Joo Tan and Genevieve Flores Dipolog and Garry Wei Han Tan and Saeid Motevalli and Nadia Samsudin and Chin Siang Ang},
keywords = {ChatGPT, Hermeneutic phenomenology, VUCA model, Educational quality, AI policy guidelines},
abstract = {This study explores how generative intelligence (GenAI) is used in teaching and learning, assessments, and research at Southeast Asian (SEA) universities. Using hermeneutic phenomenology as the philosophical underpinning and research methodology, SEA teachers’ ‘lived experiences’ of using ChatGPT and other GenAI tools were uncovered. 38 teachers from 10 SEA countries participated in 11 focus group interviews over five months. Three themes emerged: Learning Anew; Disequilibrium and Lack of Rootedness; and Ambiguity about New Norms, New Practices. It was found that teachers work with GenAI in deeply personal, fragmented, and continuously evolving ways. GenAI took the form of novel work companions, enhancing the efficiency and effectiveness of some work practices. It also was a disruptor to old habits of thinking, behaviour and practices. Teachers were in a state of disequilibrium in this new world beset by VUCA (volatility, uncertainty, complexity, and ambiguity). Some felt overwhelmed and ‘at breaking point’. A lack of rootedness in teachers’ beliefs and practices emerged. Teachers were generally against the notions of plagiarism and academic integrity held by students who believed the ends justified the means. However, with new ways of teaching, learning and assessment, many teachers recognised their beliefs and practices would have to change. Thus, in the absence of detailed AI guidelines, they called for the urgent need to establish boundaries and teach AI literacy to promote innovative and responsible use. In this VUCA world, more targeted change management training for teachers and students was strongly needed.}
}
@article{HASAN2024,
title = {Governance of Generative Artificial Intelligence:},
journal = {International Journal of Knowledge Management},
volume = {21},
number = {1},
year = {2024},
issn = {1548-0666},
doi = {https://doi.org/10.4018/IJKM.383061},
url = {https://www.sciencedirect.com/science/article/pii/S1548066625000359},
author = {A K M Kamrul Hasan},
keywords = {Knowledge Management, Knowledge Management System, Generative Artificial Intelligence (GenAI), Governance Structure, Institutional Economics},
abstract = {ABSTRACT
The field of knowledge management and knowledge management systems is evolving and dynamic. In the era of developed information technology systems, the dynamics of knowledge creation and dissemination have also changed. Generative artificial intelligence (GenAI)—an embedded entity in the knowledge management system—has become a prominent area of research nowadays, while accountability, transparency, and ethics are common research agendas in institutional economics related to GenAI. The research in this paper has investigated the convictions behind GenAI adoption and how to develop a GenAI governance framework. The research adopts a qualitative approach to investigate the problem and surveys undergraduate students to explore their motive for using GenAI. The study sheds analytical light on institutional economists’ view on the governance of GenAI. The study has found a positive relationship between perceived benefits and the adoption of GenAI in education by students. The theoretical model will have a considerable impact on the ongoing debate on the governance of GenAI and knowledge management systems.}
}
@article{LI2025112349,
title = {Generative artificial intelligence-based framework for bridging lifecycle gaps in semiconductor HVAC systems},
journal = {Journal of Building Engineering},
volume = {105},
pages = {112349},
year = {2025},
issn = {2352-7102},
doi = {https://doi.org/10.1016/j.jobe.2025.112349},
url = {https://www.sciencedirect.com/science/article/pii/S2352710225005868},
author = {Yanlin Li and Chi-Yun Liu and Hsiao-Ping Ni and Fermodelie Paul and Wai Oswald Chong and Jui-Sheng Chou},
keywords = {HVAC system performance, Semiconductor manufacturing facility, HVAC equipment degradation prediction, AI-Driven models, Advanced building systems},
abstract = {The production of modern semiconductor chips is susceptible to variations in air temperature, humidity, and quality, mainly as chip dimensions shrink to smaller than atmospheric dust particles. Heating, ventilation, and air-conditioning (HVAC) systems are critical in this context, given their role in stabilizing these environmental factors. Gaps in Design and Construction (D&C) can critically undermine the reliability, performance, quality, and lifespan of HVAC systems during their Operation and Maintenance (O&M) stages. Current studies illustrate how existing models predicted performance degradation and how the Design, Construction, Operations, and Maintenance (DCOM) gap arises. Despite the substantial implications for Semiconductor Manufacturing Facilities (SMFs), research on HVAC performance degradation remains limited, particularly in capturing and quantifying degradation-related patterns. Compared to other types of buildings, the renovation and transformation of high-end manufacturing facilities are more frequent, and customized design and equipment also lead to model application issues, such as data limitations and incompatibility. This paper aims to propose a novel HVAC system degradation prediction model utilizing Generative Adversarial Networks (GAN) and Informer algorithms based on the building characteristics and operation mode of semiconductor facilities to overcome the limitations of data scarcity and long-term prediction, evaluate the comprehensive impact of the gap between D&C and O&M stages on HVAC systems. By integrating data augmentation, this model reduces data dependency and can handle incomplete, inconsistent, or discrete data for early prediction in operation, bridging the gap between D&C and O&M stages, and improving the overall efficiency and effectiveness of facility operation and maintenance. In addition to SMFs, the proposed model exhibits considerable application potential in other high-precision building types due to the structural variability.}
}
@article{LIM2025105306,
title = {Development and implementation of a generative artificial intelligence-enhanced simulation to enhance problem-solving skills for pre-service teachers},
journal = {Computers & Education},
volume = {232},
pages = {105306},
year = {2025},
issn = {0360-1315},
doi = {https://doi.org/10.1016/j.compedu.2025.105306},
url = {https://www.sciencedirect.com/science/article/pii/S0360131525000740},
author = {Jieun Lim and Unggi Lee and Junbo Koh and Yeil Jeong and Yunseo Lee and Gyuri Byun and Haewon Jung and Yoonsun Jang and Sanghyeok Lee and Jewoong Moon},
keywords = {Generative AI, Virtual simulation, Teacher education, Problem-based learning, Design-based research},
abstract = {Effective teachers should be equipped to solve complex problems across diverse instructional and learning contexts. However, many teacher training programs struggle to bridge the gap between theoretical knowledge to real-world applications. The current study tackles this challenge by developing a generative artificial intelligence (GenAI)-enhanced simulation to improve preservice teachers’ problem-solving abilities. Using design-based research (DBR), we created a virtual environment that integrates problem-based learning (PBL) with GenAI technology. The simulation was rigorously refined through expert review and usability testing before being implemented in a teacher training program. We evaluated its effectiveness by comparing three groups: (1) a text-based scenario, (2) a rule-based simulation, and (3) a GenAI-enhanced simulation. Pre- and post-test results showed significant improvements in problem-solving skills for both the rule-based and GenAI-enhanced simulation groups compared to the text-based scenario group. Notably, qualitative findings revealed that students reported heightened realism and immersion in the GenAI-enhanced simulation, attributing this to more dynamic interactions with AI agents that helped them better contextualize PBL and increased their motivation. Our study findings contribute design principles for developing GenAI-enhanced simulations in teacher education, offering promising insights into leveraging AI technology to create more engaging and effective training experiences.}
}
@article{LI2024118988,
title = {Inverse design of cellular structures with the geometry of triply periodic minimal surfaces using generative artificial intelligence algorithms},
journal = {Engineering Structures},
volume = {321},
pages = {118988},
year = {2024},
issn = {0141-0296},
doi = {https://doi.org/10.1016/j.engstruct.2024.118988},
url = {https://www.sciencedirect.com/science/article/pii/S0141029624015505},
author = {Zhou Li and Junhao Li and Jiahao Tian and Shiqi Xia and Kai Li and Maojun Li and Yao Lu and Mengyuan Ren and Zhengyi Jiang},
keywords = {Triply periodic minimal surface, Generative artificial intelligence algorithms, Additive manufacturing, Inverse design, Numerical simulation},
abstract = {Triply periodic minimal surfaces (TPMS) exhibit excellent mechanical and energy absorption properties due to their structural advantages. However, existing porous TPMS structural design methods are constrained to a forward process from structural parameters to mechanical properties. This study proposed an inverse design method that combines bidirectional generative adversarial networks (BiGAN) and mechanical performance targets, resulting in a combined TPMS structure of Primitive and IWP types with superior buffering and energy absorption capabilities. The results show that under a single load value target condition of the designed structure, the minimum deviation index (R2) between the load value corresponding to the displacement point and the target load value is only 0.987, and the maximum mean absolute percentage error (MAPE) is only 5.92 %. When considering the elastic modulus target, the approach successfully conducts two sets of combined structural designs meeting the requirements of both high and low elastic moduli. When targeting the specified load-displacement curve conditions, specifically when combining high elastic modulus with ascending plasticity, the designed structures exhibit an error of only 2.2 % compared to the target property. Moreover, the quasi-static uniaxial compression experiments conducted on additively manufactured designed structures confirm that the experimental curves match the target curves in terms of deformation trends and load value ranges. The success of this inverse design approach for cellular TPMS structures has the potential to expedite new structural material development processes.}
}
@article{HUESO2023309,
title = {Is Generative Artificial Intelligence the Next Step Toward a Personalized Hemodialysis?},
journal = {Revista de Investigación Clínica},
volume = {75},
number = {6},
pages = {309-317},
year = {2023},
issn = {0034-8376},
doi = {https://doi.org/10.24875/RIC.23000162},
url = {https://www.sciencedirect.com/science/article/pii/S0034837625001597},
author = {Miguel Hueso and Rafael Álvarez and David Marí and Vicent Ribas-Ripoll and Karim Lekadir and Alfredo Vellido},
keywords = {Personalized hemodialysis, Artificial intelligence, Natural language processing, Large Language Models},
abstract = {ABSTRACT
Artificial intelligence (AI) generative models driven by the integration of AI and natural language processing technologies, such as OpenAI’s chatbot generative pre-trained transformer large language model (LLM), are receiving much public attention and have the potential to transform personalized medicine. Dialysis patients are highly dependent on technology and their treatment generates a challenging large volume of data that has to be analyzed for knowledge extraction. We argue that, by integrating the data acquired from hemodialysis treatments with the powerful conversational capabilities of LLMs, nephrologists could personalize treatments adapted to patients’ lifestyles and preferences. We also argue that this new conversational AI integrated with a personalized patient-computer interface will enhance patients’ engagement and self-care by providing them with a more personalized experience. However, generative AI models require continuous and accurate updates of data, and expert supervision and must address potential biases and limitations. Dialysis patients can also benefit from other new emerging technologies such as Digital Twins with which patients’ care can also be addressed from a personalized medicine perspective. In this paper, we will revise LLMs potential strengths in terms of their contribution to personalized medicine, and, in particular, their potential impact, and limitations in nephrology. Nephrologists’ collaboration with AI academia and companies, to develop algorithms and models that are more transparent, understandable, and trustworthy, will be crucial for the next generation of dialysis patients. The combination of technology, patient-specific data, and AI should contribute to create a more personalized and interactive dialysis process, improving patients’ quality of life. (REV INVEST CLIN. 2023;75(6):309-17)}
}
@article{WOBST2025115571,
title = {Avoiding algorithm errors in textual analysis: A guide to selecting software, and a research agenda toward generative artificial intelligence},
journal = {Journal of Business Research},
volume = {199},
pages = {115571},
year = {2025},
issn = {0148-2963},
doi = {https://doi.org/10.1016/j.jbusres.2025.115571},
url = {https://www.sciencedirect.com/science/article/pii/S0148296325003947},
author = {Janice Wobst and Rainer Lueg},
keywords = {Generative AI, Large language models, Textual analysis, Software selection, Algorithm error, Validity, Reliability, Value-based management},
abstract = {The use of textual analysis is expanding in organizational research, yet software packages vary in their compatibility with complex constructs. This study helps researchers select suitable tools by focusing on phrase-based dictionary methods. We empirically evaluate four software packages—LIWC, DICTION, CAT Scanner, and a custom Python tool—using the complex construct of value-based management as a test case. The analysis shows that software from the same methodological family produces highly consistent results, while popular but mismatched tools yield significant errors such as miscounted phrases. Based on this, we develop a structured selection guideline that links construct features with software capabilities. The framework enhances construct validity, supports methodological transparency, and is applicable across disciplines. Finally, we position the approach as a bridge to AI-enabled textual analysis, including prompt-based workflows, reinforcing the continued need for theory-grounded construct design.}
}
@article{CARROLL2024102899,
title = {Integrating large language models and generative artificial intelligence tools into information literacy instruction},
journal = {The Journal of Academic Librarianship},
volume = {50},
number = {4},
pages = {102899},
year = {2024},
issn = {0099-1333},
doi = {https://doi.org/10.1016/j.acalib.2024.102899},
url = {https://www.sciencedirect.com/science/article/pii/S0099133324000600},
author = {Alexander J. Carroll and Joshua Borycz},
keywords = {Generative artificial intelligence, Large language models, Information literacy, STEM education, Information retrieval, Critical thinking},
abstract = {Generative artificial intelligence (AI) and large language models (LLMs) have induced a mixture of excitement and panic among educators. However, there is a lack of consensus over how much experience science and engineering students have with using these tools for research-related tasks. Likewise, it is not yet known how educators and information professionals can leverage these tools to teach students strategies for information retrieval and knowledge synthesis. This study assesses the extent of students' use of AI tools in research-related tasks and if information literacy instruction could impact their perception of these tools. Responses to Likert-scale questions indicate that many students did not have extensive experience using LLMs for research-related purposes prior to the information literacy sessions. However, after participating in a didactic lecture and discussion with an engineering librarian that explored how to use these tools effectively and responsibly, many students reported viewing these tools as potentially useful for future assignments. Student responses to open-response questions suggest that librarian-led information literacy training can assist students in developing more sophisticated understandings of the limitations and use cases for artificial intelligence in inquiry-based coursework.}
}
@article{RUIZ202542,
title = {71361968-2414 - Is Generative-Artificial Intelligence (AI) able to diagnose and classify facial trauma as an Oral Surgeon?},
journal = {International Journal of Oral and Maxillofacial Surgery},
volume = {54},
pages = {42},
year = {2025},
note = {ICOMS Singapore 2025},
issn = {0901-5027},
doi = {https://doi.org/10.1016/j.ijom.2025.04.126},
url = {https://www.sciencedirect.com/science/article/pii/S0901502725002401},
author = {O. Peña Ruiz and J. Sifuentes-Cervantes and J. Castellanos and F. Bermudez}
}
@article{ZHANG20252238,
title = {Research on the impact of generative artificial intelligence (GenAI) on enterprise innovation performance: a knowledge management perspective},
journal = {Journal of Knowledge Management},
volume = {29},
number = {7},
pages = {2238-2257},
year = {2025},
issn = {1367-3270},
doi = {https://doi.org/10.1108/JKM-10-2024-1198},
url = {https://www.sciencedirect.com/science/article/pii/S136732702500033X},
author = {Qichao Zhang and Jiaxiang Zuo and Songlin Yang},
keywords = {Generative artificial intelligence, Knowledge management, Enterprise innovation performance, Human–AI collaboration},
abstract = {Purpose
This study aims to investigate the impact of generative artificial intelligence (GenAI) on enterprise innovation performance, particularly from the perspective of knowledge management. It addresses key challenges in GenAI adoption – such as data biases, information overload and technological dependence – and proposes strategies to overcome these obstacles to enhance innovation.
Design/methodology/approach
Adopting a theoretical approach, this research analyzes the role of knowledge management in bridging the gap between GenAI and enterprise innovation. A structured framework based on four essential knowledge management processes – knowledge creation, retrieval and storage, transfer and sharing and application – is developed to tackle these challenges effectively.
Findings
The study reveals that while GenAI presents both opportunities and challenges for enterprise innovation, leveraging a structured knowledge management framework is key to unlocking its potential. It underscores the critical role of human–AI collaboration in mitigating issues such as data biases and integration challenges, ultimately improving innovation performance. The findings highlight the importance of complementing AI capabilities with human judgment to ensure successful outcomes in GenAI-driven innovation.
Research limitations/implications
This conceptual study calls for further empirical research to validate the findings and expand their generalizability. Future studies should explore contextual factors such as organizational characteristics, business environments and policy frameworks to refine the proposed framework.
Originality/value
This research offers novel insights into the intersection of GenAI, knowledge management and enterprise innovation. It stresses the importance of human involvement alongside GenAI, providing actionable recommendations for organizations navigating the complexities of AI adoption. In addition, it contributes to the evolving discourse on AI and innovation management, offering pathways for businesses to harness GenAI’s full potential and drive performance.}
}
@article{TRINDADE2025101104,
title = {Teaching mathematical concepts in management with generative artificial intelligence: The power of human oversight in AI-driven learning},
journal = {The International Journal of Management Education},
volume = {23},
number = {2},
pages = {101104},
year = {2025},
issn = {1472-8117},
doi = {https://doi.org/10.1016/j.ijme.2024.101104},
url = {https://www.sciencedirect.com/science/article/pii/S1472811724001757},
author = {Maria A.M. Trindade and Gihan S. Edirisinghe and Lan Luo},
keywords = {Generative artificial intelligence in education, Generative AI-Driven learning, Mathematics in management education, Operations management, Economic order quantity, Generative AI in management education},
abstract = {This study demonstrates a successful use of Generative Artificial Intelligence (AI) in teaching mathematical material to management students. We herein introduce the EOQ World Tour game, which substantially improves understanding of inventory-related concepts and long-term knowledge retention compared with traditional methods. Generative AI is revolutionizing management education, by offering innovative methods for teaching and learning. The integration of AI into quantitative business disciplines through novel learning mechanisms provides significant benefits, including enhanced data analysis, improved decision-making models, and sophisticated simulations for hands-on experience. This study introduces the EOQ World Tour game, specifically designed to teach the Economic Order Quantity concept in Operations Management. The game addresses challenges in integrating Generative AI into mathematics in management education by combining human oversight and instructor control through three innovative features: (1) a Generative AI-based simulation, (2) a macropowered Excel worksheet for validating the calculations of an AI chatbot, and (3) a Google Sheets dashboard for centralizing team-generated AI data for postgame analysis. Our study included 41 students divided into experimental and control groups. Pretest results indicated no significant differences in baseline knowledge. However, the post-test results showed that the experimental group achieved a better understanding of inventory-related concepts and practical applications, along with higher engagement, excitement, confidence, and long-term knowledge retention.}
}
@article{ALHUSBAN202421,
title = {Exploring professional perspectives on integrating generative artificial intelligence into corporate learning and development: an organizational change perspective},
journal = {Development and Learning in Organizations: An International Journal},
volume = {39},
number = {2},
pages = {21-24},
year = {2024},
issn = {1477-7282},
doi = {https://doi.org/10.1108/DLO-05-2024-0131},
url = {https://www.sciencedirect.com/science/article/pii/S1477728224000522},
author = {Mohammad Issa Alhusban and Hashem Alshurafat and Ibrahim N. Khatatbeh},
keywords = {Learning and development, Expert interviews, Organizational change, ChatGPT, Generative artificial intelligence},
abstract = {Purpose
The primary aim of this study is to investigate the integration of generative artificial intelligence, specifically ChatGPT, into workplace L&D practices, exploring the associated advantages and challenges such integration from an organizational change perspective.
Design/methodology/approach
This study uses a qualitative approach, conducting semi-structured interviews with twelve learning and development (L&D) experts.
Findings
This study indicates that ChatGPT can positively impact L&D by streamlining processes and potentially enhancing employee performance, engagement and satisfaction. However, to mitigate employee resistance, organizations must clearly communicate the necessity and rationale behind the change, involve employees in the implementation process and address trust issues. Key challenges such as overreliance on ChatGPT, AI skill shortages and technology issues like privacy breaches and misinformation must be managed through strong governance frameworks, including policies, guidelines and regular audits.
Research limitations/implications
The study’s scope is confined to semi-structured interviews with L&D experts, potentially limiting its generalizability. Further research could explore the long-term effects and broader implications of ChatGPT integration in different organizational contexts.
Practical implications
By framing GenAI integration within the context of organizational change, this study offers insights into managing the transition effectively by providing guidance for managers on effectively integrating ChatGPT into L&D practices, emphasizing the importance of mitigating potential negative consequences while maximizing benefits.
Social implications
Integrating ChatGPT into organizational L&D has the potential to reshape how employees acquire new skills and knowledge, potentially influencing organizational culture and dynamics. However, careful consideration is required to ensure that the integration process aligns with ethical and social norms, minimizing adverse impacts.
Originality/value
This research contributes foundational insights into the integration of ChatGPT in corporate L&D by researching and understanding the opinions of corporate professionals. It serves as a starting point for organizations to identify challenges in adopting GenAI.}
}
@article{WISLOCKI2025,
title = {Comparing Generative Artificial Intelligence and Mental Health Professionals for Clinical Decision-Making With Trauma-Exposed Populations: Vignette-Based Experimental Study},
journal = {JMIR Mental Health},
volume = {12},
year = {2025},
issn = {2368-7959},
doi = {https://doi.org/10.2196/80801},
url = {https://www.sciencedirect.com/science/article/pii/S2368795925001040},
author = {Katherine E Wislocki and Sabahat Sami and Gahl Liberzon and Alyson K Zalta},
keywords = {generative artificial intelligence, trauma, mental health professionals, diagnosis, treatment},
abstract = {Background
Trauma exposure is highly prevalent and associated with various health issues. However, health care professionals can exhibit trauma-related diagnostic overshadowing bias, leading to misdiagnosis and inadequate treatment of trauma-exposed populations. Generative artificial intelligence (GAI) models are increasingly used in health care contexts. No research has examined whether GAI demonstrates this bias in decision-making and how rates of this bias may compare to mental health professionals (MHPs).
Objective
This study aimed to assess trauma-related diagnostic overshadowing among frontier GAI models and compare evidence of trauma-related diagnostic overshadowing between frontier GAI models and MHPs.
Methods
MHPs (N=232; mean [SD] age 43.7 [15.95] years) completed an experimental paradigm consisting of 2 vignettes describing adults presenting with obsessive-compulsive symptoms or substance abuse symptoms. One vignette included a trauma exposure history (ie, sexual trauma or physical trauma), and one vignette did not include a trauma exposure history. Participants answered questions about their preferences for diagnosis and treatment options for clients within the vignettes. GAI models (eg, Gemini 1.5 Flash, ChatGPT-4o mini, Claude Sonnet, and Meta Llama 3) completed the same experimental paradigm, with each block being reviewed by each GAI model 20 times. Mann-Whitney U tests and chi-square analyses were used to assess diagnostic and treatment decision-making across vignette factors and respondents.
Results
GAI models, similar to MHPs, demonstrated some evidence of trauma-related diagnostic overshadowing bias, particularly in Likert-based ratings of posttraumatic stress disorder diagnosis and treatment when sexual trauma was present (P<.001). However, GAI models generally exhibited significantly less bias than MHPs across both Likert and forced-choice clinical decision tasks. Compared to MHPs, GAI models assigned higher ratings for the target diagnosis and treatment in obsessive-compulsive disorder vignettes (rb=0.43‐0.63; P<.001) and for the target treatment in substance use disorder vignettes (rb=0.57; P<.001) when trauma was present. In forced-choice tasks, GAI models were significantly more accurate than MHPs in selecting the correct diagnosis and treatment for obsessive-compulsive disorder vignettes (χ²1=48.84‐61.07; P<.001) and for substance use disorder vignettes involving sexual trauma (χ²1=15.17‐101.61; P<.001).
Conclusions
GAI models demonstrate some evidence of trauma-related diagnostic overshadowing bias, yet the degree of bias varied by task and model. Moreover, GAI models generally demonstrated less bias than MHPs in this experimental paradigm. These findings highlight the importance of understanding GAI biases in mental health care. More research into bias reduction strategies and responsible implementation of GAI models in mental health care is needed.}
}
@article{LI2024112,
title = {On the Application of Generative Artificial Intelligence ChatGPT in Digital Trade},
journal = {Procedia Computer Science},
volume = {247},
pages = {112-120},
year = {2024},
note = {The 11th International Conference on Applications and Techniques in Cyber Intelligence},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2024.10.014},
url = {https://www.sciencedirect.com/science/article/pii/S187705092402814X},
author = {Rui Li and Qiaoling Zhong},
keywords = {Generative Artificial Intelligence ChatGPT, Natural Language Processing, Customer Service, Dialogue Interaction},
abstract = {The combination of human subjective judgment and machine data processing capabilities in human-machine collaborative evaluation can create a more efficient, accurate, and personalized customer service dialogue interaction system, thereby promoting digital trade efficiency and improving service quality. Generative artificial intelligence has the ability of intelligent interaction and contextual semantic understanding, which is an important means of implementing the concept of human-machine collaboration. This article introduces the basic principles and technical characteristics of ChatGPT, and explores in detail its various application scenarios in digital trade, including automated customer service, personalized recommendations, intelligent marketing, and data analysis. Finally, this article also discusses the challenges and future development directions of ChatGPT in digital trade, in order to provide certain reference value for research and practice in related fields. The data from the questionnaire survey shows that men, aged between 18-30 and 41-50 years old, with high education level, high monthly online shopping expenses, high monthly income, and frequent use of well-known e-commerce platforms, generally have a high level of understanding of ChatGPT.}
}

@article{HEROLD2025101012,
title = {Brave new procurement deals: An experimental study of how generative artificial intelligence reshapes buyer–supplier negotiations},
journal = {Journal of Purchasing and Supply Management},
volume = {31},
number = {4},
pages = {101012},
year = {2025},
issn = {1478-4092},
doi = {https://doi.org/10.1016/j.pursup.2025.101012},
url = {https://www.sciencedirect.com/science/article/pii/S1478409225000214},
author = {Silke Herold and Jonas Heller and Frank Rozemeijer and Dominik Mahr},
keywords = {Artificial intelligence, Chatbots, Negotiation},
abstract = {The technological breakthrough of artificial intelligence (AI) is impacting buyer-supplier negotiations, which are increasingly moving toward human-to-machine negotiations using AI-based chatbots. While the first AI-powered negotiation solutions are currently being used by procurement professionals to negotiate for non-critical spend items, which is an example of structural influence, the behavioral influence of AI-based chatbots (i.e., on negotiation approach) remains unknown. It is unclear in which behavioral settings these chatbots deliver value to the buying firm in terms of economic, psychological, and relational outcomes. To fill this gap, we conduct three experiments in buyer–supplier negotiation settings, two in a lab-setting with undergraduate business students and one online experiment with professional negotiators. In our interactive simulations, participants play the role of the supplier, while a ChatGPT-based custom-trained chatbot acts as the buyer. We find that when the chatbot deploys a competitive, as compared to a collaborative, negotiation approach, it will achieve a higher price discount, better payment terms, and a quicker negotiation. However, suppliers trust a collaboratively prompted, as compared to a competitively prompted, chatbot more and demonstrate higher outcome satisfaction, as well as a stronger desire for future interaction. A text analysis of the chat interactions indicates a higher level of similarity when a competitively prompted chatbot is employed, which implies that suppliers also use more insistent and intimidating language, thereby matching the chatbot's negotiation approach to a greater degree. While the negotiation approach is a significant influencing factor, we do not find significant evidence that item type, in our case non-critical or bottleneck, matters, which indicates that AI-based chatbots can be effective in various buyer–supplier settings.}
}
@article{PUGLIESE2025667,
title = {Generative Artificial Intelligence in Nutrition: A Revolution in Accessibility and Personalization},
journal = {The Journal of Nutrition},
volume = {155},
number = {3},
pages = {667-668},
year = {2025},
issn = {0022-3166},
doi = {https://doi.org/10.1016/j.tjnut.2025.01.025},
url = {https://www.sciencedirect.com/science/article/pii/S002231662500032X},
author = {Nicola Pugliese and Federico Ravaioli}
}
@article{LV2023208,
title = {Generative artificial intelligence in the metaverse era},
journal = {Cognitive Robotics},
volume = {3},
pages = {208-217},
year = {2023},
issn = {2667-2413},
doi = {https://doi.org/10.1016/j.cogr.2023.06.001},
url = {https://www.sciencedirect.com/science/article/pii/S2667241323000198},
author = {Zhihan Lv},
abstract = {Generative artificial intelligence (AI) is a form of AI that can autonomously generate new content, such as text, images, audio, and video. Generative AI provides innovative approaches for content production in the metaverse, filling gaps in the development of the metaverse. Products such as ChatGPT have the potential to enhance the search experience, reshape information generation and presentation methods, and become new entry points for online traffic. This is expected to significantly impact traditional search engine products, accelerating industry innovation and upgrading. This paper presents an overview of the technologies and prospective applications of generative AI in the breakthrough of metaverse technology and offers insights for increasing the effectiveness of generative AI in creating creative content.}
}
@article{CHEN2024100531,
title = {Generative Artificial Intelligence Enhancements for Reducing Image-based Training Data Requirements},
journal = {Ophthalmology Science},
volume = {4},
number = {5},
pages = {100531},
year = {2024},
issn = {2666-9145},
doi = {https://doi.org/10.1016/j.xops.2024.100531},
url = {https://www.sciencedirect.com/science/article/pii/S2666914524000678},
author = {Dake Chen and Ying Han and Jacque Duncan and Lin Jia and Jing Shan},
keywords = {Glaucoma, Generative AI, Data scarcity},
abstract = {Objective
Training data fuel and shape the development of artificial intelligence (AI) models. Intensive data requirements are a major bottleneck limiting the success of AI tools in sectors with inherently scarce data. In health care, training data are difficult to curate, triggering growing concerns that the current lack of access to health care by under-privileged social groups will translate into future bias in health care AIs. In this report, we developed an autoencoder to grow and enhance inherently scarce datasets to alleviate our dependence on big data.
Design
Computational study with open-source data.
Subjects
The data were obtained from 6 open-source datasets comprising patients aged 40–80 years in Singapore, China, India, and Spain.
Methods
The reported framework generates synthetic images based on real-world patient imaging data. As a test case, we used autoencoder to expand publicly available training sets of optic disc photos, and evaluated the ability of the resultant datasets to train AI models in the detection of glaucomatous optic neuropathy.
Main Outcome Measures
Area under the receiver operating characteristic curve (AUC) were used to evaluate the performance of the glaucoma detector. A higher AUC indicates better detection performance.
Results
Results show that enhancing datasets with synthetic images generated by autoencoder led to superior training sets that improved the performance of AI models.
Conclusions
Our findings here help address the increasingly untenable data volume and quality requirements for AI model development and have implications beyond health care, toward empowering AI adoption for all similarly data-challenged fields.
Financial Disclosure(s)
The authors have no proprietary or commercial interest in any materials discussed in this article.}
}
@article{BERA20258735,
title = {Accurate prediction of the kinetic sequence of physicochemical states using generative artificial intelligence††Electronic supplementary information (ESI) available. See DOI: https://doi.org/10.1039/d5sc00108k},
journal = {Chemical Science},
volume = {16},
number = {20},
pages = {8735-8751},
year = {2025},
issn = {2041-6520},
doi = {https://doi.org/10.1039/d5sc00108k},
url = {https://www.sciencedirect.com/science/article/pii/S2041652025006327},
author = {Palash Bera and Jagannath Mondal},
abstract = {Capturing the time evolution and predicting kinetic sequences of states of physicochemical systems present significant challenges due to the precision and computational effort required. In this study, we demonstrate that ‘Generative Pre-trained Transformer (GPT)’, an artificial intelligence model renowned for machine translation and natural language processing, can be effectively adapted to predict the dynamical state-to-state transition kinetics of biologically relevant physicochemical systems. Specifically, by using sequences of time-discretized states from Molecular Dynamics (MD) simulation trajectories akin to the vocabulary corpus of a language, we show that a GPT-based model can learn the complex syntactic and semantic relationships within the trajectory. This enables GPT to predict kinetically accurate sequences of states for a diverse set of biomolecules of varying complexity, at a much quicker pace than traditional MD simulations and with a better efficiency than other baseline time-series prediction approaches. More significantly, the approach is found to be equally adept at forecasting the time evolution of out-of-equilibrium active systems that do not maintain detailed balance. An analysis of the mechanism inherent in GPT reveals the crucial role of the ‘self-attention mechanism’ in capturing the long-range correlations necessary for accurate state-to-state transition predictions. Together, our results highlight generative artificial intelligence's ability to generate kinetic sequences of states of physicochemical systems with statistical precision.}
}
@article{WENG2024100315,
title = {Personality traits for self-regulated learning with generative artificial intelligence: The case of ChatGPT},
journal = {Computers and Education: Artificial Intelligence},
volume = {7},
pages = {100315},
year = {2024},
issn = {2666-920X},
doi = {https://doi.org/10.1016/j.caeai.2024.100315},
url = {https://www.sciencedirect.com/science/article/pii/S2666920X24001188},
author = {Xiaojing Weng and Qi Xia and Zubair Ahmad and Thomas K.F. Chiu},
keywords = {GenAI, Personality traits, Self-regulated learning, Instructional design, Higher education},
abstract = {Personality traits and educational technology may affect how well students utilise their abilities and strategies to achieve their learning objectives and potential. As generative artificial intelligence (GenAI) is creating new learning experiences, understanding the impact of five representative personality traits on students' self-regulated learning (SRL) while learning with GenAI tools can help to predict which personality traits indicate better self-regulation when learning with this innovative educational technology. Such a prediction can help educators to design effective learning activities by providing educational experiences that cater to students' different personality traits for specific learning objectives in the GenAI context. This study explored how variations in five representative personality traits affect students’ SRL performance when learning with ChatGPT. It used an explanatory approach based on structural equation modelling with a path analysis design. Four hundred and nine university students participated in the study and finished a self-reported questionnaire with validated items that are driven by previous studies. The results revealed that the personality traits of openness, extraversion, and agreeableness were significant predictors of all three stages of SRL; conscientiousness was a significant predictor of the forethought and self-reflection stages; and neuroticism failed to predict any of the three stages of SRL. These results may be attributable to the subjective nature of personality traits and the cognitive characteristics of SRL skills. The findings enrich the literature on SRL by introducing personality traits and GenAI as innovative perspectives and suggesting corresponding strategies for supporting different stages of SRL.}
}
@article{RODMAN2025689,
title = {Is generative artificial intelligence capable of clinical reasoning?},
journal = {The Lancet},
volume = {405},
number = {10480},
pages = {689},
year = {2025},
issn = {0140-6736},
doi = {https://doi.org/10.1016/S0140-6736(25)00348-4},
url = {https://www.sciencedirect.com/science/article/pii/S0140673625003484},
author = {Adam Rodman and Eric J Topol}
}
@article{BLEASE2024115724,
title = {Psychiatrists’ experiences and opinions of generative artificial intelligence in mental healthcare: An online mixed methods survey},
journal = {Psychiatry Research},
volume = {333},
pages = {115724},
year = {2024},
issn = {0165-1781},
doi = {https://doi.org/10.1016/j.psychres.2024.115724},
url = {https://www.sciencedirect.com/science/article/pii/S0165178124000118},
author = {Charlotte Blease and Abigail Worthen and John Torous},
keywords = {Chatbots, LLM, Workforce, Psychiatry, Artificial intelligence},
abstract = {Following the launch of ChatGPT in November 2022, interest in large language model (LLM)-powered chatbots has surged with increasing focus on the clinical potential of these tools. Missing from this discussion, however, are the perspectives of physicians. The current study aimed to explore psychiatrists’ experiences and opinions on this new generation of chatbots in mental health care. An online survey including both quantitative and qualitative responses was distributed to a non-probability sample of psychiatrists affiliated with the American Psychiatric Association. Findings revealed 44 % of psychiatrists had used OpenAI's ChatGPT-3.5 and 33 % had used GPT-4.0 “to assist with answering clinical questions.” Administrative tasks were cited as a major benefit of these tools: 70 % somewhat agreed/agreed “documentation will be/is more efficient”. Three in four psychiatrists (75 %) somewhat agreed/agreed “the majority of their patients will consult these tools before first seeing a doctor”. Nine in ten somewhat agreed/agreed that clinicians need more support/training in understanding these tools. Open-ended responses reflected these opinions but respondents also expressed divergent opinions on the value of generative AI in clinical practice, including its impact on the future of the profession.}
}
@article{DAUNGSUPAWONG2024848,
title = {Generative artificial intelligence in ophthalmology: Correspondence},
journal = {Survey of Ophthalmology},
volume = {69},
number = {5},
pages = {848},
year = {2024},
issn = {0039-6257},
doi = {https://doi.org/10.1016/j.survophthal.2024.06.002},
url = {https://www.sciencedirect.com/science/article/pii/S0039625724000717},
author = {Hinpetch Daungsupawong and Viroj Wiwanitkit}
}
@article{BRUNS2024103790,
title = {Do you create your content yourself? Using generative artificial intelligence for social media content creation diminishes perceived brand authenticity},
journal = {Journal of Retailing and Consumer Services},
volume = {79},
pages = {103790},
year = {2024},
issn = {0969-6989},
doi = {https://doi.org/10.1016/j.jretconser.2024.103790},
url = {https://www.sciencedirect.com/science/article/pii/S0969698924000869},
author = {Jasper David Brüns and Martin Meißner},
keywords = {Generative artificial intelligence, Content creation, Brand authenticity, Algorithm aversion, Social media},
abstract = {Recent studies have demonstrated the potential of generative artificial intelligence (GenAI) in enhancing marketing content. However, its impact on consumer behavior has remained empirically untested. In response to social media platforms mandating the disclosure of GenAI content, we investigate how followers perceive brands that use GenAI for content creation. Drawing from literature on algorithm aversion and brand authenticity, the results of three experimental studies indicate that brands' GenAI adoption induces negative attitudinal and behavioral follower reactions. These effects are mediated by followers' perceptions of brand authenticity and can be triggered by GenAI disclosure. Negative reactions are attenuated if GenAI is used to assist humans in content creation rather than to replace them through automation. Our findings underscore the need for nuance in brands’ GenAI adoption to unlock economic benefits without compromising on relationships with consumers.}
}
@article{LIU2023798,
title = {Generative artificial intelligence and its applications in materials science: Current situation and future perspectives},
journal = {Journal of Materiomics},
volume = {9},
number = {4},
pages = {798-816},
year = {2023},
issn = {2352-8478},
doi = {https://doi.org/10.1016/j.jmat.2023.05.001},
url = {https://www.sciencedirect.com/science/article/pii/S2352847823000771},
author = {Yue Liu and Zhengwei Yang and Zhenyao Yu and Zitu Liu and Dahui Liu and Hailong Lin and Mingqing Li and Shuchang Ma and Maxim Avdeev and Siqi Shi},
keywords = {Machine learning, Artificial intelligence, Generative artificial intelligence, Materials science, Novel materials discovery, Deep learning},
abstract = {Generative Artificial Intelligence (GAI) is attracting the increasing attention of materials community for its excellent capability of generating required contents. With the introduction of Prompt paradigm and reinforcement learning from human feedback (RLHF), GAI shifts from the task-specific to general pattern gradually, enabling to tackle multiple complicated tasks involved in resolving the structure-activity relationships. Here, we review the development status of GAI comprehensively and analyze pros and cons of various generative models in the view of methodology. The applications of task-specific generative models involving materials inverse design and data augmentation are also dissected. Taking ChatGPT as an example, we explore the potential applications of general GAI in generating multiple materials content, solving differential equation as well as querying materials FAQs. Furthermore, we summarize six challenges encountered for the use of GAI in materials science and provide the corresponding solutions. This work paves the way for providing effective and explainable materials data generation and analysis approaches to accelerate the materials research and development.}
}
@article{HAASE2023100066,
title = {Artificial muses: Generative artificial intelligence chatbots have risen to human-level creativity},
journal = {Journal of Creativity},
volume = {33},
number = {3},
pages = {100066},
year = {2023},
issn = {2713-3745},
doi = {https://doi.org/10.1016/j.yjoc.2023.100066},
url = {https://www.sciencedirect.com/science/article/pii/S2713374523000250},
author = {Jennifer Haase and Paul H.P. Hanel},
keywords = {Creativity, Originality, AI, Generative artificial intelligence},
abstract = {A widespread view is that Artificial Intelligence cannot be creative. We tested this assumption by comparing human-generated ideas with those generated by six Generative Artificial Intelligence (GAI) chatbots: alpa.ai, Copy.ai, ChatGPT (versions 3 and 4), Studio.ai, and YouChat. Humans and a specifically trained AI independently assessed the quality and quantity of ideas. We found no qualitative difference between AI and human-generated creativity, although there are differences in how ideas are generated. Interestingly, 9.4 % of humans were more creative than the most creative GAI, GPT-4. Our findings suggest that GAIs are valuable assistants in the creative process. Continued research and development of GAI in creative tasks is crucial to fully understand this technology's potential benefits and drawbacks in shaping the future of creativity. Finally, we discuss the question of whether GAIs are capable of being “truly” creative.}
}
@article{WAQAS2023100255,
title = {Revolutionizing Digital Pathology With the Power of Generative Artificial Intelligence and Foundation Models},
journal = {Laboratory Investigation},
volume = {103},
number = {11},
pages = {100255},
year = {2023},
issn = {0023-6837},
doi = {https://doi.org/10.1016/j.labinv.2023.100255},
url = {https://www.sciencedirect.com/science/article/pii/S0023683723001988},
author = {Asim Waqas and Marilyn M. Bui and Eric F. Glassy and Issam {El Naqa} and Piotr Borkowski and Andrew A. Borkowski and Ghulam Rasool},
keywords = {artificial intelligence, computational and digital pathology, foundation models, large language models, multimodal data, vision-language models},
abstract = {Digital pathology has transformed the traditional pathology practice of analyzing tissue under a microscope into a computer vision workflow. Whole-slide imaging allows pathologists to view and analyze microscopic images on a computer monitor, enabling computational pathology. By leveraging artificial intelligence (AI) and machine learning (ML), computational pathology has emerged as a promising field in recent years. Recently, task-specific AI/ML (eg, convolutional neural networks) has risen to the forefront, achieving above-human performance in many image-processing and computer vision tasks. The performance of task-specific AI/ML models depends on the availability of many annotated training datasets, which presents a rate-limiting factor for AI/ML development in pathology. Task-specific AI/ML models cannot benefit from multimodal data and lack generalization, eg, the AI models often struggle to generalize to new datasets or unseen variations in image acquisition, staining techniques, or tissue types. The 2020s are witnessing the rise of foundation models and generative AI. A foundation model is a large AI model trained using sizable data, which is later adapted (or fine-tuned) to perform different tasks using a modest amount of task-specific annotated data. These AI models provide in-context learning, can self-correct mistakes, and promptly adjust to user feedback. In this review, we provide a brief overview of recent advances in computational pathology enabled by task-specific AI, their challenges and limitations, and then introduce various foundation models. We propose to create a pathology-specific generative AI based on multimodal foundation models and present its potentially transformative role in digital pathology. We describe different use cases, delineating how it could serve as an expert companion of pathologists and help them efficiently and objectively perform routine laboratory tasks, including quantifying image analysis, generating pathology reports, diagnosis, and prognosis. We also outline the potential role that foundation models and generative AI can play in standardizing the pathology laboratory workflow, education, and training.}
}
@article{KATHAIT20241575,
title = {Assessing Laterality Errors in Radiology: Comparing Generative Artificial Intelligence and Natural Language Processing},
journal = {Journal of the American College of Radiology},
volume = {21},
number = {10},
pages = {1575-1582},
year = {2024},
note = {Focus on Innovation},
issn = {1546-1440},
doi = {https://doi.org/10.1016/j.jacr.2024.06.014},
url = {https://www.sciencedirect.com/science/article/pii/S154614402400591X},
author = {Anjaneya Singh Kathait and Emiliano Garza-Frias and Tejash Sikka and Thomas J. Schultz and Bernardo Bizzo and Mannudeep K. Kalra and Keith J. Dreyer},
keywords = {generative AI, large language models, natural language processing, patient safety, radiology errors},
abstract = {Purpose
We compared the performance of generative artificial intelligence (AI) (Augmented Transformer Assisted Radiology Intelligence [ATARI, Microsoft Nuance, Microsoft Corporation, Redmond, Washington]) and natural language processing (NLP) tools for identifying laterality errors in radiology reports and images.
Methods
We used an NLP-based (mPower, Microsoft Nuance) tool to identify radiology reports flagged for laterality errors in its Quality Assurance Dashboard. The NLP model detects and highlights laterality mismatches in radiology reports. From an initial pool of 1,124 radiology reports flagged by the NLP for laterality errors, we selected and evaluated 898 reports that encompassed radiography, CT, MRI, and ultrasound modalities to ensure comprehensive coverage. A radiologist reviewed each radiology report to assess if the flagged laterality errors were present (reporting error—true-positive) or absent (NLP error—false-positive). Next, we applied ATARI to 237 radiology reports and images with consecutive NLP true-positive (118 reports) and false-positive (119 reports) laterality errors. We estimated accuracy of NLP and generative AI tools to identify overall and modality-wise laterality errors.
Results
Among the 898 NLP-flagged laterality errors, 64% (574 of 898) had NLP errors and 36% (324 of 898) were reporting errors. The text query ATARI feature correctly identified the absence of laterality mismatch (NLP false-positives) with a 97.4% accuracy (115 of 118 reports; 95% confidence interval [CI] = 96.5%-98.3%). Combined vision and text query resulted in 98.3% accuracy (116 of 118 reports or images; 95% CI = 97.6%-99.0%), and query alone had a 98.3% accuracy (116 of 118 images; 95% CI = 97.6%-99.0%).
Conclusion
The generative AI-empowered ATARI prototype outperformed the assessed NLP tool for determining true and false laterality errors in radiology reports while enabling an image-based laterality determination. Underlying errors in ATARI text query in complex radiology reports emphasize the need for further improvement in the technology.}
}
@article{OGRADY2024S450,
title = {MSR63 Prompt Engineering for the Use of Generative Artificial Intelligence (AI) in Health Economic Modeling: Findings From a Targeted Literature Review},
journal = {Value in Health},
volume = {27},
number = {12, Supplement },
pages = {S450},
year = {2024},
note = {ISPOR Europe 2024},
issn = {1098-3015},
doi = {https://doi.org/10.1016/j.jval.2024.10.2297},
url = {https://www.sciencedirect.com/science/article/pii/S109830152405160X},
author = {M O'Grady and N Adair and R Arguello and J Benner}
}
@article{DUAH2024180,
title = {How generative artificial intelligence has blurred notions of authorial identity and academic norms in higher education, necessitating clear university usage policies},
journal = {International Journal of Information and Learning Technology},
volume = {41},
number = {2},
pages = {180-193},
year = {2024},
issn = {2056-4880},
doi = {https://doi.org/10.1108/IJILT-11-2023-0213},
url = {https://www.sciencedirect.com/science/article/pii/S2056488024000015},
author = {James Ewert Duah and Paul McGivern},
keywords = {Students, Universities, Artificial intelligence, Education, Educational policy, Psychology},
abstract = {Purpose
This study examines the impact of generative artificial intelligence (GenAI), particularly ChatGPT, on higher education (HE). The ease with which content can be generated using GenAI has raised concerns across academia regarding its role in academic contexts, particularly regarding summative assessments. This research makes a unique contribution to the literature by examining university student and staff perceptions of current and future issues pertaining to the role of GenAI in universities.
Design/methodology/approach
A qualitative method involving five one-to-one semi-structured interviews with four students and a lecturer explored the ethical and practical issues of GenAI text generation in academia. An inductive thematic analysis was chosen as it provided nuanced insights aligned with the study’s goals.
Findings
Use of GenAI was discussed within the context of a range of topics, including perceptions of academic misconduct, authorial integrity and issues pertaining to university policies. Participants universally defined traditional classifications of academic misconduct but were unable to provide clear definitions where the use of GenAI was included for writing summative assessments. Students showed a more open engagement with GenAI, considering it a tool for overcoming obstacles rather than a means to plagiarise. Educators were generally more cautious and less optimistic about the academic role of GenAI. Lack of clear institutional policies surrounding such tools also contributed to ethical ambiguities.
Originality/value
The study highlights diverging perspectives between students and academics, which necessitate a forum for dialogue, ensuring the need to develop clear policies to steer the integration of GenAI in a manner that is beneficial for students and academics.}
}
@incollection{MUKHUTY202537,
title = {Chapter 3 - Industry 5.0 era of digital supply chain: A generative artificial intelligence (GenAI) action model for workforce engagement},
editor = {Syed Abdul Rehman Khan and Adnan Ahmed Sheikh and Jyri Vilko and Sajid Nazir and Mahmood Ali and Marko Torkkeli},
booktitle = {Technological Innovations and Industry 5.0},
publisher = {Elsevier},
pages = {37-53},
year = {2025},
series = {Developments and Advances in the Supply Chain Industry},
isbn = {978-0-443-33813-7},
doi = {https://doi.org/10.1016/B978-0-443-33813-7.00003-8},
url = {https://www.sciencedirect.com/science/article/pii/B9780443338137000038},
author = {Sumona Mukhuty and Robert Dixon and Arvind Upadhyay},
keywords = {Generative artificial intelligence, Industry 4.0, Industry 5.0, Productivity enhancement, Supply chains},
abstract = {Industry 5.0 advocates triangulating the technology-centric emphasis of Industry 4.0 with human-centricity and sustainability. The focus is on creating an inclusive work environment facilitating human-machine reconciliation leading to “sustainable social welfare.” Within this context, the advent and accessibility of generative artificial intelligence (GenAI) have been received with equal measures of excitement and existential dread. This is a major disruptive digital technology that has begun to shake the equilibrium and stability of business survival and job security. Yet, the potential of GenAI in enhancing efficiency is revolutionary, spanning all sectors, including supply chains. Organizational success within the Industry 5.0 context is heavily dependent on the appropriate skills and capabilities. However, the rapid advancement and adoption of GenAI has left organizations with severe knowledge and skills gaps. In this study, we conduct a succinct review of GenAI’s impact on supply chains. Thereafter we draw upon strategic management theories and organizational change theories to develop an organizational GenAI action model to enable supply chain organizations to transition workers from a state of “unconscious GenAI incompetence” to “conscious GenAI competence,” working through the five stages of the model: getting urgent, exploration, formulation, iteration, and embedding. We will predominantly draw upon high-impact peer-reviewed articles, complemented by relevant gray literature, including the European Commission publications, in developing this review and conceptual model. We will close by highlighting the model’s applicability and future research directions.}
}
@article{CHONG2025103583,
title = {1345 A Generative Artificial Intelligence Framework for Automated Pathologic Diagnosis of Gastric Endoscopic Biopsy Samples},
journal = {Laboratory Investigation},
volume = {105},
number = {3, Supplement },
pages = {103583},
year = {2025},
note = {USCAP 114th Annual Meeting: See the Light},
issn = {0023-6837},
doi = {https://doi.org/10.1016/j.labinv.2024.103583},
url = {https://www.sciencedirect.com/science/article/pii/S0023683724032616},
author = {Yosep Chong and Anh Nguyen and Jin Sol Song and Kwangil Yim and Jumi Park and Jin Tae Kwak}
}
@article{YASSIN2025102284,
title = {Evaluating a generative artificial intelligence accuracy in providing medication instructions from smartphone images},
journal = {Journal of the American Pharmacists Association},
volume = {65},
number = {1},
pages = {102284},
year = {2025},
issn = {1544-3191},
doi = {https://doi.org/10.1016/j.japh.2024.102284},
url = {https://www.sciencedirect.com/science/article/pii/S1544319124003157},
author = {Yusef Yassin and Thien Nguyen and Krishna Panchal and Katharine Getchell and Timothy Aungst},
abstract = {Background
The Food and Drug Administration mandates patient labeling materials like the Medication Guide (MG) and Instructions for Use (IFU) to support appropriate medication use. However, challenges such as low health literacy and difficulties navigating these materials may lead to incorrect medication usage, resulting in therapy failure or adverse outcomes. The rise of generative AI, presents an opportunity to provide scalable, personalized patient education through image recognition and text generation.
Objective
This study aimed to evaluate the accuracy and safety of medication instructions generated by ChatGPT based on user-provided drug images, compared to the manufacturer's standard instructions.
Methods
Images of 12 medications requiring multiple steps for administration were uploaded to ChatGPT's image recognition function. ChatGPT's responses were compared to the official IFU and MG using text classifiers, Count Vectorization (CountVec), and Term Frequency-Inverse Document Frequency (TF-IDF). The clinical accuracy was further evaluated by independent pharmacists to determine if ChatGPT responses were valid for patient instruction.
Results
ChatGPT correctly identified all medications and generated patient instructions. CountVec outperformed TF-IDF in text similarity analysis, with an average similarity score of 76%. However, clinical evaluation revealed significant gaps in the instructions, particularly for complex administration routes, where ChatGPT's guidance lacked essential details, leading to lower clinical accuracy scores.
Conclusion
While ChatGPT shows promise in generating patient-friendly medication instructions, its effectiveness varies based on the complexity of the medication. The findings underscore the need for further refinement and clinical oversight to ensure the safety and accuracy of AI-generated medical guidance, particularly for medications with complex administration processes.}
}
@article{TEIXEIRADASILVA2025111607,
title = {Editing companies have the responsibility of ensuring their declared use of generative artificial intelligence},
journal = {Journal of Clinical Epidemiology},
volume = {177},
pages = {111607},
year = {2025},
issn = {0895-4356},
doi = {https://doi.org/10.1016/j.jclinepi.2024.111607},
url = {https://www.sciencedirect.com/science/article/pii/S0895435624003639},
author = {Jaime A. {Teixeira da Silva}}
}
@article{TAN2023100394,
title = {Generative Artificial Intelligence Through ChatGPT and Other Large Language Models in Ophthalmology: Clinical Applications and Challenges},
journal = {Ophthalmology Science},
volume = {3},
number = {4},
pages = {100394},
year = {2023},
issn = {2666-9145},
doi = {https://doi.org/10.1016/j.xops.2023.100394},
url = {https://www.sciencedirect.com/science/article/pii/S2666914523001264},
author = {Ting Fang Tan and Arun James Thirunavukarasu and J. Peter Campbell and Pearse A. Keane and Louis R. Pasquale and Michael D. Abramoff and Jayashree Kalpathy-Cramer and Flora Lum and Judy E. Kim and Sally L. Baxter and Daniel Shu Wei Ting},
keywords = {Artificial intelligence, Chatbots, ChatGPT, Large language models},
abstract = {The rapid progress of large language models (LLMs) driving generative artificial intelligence applications heralds the potential of opportunities in health care. We conducted a review up to April 2023 on Google Scholar, Embase, MEDLINE, and Scopus using the following terms: “large language models,” “generative artificial intelligence,” “ophthalmology,” “ChatGPT,” and “eye,” based on relevance to this review. From a clinical viewpoint specific to ophthalmologists, we explore from the different stakeholders’ perspectives—including patients, physicians, and policymakers—the potential LLM applications in education, research, and clinical domains specific to ophthalmology. We also highlight the foreseeable challenges of LLM implementation into clinical practice, including the concerns of accuracy, interpretability, perpetuating bias, and data security. As LLMs continue to mature, it is essential for stakeholders to jointly establish standards for best practices to safeguard patient safety.
Financial Disclosure(s)
Proprietary or commercial disclosure may be found in the Footnotes and Disclosures at the end of this article.}
}
@article{OOI2025417,
title = {Unveiling the potential of generative artificial intelligence: a multidimensional journey into the future},
journal = {Industrial Management & Data Systems},
volume = {125},
number = {2},
pages = {417-432},
year = {2025},
issn = {0263-5577},
doi = {https://doi.org/10.1108/IMDS-10-2023-0703},
url = {https://www.sciencedirect.com/science/article/pii/S0263557724000228},
author = {Keng-Boon Ooi and Alex Koohang and Eugene Cheng-Xi Aw and Tat-Huei Cham and Cihan Cobanoglu and Charles Dennis and Yogesh K Dwivedi and Jun-Jie Hew and Heather {Linton Kelly} and Laurie Hughes and Chieh-Yu Lin and Anubhav Mishra and Ian Phau and Ramakrishnan Raman and Marianna Sigala and Yun-Chia Tang and Lai-Wan Wong and Garry Wei-Han Tan},
keywords = {Generative artificial intelligence, Artificial intelligence, Large language model, ChatGPT, Hospitality, Tourism, Marketing, Retailing, Service operations, Manufacturing, Healthcare},
abstract = {Purpose
The launch of ChatGPT has brought the large language model (LLM)-based generative artificial intelligence (GAI) into the spotlight, triggering the interests of various stakeholders to seize the possible opportunities implicated by it. Nevertheless, there are also challenges that the stakeholders should observe when they are considering the potential of GAI. Given this backdrop, this study presents the viewpoints gathered from various subject experts on six identified areas.
Design/methodology/approach
Through an expert-based approach, this paper gathers the viewpoints of various subject experts on the identified areas of tourism and hospitality, marketing, retailing, service operations, manufacturing and healthcare.
Findings
The subject experts first share an overview of the use of GAI, followed by the relevant opportunities and challenges in implementing GAI in each identified area. Afterwards, based on the opportunities and challenges, the subject experts propose several research agendas for the stakeholders to consider.
Originality/value
This paper serves as a frontier in exploring the opportunities and challenges implicated by the GAI in six identified areas that this emerging technology would considerably influence. It is believed that the viewpoints offered by the subject experts would enlighten the stakeholders in the identified areas.}
}
@article{WAISBERG2024849,
title = {Future directions of generative artificial intelligence in ophthalmology and vision science},
journal = {Survey of Ophthalmology},
volume = {69},
number = {5},
pages = {849-850},
year = {2024},
issn = {0039-6257},
doi = {https://doi.org/10.1016/j.survophthal.2024.06.003},
url = {https://www.sciencedirect.com/science/article/pii/S0039625724000729},
author = {Ethan Waisberg and Joshua Ong and Mouayad Masalkhi and Andrew G. Lee and Alireza Tavakkoli},
keywords = {Generative adversarial networks, Deep learning, ChatGPT, GPT4, Artificial ophthalmic image synthesis, AI, Machine learning}
}
@article{ROWE2024469,
title = {Artificial intelligence in radiation therapy: An emerging revolution that will be driven by generative methodologies},
journal = {Diagnostic and Interventional Imaging},
volume = {105},
number = {12},
pages = {469-470},
year = {2024},
issn = {2211-5684},
doi = {https://doi.org/10.1016/j.diii.2024.09.006},
url = {https://www.sciencedirect.com/science/article/pii/S2211568424001992},
author = {Steven P. Rowe and N. Ari Wijetunga},
keywords = {Artificial intelligence, Generative AI, Large-language models, Machine learning, Radiation therapy}
}
@article{ZENG2024,
title = {Assessing the Role of the Generative Pretrained Transformer (GPT) in Alzheimer’s Disease Management: Comparative Study of Neurologist- and Artificial Intelligence–Generated Responses},
journal = {Journal of Medical Internet Research},
volume = {26},
year = {2024},
issn = {1438-8871},
doi = {https://doi.org/10.2196/51095},
url = {https://www.sciencedirect.com/science/article/pii/S1438887124007325},
author = {Jiaqi Zeng and Xiaoyi Zou and Shirong Li and Yao Tang and Sisi Teng and Huanhuan Li and Changyu Wang and Yuxuan Wu and Luyao Zhang and Yunheng Zhong and Jialin Liu and Siru Liu},
keywords = {Alzheimer's disease, artificial intelligence, AI, large language model, LLM, Generative Pretrained Transformer, GPT, ChatGPT, patient information},
abstract = {Background
Alzheimer’s disease (AD) is a progressive neurodegenerative disorder posing challenges to patients, caregivers, and society. Accessible and accurate information is crucial for effective AD management.
Objective
This study aimed to evaluate the accuracy, comprehensibility, clarity, and usefulness of the Generative Pretrained Transformer’s (GPT) answers concerning the management and caregiving of patients with AD.
Methods
In total, 14 questions related to the prevention, treatment, and care of AD were identified and posed to GPT-3.5 and GPT-4 in Chinese and English, respectively, and 4 respondent neurologists were asked to answer them. We generated 8 sets of responses (total 112) and randomly coded them in answer sheets. Next, 5 evaluator neurologists and 5 family members of patients were asked to rate the 112 responses using separate 5-point Likert scales. We evaluated the quality of the responses using a set of 8 questions rated on a 5-point Likert scale. To gauge comprehensibility and participant satisfaction, we included 3 questions dedicated to each aspect within the same set of 8 questions.
Results
As of April 10, 2023, the 5 evaluator neurologists and 5 family members of patients with AD rated the 112 responses: GPT-3.5: n=28, 25%, responses; GPT-4: n=28, 25%, responses; respondent neurologists: 56 (50%) responses. The top 5 (4.5%) responses rated by evaluator neurologists had 4 (80%) GPT (GPT-3.5+GPT-4) responses and 1 (20%) respondent neurologist’s response. For the top 5 (4.5%) responses rated by patients’ family members, all but the third response were GPT responses. Based on the evaluation by neurologists, the neurologist-generated responses achieved a mean score of 3.9 (SD 0.7), while the GPT-generated responses scored significantly higher (mean 4.4, SD 0.6; P<.001). Language and model analyses revealed no significant differences in response quality between the GPT-3.5 and GPT-4 models (GPT-3.5: mean 4.3, SD 0.7; GPT-4: mean 4.4, SD 0.5; P=.51). However, English responses outperformed Chinese responses in terms of comprehensibility (Chinese responses: mean 4.1, SD 0.7; English responses: mean 4.6, SD 0.5; P=.005) and participant satisfaction (Chinese responses: mean 4.2, SD 0.8; English responses: mean 4.5, SD 0.5; P=.04). According to the evaluator neurologists’ review, Chinese responses had a mean score of 4.4 (SD 0.6), whereas English responses had a mean score of 4.5 (SD 0.5; P=.002). As for the family members of patients with AD, no significant differences were observed between GPT and neurologists, GPT-3.5 and GPT-4, or Chinese and English responses.
Conclusions
GPT can provide patient education materials on AD for patients, their families and caregivers, nurses, and neurologists. This capability can contribute to the effective health care management of patients with AD, leading to enhanced patient outcomes.}
}
@article{PREIKSAITIS2023,
title = {Opportunities, Challenges, and Future Directions of Generative Artificial Intelligence in Medical Education: Scoping Review},
journal = {JMIR Medical Education},
volume = {9},
year = {2023},
issn = {2369-3762},
doi = {https://doi.org/10.2196/48785},
url = {https://www.sciencedirect.com/science/article/pii/S2369376223000697},
author = {Carl Preiksaitis and Christian Rose},
keywords = {medical education, artificial intelligence, ChatGPT, Bard, AI, educator, scoping, review, learner, generative},
abstract = {Background
Generative artificial intelligence (AI) technologies are increasingly being utilized across various fields, with considerable interest and concern regarding their potential application in medical education. These technologies, such as Chat GPT and Bard, can generate new content and have a wide range of possible applications.
Objective
This study aimed to synthesize the potential opportunities and limitations of generative AI in medical education. It sought to identify prevalent themes within recent literature regarding potential applications and challenges of generative AI in medical education and use these to guide future areas for exploration.
Methods
We conducted a scoping review, following the framework by Arksey and O'Malley, of English language articles published from 2022 onward that discussed generative AI in the context of medical education. A literature search was performed using PubMed, Web of Science, and Google Scholar databases. We screened articles for inclusion, extracted data from relevant studies, and completed a quantitative and qualitative synthesis of the data.
Results
Thematic analysis revealed diverse potential applications for generative AI in medical education, including self-directed learning, simulation scenarios, and writing assistance. However, the literature also highlighted significant challenges, such as issues with academic integrity, data accuracy, and potential detriments to learning. Based on these themes and the current state of the literature, we propose the following 3 key areas for investigation: developing learners’ skills to evaluate AI critically, rethinking assessment methodology, and studying human-AI interactions.
Conclusions
The integration of generative AI in medical education presents exciting opportunities, alongside considerable challenges. There is a need to develop new skills and competencies related to AI as well as thoughtful, nuanced approaches to examine the growing use of generative AI in medical education.}
}
@article{GALHOTRA2025S19,
title = {ID: 4349993 QUALITATIVE EVALUATION FRAMEWORK FOR COMPARING THE EFFECTIVENESS OF LARGE LANGUAGE MODELS THAT POWER HEALTH CARE CONVERSATIONS USING GENERATIVE ARTIFICIAL INTELLIGENCE IN ATRIAL FIBRILLATION},
journal = {Heart Rhythm O2},
volume = {6},
number = {9, Supplement },
pages = {S19-S20},
year = {2025},
note = {HRX AbstracX 2025},
issn = {2666-5018},
doi = {https://doi.org/10.1016/j.hroo.2025.07.059},
url = {https://www.sciencedirect.com/science/article/pii/S2666501825003241},
author = {Sainyam Galhotra and Hemang Jiwnani and Audrey Nicholson and Prashanthan Sanders and Ajay Tripuraneni}
}
@article{AHMED20241975,
title = {Generative Artificial Intelligence Tools in Gastroenterology Training},
journal = {Clinical Gastroenterology and Hepatology},
volume = {22},
number = {10},
pages = {1975-1978},
year = {2024},
issn = {1542-3565},
doi = {https://doi.org/10.1016/j.cgh.2024.05.050},
url = {https://www.sciencedirect.com/science/article/pii/S1542356524006001},
author = {Tasnim Ahmed and Loren G. Rabinowitz and Adam Rodman and Tyler M. Berzin}
}
@article{SHLOBIN2024e398,
title = {Opportunities and Considerations for the Incorporation of Artificial Intelligence into Global Neurosurgery: A Generative Pretrained Transformer Chatbot-Based Approach},
journal = {World Neurosurgery},
volume = {186},
pages = {e398-e412},
year = {2024},
issn = {1878-8750},
doi = {https://doi.org/10.1016/j.wneu.2024.03.149},
url = {https://www.sciencedirect.com/science/article/pii/S1878875024005357},
author = {Nathan A. Shlobin and Gail Rosseau},
keywords = {Global health, Global neurosurgery, Global surgery, International development, Public health},
abstract = {Objective
Global neurosurgery is a public health focus in neurosurgery that seeks to ensure safe, timely, and affordable neurosurgical care to all individuals worldwide. Although investigators have begun to explore the promise of artificial intelligence (AI) for neurosurgery, its applicability to global neurosurgery has been largely hypothetical. We characterize opportunities and considerations for the incorporation of AI into global neurosurgery by synthesizing key themes yielded from a series of generative pretrained transformers (GPTs), discuss important limitations of GPTs and cautions when using AI in neurosurgery, and develop a framework for the equitable incorporation of AI into global neurosurgery.
Methods
ChatGPT, Bing Chat/Copilot, You, Perplexity.ai, and Google Bard were queried with the prompt “How can AI be incorporated into global neurosurgery?” A layered ChatGPT-based thematic analysis was performed. The authors synthesized the results into opportunities and considerations for the incorporation of AI in global neurosurgery. A Pareto analysis was conducted to determine common themes.
Results
Eight opportunities and 14 important considerations were synthesized. Six opportunities related to patient care, 1 to education, and another to public health planning. Four of the important considerations were deemed specific to global neurosurgery. The Pareto analysis included all 8 opportunities and 5 considerations.
Conclusions
AI may be incorporated into global neurosurgery in a variety of capacities requiring numerous considerations. The framework presented in this manuscript may facilitate the incorporation of AI into global neurosurgery initiatives while balancing contextual factors and the reality of limited resources.}
}
@article{CHAUHAN20241406,
title = {The Impact of Generative Artificial Intelligence in Scientific Content Synthesis for Authors},
journal = {The American Journal of Pathology},
volume = {194},
number = {8},
pages = {1406-1408},
year = {2024},
issn = {0002-9440},
doi = {https://doi.org/10.1016/j.ajpath.2024.06.002},
url = {https://www.sciencedirect.com/science/article/pii/S0002944024002001},
author = {Chhavi Chauhan}
}
@article{RODRIGUES202578,
title = {Simulating social dynamics with artificial intelligence: Comment on “LLMs and generative agent-based models for complex systems research” by Yikang Lu et al.},
journal = {Physics of Life Reviews},
volume = {54},
pages = {78-79},
year = {2025},
issn = {1571-0645},
doi = {https://doi.org/10.1016/j.plrev.2025.05.011},
url = {https://www.sciencedirect.com/science/article/pii/S1571064525000910},
author = {Francisco A. Rodrigues and Paula Giovanna Rodrigues}
}
@article{SATURNO2023248,
title = {Generative artificial intelligence fails to provide sufficiently accurate recommendations when compared to established breast reconstruction surgery guidelines},
journal = {Journal of Plastic, Reconstructive & Aesthetic Surgery},
volume = {86},
pages = {248-250},
year = {2023},
issn = {1748-6815},
doi = {https://doi.org/10.1016/j.bjps.2023.09.030},
url = {https://www.sciencedirect.com/science/article/pii/S1748681523005247},
author = {Michael P. Saturno and Mateo Restrepo Mejia and Anya Wang and Daniel Kwon and Olachi Oleru and Nargiz Seyidova and Peter W. Henderson},
keywords = {Large language model, ChatGPT, Artificial intelligence, Reconstructive breast surgery, Plastic and reconstructive surgery, Guidelines}
}
@article{CHAU2024616,
title = {Performance of Generative Artificial Intelligence in Dental Licensing Examinations},
journal = {International Dental Journal},
volume = {74},
number = {3},
pages = {616-621},
year = {2024},
issn = {0020-6539},
doi = {https://doi.org/10.1016/j.identj.2023.12.007},
url = {https://www.sciencedirect.com/science/article/pii/S0020653923009899},
author = {Reinhard Chun Wang Chau and Khaing Myat Thu and Ollie Yiru Yu and Richard Tai-Chiu Hsung and Edward Chin Man Lo and Walter Yu Hang Lam},
keywords = {Artificial intelligence, Communication, Dental education, Digital technology, Examination questions, Specialties, Dental},
abstract = {ABSTRACT
Objectives
Generative artificial intelligence (GenAI), including large language models (LLMs), has vast potential applications in health care and education. However, it is unclear how proficient LLMs are in interpreting written input and providing accurate answers in dentistry. This study aims to investigate the accuracy of GenAI in answering questions from dental licensing examinations.
Methods
A total of 1461 multiple-choice questions from question books for the US and the UK dental licensing examinations were input into 2 versions of ChatGPT 3.5 and 4.0. The passing rates of the US and UK dental examinations were 75.0% and 50.0%, respectively. The performance of the 2 versions of GenAI in individual examinations and dental subjects was analysed and compared.
Results
ChatGPT 3.5 correctly answered 68.3% (n = 509) and 43.3% (n = 296) of questions from the US and UK dental licensing examinations, respectively. The scores for ChatGPT 4.0 were 80.7% (n = 601) and 62.7% (n = 429), respectively. ChatGPT 4.0 passed both written dental licensing examinations, whilst ChatGPT 3.5 failed. ChatGPT 4.0 answered 327 more questions correctly and 102 incorrectly compared to ChatGPT 3.5 when comparing the 2 versions.
Conclusions
The newer version of GenAI has shown good proficiency in answering multiple-choice questions from dental licensing examinations. Whilst the more recent version of GenAI generally performed better, this observation may not hold true in all scenarios, and further improvements are necessary. The use of GenAI in dentistry will have significant implications for dentist–patient communication and the training of dental professionals.}
}
@article{BREWER2024525,
title = {Navigating the challenges of generative technologies: Proposing the integration of artificial intelligence and blockchain},
journal = {Business Horizons},
volume = {67},
number = {5},
pages = {525-535},
year = {2024},
note = {SPECIAL ISSUE: WRITTEN BY CHATGPT},
issn = {0007-6813},
doi = {https://doi.org/10.1016/j.bushor.2024.04.011},
url = {https://www.sciencedirect.com/science/article/pii/S0007681324000569},
author = {Jordan Brewer and Dhru Patel and Dennie Kim and Alex Murray},
keywords = {Blockcain, Generative artificial intelligence (GenAI), ChatGPT, Large language models (LLMs), Chatbots},
abstract = {The transformative impact of generative AI (GenAI), extending beyond traditional AI, raises numerous concerns including the replacement of human roles and AI misuse in an array of industries. This article introduces blockchain technology as a complementary technological safeguard to address some of these challenges. We emphasize blockchain’s role in promoting transparency, verifiability, and decentralization in AI development and usage, thereby offering potential solutions for four distinct challenges: (1) AI toxicity, biases, hallucinations, (2) AI interest misalignment, (3) AI as a black box, and (4) AI misuse. This article proposes ways to ensure responsible and transparent AI usage through the integration of blockchain. We position the convergence of AI and blockchain as a means to manage AI’s societal impact and unlock its benefits—contingent upon collaborative efforts among various stakeholders such as businesses, developers, and regulatory bodies. We contribute to the discourse on ethical AI usage and the potential of blockchain to enhance AI’s reliability and accountability for organizations.}
}
@article{WANG2023100516,
title = {Large-scale generative simulation artificial intelligence: The next hotspot},
journal = {The Innovation},
volume = {4},
number = {6},
pages = {100516},
year = {2023},
issn = {2666-6758},
doi = {https://doi.org/10.1016/j.xinn.2023.100516},
url = {https://www.sciencedirect.com/science/article/pii/S2666675823001443},
author = {Qi Wang and Yanghe Feng and Jincai Huang and Yiqin Lv and Zheng Xie and Xiaoshan Gao}
}
@article{ABOGUNRIN2024S482,
title = {MSR224 Generative Artificial Intelligence: An Effective Alternative for Screening Titles and Abstracts in Systematic Literature Reviews},
journal = {Value in Health},
volume = {27},
number = {12, Supplement },
pages = {S482},
year = {2024},
note = {ISPOR Europe 2024},
issn = {1098-3015},
doi = {https://doi.org/10.1016/j.jval.2024.10.2457},
url = {https://www.sciencedirect.com/science/article/pii/S1098301524053208},
author = {S Abogunrin and RR Sieiro and M Lane}
}
@article{YILMAZ2023100147,
title = {The effect of generative artificial intelligence (AI)-based tool use on students' computational thinking skills, programming self-efficacy and motivation},
journal = {Computers and Education: Artificial Intelligence},
volume = {4},
pages = {100147},
year = {2023},
issn = {2666-920X},
doi = {https://doi.org/10.1016/j.caeai.2023.100147},
url = {https://www.sciencedirect.com/science/article/pii/S2666920X23000267},
author = {Ramazan Yilmaz and Fatma Gizem {Karaoglan Yilmaz}},
keywords = {Artificial intelligence, ChatGPT, Generative pretrained transformer, Programming education, Computational thinking},
abstract = {ChatGPT (generative pre-trained transformer) is one of the artificial intelligence (AI) technologies that have started to be used in programming education. However, the effect of using ChatGPT in programming education on learning processes and outcomes is not yet known. This study investigated the effect of programming education using the ChatGPT on students' computational thinking skills, programming self-efficacy, and motivation toward the lesson. The research was conducted on 45 undergraduate students who took a university-level programming course. The research was carried out according to the experimental design with the pretest-posttest control group. Students were randomly divided into experimental (n = 21) and control (n = 24) groups. While the experimental group students benefited from the ChatGPT during the weekly programming practices, the control group students did not use this tool. Research data were obtained through the computational thinking scale, computer programming self-efficacy scale, and learning motivation in computer programming courses scale. Research findings revealed that the experimental group students' computational thinking skills, programming self-efficacy, and motivation for the lesson were significantly higher than the control group students. In line with this result, it can be said that it may be useful to benefit from AI technologies such as ChatGPT in programming trainings. The research findings, it was emphasized how the most effective use of AI support in the lessons could be made, and various suggestions were made for researchers and educators in this regard.}
}
@article{SHAPIRO2024492,
title = {Revolutionizing teledermatology: Exploring the integration of artificial intelligence, including Generative Pre-trained Transformer chatbots for artificial intelligence-driven anamnesis, diagnosis, and treatment plans},
journal = {Clinics in Dermatology},
volume = {42},
number = {5},
pages = {492-497},
year = {2024},
note = {Artificial Intelligence II},
issn = {0738-081X},
doi = {https://doi.org/10.1016/j.clindermatol.2024.06.020},
url = {https://www.sciencedirect.com/science/article/pii/S0738081X24001044},
author = {Jonathan Shapiro and Anna Lyakhovitsky},
abstract = {The integration of teledermatology and artificial intelligence (AI) marks a significant advancement in dermatologic care. This study examines the synergistic interplay between these two domains, highlighting their collective impact on enhancing the accuracy, accessibility, and efficiency of teledermatologic services. Teledermatology expands dermatologic care to remote and underserved areas, and AI technologies show considerable potential in analyzing dermatologic images and performing various tasks involved in teledermatology consultations. Such integration facilitates rapid, precise diagnoses, personalized treatment plans, and data-driven insights. Our explorative study involved designing a GPT-based chatbot named “Dr. DermBot” and exploring its performance in a teledermatologic consultation process. The design phase focused on the chatbot's ability to conduct consultations autonomously. The subsequent testing phase assessed its performance against the backdrop of current teledermatologic practices, exploring the potential of AI and chatbots to simulate and potentially enhance teledermatologic health care. Our study demonstrates the promising future of combining teledermatology with AI. It also brings to light ethical and legal concerns, including the protection of patient data privacy and adherence to regulatory standards. The union of teledermatology and AI not only aims to enhance the precision of teledermatologic diagnoses but also broadens the accessibility of dermatologic services to previously underserved populations, benefiting patients, health care providers, and the overall health care system.}
}
@article{ZHUANG2024102122,
title = {From hearing to seeing: Linking auditory and visual place perceptions with soundscape-to-image generative artificial intelligence},
journal = {Computers, Environment and Urban Systems},
volume = {110},
pages = {102122},
year = {2024},
issn = {0198-9715},
doi = {https://doi.org/10.1016/j.compenvurbsys.2024.102122},
url = {https://www.sciencedirect.com/science/article/pii/S0198971524000516},
author = {Yonggai Zhuang and Yuhao Kang and Teng Fei and Meng Bian and Yunyan Du},
keywords = {Soundscape, Street view images, Sense of place, Stable diffusion, Generative AI, LLMs},
abstract = {People experience the world through multiple senses simultaneously, contributing to our sense of place. Prior quantitative geography studies have mostly emphasized human visual perceptions, neglecting human auditory perceptions at place due to the challenges in characterizing the acoustic environment vividly. Also, few studies have synthesized the two-dimensional (auditory and visual) perceptions in understanding human sense of place. To bridge these gaps, we propose a Soundscape-to-Image Diffusion model, a generative Artificial Intelligence (AI) model supported by Large Language Models (LLMs), aiming to visualize soundscapes through the generation of street view images. By creating audio-image pairs, acoustic environments are first represented as high-dimensional semantic audio vectors. Our proposed Soundscape-to-Image Diffusion model, which contains a Low-Resolution Diffusion Model and a Super-Resolution Diffusion Model, can then translate those semantic audio vectors into visual representations of place effectively. We evaluated our proposed model by using both machine-based and human-centered approaches. We proved that the generated street view images align with our common perceptions, and accurately create several key street elements of the original soundscapes. It also demonstrates that soundscapes provide sufficient visual information places. This study stands at the forefront of the intersection between generative AI and human geography, demonstrating how human multi-sensory experiences can be linked. We aim to enrich geospatial data science and AI studies with human experiences. It has the potential to inform multiple domains such as human geography, environmental psychology, and urban design and planning, as well as advancing our knowledge of human-environment relationships.}
}
@article{JEHA20232105,
title = {ChatGPT and Generative Artificial Intelligence in Mohs Surgery: A New Frontier of Innovation},
journal = {Journal of Investigative Dermatology},
volume = {143},
number = {11},
pages = {2105-2107},
year = {2023},
issn = {0022-202X},
doi = {https://doi.org/10.1016/j.jid.2023.05.018},
url = {https://www.sciencedirect.com/science/article/pii/S0022202X23021425},
author = {George M. Jeha and Sultan Qiblawi and Neil Jairath and Kimberly Sable and Keith LeBlanc and Juliet Aylward and Yaohui Gloria Xu}
}
@article{BRAGAZZI2024,
title = {Assessing the Accuracy of Generative Conversational Artificial Intelligence in Debunking Sleep Health Myths: Mixed Methods Comparative Study With Expert Analysis},
journal = {JMIR Formative Research},
volume = {8},
year = {2024},
issn = {2561-326X},
doi = {https://doi.org/10.2196/55762},
url = {https://www.sciencedirect.com/science/article/pii/S2561326X24002178},
author = {Nicola Luigi Bragazzi and Sergio Garbarino},
keywords = {sleep, sleep health, sleep-related disbeliefs, generative conversational artificial intelligence, chatbot, ChatGPT, misinformation, artificial intelligence, comparative study, expert analysis, adequate sleep, well-being, sleep trackers, sleep health education, sleep-related, chronic disease, healthcare cost, sleep timing, sleep duration, presleep behaviors, sleep experts, healthy behavior, public health, conversational agents},
abstract = {Background
Adequate sleep is essential for maintaining individual and public health, positively affecting cognition and well-being, and reducing chronic disease risks. It plays a significant role in driving the economy, public safety, and managing health care costs. Digital tools, including websites, sleep trackers, and apps, are key in promoting sleep health education. Conversational artificial intelligence (AI) such as ChatGPT (OpenAI, Microsoft Corp) offers accessible, personalized advice on sleep health but raises concerns about potential misinformation. This underscores the importance of ensuring that AI-driven sleep health information is accurate, given its significant impact on individual and public health, and the spread of sleep-related myths.
Objective
This study aims to examine ChatGPT’s capability to debunk sleep-related disbeliefs.
Methods
A mixed methods design was leveraged. ChatGPT categorized 20 sleep-related myths identified by 10 sleep experts and rated them in terms of falseness and public health significance, on a 5-point Likert scale. Sensitivity, positive predictive value, and interrater agreement were also calculated. A qualitative comparative analysis was also conducted.
Results
ChatGPT labeled a significant portion (n=17, 85%) of the statements as “false” (n=9, 45%) or “generally false” (n=8, 40%), with varying accuracy across different domains. For instance, it correctly identified most myths about “sleep timing,” “sleep duration,” and “behaviors during sleep,” while it had varying degrees of success with other categories such as “pre-sleep behaviors” and “brain function and sleep.” ChatGPT’s assessment of the degree of falseness and public health significance, on the 5-point Likert scale, revealed an average score of 3.45 (SD 0.87) and 3.15 (SD 0.99), respectively, indicating a good level of accuracy in identifying the falseness of statements and a good understanding of their impact on public health. The AI-based tool showed a sensitivity of 85% and a positive predictive value of 100%. Overall, this indicates that when ChatGPT labels a statement as false, it is highly reliable, but it may miss identifying some false statements. When comparing with expert ratings, high intraclass correlation coefficients (ICCs) between ChatGPT’s appraisals and expert opinions could be found, suggesting that the AI’s ratings were generally aligned with expert views on falseness (ICC=.83, P<.001) and public health significance (ICC=.79, P=.001) of sleep-related myths. Qualitatively, both ChatGPT and sleep experts refuted sleep-related misconceptions. However, ChatGPT adopted a more accessible style and provided a more generalized view, focusing on broad concepts, while experts sometimes used technical jargon, providing evidence-based explanations.
Conclusions
ChatGPT-4 can accurately address sleep-related queries and debunk sleep-related myths, with a performance comparable to sleep experts, even if, given its limitations, the AI cannot completely replace expert opinions, especially in nuanced and complex fields such as sleep health, but can be a valuable complement in the dissemination of updated information and promotion of healthy behaviors.}
}
@article{GUO2024102547,
title = {Harnessing Artificial Intelligence in Generative Content for enhancing motivation in learning},
journal = {Learning and Individual Differences},
volume = {116},
pages = {102547},
year = {2024},
issn = {1041-6080},
doi = {https://doi.org/10.1016/j.lindif.2024.102547},
url = {https://www.sciencedirect.com/science/article/pii/S1041608024001407},
author = {Jiesi Guo and Ying Ma and Tingting Li and Michael Noetel and Kewen Liao and Samuel Greiff}
}
@article{ASHRAF2024,
title = {Search Engines and Generative Artificial Intelligence Integration: Public Health Risks and Recommendations to Safeguard Consumers Online},
journal = {JMIR Public Health and Surveillance},
volume = {10},
year = {2024},
issn = {2369-2960},
doi = {https://doi.org/10.2196/53086},
url = {https://www.sciencedirect.com/science/article/pii/S2369296024000504},
author = {Amir Reza Ashraf and Tim Ken Mackey and András Fittler},
keywords = {generative artificial intelligence, artificial intelligence, comparative assessment, search engines, online pharmacies, patient safety, generative, safety, search engine, search, searches, searching, website, websites, Google, Bing, retrieval, information seeking, illegal, pharmacy, pharmacies, risk, risks, consumer, consumers, customer, customers, recommendation, recommendations, vendor, vendors, substance use, substance abuse, controlled substances, controlled substance, drug, drugs, pharmaceutic, pharmaceutics, pharmaceuticals, pharmaceutical, medication, medications},
abstract = {Background
The online pharmacy market is growing, with legitimate online pharmacies offering advantages such as convenience and accessibility. However, this increased demand has attracted malicious actors into this space, leading to the proliferation of illegal vendors that use deceptive techniques to rank higher in search results and pose serious public health risks by dispensing substandard or falsified medicines. Search engine providers have started integrating generative artificial intelligence (AI) into search engine interfaces, which could revolutionize search by delivering more personalized results through a user-friendly experience. However, improper integration of these new technologies carries potential risks and could further exacerbate the risks posed by illicit online pharmacies by inadvertently directing users to illegal vendors.
Objective
The role of generative AI integration in reshaping search engine results, particularly related to online pharmacies, has not yet been studied. Our objective was to identify, determine the prevalence of, and characterize illegal online pharmacy recommendations within the AI-generated search results and recommendations.
Methods
We conducted a comparative assessment of AI-generated recommendations from Google’s Search Generative Experience (SGE) and Microsoft Bing’s Chat, focusing on popular and well-known medicines representing multiple therapeutic categories including controlled substances. Websites were individually examined to determine legitimacy, and known illegal vendors were identified by cross-referencing with the National Association of Boards of Pharmacy and LegitScript databases.
Results
Of the 262 websites recommended in the AI-generated search results, 47.33% (124/262) belonged to active online pharmacies, with 31.29% (82/262) leading to legitimate ones. However, 19.04% (24/126) of Bing Chat’s and 13.23% (18/136) of Google SGE’s recommendations directed users to illegal vendors, including for controlled substances. The proportion of illegal pharmacies varied by drug and search engine. A significant difference was observed in the distribution of illegal websites between search engines. The prevalence of links leading to illegal online pharmacies selling prescription medications was significantly higher (P=.001) in Bing Chat (21/86, 24%) compared to Google SGE (6/92, 6%). Regarding the suggestions for controlled substances, suggestions generated by Google led to a significantly higher number of rogue sellers (12/44, 27%; P=.02) compared to Bing (3/40, 7%).
Conclusions
While the integration of generative AI into search engines offers promising potential, it also poses significant risks. This is the first study to shed light on the vulnerabilities within these platforms while highlighting the potential public health implications associated with their inadvertent promotion of illegal pharmacies. We found a concerning proportion of AI-generated recommendations that led to illegal online pharmacies, which could not only potentially increase their traffic but also further exacerbate existing public health risks. Rigorous oversight and proper safeguards are urgently needed in generative search to mitigate consumer risks, making sure to actively guide users to verified pharmacies and prioritize legitimate sources while excluding illegal vendors from recommendations.}
}
@article{ESMAEILI2024127676,
title = {Enhancing digital rock analysis through generative artificial intelligence: Diffusion models},
journal = {Neurocomputing},
volume = {587},
pages = {127676},
year = {2024},
issn = {0925-2312},
doi = {https://doi.org/10.1016/j.neucom.2024.127676},
url = {https://www.sciencedirect.com/science/article/pii/S0925231224004478},
author = {Mohammad Esmaeili},
keywords = {Diffusion Models, Generative Artificial Intelligence, Computer Vision, Digital Rock Analysis, Single Image Super-Resolution},
abstract = {Within the realm of computer vision, the landscape has been significantly reshaped by the abundance of extensive and diverse datasets, leading to remarkable breakthroughs in image processing. These advancements have reverberated across a wide spectrum of applications, catalyzing transformative outcomes. However, in stark contrast, the field of digital rock analysis finds itself grappling with a conspicuous dearth of data, a challenge that casts a formidable shadow over the effective deployment of computer vision techniques for rock image analysis. In response to this pressing issue, this paper presents a pioneering methodology designed to surmount the hurdles posed by data limitation in the realm of digital rock analysis. At the core of this innovative approach lies the fusion of artificially generated digital rock images, created using a state-of-the-art diffusion model, with their authentic counterparts. This fusion is guided by the overarching objective of augmenting the efficacy of various digital rock analysis applications. This integration endeavors to bridge the gap between the limited available data and the substantial demands of the digital rock analysis domain. The practical significance and potential of this integrated approach are vividly demonstrated through a series of concrete implementations. These include, but are by no means limited to, enhancing image quality to facilitate clearer visualization of intricate rock structures and refining the estimation of petrophysical properties with increased accuracy.}
}
@article{AMACHER2024100587,
title = {Prediction of outcomes after cardiac arrest by a generative artificial intelligence model},
journal = {Resuscitation Plus},
volume = {18},
pages = {100587},
year = {2024},
issn = {2666-5204},
doi = {https://doi.org/10.1016/j.resplu.2024.100587},
url = {https://www.sciencedirect.com/science/article/pii/S2666520424000389},
author = {Simon A. Amacher and Armon Arpagaus and Christian Sahmer and Christoph Becker and Sebastian Gross and Tabita Urben and Kai Tisljar and Raoul Sutter and Stephan Marsch and Sabina Hunziker},
keywords = {Artificial intelligence, Cardiac arrest, Cardiopulmonary resuscitation, Mortality prediction, Neurological outcome},
abstract = {Aims
To investigate the prognostic accuracy of a non-medical generative artificial intelligence model (Chat Generative Pre-Trained Transformer 4 - ChatGPT-4) as a novel aspect in predicting death and poor neurological outcome at hospital discharge based on real-life data from cardiac arrest patients.
Methods
This prospective cohort study investigates the prognostic performance of ChatGPT-4 to predict outcomes at hospital discharge of adult cardiac arrest patients admitted to intensive care at a large Swiss tertiary academic medical center (COMMUNICATE/PROPHETIC cohort study). We prompted ChatGPT-4 with sixteen prognostic parameters derived from established post-cardiac arrest scores for each patient. We compared the prognostic performance of ChatGPT-4 regarding the area under the curve (AUC), sensitivity, specificity, positive and negative predictive values, and likelihood ratios of three cardiac arrest scores (Out-of-Hospital Cardiac Arrest [OHCA], Cardiac Arrest Hospital Prognosis [CAHP], and PROgnostication using LOGistic regression model for Unselected adult cardiac arrest patients in the Early stages [PROLOGUE score]) for in-hospital mortality and poor neurological outcome.
Results
Mortality at hospital discharge was 43% (n = 309/713), 54% of patients (n = 387/713) had a poor neurological outcome. ChatGPT-4 showed good discrimination regarding in-hospital mortality with an AUC of 0.85, similar to the OHCA, CAHP, and PROLOGUE (AUCs of 0.82, 0.83, and 0.84, respectively) scores. For poor neurological outcome, ChatGPT-4 showed a similar prediction to the post-cardiac arrest scores (AUC 0.83).
Conclusions
ChatGPT-4 showed a similar performance in predicting mortality and poor neurological outcome compared to validated post-cardiac arrest scores. However, more research is needed regarding illogical answers for potential incorporation of an LLM in the multimodal outcome prognostication after cardiac arrest.}
}
@article{RAMAN2024e24727,
title = {Fake news research trends, linkages to generative artificial intelligence and sustainable development goals},
journal = {Heliyon},
volume = {10},
number = {3},
pages = {e24727},
year = {2024},
issn = {2405-8440},
doi = {https://doi.org/10.1016/j.heliyon.2024.e24727},
url = {https://www.sciencedirect.com/science/article/pii/S2405844024007588},
author = {Raghu Raman and Vinith {Kumar Nair} and Prema Nedungadi and Aditya {Kumar Sahu} and Robin Kowalski and Sasangan Ramanathan and Krishnashree Achuthan},
keywords = {Deep fake, Ethics, Fake news, Generative AI, Prominence percentile, Sustainable development goal},
abstract = {In the digital age, where information is a cornerstone for decision-making, social media's not-so-regulated environment has intensified the prevalence of fake news, with significant implications for both individuals and societies. This study employs a bibliometric analysis of a large corpus of 9678 publications spanning 2013–2022 to scrutinize the evolution of fake news research, identifying leading authors, institutions, and nations. Three thematic clusters emerge: Disinformation in social media, COVID-19-induced infodemics, and techno-scientific advancements in auto-detection. This work introduces three novel contributions: 1) a pioneering mapping of fake news research to Sustainable Development Goals (SDGs), indicating its influence on areas like health (SDG 3), peace (SDG 16), and industry (SDG 9); 2) the utilization of Prominence percentile metrics to discern critical and economically prioritized research areas, such as misinformation and object detection in deep learning; and 3) an evaluation of generative AI's role in the propagation and realism of fake news, raising pressing ethical concerns. These contributions collectively provide a comprehensive overview of the current state and future trajectories of fake news research, offering valuable insights for academia, policymakers, and industry.}
}
@article{SAJJADIMOHAMMADABADI2024267,
title = {Generative artificial intelligence for distributed learning to enhance smart grid communication},
journal = {International Journal of Intelligent Networks},
volume = {5},
pages = {267-274},
year = {2024},
issn = {2666-6030},
doi = {https://doi.org/10.1016/j.ijin.2024.05.007},
url = {https://www.sciencedirect.com/science/article/pii/S2666603024000265},
author = {Seyed Mahmoud {Sajjadi Mohammadabadi} and Mahmoudreza Entezami and Aidin {Karimi Moghaddam} and Mansour Orangian and Shayan Nejadshamsi},
keywords = {Energy forecasting, Generative AI, Smart grid, Communication efficiency, Distributed training, LSTM},
abstract = {Machine learning models are the backbone of smart grid optimization, but their effectiveness hinges on access to vast amounts of training data. However, smart grids face critical communication bottlenecks due to the ever-increasing volume of data from distributed sensors. This paper introduces a novel approach leveraging Generative Artificial Intelligence (GenAI), specifically a type of pre-trained Foundation Model (FM) architecture suitable for time series data due to its efficiency and privacy-preserving properties. These GenAI models are distributed to agents, or data holders, empowering them to fine-tune the foundation model with their local datasets. By fine-tuning the foundation model, the updated model can produce synthetic data that mirrors real-world grid conditions. The server aggregates fine-tuned model from all agents and then generates synthetic data which considers all data collected in the grid. This synthetic data can be used to train global machine learning models for specific tasks like anomaly detection and energy optimization. Then, the trained task models are distributed to agents in the grid to leverage them. The paper highlights the advantages of GenAI for smart grid communication, including reduced communication burden, enhanced privacy through anonymized data transmission, and improved efficiency and scalability. By enabling a distributed and intelligent communication architecture, GenAI introduces a novel way for a more secure, efficient, and sustainable energy future.}
}
@article{SAKURAYA2024103947,
title = {Statement on use of generative artificial intelligence by adolescents},
journal = {Asian Journal of Psychiatry},
volume = {94},
pages = {103947},
year = {2024},
issn = {1876-2018},
doi = {https://doi.org/10.1016/j.ajp.2024.103947},
url = {https://www.sciencedirect.com/science/article/pii/S187620182400039X},
author = {Asuka Sakuraya and Masayo Matsumura and Shohei Komatsu and Kotaro Imamura and Mako Iida and Norito Kawakami},
keywords = {Generative artificial intelligence, Adolescents, Mental health}
}
@article{MESSER2024100056,
title = {Co-creating art with generative artificial intelligence: Implications for artworks and artists},
journal = {Computers in Human Behavior: Artificial Humans},
volume = {2},
number = {1},
pages = {100056},
year = {2024},
issn = {2949-8821},
doi = {https://doi.org/10.1016/j.chbah.2024.100056},
url = {https://www.sciencedirect.com/science/article/pii/S2949882124000161},
author = {Uwe Messer},
keywords = {Art, Authenticity, Generative AI, Human-AI-Collaboration},
abstract = {Synthetic visual art is becoming a commodity due to generative artificial intelligence (AI). The trend of using AI for co-creation will not spare artists’ creative processes, and it is important to understand how the use of generative AI at different stages of the creative process affects both the evaluation of the artist and the result of the human-machine collaboration (i.e., the visual artifact). In three experiments (N = 560), this research explores how the evaluation of artworks is transformed by the revelation that the artist collaborated with AI at different stages of the creative process. The results show that co-created art is less liked and recognized, especially when AI was used in the implementation stage. While co-created art is perceived as more novel, it lacks creative authenticity, which exerts a dominant influence. The results also show that artists’ perceptions suffer from the co-creation process, and that artists who co-create are less admired because they are perceived as less authentic. Two boundary conditions are identified. The negative effect can be mitigated by disclosing the level of artist involvement in co-creation with AI (e.g., by training the algorithm on a curated set of images vs. simply prompting an off-the-shelf AI image generator). In the context of art that is perceived as commercially motivated (e.g., stock images), the effect is also diminished. This research has important implications for the literature on human-AI-collaboration, research on authenticity, and the ongoing policy debate regarding the transparency of algorithmic presence.}
}
@article{ODRI2023103706,
title = {Detecting generative artificial intelligence in scientific articles: Evasion techniques and implications for scientific integrity},
journal = {Orthopaedics & Traumatology: Surgery & Research},
volume = {109},
number = {8},
pages = {103706},
year = {2023},
issn = {1877-0568},
doi = {https://doi.org/10.1016/j.otsr.2023.103706},
url = {https://www.sciencedirect.com/science/article/pii/S1877056823002244},
author = {Guillaume-Anthony Odri and Diane {Ji Yun Yoon}},
keywords = {Generative artificial intelligence, Academic writing, Scientific fraud},
abstract = {Background
Artificial intelligence (AI) tools, although beneficial for data collection and analysis, can also facilitate scientific fraud. AI detectors can help resolve this problem, but their effectiveness depends on their ability to track AI progress. In addition, many methods of evading AI detection exist and their constantly evolving sophistication can make the task more difficult. Thus, from an AI-generated text, we wanted to: (1) evaluate the AI detection sites on a text generated entirely by the AI, (2) test the methods described for evading AI detection, and (3) evaluate the effectiveness of these methods to evade AI detection on the sites tested previously.
Hypothesis
Not all AI detection tools are equally effective in detecting AI-generated text and some techniques used to evade AI detection can make an AI-produced text almost undetectable.
Materials and methods
We created a text with ChatGPT-4 (Chat Generative Pre-trained Transformer) and submitted it to 11 AI detection web tools (Originality, ZeroGPT, Writer, Copyleaks, Crossplag, GPTZero, Sapling, Content at scale, Corrector, Writefull et Quill), before and after applying strategies to minimise AI detection. The strategies used to minimize AI detection were the improvement of command messages in ChatPGT, the introduction of minor grammatical errors such as comma deletion, paraphrasing, and the substitution of Latin letters with similar Cyrillic letters (а and о) which is also a method used elsewhere to evade the detection of plagiarism. We have also tested the effectiveness of these tools in correctly identifying a scientific text written by a human in 1960.
Results
From the initial text generated by the AI, 7 of the 11 detectors concluded that the text was mainly written by humans. Subsequently, the introduction of simple modifications, such as the removal of commas or paraphrasing can effectively reduce AI detection and make the text appear human for all detectors. In addition, replacing certain Latin letters with Cyrillic letters can make an AI text completely undetectable. Finally, we observe that in a paradoxical way, certain sites detect a significant proportion of AI in a text written by a human in 1960.
Discussion
AI detectors have low efficiency, and simple modifications can allow even the most robust detectors to be easily bypassed. The rapid development of generative AI raises questions about the future of scientific writing but also about the detection of scientific fraud, such as data fabrication.
Level of evidence
III Control case study.}
}
@article{STERPETTI2025388,
title = {Letter Regarding: Generative Artificial Intelligence in Academic Surgery: Ethical Implications and Transformative Potential},
journal = {Journal of Surgical Research},
volume = {310},
pages = {388-389},
year = {2025},
issn = {0022-4804},
doi = {https://doi.org/10.1016/j.jss.2025.02.046},
url = {https://www.sciencedirect.com/science/article/pii/S0022480425001325},
author = {Antonio V. Sterpetti}
}
@article{SACHDEVA2024S445,
title = {MSR40 Leveraging Artificial Intelligence (AI) and Generative AI (GenAI) for Transforming Real-World Evidence ( RWE) Across the Product Value Chain and Industry Functions},
journal = {Value in Health},
volume = {27},
number = {12, Supplement },
pages = {S445},
year = {2024},
note = {ISPOR Europe 2024},
issn = {1098-3015},
doi = {https://doi.org/10.1016/j.jval.2024.10.2274},
url = {https://www.sciencedirect.com/science/article/pii/S1098301524051374},
author = {S Sachdeva and J Kaneria and R Malik and A Prasad and J Gopalakrishna and RS Shah and S Nandiraju}
}
@article{ROLLS2024e31965,
title = {The memory systems of the human brain and generative artificial intelligence},
journal = {Heliyon},
volume = {10},
number = {11},
pages = {e31965},
year = {2024},
issn = {2405-8440},
doi = {https://doi.org/10.1016/j.heliyon.2024.e31965},
url = {https://www.sciencedirect.com/science/article/pii/S2405844024079969},
author = {Edmund T. Rolls},
keywords = {The brain and AI, Generative Pre-trained Transformer, Generative artificial intelligence, Episodic memory, Semantic memory, Hippocampal memory system, Chat-GPT},
abstract = {Generative Artificial Intelligence foundation models (for example Generative Pre-trained Transformer – GPT – models) can generate the next token given a sequence of tokens. How can this ‘generative AI’ be compared with the ‘real’ intelligence of the human brain, when for example a human generates a whole memory in response to an incomplete retrieval cue, and then generates further prospective thoughts? Here these two types of generative intelligence, artificial in machines and real in the human brain are compared, and it is shown how when whole memories are generated by hippocampal recall in response to an incomplete retrieval cue, what the human brain computes, and how it computes it, are very different from generative AI. Key differences are the use of local associative learning rules in the hippocampal memory system, and of non-local backpropagation of error learning in AI. Indeed, it is argued that the whole operation of the human brain is performed computationally very differently to what is implemented in generative AI. Moreover, it is emphasized that the primate including human hippocampal system includes computations about spatial view and where objects and people are in scenes, whereas in rodents the emphasis is on place cells and path integration by movements between places. This comparison with generative memory and processing in the human brain has interesting implications for the further development of generative AI and for neuroscience research.}
}
@article{MESKO2023,
title = {The ChatGPT (Generative Artificial Intelligence) Revolution Has Made Artificial Intelligence Approachable for Medical Professionals},
journal = {Journal of Medical Internet Research},
volume = {25},
year = {2023},
issn = {1438-8871},
doi = {https://doi.org/10.2196/48392},
url = {https://www.sciencedirect.com/science/article/pii/S143888712300465X},
author = {Bertalan Mesko},
keywords = {artificial intelligence, digital health, future, technology, ChatGPT, medical practice, large language model, language model, generative, conversational agent, conversation agents, chatbot, generated text, computer generated, medical education, continuing education, professional development, curriculum, curricula},
abstract = {In November 2022, OpenAI publicly launched its large language model (LLM), ChatGPT, and reached the milestone of having over 100 million users in only 2 months. LLMs have been shown to be useful in a myriad of health care–related tasks and processes. In this paper, I argue that attention to, public access to, and debate about LLMs have initiated a wave of products and services using generative artificial intelligence (AI), which had previously found it hard to attract physicians. This paper describes what AI tools have become available since the beginning of the ChatGPT revolution and contemplates how it they might change physicians’ perceptions about this breakthrough technology.}
}
@article{HABIB2024100072,
title = {How does generative artificial intelligence impact student creativity?},
journal = {Journal of Creativity},
volume = {34},
number = {1},
pages = {100072},
year = {2024},
issn = {2713-3745},
doi = {https://doi.org/10.1016/j.yjoc.2023.100072},
url = {https://www.sciencedirect.com/science/article/pii/S2713374523000316},
author = {Sabrina Habib and Thomas Vogel and Xiao Anli and Evelyn Thorne},
keywords = {Creative process, Artificial intelligence (AI), Alternative uses Task (AUT), Mixed methods, Creative thinking, Higher education, Creative confidence},
abstract = {This study aimed to learn about the impact of generative artificial intelligence (AI) on student creative thinking skills and subsequently provide instructors with information on how to guide the use of AI for creative growth within classroom instruction. This mixed methods study used qualitative and quantitative data collected through an AUT test conducted in a college-level creativity course. The authors measured flexibility, fluency, elaboration, and originality of the data to assess the impact of ChatGPT-3 on students’ divergent thinking. The results advocate for a careful approach in integrating AI into creative education. While AI has the potential to significantly support creative thinking, there are also negative impacts on creativity and creative confidence. The authors of this study believe that creativity is central to learning, developing students’ ability to respond to challenges and find solutions within any field; thus the results of this study can be applicable to any classroom faced with the impact and/or integrating the use of AI on idea generation.}
}
@article{MULE202343,
title = {Generative adversarial networks (GAN)-based data augmentation of rare liver cancers: The SFR 2021 Artificial Intelligence Data Challenge},
journal = {Diagnostic and Interventional Imaging},
volume = {104},
number = {1},
pages = {43-48},
year = {2023},
issn = {2211-5684},
doi = {https://doi.org/10.1016/j.diii.2022.09.005},
url = {https://www.sciencedirect.com/science/article/pii/S2211568422001711},
author = {Sébastien Mulé and Littisha Lawrance and Younes Belkouchi and Valérie Vilgrain and Maité Lewin and Hervé Trillaud and Christine Hoeffel and Valérie Laurent and Samy Ammari and Eric Morand and Orphée Faucoz and Arthur Tenenhaus and Anne Cotten and Jean-François Meder and Hugues Talbot and Alain Luciani and Nathalie Lassau},
keywords = {Artificial intelligence, Deep learning, Generative adversarial networks, Liver cancer, Magnetic resonance imaging},
abstract = {Purpose
The 2021 edition of the Artificial Intelligence Data Challenge was organized by the French Society of Radiology together with the Centre National d’Études Spatiales and CentraleSupélec with the aim to implement generative adversarial networks (GANs) techniques to provide 1000 magnetic resonance imaging (MRI) cases of macrotrabecular-massive (MTM) hepatocellular carcinoma (HCC), a rare and aggressive subtype of HCC, generated from a limited number of real cases from multiple French centers.
Materials and methods
A dedicated platform was used by the seven inclusion centers to securely upload their anonymized MRI examinations including all three cross-sectional images (one late arterial and one portal-venous phase T1-weighted images and one fat-saturated T2-weighted image) in compliance with general data protection regulation. The quality of the database was checked by experts and manual delineation of the lesions was performed by the expert radiologists involved in each center. Multidisciplinary teams competed between October 11th, 2021 and February 13th, 2022.
Results
A total of 91 MTM-HCC datasets of three images each were collected from seven French academic centers. Six teams with a total of 28 individuals participated in this challenge. Each participating team was asked to generate one thousand 3-image cases. The qualitative evaluation was performed by three radiologists using the Likert scale on ten randomly selected cases generated by each participant. A quantitative evaluation was also performed using two metrics, the Frechet inception distance and a leave-one-out accuracy of a 1-Nearest Neighbor algorithm.
Conclusion
This data challenge demonstrates the ability of GANs techniques to generate a large number of images from a small sample of imaging examinations of a rare malignant tumor.}
}
@article{NA2025103614,
title = {1376 Virtual H&E Staining Using Generative Artificial Intelligence: A Novel Technique for Digital Transformation of Unstained Pathology Slides},
journal = {Laboratory Investigation},
volume = {105},
number = {3, Supplement },
pages = {103614},
year = {2025},
note = {USCAP 114th Annual Meeting: See the Light},
issn = {0023-6837},
doi = {https://doi.org/10.1016/j.labinv.2024.103614},
url = {https://www.sciencedirect.com/science/article/pii/S0023683724032926},
author = {Sei Na and Dawoon Na and Kyoungsook Park and SangYong Song and Byullee Park and Hyung Kyung Kim}
}
@article{M2025530,
title = {Debunking myths about Enhanced Recovery After Surgery (ERAS) using Generative Artificial Intelligence},
journal = {Clinical Nutrition ESPEN},
volume = {65},
pages = {530-531},
year = {2025},
issn = {2405-4577},
doi = {https://doi.org/10.1016/j.clnesp.2024.10.104},
url = {https://www.sciencedirect.com/science/article/pii/S2405457724014414},
author = {Aravind M}
}
@article{CONTE2024110893,
title = {Statistical analysis and generative Artificial Intelligence (AI) for assessing pain experience, pain-induced disability, and quality of life in Parkinson's disease patients},
journal = {Brain Research Bulletin},
volume = {208},
pages = {110893},
year = {2024},
issn = {0361-9230},
doi = {https://doi.org/10.1016/j.brainresbull.2024.110893},
url = {https://www.sciencedirect.com/science/article/pii/S0361923024000261},
author = {Luana Conte and Roberto Lupo and Pierluigi Lezzi and Alessio Pedone and Ivan Rubbi and Alessia Lezzi and Elsa Vitale and Antonio Fasano and Giorgio {De Nunzio}},
keywords = {Parkinson's disease, Pain, King's Parkinson's Disease Pain Questionnaire (KPPQ), Parkinson's Disease Questionnaire (PDQ), Generative Artificial Intelligence (AI)},
abstract = {The Parkinson's Disease (PD) is a chronic neurodegenerative condition characterized by motor symptoms such as tremors, rigidity, and bradykinesia, which can significantly impact various aspects of daily life. Among these aspects, pain is a prominent element. Despite the widespread use of therapies aimed at improving symptoms and quality of life, effective pain management is essential to enhance the quality of life of individuals affected by this disease. However, a detailed understanding of the factors associated with pain in PD is still evolving. In this study, we examined the disability caused by pain and the pain experienced by PD patients using two validated questionnaires, namely the Parkinson's Disease Questionnaire (PDQ) and the King's Parkinson's Disease Pain Questionnaire (KPPQ). Customized questions were also included to further explore the pain experience and management strategies adopted by PD patients. Through statistical analysis, we explored the relationships between questionnaire scores, socio-demographic data, and other relevant variables. Additionally, generative Artificial Intelligence (AI) was employed to gain a deeper understanding of patient responses. The results indicate the extent and impact of pain in PD and provide valuable insights for more targeted and personalized management. This study lays the foundation for future research and the development of interventions aimed at improving the quality of life for individuals affected by this condition.}
}
@article{CAO2024e147,
title = {GENERATIVE ARTIFICIAL INTELLIGENCE SUBSTANTIALLY ENHANCES THE ACCURACY OF EMBRYO SELECTION MODELS},
journal = {Fertility and Sterility},
volume = {122},
number = {4, Supplement },
pages = {e147},
year = {2024},
note = {80th Scientific Congress of the American Society for Reproductive Medicine},
issn = {0015-0282},
doi = {https://doi.org/10.1016/j.fertnstert.2024.07.533},
url = {https://www.sciencedirect.com/science/article/pii/S0015028224011506},
author = {Ping Cao and Ganesh Acharya and Andres Salumets and Masoud Zamani Esteki}
}
@article{FIJACKO2024100584,
title = {Using generative artificial intelligence in bibliometric analysis: 10 years of research trends from the European Resuscitation Congresses},
journal = {Resuscitation Plus},
volume = {18},
pages = {100584},
year = {2024},
issn = {2666-5204},
doi = {https://doi.org/10.1016/j.resplu.2024.100584},
url = {https://www.sciencedirect.com/science/article/pii/S2666520424000353},
author = {Nino Fijačko and Ruth Masterson Creber and Benjamin S. Abella and Primož Kocbek and Špela Metličar and Robert Greif and Gregor Štiglic},
keywords = {Emergency medicine, European Resuscitation Council, Congress, Bibliometrics analysis, Generative artificial intelligence},
abstract = {Aims
The aim of this study is to use generative artificial intelligence to perform bibliometric analysis on abstracts published at European Resuscitation Council (ERC) annual scientific congress and define trends in ERC guidelines topics over the last decade.
Methods
In this bibliometric analysis, the WebHarvy software (SysNucleus, India) was used to download data from the Resuscitation journal's website through the technique of web scraping. Next, the Chat Generative Pre-trained Transformer 4 (ChatGPT-4) application programming interface (Open AI, USA) was used to implement the multinomial classification of abstract titles following the ERC 2021 guidelines topics.
Results
From 2012 to 2022 a total of 2491 abstracts have been published at ERC congresses. Published abstracts ranged from 88 (in 2020) to 368 (in 2015). On average, the most common ERC guidelines topics were Adult basic life support (50.1%), followed by Adult advanced life support (41.5%), while Newborn resuscitation and support of transition of infants at birth (2.1%) was the least common topic. The findings also highlight that the Basic Life Support and Adult Advanced Life Support ERC guidelines topics have the strongest co-occurrence to all ERC guidelines topics, where the Newborn resuscitation and support of transition of infants at birth (2.1%; 52/2491) ERC guidelines topic has the weakest co-occurrence.
Conclusion
This study demonstrates the capabilities of generative artificial intelligence in the bibliometric analysis of abstract titles using the example of resuscitation medicine research over the last decade at ERC conferences using large language models.}
}
@incollection{BEHESHTI2025333,
title = {Chapter 13 - Exploring the convergence of Internet of things and big data technologies in the age of generative artificial intelligence},
editor = {Mohamed Adel Serhani and Yang Xu and Zakaria Maamar},
booktitle = {Empowering IoT with Big Data Analytics},
publisher = {Academic Press},
pages = {333-354},
year = {2025},
series = {Intelligent Data-Centric Systems},
isbn = {978-0-443-21640-4},
doi = {https://doi.org/10.1016/B978-0-443-21640-4.00004-1},
url = {https://www.sciencedirect.com/science/article/pii/B9780443216404000041},
author = {Amin Beheshti and Wathiq Mansoor},
keywords = {Internet of things (IoT), Big data analytics, Generative artificial intelligence (AI), Data curation},
abstract = {The Internet of things (IoT) has transformed the way we interact with the physical world, generating an unprecedented volume of data. In modern enterprises, the convergence of IoT, big data, and generative artificial intelligence (GAI) is reshaping the landscape of digital solutions. This chapter explores this convergence, shedding light on emerging solutions, software architectures, and challenges and opportunities in the age of GAI. We explore the complexities of effectively using IoT-generated data, emphasizing the challenges of gathering, organizing, curating, and processing these data for meaningful insights. We highlight the importance of linking analytical, cognitive, and GAI to enable the development of self-evolving systems capable of learning from extensive data streams and making instant data-driven decisions and predictions. This synergy between IoT, big data, and AI can transform various industries by enhancing automation, augmentation, and improvement of their processes.}
}
@article{AZIZOGLU2025162359,
title = {Generative Artificial Intelligence Accuracy in Interpreting Forest Plots in Pediatric Surgery Meta-analyses: A Perspective From Pediatric Surgery Meta-analysis Study Group (PESMA)},
journal = {Journal of Pediatric Surgery},
volume = {60},
number = {7},
pages = {162359},
year = {2025},
issn = {0022-3468},
doi = {https://doi.org/10.1016/j.jpedsurg.2025.162359},
url = {https://www.sciencedirect.com/science/article/pii/S0022346825002040},
author = {Mustafa Azizoglu and Maria Escolino and Tahsin Onat Kamci and Sergey Klyuev and Sonia {Perez Bertolez} and Toni Risteski and Ismael Elhalaby and Nitinkumar Borkar and Ciro Esposito and Mehmet Hanifi Okur and Martin Lacher and Annika Mutanen and Sameh Shehata and Fabio Chiarenza and Mark Davenport}
}
@article{BYRNE2023519,
title = {Generative Artificial Intelligence and ChatGPT},
journal = {Journal of PeriAnesthesia Nursing},
volume = {38},
number = {3},
pages = {519-522},
year = {2023},
issn = {1089-9472},
doi = {https://doi.org/10.1016/j.jopan.2023.04.001},
url = {https://www.sciencedirect.com/science/article/pii/S1089947223001405},
author = {Matthew D. Byrne}
}
@article{WONG2024100278,
title = {The sudden disruptive rise of generative artificial intelligence? An evaluation of their impact on higher education and the global workplace},
journal = {Journal of Open Innovation: Technology, Market, and Complexity},
volume = {10},
number = {2},
pages = {100278},
year = {2024},
issn = {2199-8531},
doi = {https://doi.org/10.1016/j.joitmc.2024.100278},
url = {https://www.sciencedirect.com/science/article/pii/S2199853124000726},
author = {Wilson Kia Onn Wong},
keywords = {GAI, Disruptive, GPT, LLMs, “AI-optimists”, “AI-sceptics”},
abstract = {This paper evaluates the rise of “Generative Artificial Intelligence” (GAI) in its myriad forms, with the highest profile being the “Large Language Models” (LLMs). More importantly, it analyses the potentially disruptive impact of this ascendant technology on higher education and the global workplace. The findings of this paper indicate that students pursuing higher education tend to perceive GAI favourably, as it frees them from the toil of rote-learning. However, the view is rather mixed in the case of educators, who are still coming to grips with this seemingly disruptive technology. In the case of the global labour market, GAI has the potential to decimate legions of white-collar jobs once it eliminates inherent issues of biases, security and misinformation. Despite the media’s constant labelling of GAI as a disruptive technology that has suddenly burst onto the technological scene, it is evidenced in this paper that the technology has taken nearly eight decades to reach today’s level of technological advancement. Further, it is far from reaching its full potential, as it is still incorporating advances in pattern recognition, planning and problem solving, and quantum computing technologies. This study also warns of concentrating the power of this game-changing technology in the hands of a few major corporate titans.}
}
@article{PIERCE2024S444,
title = {MSR33 Utilizing Generative Artificial Intelligence in Network Meta-Analysis: Assessing the Effectiveness of GenAI as a Tool in Feasibility Assessments},
journal = {Value in Health},
volume = {27},
number = {12, Supplement },
pages = {S444},
year = {2024},
note = {ISPOR Europe 2024},
issn = {1098-3015},
doi = {https://doi.org/10.1016/j.jval.2024.10.2267},
url = {https://www.sciencedirect.com/science/article/pii/S1098301524051301},
author = {P Pierce and C Kraan and C Bennison and S Petersohn and S Kroep and K Nickel}
}
@article{BRITOZERON2025570,
title = {POS0311 SARCOIDOSIS AS A SYSTEMIC DISEASE: IDENTIFYING PATTERNS OF MULTIORGAN-SPECIFIC INVOLVEMENT AND EPIDEMIOLOGICAL PROFILING THROUGH GENERATIVE ARTIFICIAL INTELLIGENCE-DRIVEN CLUSTERING},
journal = {Annals of the Rheumatic Diseases},
volume = {84},
pages = {570-571},
year = {2025},
note = {EULAR 2025: European Congress of Rheumatology},
issn = {0003-4967},
doi = {https://doi.org/10.1016/j.ard.2025.05.698},
url = {https://www.sciencedirect.com/science/article/pii/S0003496725017315},
author = {P. Brito-Zerón and A. Flores-Chávez and C. Feijoo-Masso and G. Policarpo-Torres and R. {Gómez de la Torre} and B. Escalante and J.M. Lopez-Dupla and C. Soler-i-Ferrer and E. Fonseca-Aizpuru and A. González-García and J.C. Herranz-Pérez and S. {GARCÍA MORILLO} and A. Alguacil and Á. {Robles Marhuenda} and M. Bonet and M.V. Villalba-García and A.J. Chamorro and B. {De Miguel-Campo} and M.G. {CRUZ CAPARROS} and M. {Akasbi Montalvo} and A. Mayer-Fuentes and M. Ramos-Casals},
keywords = {Registries, Artificial Intelligence, Prognostic factors, Epidemiology, Comorbidities},
abstract = {Background:
Sarcoidosis is a heterogeneous granulomatous disease characterized by a wide range of clinical manifestations stemming from multiple organ involvement. While clustering techniques offer a robust method for uncovering these patterns, traditional approaches may fail to fully capture the complexity of multisystem diseases like sarcoidosis. Leveraging generative artificial intelligence (AI) offers a unique opportunity to improve data analysis and interpretation in complex systemic settings, providing novel insights into multifaceted disease patterns and guiding both hypothesis generation and clinical decision-making.
Objectives:
This study aimed to identify distinct clusters of organ involvement in patients with sarcoidosis, assess their corresponding epidemiological characteristics, and highlight the benefits of AI-driven methodologies in handling complex multisystem data—underscoring the feasibility and advantages of advanced AI-based approaches for systemic phenotypes in this heterogeneous disease.
Methods:
We conducted an AI-assisted analysis to identify organ-involvement clusters in a dataset of 2,187 anonymized sarcoidosis patients (Spanish National Registry SarcoGEAS, all fulfilling the 1999 ATS/ERS/WASOG criteria). Organ involvement was retrospectively determined in each patient at the time of diagnosis using the 2014 WASOG organ assessment instrument. Clustering was carried out via the k-means algorithm in Python's scikit-learn library (version 1.0.2). The optimal number of clusters was determined using the elbow method, supported by silhouette scores to evaluate cluster quality. Statistical comparisons (ANOVA, Kruskal-Wallis, and Chi-square tests—using exact tests for low-frequency data) were applied to characterize cluster differences. Significance was set at p < 0.05, ensuring rigorous evaluation of epidemiological and clinical distinctions. The analysis was conducted in a secure computational environment using generative AI (via OpenAI's GPT-4 model) using Python (version 3.9) with essential libraries including pandas (1.4.3) for data manipulation, numpy (1.21.5) for numerical computations, and matplotlib (3.5.1) and seaborn (0.11.2) for visualizations. Data processing and analysis workflows adhered to GDPR standards to ensure patient privacy. All patient data were anonymized prior to analysis, and no identifiable information was accessed at any point. Code modularity and reproducibility were prioritized, with all scripts managed in version control systems (e.g., Git) to enable transparency.
Results:
The cohort comprised 2,187 patients, with a female predominance (61.4%), a mean age at diagnosis of 48.6 years (range: 5-95), and a majority identifying as White (88%). Cluster quality analysis identified 5 as the optimal number of clusters potential; an additional clinically significant cluster (hepatic-splenic) was manually identified and confirmed post hoc through statistical validation. Ultimately, we defined six distinct clusters of systemic involvement: the lymphadenopathic cluster (Cluster 1, characterized by 100% lymphadenopathy), the pulmonary cluster (Cluster 2, characterized by 100% lung involvement and co-occurring 100% lymphadenopathy), the cutaneous cluster (Cluster 3, 100% of cutaneous involvement), the ocular cluster (Cluster 4, 100% ocular involvement), the hepato-splenic cluster (Cluster 5, defined by 100% hepatic and splenic involvement), and the multisystemic cluster (Cluster 6, exhibiting generalized, but not predominant, organ involvement). Each cluster demonstrated statistically significant epidemiological differences (Figure 1). For age, the lymphadenopathic cluster had the highest mean (51.7 years), whereas the cutaneous cluster had the lowest (42.9 years) (p = 0.00056). For sex, the proportion of females ranged from 49.0% in the hepato-splenic cluster to 65.9% in the ocular cluster (p = 0.000017). For ethnicity, the proportion of White patients ranged from 81.4% in the ocular cluster to 94.6% in the lymphadenopathic cluster (p = 0.00135).
Conclusion:
This generative AI-driven clustering study successfully identified six distinct patterns of systemic involvement in sarcoidosis, offering a deeper understanding of the disease's heterogeneity. Each cluster exhibited specific epidemiological profiles: cutaneous cluster was associated with the youngest age at sarcoidosis diagnosis, lymphadenopathic cluster with the oldest age and the highest frequency of White patients, ocular cluster with the highest frequency of women and highest frequency of non-White patients, and the hepato-splenic cluster with the highest rate of men. The significant epidemiological disparities among clusters underscore the disease's variability and offer a framework for refined patient stratification.
REFERENCES:
NIL. 
Acknowledgements:
NIL.
Disclosure of Interests:
None declared. © The Authors 2025. This abstract is an open access article published in Annals of Rheumatic Diseases under the CC BY-NC-ND license (http://creativecommons.org/licenses/by-nc-nd/4.0/). Neither EULAR nor the publisher make any representation as to the accuracy of the content. The authors are solely responsible for the content in their abstract including accuracy of the facts, statements, results, conclusion, citing resources etc.}
}
@article{ROBINSON2025390,
title = {Response Regarding: Generative Artificial Intelligence in Academic Surgery: Ethical Implications and Transformative Potential},
journal = {Journal of Surgical Research},
volume = {310},
pages = {390-391},
year = {2025},
issn = {0022-4804},
doi = {https://doi.org/10.1016/j.jss.2025.03.012},
url = {https://www.sciencedirect.com/science/article/pii/S0022480425001337},
author = {Jamie R. Robinson and Anne Stey and David F. Schneider and Anai N. Kothari and Brenessa Lindeman and Haytham M. Kaafarani and Krista L. Haines}
}
@article{BURNS2024100166,
title = {Practical implementation of generative artificial intelligence systems in healthcare: A United States perspective},
journal = {Future Healthcare Journal},
volume = {11},
number = {3},
pages = {100166},
year = {2024},
issn = {2514-6645},
doi = {https://doi.org/10.1016/j.fhj.2024.100166},
url = {https://www.sciencedirect.com/science/article/pii/S251466452401556X},
author = {Barclay Burns and Bo Nemelka and Anmol Arora}
}
@article{BRITOZERON20252097,
title = {ABS0885 COMPLEMENT CONSUMPTION PATTERNS AS AN EARLY PREDICTOR OF SYSTEMIC SJÖGREN DISEASE: GENERATIVE ARTIFICIAL INTELLIGENCE-ASSISTED ANALYSIS USING STRATIFIED CROSS-VALIDATION GENERALIZABILITY MODELS},
journal = {Annals of the Rheumatic Diseases},
volume = {84},
pages = {2097-2098},
year = {2025},
note = {EULAR 2025: European Congress of Rheumatology},
issn = {0003-4967},
doi = {https://doi.org/10.1016/j.ard.2025.06.1702},
url = {https://www.sciencedirect.com/science/article/pii/S0003496725037550},
author = {P. Brito-Zerón and A. Flores-Chávez and L.T. {Delgado Garcia} and I.F. Horváth and R. Priori and H. Bootsma and B. Armagan and V. Manfrè and S. Praprotnik and G. Hernandez-Molina and R. {Pereira da Costa} and R. Gerli and M. Rischmueller and Y. Suzuki and R. Solans-Laqué and S. Pasoto and E. Skoglund and I. Sanchez-Berna and A. Alunno and V. {Fernandes Moça Trevisani} and V. Valim and S. {Melchor Díaz} and B. {Maure Noia} and E. Fonseca-Aizpuru and H. Nakamura and L.D. Miguel and M. Vázquez and M. {Akasbi Montalvo} and G. Policarpo-Torres and B. {De Miguel-Campo} and A. Szántó and A. Gattamelata and A. Vissink and L. Quartuccio and L. Kiliç and K. Perdan-Pirkmajer and V.C. Romão and E. Bartoloni and S. Downie-Doyle and Y. Fujisawa and M. Ramos-Casals},
keywords = {Validation, Artificial Intelligence},
abstract = {Background:
Complement consumption, characterized by decreased C3 and/or C4 levels, is a hallmark of immune complex-mediated inflammation and vascular involvement in patients with systemic autoimmune diseases. In patients with Sjögren Disease (SjD), hypocomplementemia at diagnosis has been mainly linked to an increased risk of lymphoma. By analysing the relationship between complement consumption profiles and systemic activity in the largest international cohort, we aim to refine early prognostic paradigms and inform tailored clinical surveillance strategies in SjD, thereby addressing a critical gap in precision medicine for this complex autoimmune disease.
Objectives:
The objectives of this study were to identify and classify complement consumption patterns, investigate their association with an early phenotype consisting of systemic activity across ESSDAI domains while adjusting for age and gender, and explore how cross-validation techniques may validate the predictive accuracy and generalizability of developed models.
Methods:
This study analyzed data from the International Sjögren Big Data Registry. Patients were categorized into four distinct groups according to their complement consumption patterns (isolated low C3, isolated low C4, combined low C3 and C4, and normal C3 and C4 levels). We used Chi-square tests to evaluate univariate associations, and Kruskal-Wallis H-test and Mann-Whitney U test to investigate significant differences with respect to systemic activity (mean ESSDAI score and DAS categories). Multivariable logistic regression models were developed to analyze associations between complement patterns and ESSDAI domains, adjusting for age and gender. Odds ratios (ORs) and 95% confidence intervals (CIs) were calculated. A five-fold stratified cross-validation was carried out to rigorously evaluate the models' generalizability, with the Area Under the Curve (AUC) serving as the primary performance metric. Generative Artificial Intelligence (AI) (ChatGPT-4o model) was used within a secure offline environment to automate anonymized data recoding and statistical scripting. Python libraries, including pandas, statsmodels, and scikit-learn, were integral for data processing, model development, and cross-validation.
Results:
Complement values determined at diagnosis were available in 13,710 patients. Stratification according to the 4 complement consumption patterns identified that 79.58% of patients had normal levels of C3 and C4, 7.42% exhibited isolated low C3, 6.90% showed isolated low C4, and 6.09% presented combined low C3 and C4 levels. Combined low C3-C4 levels exhibited the highest mean ESSDAI score (11.41), follwed by isolated low C3, isolated low C4 and normocomplementemia (mean ESSDAI score of 9.26, 7.39, and 5.66, respectively) (Figure 1); Kruskal-Wallis H-test revealed a highly significant difference between the groups (p<0.001), as well as pairwise comparisons using the Mann-Whitney U test (p<0.001). The Chi-square test revealed significant differences in the distribution of DAS categories across the C3-C4 combined groups (χ2=476.41, p<0.001) (Figure 2). However, multivariate logistic regression confirmed significant associations in only three domains. For the pulmonary domain, combined low C3 and C4 levels were associated with the highest odds of activity (OR: 3.12, 95% CI: 2.50–3.91, p < 0.001; AUC: 0.591). In the biological domain, isolated low C3 strongly correlated with activity (OR: 2.45, 95% CI: 1.98–3.03, p < 0.001; AUC: 0.580). For constitutional symptoms, isolated low C3 was associated with the highest activity frequency (18.54%), whereas normal complement levels showed the lowest frequency (11.06%, OR: 0.56, 95% CI: 0.48–0.67, p < 0.001; AUC: 0.563). After adjusting for epidemiological factors, sex and age emerged as influential variables: men had higher odds of constitutional activity (OR 1.24, 95% CI: 1.02–1.52, p = 0.03), while older age had a protective effect, reducing systemic activity by about 1% per year (OR: 0.99, 95% CI: 0.99–1.00, p = 0.0003). The AUC values obtained after running the five-fold stratified cross-validation generalizability models ranged between 0.56 and 0.59, indicating modest ability to discriminate between active and inactive states.
Conclusion:
This study demonstrates that complement consumption patterns are strongly associated with baseline systemic activity in SjD, highlighting their potential as early prognostic markers. While complement patterns provide valuable insights for risk stratification, the current predictive models exhibit modest discriminatory ability (AUC values between 0.5 and 0.6), suggesting that complement patterns are relevant but insufficient alone as predictors to improve clinical applicability. The nuanced influence of epidemiological factors—such as the protective effect of age and the increased susceptibility of men to systemic disease—adds complexity to our understanding of early systemic Sjögren.
REFERENCES:
NIL. 
Acknowledgements:
NIL.
Disclosure of Interests:
None declared. © The Authors 2025. This abstract is an open access article published in Annals of Rheumatic Diseases under the CC BY-NC-ND license (http://creativecommons.org/licenses/by-nc-nd/4.0/). Neither EULAR nor the publisher make any representation as to the accuracy of the content. The authors are solely responsible for the content in their abstract including accuracy of the facts, statements, results, conclusion, citing resources etc.}
}
@article{THELANCET20241,
title = {Rethinking research and generative artificial intelligence},
journal = {The Lancet},
volume = {404},
number = {10447},
pages = {1},
year = {2024},
issn = {0140-6736},
doi = {https://doi.org/10.1016/S0140-6736(24)01394-1},
url = {https://www.sciencedirect.com/science/article/pii/S0140673624013941},
author = { {The Lancet}}
}
@article{MARTIN2024100265,
title = {Navigating the data frontier in science assessment: Advancing data augmentation strategies for machine learning applications with generative artificial intelligence},
journal = {Computers and Education: Artificial Intelligence},
volume = {7},
pages = {100265},
year = {2024},
issn = {2666-920X},
doi = {https://doi.org/10.1016/j.caeai.2024.100265},
url = {https://www.sciencedirect.com/science/article/pii/S2666920X24000687},
author = {Paul P. Martin and Nicole Graulich},
keywords = {Assessment, Large language models (LLMs), Machine learning (ML), Data augmentation, Science education},
abstract = {Machine learning (ML) techniques are commonly seen as an inductive learning procedure, typically involving the identification of patterns in a specific training dataset to make predictions in novel contexts. By doing so, the performance and generalizability of these techniques often rely on the quality and quantity of the available training data. However, gathering a diverse training dataset that captures multiple nuances of students’ reasoning poses challenges in educational settings due to resource constraints. We compared three data augmentation strategies to address this issue: collecting additional student data, utilizing chatbots to paraphrase existing responses, and prompting chatbots to generate synthetic responses. We found that leveraging data augmentation significantly improved ML model performance. In detail, combining authentic and/or paraphrased responses with chatbot responses yielded the best machine-human score agreements across various validation conditions. This data augmentation allowed us to expand our applied scoring rubric by introducing a more detailed categorization that better captured the level of causality in undergraduate chemistry students’ reasoning about reaction mechanisms. Together, these findings highlight effective possibilities for augmenting the size and heterogeneity of the training data to improve ML model performance and generalizability, introduce a more fine-grained categorization, and reduce human effort in data collection. In the future, these benefits may enhance the scalability of formative assessments that adaptively support students’ reasoning in postsecondary chemistry classes.}
}
@article{KHOSRAVI2024101503,
title = {Analyzing Racial Differences in Imaging Joint Replacement Registries Using Generative Artificial Intelligence: Advancing Orthopaedic Data Equity},
journal = {Arthroplasty Today},
volume = {29},
pages = {101503},
year = {2024},
issn = {2352-3441},
doi = {https://doi.org/10.1016/j.artd.2024.101503},
url = {https://www.sciencedirect.com/science/article/pii/S2352344124001882},
author = {Bardia Khosravi and Pouria Rouzrokh and Bradley J. Erickson and Hillary W. Garner and Doris E. Wenger and Michael J. Taunton and Cody C. Wyles},
keywords = {Generative AI, Explainability, Dataset curation, Equity, Bias},
abstract = {Background
Discrepancies in medical data sets can perpetuate bias, especially when training deep learning models, potentially leading to biased outcomes in clinical applications. Understanding these biases is crucial for the development of equitable healthcare technologies. This study employs generative deep learning technology to explore and understand radiographic differences based on race among patients undergoing total hip arthroplasty.
Methods
Utilizing a large institutional registry, we retrospectively analyzed pelvic radiographs from total hip arthroplasty patients, characterized by demographics and image features. Denoising diffusion probabilistic models generated radiographs conditioned on demographic and imaging characteristics. Fréchet Inception Distance assessed the generated image quality, showing the diversity and realism of the generated images. Sixty transition videos were generated that showed transforming White pelvises to their closest African American counterparts and vice versa while controlling for patients’ sex, age, and body mass index. Two expert surgeons and 2 radiologists carefully studied these videos to understand the systematic differences that are present in the 2 races’ radiographs.
Results
Our data set included 480,407 pelvic radiographs, with a predominance of White patients over African Americans. The generative denoising diffusion probabilistic model created high-quality images and reached an Fréchet Inception Distance of 6.8. Experts identified 6 characteristics differentiating races, including interacetabular distance, osteoarthritis degree, obturator foramina shape, femoral neck-shaft angle, pelvic ring shape, and femoral cortical thickness.
Conclusions
This study demonstrates the potential of generative models for understanding disparities in medical imaging data sets. By visualizing race-based differences, this method aids in identifying bias in downstream tasks, fostering the development of fairer healthcare practices.}
}
@article{DAUNGSUPAWONG2024105498,
title = {Correspondence: Generative artificial intelligence in healthcare},
journal = {International Journal of Medical Informatics},
volume = {189},
pages = {105498},
year = {2024},
issn = {1386-5056},
doi = {https://doi.org/10.1016/j.ijmedinf.2024.105498},
url = {https://www.sciencedirect.com/science/article/pii/S1386505624001618},
author = {Hineptch Daungsupawong and Viroj Wiwanitkit},
keywords = {Generative, Artificial intelligence, Healthcare}
}
@article{GLYNN2024596,
title = {Suspected undeclared use of generative artificial intelligence},
journal = {Intelligent Pharmacy},
volume = {2},
number = {5},
pages = {596-597},
year = {2024},
issn = {2949-866X},
doi = {https://doi.org/10.1016/j.ipha.2024.03.003},
url = {https://www.sciencedirect.com/science/article/pii/S2949866X24000492},
author = {Alex Glynn},
keywords = {Generative artificial intelligence, Transparency, Accountability},
abstract = {In a recent article in Intelligent Pharmacy, a portion of the text appears to have been generated by a generative artificial intelligence (AI) system. The usage of AI is not documented in the article. If AI was used, therefore, the article is in violation of the journal's policy on generative AI use and declaration.}
}
@article{PILLAI2023100213,
title = {Accuracy of generative artificial intelligence models in differential diagnoses of familial Mediterranean fever and deficiency of Interleukin-1 receptor antagonist},
journal = {Journal of Translational Autoimmunity},
volume = {7},
pages = {100213},
year = {2023},
issn = {2589-9090},
doi = {https://doi.org/10.1016/j.jtauto.2023.100213},
url = {https://www.sciencedirect.com/science/article/pii/S2589909023000266},
author = {Joshua Pillai and Kathryn Pillai},
keywords = {DIRA, Deficiency of Interleukin-1 receptor antagonist, Familial Mediterranean fever, FMF, Artificial intelligence},
abstract = {With the increasing development of artificial intelligence, large language models (LLMs) have been utilized to solve problems in natural language processing tasks. More recently, LLMs have shown unique potential in numerous applications within medicine but have been particularly investigated for their ability in clinical reasoning. Although the diagnostic accuracy of LLMs in forming differential diagnoses has been reviewed in general internal medicine applications, much is unknown in autoinflammatory disorders. From the nature of autoinflammatory diseases, forming a differential diagnosis is challenging due to the overlapping symptoms between disorders and even more difficult without genetic screening. In this work, the diagnostic accuracy of the Generative Pre-Trained Transformer Model-4 (GPT-4), GPT-3.5, and Large Language Model Meta AI (LLaMa) were evaluated in clinical vignettes of Deficiency of Interleukin-1 Receptor Antagonist (DIRA) and Familial Mediterranean Fever (FMF). We then compared these models to a control group including one internal medicine physician. It was found that GPT-4 did not significantly differ in correctly identifying DIRA and FMF patients compared to the internist. However, the physician maintained a significantly higher accuracy than GPT-3.5 and LLaMa 2 for either disease. Overall, we explore and discuss the unique potential of LLMs in diagnostics for autoimmune diseases.}
}
@article{HYUNBAEK2023102030,
title = {Is ChatGPT scary good? How user motivations affect creepiness and trust in generative artificial intelligence},
journal = {Telematics and Informatics},
volume = {83},
pages = {102030},
year = {2023},
issn = {0736-5853},
doi = {https://doi.org/10.1016/j.tele.2023.102030},
url = {https://www.sciencedirect.com/science/article/pii/S0736585323000941},
author = {Tae {Hyun Baek} and Minseong Kim},
keywords = {ChatGPT, Generative artificial intelligence (AI), Uses and gratifications theory, Creepiness, Trust, Continuance intention},
abstract = {Few studies have examined user motivations to use generative artificial intelligence (AI). This research aims to address this gap by examining how user motivations for ChatGPT usage affect perceived creepiness, trust, and the intention to continue using AI chatbot technology. The findings of an online survey (N = 421) reveal a negative relationship between personalization and creepiness, while task efficiency and social interaction are positively associated with creepiness. Increased levels of creepiness, in turn, result in decreased continuance intention. Furthermore, task efficiency and personalization have a positive impact on trust, leading to increased continuance intention. The results contribute to the field of human–computer interaction by investigating the motivations for utilizing generative AI chatbots and advancing our comprehension of AI creepiness, trust, and continuance intention. The practical ramifications of this research can inform the design of user interfaces and the development of features for generative AI chatbots.}
}
@article{BRAGAZZI2023,
title = {The Impact of Generative Conversational Artificial Intelligence on the Lesbian, Gay, Bisexual, Transgender, and Queer Community: Scoping Review},
journal = {Journal of Medical Internet Research},
volume = {25},
year = {2023},
issn = {1438-8871},
doi = {https://doi.org/10.2196/52091},
url = {https://www.sciencedirect.com/science/article/pii/S1438887123009330},
author = {Nicola Luigi Bragazzi and Andrea Crapanzano and Manlio Converti and Riccardo Zerbetto and Rola Khamisy-Farah},
keywords = {generative conversational artificial intelligence, chatbot, lesbian, gay, bisexual, transgender, and queer community, LGBTQ, scoping review, mobile phone},
abstract = {Background
Despite recent significant strides toward acceptance, inclusion, and equality, members of the lesbian, gay, bisexual, transgender, and queer (LGBTQ) community still face alarming mental health disparities, being almost 3 times more likely to experience depression, anxiety, and suicidal thoughts than their heterosexual counterparts. These unique psychological challenges are due to discrimination, stigmatization, and identity-related struggles and can potentially benefit from generative conversational artificial intelligence (AI). As the latest advancement in AI, conversational agents and chatbots can imitate human conversation and support mental health, fostering diversity and inclusivity, combating stigma, and countering discrimination. In contrast, if not properly designed, they can perpetuate exclusion and inequities.
Objective
This study aims to examine the impact of generative conversational AI on the LGBTQ community.
Methods
This study was designed as a scoping review. Four electronic scholarly databases (Scopus, Embase, Web of Science, and MEDLINE via PubMed) and gray literature (Google Scholar) were consulted from inception without any language restrictions. Original studies focusing on the LGBTQ community or counselors working with this community exposed to chatbots and AI-enhanced internet-based platforms and exploring the feasibility, acceptance, or effectiveness of AI-enhanced tools were deemed eligible. The findings were reported in accordance with the PRISMA-ScR (Preferred Reporting Items for Systematic Reviews and Meta-Analyses extension for Scoping Reviews).
Results
Seven applications (HIVST-Chatbot, TelePrEP Navigator, Amanda Selfie, Crisis Contact Simulator, REALbot, Tough Talks, and Queer AI) were included and reviewed. The chatbots and internet-based assistants identified served various purposes: (1) to identify LGBTQ individuals at risk of suicide or contracting HIV or other sexually transmitted infections, (2) to provide resources to LGBTQ youth from underserved areas, (3) facilitate HIV status disclosure to sex partners, and (4) develop training role-play personas encompassing the diverse experiences and intersecting identities of LGBTQ youth to educate counselors. The use of generative conversational AI for the LGBTQ community is still in its early stages. Initial studies have found that deploying chatbots is feasible and well received, with high ratings for usability and user satisfaction. However, there is room for improvement in terms of the content provided and making conversations more engaging and interactive. Many of these studies used small sample sizes and short-term interventions measuring limited outcomes.
Conclusions
Generative conversational AI holds promise, but further development and formal evaluation are needed, including studies with larger samples, longer interventions, and randomized trials to compare different content, delivery methods, and dissemination platforms. In addition, a focus on engagement with behavioral objectives is essential to advance this field. The findings have broad practical implications, highlighting that AI’s impact spans various aspects of people’s lives. Assessing AI’s impact on diverse communities and adopting diversity-aware and intersectional approaches can help shape AI’s positive impact on society as a whole.}
}
@article{PATEL2024105791,
title = {Generative artificial intelligence versus clinicians: Who diagnoses multiple sclerosis faster and with greater accuracy?},
journal = {Multiple Sclerosis and Related Disorders},
volume = {90},
pages = {105791},
year = {2024},
issn = {2211-0348},
doi = {https://doi.org/10.1016/j.msard.2024.105791},
url = {https://www.sciencedirect.com/science/article/pii/S2211034824003687},
author = {Mahi A. Patel and Francisco Villalobos and Kevin Shan and Lauren M. Tardo and Lindsay A. Horton and Peter V. Sguigna and Kyle M. Blackburn and Shanan B. Munoz and Tatum M. Moog and Alexander D. Smith and Katy W. Burgess and Morgan McCreary and Darin T. Okuda},
keywords = {Multiple sclerosis, Artificial intelligence, ChatGPT, Diagnosis, Generative AI},
abstract = {Background
Those receiving the diagnosis of multiple sclerosis (MS) over the next ten years will predominantly be part of Generation Z (Gen Z). Recent observations within our clinic suggest that younger people with MS utilize online generative artificial intelligence (AI) platforms for personalized medical advice prior to their first visit with a specialist in neuroimmunology. The use of such platforms is anticipated to increase given the technology driven nature, desire for instant communication, and cost-conscious nature of Gen Z. Our objective was to determine if ChatGPT (Generative Pre-trained Transformer) could diagnose MS in individuals earlier than their clinical timeline, and to assess if the accuracy differed based on age, sex, and race/ethnicity.
Methods
People with MS between 18 and 59 years of age were studied. The clinical timeline for people diagnosed with MS was retrospectively identified and simulated using ChatGPT-3.5 (GPT-3.5). Chats were conducted using both actual and derivatives of their age, sex, and race/ethnicity to test diagnostic accuracy. A Kaplan-Meier survival curve was estimated for time to diagnosis, clustered by subject. The p-value testing for differences in time to diagnosis was accomplished using a general Wilcoxon test. Logistic regression (subject-specific intercept) was used to capture intra-subject correlation to test the accuracy prior to and after the inclusion of MRI data.
Results
The study cohort included 100 unique people with MS. Of those, 50 were members of Gen Z (38 female; 22 White; mean age at first symptom was 20.6 years (y) (standard deviation (SD)=2.2y)), and 50 were non-Gen Z (34 female; 27 White; mean age at first symptom was 37.0y (SD=10.4y)). In addition, a total of 529 people that represented digital simulations of the original cohort of 100 people (333 female; 166 White; 136 Black/African American; 107 Asian; 120 Hispanic, mean age at first symptom was 31.6y (SD=12.4y)) were generated allowing for 629 scripted conversations to be analyzed. The estimated median time to diagnosis in clinic was significantly longer at 0.35y (95% CI=[0.28, 0.48]) versus that by ChatGPT at 0.08y (95% CI=[0.04, 0.24]) (p<0.0001). There was no difference in the diagnostic accuracy between ages and by race/ethnicity prior to the inclusion of MRI data. However, prior to including the MRI data, males had a 47% less likely chance of a correct diagnosis relative to females (p=0.05). Post-MRI data inclusion within GPT-3.5, the odds of an accurate diagnosis was 4.0-fold greater for Gen Z participants, relative to non-Gen Z participants (p=0.01) with the diagnostic accuracy being 68% less in males relative to females (p=0.009), and 75% less for White subjects, relative to non-White subjects (p=0.0004).
Conclusion
Although generative AI platforms enable rapid information access and are not principally designed for use in healthcare, an increase in use by Gen Z is anticipated. However, the obtained responses may not be generalizable to all users and bias may exist in select groups.}
}
@article{WINNIFRITH2024102794,
title = {Generative artificial intelligence for de novo protein design},
journal = {Current Opinion in Structural Biology},
volume = {86},
pages = {102794},
year = {2024},
issn = {0959-440X},
doi = {https://doi.org/10.1016/j.sbi.2024.102794},
url = {https://www.sciencedirect.com/science/article/pii/S0959440X24000216},
author = {Adam Winnifrith and Carlos Outeiral and Brian L. Hie},
abstract = {Engineering new molecules with desirable functions and properties has the potential to extend our ability to engineer proteins beyond what nature has so far evolved. Advances in the so-called ‘de novo’ design problem have recently been brought forward by developments in artificial intelligence. Generative architectures, such as language models and diffusion processes, seem adept at generating novel, yet realistic proteins that display desirable properties and perform specified functions. State-of-the-art design protocols now achieve experimental success rates nearing 20%, thus widening the access to de novo designed proteins. Despite extensive progress, there are clear field-wide challenges, for example, in determining the best in silico metrics to prioritise designs for experimental testing, and in designing proteins that can undergo large conformational changes or be regulated by post-translational modifications. With an increase in the number of models being developed, this review provides a framework to understand how these tools fit into the overall process of de novo protein design. Throughout, we highlight the power of incorporating biochemical knowledge to improve performance and interpretability.}
}
@article{CHAUHAN20242234,
title = {The Impact of Generative Artificial Intelligence on Research Integrity in Scholarly Publishing},
journal = {The American Journal of Pathology},
volume = {194},
number = {12},
pages = {2234-2238},
year = {2024},
issn = {0002-9440},
doi = {https://doi.org/10.1016/j.ajpath.2024.10.001},
url = {https://www.sciencedirect.com/science/article/pii/S0002944024003651},
author = {Chhavi Chauhan and George Currie}
}
@article{HE20241210,
title = {Generative Artificial Intelligence: A New Frontier of Scientific Misconduct?},
journal = {International Journal of Radiation Oncology*Biology*Physics},
volume = {120},
number = {5},
pages = {1210-1213},
year = {2024},
issn = {0360-3016},
doi = {https://doi.org/10.1016/j.ijrobp.2024.03.026},
url = {https://www.sciencedirect.com/science/article/pii/S0360301624004413},
author = {Ling He and Hannah Hausman and Frank Pajonk}
}
@article{KSHETRI2024102760,
title = {The academic industry’s response to generative artificial intelligence: An institutional analysis of large language models},
journal = {Telecommunications Policy},
volume = {48},
number = {5},
pages = {102760},
year = {2024},
issn = {0308-5961},
doi = {https://doi.org/10.1016/j.telpol.2024.102760},
url = {https://www.sciencedirect.com/science/article/pii/S0308596124000570},
author = {Nir Kshetri},
keywords = {Academic industry, ChatGPT, Generative artificial intelligence, Institutional theory, Large language models, Theorization},
abstract = {This paper examines academic institutions' heterogeneous initial responses to generative AI (GAI) tools like ChatGPT and factors influencing increased acceptance over time. GAI's disruptive nature coupled with uncertainty about impacts poses adoption challenges. However, external pressures from stakeholders seeking GAI integration contribute to changing attitudes. Actions of institutional change agents also drive growing acceptance by increasing awareness of GAI advantages. They challenge prevailing logics emphasizing assessments, proposing new values around employability and job performance. Additionally, academic institutions reevaluating GAI's value creation potential through applications and evolving business models contributes to favorable responses. The paper proposes an institutional theory framework explaining dynamics underpinning academic institutions' assimilation of GAI. It highlights how various mechanisms like external pressures, institutional entrepreneurs' theorization efforts justifying technology use, and internal sensemaking shape institutional norms and values, enabling academic systems' adaptation. The study informs policy and practice while directing future research toward validating propositions empirically and examining contextual dimensions including industry characteristics affecting GAI adoption.}
}
@article{YANG20241184,
title = {Chat Generative Pretrained Transformer (ChatGPT) and Bard: Artificial Intelligence Does not yet Provide Clinically Supported Answers for Hip and Knee Osteoarthritis},
journal = {The Journal of Arthroplasty},
volume = {39},
number = {5},
pages = {1184-1190},
year = {2024},
issn = {0883-5403},
doi = {https://doi.org/10.1016/j.arth.2024.01.029},
url = {https://www.sciencedirect.com/science/article/pii/S0883540324000275},
author = {JaeWon Yang and Kyle S. Ardavanis and Katherine E. Slack and Navin D. Fernando and Craig J. {Della Valle} and Nicholas M. Hernandez},
keywords = {ChatGPT, bard, machine learning, artificial intelligence, large language models},
abstract = {Background
Advancements in artificial intelligence (AI) have led to the creation of large language models (LLMs), such as Chat Generative Pretrained Transformer (ChatGPT) and Bard, that analyze online resources to synthesize responses to user queries. Despite their popularity, the accuracy of LLM responses to medical questions remains unknown. This study aimed to compare the responses of ChatGPT and Bard regarding treatments for hip and knee osteoarthritis with the American Academy of Orthopaedic Surgeons (AAOS) Evidence-Based Clinical Practice Guidelines (CPGs) recommendations.
Methods
Both ChatGPT (Open AI) and Bard (Google) were queried regarding 20 treatments (10 for hip and 10 for knee osteoarthritis) from the AAOS CPGs. Responses were classified by 2 reviewers as being in “Concordance,” “Discordance,” or “No Concordance” with AAOS CPGs. A Cohen’s Kappa coefficient was used to assess inter-rater reliability, and Chi-squared analyses were used to compare responses between LLMs.
Results
Overall, ChatGPT and Bard provided responses that were concordant with the AAOS CPGs for 16 (80%) and 12 (60%) treatments, respectively. Notably, ChatGPT and Bard encouraged the use of non-recommended treatments in 30% and 60% of queries, respectively. There were no differences in performance when evaluating by joint or by recommended versus non-recommended treatments. Studies were referenced in 6 (30%) of the Bard responses and none (0%) of the ChatGPT responses. Of the 6 Bard responses, studies could only be identified for 1 (16.7%). Of the remaining, 2 (33.3%) responses cited studies in journals that did not exist, 2 (33.3%) cited studies that could not be found with the information given, and 1 (16.7%) provided links to unrelated studies.
Conclusions
Both ChatGPT and Bard do not consistently provide responses that align with the AAOS CPGs. Consequently, physicians and patients should temper expectations on the guidance AI platforms can currently provide.}
}
@article{HOSSEINI2025100520,
title = {A social-environmental impact perspective of generative artificial intelligence},
journal = {Environmental Science and Ecotechnology},
volume = {23},
pages = {100520},
year = {2025},
issn = {2666-4984},
doi = {https://doi.org/10.1016/j.ese.2024.100520},
url = {https://www.sciencedirect.com/science/article/pii/S2666498424001340},
author = {Mohammad Hosseini and Peng Gao and Carolina Vivas-Valencia}
}
@article{WAELALKHATIB2023102403,
title = {Drivers of generative artificial intelligence to fostering exploitative and exploratory innovation: A TOE framework},
journal = {Technology in Society},
volume = {75},
pages = {102403},
year = {2023},
issn = {0160-791X},
doi = {https://doi.org/10.1016/j.techsoc.2023.102403},
url = {https://www.sciencedirect.com/science/article/pii/S0160791X23002087},
author = {Ayman {wael AL-khatib}},
keywords = {Generative artificial intelligence, TOE framework, Exploratory innovation, Exploitative innovation},
abstract = {This research work aims to investigate the antecedents of generative artificial intelligence (GEN-AI) adoption, and exploratory and exploitative innovation. A conceptual model based on the technology-organization-environment (TOE) framework is proposed and tested empirically using online survey-based data collected from 260 managers and administrative employees located in the Jordanian retailing industry. To achieve the objectives of this work a covariance-based- structural equation modelling (CB-SEM) was employed. The results indicate that relative advantage, top management support, organizational readiness, and customer pressures positively influence GEN-AI adoption. The empirical results demonstrated that the influence of compatibility and competitive pressures on GEN-AI adoption are insignificant. It was found that complexity negatively influence of GEN-AI adoption, also the findings confirm the positive impact of GEN-AI on both exploratory and exploitative innovation. The findings of the existing research would be valuable for GEN-AI technology providers, managers and top management in the retail firms sector in terms of building effective procedures to promote the successful adoption of GEN-AI technologies and innovation.}
}
@incollection{LEEFRANCISS2025237,
title = {Chapter 13 - Generative artificial intelligence in genetics: A comprehensive review},
editor = {Khalid Raza},
booktitle = {Deep Learning in Genetics and Genomics},
publisher = {Academic Press},
pages = {237-247},
year = {2025},
isbn = {978-0-443-27523-4},
doi = {https://doi.org/10.1016/B978-0-443-27523-4.00005-6},
url = {https://www.sciencedirect.com/science/article/pii/B9780443275234000056},
author = {Nicholas {Lee Franciss}},
keywords = {Generative artificial intelligence, Generative pretrained transformers, Large language models, Model architecture, Transformers},
abstract = {Generative artificial intelligence (GenAI) is revolutionizing genetics by applying the computational capabilities of predictive algorithms to unveil the genome's intricate complexities. From protein prediction to gene discovery and motif detection, GenAI techniques are transforming our understanding of genetic processes that were not previously possible. Here we explore how Markov chains, long-standing predecessors of more modern technologies like large language models (LLMs) and generative pretrained transformers (GPTs), have been complemented by these advanced methods, empowering researchers to extract unprecedented levels of information from DNA sequences, including regulatory networks that govern gene expression. We dive deep into how the individual model architectures enable their capability to implicitly understand and generate biological data. The cultural and intellectual implications of DeepMind's AlphaFold on the prediction of three-dimensional protein structures and, with it, its cultural impact on generative approaches in protein design and is also explored.}
}
@article{QIN2024109996,
title = {Intelligent design and optimization system for shear wall structures based on large language models and generative artificial intelligence},
journal = {Journal of Building Engineering},
volume = {95},
pages = {109996},
year = {2024},
issn = {2352-7102},
doi = {https://doi.org/10.1016/j.jobe.2024.109996},
url = {https://www.sciencedirect.com/science/article/pii/S235271022401564X},
author = {Sizhong Qin and Hong Guan and Wenjie Liao and Yi Gu and Zhe Zheng and Hongjing Xue and Xinzheng Lu},
keywords = {Intelligent design, Structural optimization, Shear wall structure, Large language model, Generative artificial intelligence},
abstract = {Intelligent design technology for shear wall structures has great potential for enhancing design efficiency and addressing the challenges of tedious and repetitive design tasks. Recently, there has been a surge in the development of this technology. However, existing deep learning-based design methods for shear wall structures suffer from poor quality and usability issues. To address these challenges, this study proposes an intelligent design and optimization system for shear wall structures based on large language models (LLMs) and generative artificial intelligence (AI). The system employs an LLM as the core controller, which interacts with engineers to interpret their language descriptions and translate them into executable computer code. Subsequently, the system utilizes the corresponding structural generation and optimization methods to accomplish intelligent design tasks automatically. Furthermore, the system incorporates such critical factors as the empirical rules, mechanical performance, and material consumption into the structural optimization process. A unique three-level, two-stage optimization method is constructed based on topology, pattern, and size to enhance the overall design quality. Being able to complete the entire workflow of architectural drawing processing, structural scheme generation, and analysis model establishment, the proposed system enables automated and efficient design of shear wall structures. Through the analysis and validation of multiple cases, it was demonstrated that this system can significantly speed up the design by approximately 30 times compared to that of traditional methods whilst ensuring the safety and cost-effectiveness of the design schemes. Consequently, this study provides valuable insights for the advancement of automated structural design undertakings.}
}
@article{CHENG2024899,
title = {Principles and challenges of generative artificial intelligence detection},
journal = {British Journal of Anaesthesia},
volume = {133},
number = {4},
pages = {899-901},
year = {2024},
issn = {0007-0912},
doi = {https://doi.org/10.1016/j.bja.2024.06.037},
url = {https://www.sciencedirect.com/science/article/pii/S000709122400415X},
author = {Kunming Cheng and Wanqing Li and Nan Zhang and Xiaojun Liu and Haiyang Wu},
keywords = {academic publishing, artificial intelligence, ChatGPT, detection, generative AI, peer review}
}
@article{XU2024e32364,
title = {Generative artificial intelligence in healthcare from the perspective of digital media: Applications, opportunities and challenges},
journal = {Heliyon},
volume = {10},
number = {12},
pages = {e32364},
year = {2024},
issn = {2405-8440},
doi = {https://doi.org/10.1016/j.heliyon.2024.e32364},
url = {https://www.sciencedirect.com/science/article/pii/S2405844024083956},
author = {Rui Xu and Zhong Wang},
keywords = {ChatGPT, Healthcare, Digital media, Applications, Opportunities, Challenges, Digital health, Generative artificial intelligence, Large language models, Artificial intelligence generated content},
abstract = {Introduction
The emergence and application of generative artificial intelligence/large language models (hereafter GenAI LLMs) have the potential for significant impact on the healthcare industry. However, there is currently a lack of systematic research on GenAI LLMs in healthcare based on reliable data. This article aims to conduct an exploratory study of the application of GenAI LLMs (i.e., ChatGPT) in healthcare from the perspective of digital media (i.e., online news), including the application scenarios, potential opportunities, and challenges.
Methods
This research used thematic qualitative text analysis in five steps: firstly, developing main topical categories based on relevant articles; secondly, encoding the search keywords using these categories; thirdly, conducting searches for news articles via Google ; fourthly, encoding the sub-categories using the elaborate category system; and finally, conducting category-based analysis and presenting the results. Natural language processing techniques, including the TermRaider and AntConc tool, were applied in the aforementioned steps to assist in text qualitative analysis. Additionally, this study built a framework, using for analyzing the above three topics, from the perspective of five different stakeholders, including healthcare demanders and providers.
Results
This study summarizes 26 applications (e.g., provide medical advice, provide diagnosis and triage recommendations, provide mental health support, etc.), 21 opportunities (e.g., make healthcare more accessible, reduce healthcare costs, improve patients care, etc.), and 17 challenges (e.g., generate inaccurate/misleading/wrong answers, raise privacy concerns, lack of transparency, etc.), and analyzes the reasons for the formation of these key items and the links between the three research topics.
Conclusions
The application of GenAI LLMs in healthcare is primarily focused on transforming the way healthcare demanders access medical services (i.e., making it more intelligent, refined, and humane) and optimizing the processes through which healthcare providers offer medical services (i.e., simplifying, ensuring timeliness, and reducing errors). As the application becomes more widespread and deepens, GenAI LLMs is expected to have a revolutionary impact on traditional healthcare service models, but it also inevitably raises ethical and security concerns. Furthermore, GenAI LLMs applied in healthcare is still in the initial stage, which can be accelerated from a specific healthcare field (e.g., mental health) or a specific mechanism (e.g., GenAI LLMs’ economic benefits allocation mechanism applied to healthcare) with empirical or clinical research.}
}
@article{KUMAR2025102078,
title = {Evaluating Generative Artificial Intelligence Query of Pelvic Congestion Syndrome Management},
journal = {Journal of Vascular Surgery: Venous and Lymphatic Disorders},
volume = {13},
number = {2},
pages = {102078},
year = {2025},
issn = {2213-333X},
doi = {https://doi.org/10.1016/j.jvsv.2024.102078},
url = {https://www.sciencedirect.com/science/article/pii/S2213333X24004980},
author = {Arjun Kumar and Besher Tolaymat and Katherine McMackin and Patrick Conroy and Laurel Hastings and Bruce Tjaden and Philip Batista and Joseph Lombardi}
}
@article{NIKOLOPOULOS2024104693,
title = {P.6.4 DEVELOPMENT OF A GENERATIVE ARTIFICIAL INTELLIGENCE ALGORITHM FOR THE REGENERATION OF VIRTUAL VOLUNTEERS IN BIOEQUIVALENCE STUDIES},
journal = {Physica Medica},
volume = {127},
pages = {104693},
year = {2024},
note = {Abstracts of the 2nd Panhellenic Congress of Medical Physics},
issn = {1120-1797},
doi = {https://doi.org/10.1016/j.ejmp.2024.104693},
url = {https://www.sciencedirect.com/science/article/pii/S1120179724012912},
author = {A. Nikolopoulos and V. Karalis}
}
@article{TRAN2024104079,
title = {Visual narratives in nursing education: A generative artificial intelligence approach},
journal = {Nurse Education in Practice},
volume = {79},
pages = {104079},
year = {2024},
issn = {1471-5953},
doi = {https://doi.org/10.1016/j.nepr.2024.104079},
url = {https://www.sciencedirect.com/science/article/pii/S1471595324002087},
author = {Linh Duc Tran and Neo Tung and Eugene Tordecilla Macalinga and Arthur Tang and Brigitte Woo and Wilson Tam},
keywords = {Nursing education, Visual narrative, Generative artificial intelligence, DALL-E},
abstract = {Aim
The aim of this paper is to investigate the incorporation of visual narratives, such as comics and graphics, into nursing education using Generative Artificial Intelligence (GAI) models like DALL-E.
Background
Visual narratives serve as a powerful method for communicating intricate concepts in nursing education. Despite their advantages, challenges in creating effective educational comics persist due to the need for expertise in graphic design and the associated time and resource constraints.
Design
This study examines existing literature that highlights the efficacy of visual narratives in education and demonstrates the potential of GAI models, specifically DALL-E, in creating visual narratives for nursing education.
Methods
We analyze the potential of GAI models, specifically DALL-E, to create visual narratives for educational purposes. This was demonstrated through illustrative examples addressing sensitive topics, illustrating research methodology and designing recruitment posters for clinical trials. Additionally, we discussed the necessity of reviewing and editing the text generated by DALL-E to ensure its accuracy and relevance in educational contexts. The method also considered legal concerns related to copyright and ownership of the generated content, highlighting the evolving legal landscape in this domain.
Results
The study found that GAI, specifically DALL-E, has significant potential to bridge the gap in creating visual narratives for nursing education. While offering cost-effectiveness and accessibility, GAI tools require careful consideration of challenges such as text-related errors, misinterpretation of user prompts and legal concerns.
Conclusions
GAI models like DALL-E offer promising solutions for enhancing visual storytelling in nursing education. However, their effective integration requires a collaborative approach, where educators engage with these tools as co-pilots, leveraging their capabilities while mitigating potential drawbacks. By doing so, educators can harness the full potential of GAI to enrich the educational experience for learners through compelling visual narratives.}
}
@article{SINGH2024102776,
title = {Enhancing Patient Education on the Heart-Healthy Diet With Generative Artificial Intelligence Models},
journal = {Current Developments in Nutrition},
volume = {8},
pages = {102776},
year = {2024},
note = {Abstracts from NUTRITION 2024},
issn = {2475-2991},
doi = {https://doi.org/10.1016/j.cdnut.2024.102776},
url = {https://www.sciencedirect.com/science/article/pii/S2475299124007108},
author = {Som P Singh and Dharti Patel and Farah S Qureshi and Rohma Zaidi and Fawad Qureshi}
}
@article{OCHIENG2024102710,
title = {Potential application of generative artificial intelligence and machine learning algorithm in oil and gas sector: Benefits and future prospects},
journal = {Technology in Society},
volume = {79},
pages = {102710},
year = {2024},
issn = {0160-791X},
doi = {https://doi.org/10.1016/j.techsoc.2024.102710},
url = {https://www.sciencedirect.com/science/article/pii/S0160791X24002586},
author = {Edward G. Ochieng and Diana Ominde and Tarila Zuofa},
keywords = {Generative artificial intelligence, Machine learning algorithm, Value chain operations, Oil and gas, Productivity performance, Risk management},
abstract = {With the rapid advancement of technology and societies, the global energy sector now acknowledges that by integrating contemporary digital technologies into their operations and capabilities, can improve their competitive advantage and innovation performance and processes. Moreover, energy operators are also facing a significant undertaking: how to best use and secure large amounts of data that promote sustainable productivity performance and minimise potential threats in the oil and gas value chain and project operations. In view of the foregoing, various facets like Generative Artificial Intelligence (GAI) and Machine Learning Algorithms (MLA) are increasingly gaining popularity within oil and gas sector operations. Thus, we explored how GAI and ML algorithms can enhance oil and gas value chain productivity performance. The Principal Component Analysis (PCA) was employed to identify significant GAI and MLA variables influencing performance in the oil and gas value chain, while Structural Equation Modelling (SEM) was used to test regression equations related to their application. The study found that risk portfolios and profiles can be appraised throughout the value chain by effectively utilising GAI and ML algorithms in upstream, midstream and downstream undertakings. While these findings are noteworthy and have significant implications for current practice, the paper advocates that an array of digital technologies beyond GAI and ML can still be examined during future studies to demonstrate a holistic perspective on how digital transformation can be achieved across the energy sector value and project operations.}
}
@article{BARKER2024A43,
title = {Generative Artificial Intelligence as a Tool for Teaching Communication in Nutrition and Dietetics Education – an Novel Education Innovation},
journal = {Journal of the Academy of Nutrition and Dietetics},
volume = {124},
number = {10, Supplement },
pages = {A43},
year = {2024},
note = {2024 Food & Nutrition Conference & Expo},
issn = {2212-2672},
doi = {https://doi.org/10.1016/j.jand.2024.06.093},
url = {https://www.sciencedirect.com/science/article/pii/S2212267224003873},
author = {L. Barker and J. Moore and H. Cook}
}
@article{RATTEN2023100857,
title = {Generative artificial intelligence (ChatGPT): Implications for management educators},
journal = {The International Journal of Management Education},
volume = {21},
number = {3},
pages = {100857},
year = {2023},
issn = {1472-8117},
doi = {https://doi.org/10.1016/j.ijme.2023.100857},
url = {https://www.sciencedirect.com/science/article/pii/S1472811723000952},
author = {Vanessa Ratten and Paul Jones},
keywords = {Academic research, Teaching, Learning, Digital transformation, Management education, Artificial intelligence, ChatGPT},
abstract = {ChatGPT has been one of the most talked about computer programs amongst management educators in recent weeks due to its transformative ability to change how assessments are undertaken and graded. Unlike other educational technologies that can be tracked when used, ChatGPT has superior abilities that make it virtually untraceable when used. This creates a dilemma for management educators wanting to utilise the technology whilst staying relevant but also interested in authentic learning. Thus, it is critical for management educators to quickly implement policies regarding ChatGPT and subsequent new generative artificial intelligence because of its ease of use and affordability. This article is conceptual in nature and discusses ChatGPT as a generative form of artificial intelligence that presents challenges for management educators that need to be addressed through appropriate strategies. Thereby contributing to the literature on how technological innovations can be included in curriculum design and management learning practices. Practical and managerial implications are stated that highlight the critical need to re-examine existing education practices as a way of incorporating new technological innovation that can be utilised in a beneficial way.}
}
@article{NIKOLOPOULOS2024104690,
title = {P.6.1 CREATING VIRTUAL PATIENTS WITH A GENERATIVE ARTIFICIAL INTELLIGENCE ALGORITHM FOR CLINICAL STUDIES},
journal = {Physica Medica},
volume = {127},
pages = {104690},
year = {2024},
note = {Abstracts of the 2nd Panhellenic Congress of Medical Physics},
issn = {1120-1797},
doi = {https://doi.org/10.1016/j.ejmp.2024.104690},
url = {https://www.sciencedirect.com/science/article/pii/S1120179724012882},
author = {A. Nikolopoulos and V. Karalis}
}
@article{KOHNKE2023100156,
title = {Exploring generative artificial intelligence preparedness among university language instructors: A case study},
journal = {Computers and Education: Artificial Intelligence},
volume = {5},
pages = {100156},
year = {2023},
issn = {2666-920X},
doi = {https://doi.org/10.1016/j.caeai.2023.100156},
url = {https://www.sciencedirect.com/science/article/pii/S2666920X23000358},
author = {Lucas Kohnke and Benjamin Luke Moorhouse and Di Zou},
keywords = {Artificial intelligence, AI, Generative AI, University language instructors, Higher education, English},
abstract = {The integration of generative artificial intelligence (AI) in English language teaching presents opportunities and challenges for instructors. This study explores the attitudes of higher education English language instructors towards generative AI tools, their intentions to use them and the institutional support and professional development necessary to teach and learn with them. As the field continues to evolve rapidly, it is essential to comprehend the readiness of front-line language instructors. This qualitative interpretive study seeks to identify the digital competencies and pedagogical knowledge required to implement generative AI in education and provide guidance for the design of professional development programmes that address the challenges and concerns associated with adopting AI. Drawing on semi-structured interviews with twelve instructors at a higher education institution in Hong Kong, the findings reveal the significance of familiarity and confidence with using AI-driven teaching tools, the challenges and concerns language instructors face and the need for tailored support and professional development. The study offers ten practical implications to cultivate language instructors’ digital competencies, pedagogical knowledge and positive attitudes towards integrating AI to enhance their students’ learning experiences.}
}
@article{SONG2024100069,
title = {Developing an immersive game-based learning platform with generative artificial intelligence and virtual reality technologies – “LearningverseVR”},
journal = {Computers & Education: X Reality},
volume = {4},
pages = {100069},
year = {2024},
issn = {2949-6780},
doi = {https://doi.org/10.1016/j.cexr.2024.100069},
url = {https://www.sciencedirect.com/science/article/pii/S2949678024000199},
author = {Yanjie Song and Kaiyi Wu and Jiaoyang Ding},
keywords = {Generative AI, Virtual reality (VR), Game-based learning, Immersion, Interaction},
abstract = {The rapid evolution of generative artificial intelligence (AI) and virtual reality (VR) technologies are revolutionising various fields, including education and gaming industries. However, studies on how to enhance immersive game-based learning with AI and VR technologies remain scant. Given this, the article presents the creation of “LearningverseVR,” an immersive game-based learning platform developed using generative AI and VR technologies, which is based on “Learningverse,” a metaverse platform developed by the lead author and her research team. The “LearningverseVR” platform uses Unity as the client and Python, Flask and MySQL as the backend. Unity's multiplayer service provides multiplayer online functionality, supporting learners to engage in immersive and interactive learning activities. The design framework of the platform consists of two main components: Game-based learning with generative AI and immersion with VR technologies. First, generative AI is used to create NPCs with diverse personalities and life backgrounds, and enable learners to interact with NPCs without scripted dialogues, creating an interactive and immersive game-based learning environment. Secondly, such a learning experience is enhanced by leveraging the Large Language Model (LLM) ecosystem with VR technology. The creation of the “LearningverseVR” platform provides novel perspectives on digital game-based learning.}
}

@article{HUO2024,
title = {Generative Artificial Intelligence in Business Higher Education:},
journal = {Journal of Global Information Management},
volume = {32},
number = {1},
year = {2024},
issn = {1062-7375},
doi = {https://doi.org/10.4018/JGIM.364093},
url = {https://www.sciencedirect.com/science/article/pii/S1062737524000416},
author = {Xuenan Huo and Keng Leng Siau},
keywords = {Generative Artificial Intelligence, Agentic Artificial Intelligence, Artificial General Intelligence, Focus Group Study, Qualitative Research, Business Higher Education},
abstract = {ABSTRACT
This research investigates the opportunities and challenges of integrating generative artificial intelligence (GenAI) into business higher education, drawing insights from an asynchronous focus group research study with doctoral students who serve dual roles as both learners and educators. Key opportunities identified through thematic analysis include knowledge acquisition, intelligent co-ideation, supportive augmentation, and personalized learning. Challenges identified include AI trustworthiness, cognitive dependency, human value, policy and instruction, assessment integrity, and identity management. This study clarifies GenAI’s specific role in business education and provides practical insights for effectively integrating GenAI to enhance learning outcomes and address emerging challenges. An analysis theory on the opportunities and challenges of GenAI on business higher education is developed and described in the paper. The potential impact of Agentic Artificial Intelligence (autonomous AI agents) and Artificial General Intelligence (AGI) on education is also discussed.}
}
@article{COBO2025103251,
title = {Physical foundations for trustworthy medical imaging: A survey for artificial intelligence researchers},
journal = {Artificial Intelligence in Medicine},
volume = {169},
pages = {103251},
year = {2025},
issn = {0933-3657},
doi = {https://doi.org/10.1016/j.artmed.2025.103251},
url = {https://www.sciencedirect.com/science/article/pii/S0933365725001861},
author = {Miriam Cobo and David {Corral Fontecha} and Wilson Silva and Lara {Lloret Iglesias}},
keywords = {Physics, Medical imaging, Artificial intelligence, Physics-informed machine learning, Generative AI},
abstract = {Artificial intelligence in medical imaging has grown rapidly in the past decade, driven by advances in deep learning and widespread access to computing resources. Applications cover diverse imaging modalities, including those based on electromagnetic radiation (e.g., X-rays), subatomic particles (e.g., nuclear imaging), and acoustic waves (ultrasound). Each modality features and limitations are defined by its underlying physics. However, many artificial intelligence practitioners lack a solid understanding of the physical principles involved in medical image acquisition. This gap hinders leveraging the full potential of deep learning, as incorporating physics knowledge into artificial intelligence systems promotes trustworthiness, especially in limited data scenarios. This work reviews the fundamental physical concepts behind medical imaging and examines their influence on recent developments in artificial intelligence, particularly, generative models and reconstruction algorithms. Finally, we describe physics-informed machine learning approaches to improve feature learning in medical imaging.}
}
@article{FELDMAN2023336,
title = {Beyond Clinical Accuracy: Considerations for the Use of Generative Artificial Intelligence Models in Gastrointestinal Care},
journal = {Gastroenterology},
volume = {165},
number = {2},
pages = {336-338},
year = {2023},
issn = {0016-5085},
doi = {https://doi.org/10.1053/j.gastro.2023.06.006},
url = {https://www.sciencedirect.com/science/article/pii/S0016508523008740},
author = {Keith Feldman and Fredy Nehme}
}
@article{LIU2026124387,
title = {How does artificial intelligence adoption shape employee performance? A novel exploration of mimetic artificial intelligence performance through a hybrid approach based on PLS-SEM and ANN},
journal = {Technological Forecasting and Social Change},
volume = {222},
pages = {124387},
year = {2026},
issn = {0040-1625},
doi = {https://doi.org/10.1016/j.techfore.2025.124387},
url = {https://www.sciencedirect.com/science/article/pii/S0040162525004184},
author = {Shengmin Liu and Yu Mei},
keywords = {Artificial intelligence adoption at work, Employee problem-solving efficacy, Employee learning from artificial intelligence, Adaptive performance, Mimetic artificial intelligence performance, ANN},
abstract = {Within the context of Industry 5.0 and digital transformation, the rapid advancement of information technology has rendered artificial intelligence ubiquitous, presenting significant challenges and opportunities for the workforce. This study employs a hybrid Partial Least Squares Structural Equation Modeling (PLS-SEM) and Artificial Neural Network (ANN) approach to investigate employee performance within artificial intelligence-adoption work environments. Utilizing a three-wave experience sampling methodology, we collected 308 valid questionnaires from employees in Chinese internet companies. Our findings demonstrate that artificial intelligence adoption at work positively associated with employees' problem-solving efficacy, which in turn influences adaptive performance. Furthermore, stronger artificial intelligence adoption at work is associated with an increased employees' mimetic artificial intelligence performance through employee learning from artificial intelligence. Task-oriented leadership amplifies the effects of artificial intelligence adoption at work on both problem-solving efficacy and adaptive performance. Conversely, knowledge-oriented leadership strengthens the relationship between artificial intelligence adoption at work and employee learning from artificial intelligence, thereby developping mimetic artificial intelligence performance. This research contributes by introducing and measuring the novel concept of “mimetic artificial intelligence performance,” extending the application of social comparison, learning and influence theories. The study offers valuable theoretical insights and practical implications for understanding and optimizing employee performance in artificial intelligence-driven workplaces.}
}
@article{VASAVADA2025S48,
title = {A NOVEL WEB APPLICATION UTILIZING GENERATIVE ARTIFICIAL INTELLIGENCE TO ENHANCE ENDOSCOPY EDUCATION FOR GASTROENTEROLOGY FELLOWS},
journal = {Gastrointestinal Endoscopy},
volume = {101},
number = {5, Supplement },
pages = {S48},
year = {2025},
note = {ASGE Abstracts - DDW 2025},
issn = {0016-5107},
doi = {https://doi.org/10.1016/j.gie.2025.03.088},
url = {https://www.sciencedirect.com/science/article/pii/S0016510725002573},
author = {Shaleen Vasavada and Theresa H. Nguyen and Scott Larson}
}
@article{MARTIN2025216,
title = {Prevalence of artificial intelligence use and instruction in nursing education: A national study of prelicensure nursing programs in the United States},
journal = {Journal of Nursing Regulation},
volume = {16},
number = {3},
pages = {216-222},
year = {2025},
note = {Technology and the Nursing Needs of Tomorrow},
issn = {2155-8256},
doi = {https://doi.org/10.1016/j.jnr.2025.08.003},
url = {https://www.sciencedirect.com/science/article/pii/S2155825625000924},
author = {Brendan Martin and Michaela Reid},
keywords = {Prelicensure nursing education, Artificial intelligence},
abstract = {Background
There is ample evidence that the integration of artificial intelligence (AI) tools into nursing practice is becoming more commonplace, but there are fewer national resources indicating to what degree prelicensure nursing programs employ these technologies and incorporate related topics into their curriculum.
Purpose
The current survey study sought to determine the prevalence of registered nurse (RN) and licensed practical nurse (LPN) education programs’ use of generative AI technologies, and the extent to which they embed AI and other digital health topics into their instructional content.
Methods
A national survey was conducted of all RN and LPN program administrators nationwide for which we had email contact information (N = 2744).
Results
Prelicensure RN programs (n = 122, 24 %) were more likely to use generative AI technology than LPN programs (n = 27, 12 %, p < 0.001), but more than three-quarters of both types of programs reported they do not use such tools or are not sure. In addition to the low usage of generative AI technology, few programs reported teaching advancements in AI and/or other digital health–related topics to their students (RN n = 87, 17 %; LPN n = 25, 11 %).
Conclusion
Nursing education programs that limit integration of AI into their curriculum risk potentially limiting students’ learning on evidence-based practice and may miss opportunities to promote critical reflection. The results of our study underscore the need to support nursing faculty to ensure prelicensure instructional content prepares nursing students for advancements in clinical practice.}
}
@article{LAZARIDIS2025,
title = {Individualized Medicine in the Era of Artificial Intelligence},
journal = {Mayo Clinic Proceedings},
year = {2025},
issn = {0025-6196},
doi = {https://doi.org/10.1016/j.mayocp.2025.07.028},
url = {https://www.sciencedirect.com/science/article/pii/S0025619625004173},
author = {Konstantinos N. Lazaridis and Eric W. Klee and Timothy B. Curry and Victor E. Ortega and William V. Bobo and Arjun P. Athreya and Rebekah M. Samsonraj},
abstract = {The goal of individualized medicine is to provide a precise approach for the prevention, diagnosis, and treatment of disease, utilizing information about an individual's genomic, environmental, and lifestyle patterns. The rapid advancements in artificial intelligence (AI) have led to the application of sophisticated approaches including machine learning, generative AI, and large language models that could lead to discoveries and practice implementations aimed at improving clinical decision making and health care delivery through diverse applications. Nevertheless, the exact role of AI in supporting individualized medicine continues to evolve. In this position paper, we present our principles of applying AI to bolster the vision of the Mayo Clinic Center for Individualized Medicine. Leveraging the Center for Individualized Medicine’s strategy on innovation and transformation as well as existing state-of-the-art operational architecture and capacity in handling large corpora of data (ie, multiomics, digital, multimodal data), we envision an AI-powered integration of such information toward an enterprise-wide adoption to serve the needs of individualized clinical practice of the future.}
}
@article{SAENKHUM2023101066,
title = {Generative artificial intelligence and second language writing},
journal = {Journal of Second Language Writing},
volume = {62},
pages = {101066},
year = {2023},
issn = {1060-3743},
doi = {https://doi.org/10.1016/j.jslw.2023.101066},
url = {https://www.sciencedirect.com/science/article/pii/S1060374323001042},
author = {Tanita Saenkhum and Soo Hyon Kim}
}
@article{CUAYCONG2024106730,
title = {Abstract 1126 Generative Artificial Intelligence in Molecular Design and Virtual Screening of Novel Caspase-1 Inhibitors},
journal = {Journal of Biological Chemistry},
volume = {300},
number = {3, Supplement },
pages = {106730},
year = {2024},
note = {Discover BMB 2024},
issn = {0021-9258},
doi = {https://doi.org/10.1016/j.jbc.2024.106730},
url = {https://www.sciencedirect.com/science/article/pii/S0021925824012031},
author = {Stephanie Cuaycong and Chidinma Ralph-Mbah and Amele Divo and Yufeng Wei},
keywords = {inflammasome, cell death, caspase-1, edothelial cells}
}
@article{LI2025100023,
title = {A review of data science and artificial intelligence applications in air transportation systems},
journal = {Artificial Intelligence for Transportation},
volume = {2},
pages = {100023},
year = {2025},
issn = {3050-8606},
doi = {https://doi.org/10.1016/j.ait.2025.100023},
url = {https://www.sciencedirect.com/science/article/pii/S3050860625000237},
author = {Lishuai Li},
keywords = {Artificial intelligence, Data science, Air transportation, Air traffic management, Airline operations, Airport management, Aviation safety, Sustainability},
abstract = {The air transportation system is a critical component of global infrastructure, moving passengers and cargo worldwide. Rising traffic volumes and operational complexity have driven the evolution of analytical methods in aviation: from early rule-based automation through mechanism-based models (simulations, digital twins), operations research (optimization, statistics) and data-driven approaches (machine learning, deep learning) to emerging autonomous systems (generative AI, agentic AI). This review examines data science and artificial intelligence (AI) applications that address specific aviation challenges and demonstrate measurable operational improvements. We analyze implementations in airline management, airport operations and air traffic management, identifying performance gains that include reduced delays, improved aircraft utilization, lower maintenance costs, and improved safety metrics. However, AI deployment faces technical barriers including legacy system integration and data standardization, along with regulatory and ethical challenges that include certification processes, data privacy, and liability frameworks for automated decision making. Future research priorities could focus on developing robust AI systems that meet aviation’s stringent safety and reliability standards, advancing AI-enabled sustainability through integrated design and operational optimization, and establishing frameworks for novel air transportation systems, including urban air mobility and autonomous flight operations.}
}
@article{JOWSEY2023971,
title = {Medical education empowered by generative artificial intelligence large language models},
journal = {Trends in Molecular Medicine},
volume = {29},
number = {12},
pages = {971-973},
year = {2023},
issn = {1471-4914},
doi = {https://doi.org/10.1016/j.molmed.2023.08.012},
url = {https://www.sciencedirect.com/science/article/pii/S1471491423002113},
author = {Tanisha Jowsey and Jessica Stokes-Parish and Rachelle Singleton and Michael Todorovic},
keywords = {artificial intelligence, large language model, machine learning, education},
abstract = {Generative artificial intelligence (GAI) large language models (LLMs), like ChatGPT, have become the world’s fastest growing applications. Here, we provide useful strategies for educators in medical and health science (M&HS) to integrate GAI-LLMs into learning and teaching practice, ultimately enhancing students’ digital capability.}
}
@article{SUMMERSCALES2025306,
title = {Physician, replace thyself: Can generative artificial intelligence locate and evaluate ovarian cancer genetic information?},
journal = {Gynecologic Oncology},
volume = {200},
pages = {306},
year = {2025},
note = {2025 Society of Gynecologic Oncology Annual Meeting on Women’s Cancer Virtual Special Issue},
issn = {0090-8258},
doi = {https://doi.org/10.1016/j.ygyno.2025.04.432},
url = {https://www.sciencedirect.com/science/article/pii/S0090825825006432},
author = {Tiffany Summerscales and Grace Pindzola and Mike McGaughey and Jeff Toole and Eirwen Miller and Thomas Krivak and Christopher Morse and Alyssa Wield and Sarah Crafton and John Nakayama}
}
@article{BHATTACHARYA2024100194,
title = {ChatGPT’s scorecard after the performance in a series of tests conducted at the multi-country level: A pattern of responses of generative artificial intelligence or large language models},
journal = {Current Research in Biotechnology},
volume = {7},
pages = {100194},
year = {2024},
issn = {2590-2628},
doi = {https://doi.org/10.1016/j.crbiot.2024.100194},
url = {https://www.sciencedirect.com/science/article/pii/S2590262824000200},
author = {Manojit Bhattacharya and Soumen Pal and Srijan Chatterjee and Abdulrahman Alshammari and Thamer H. Albekairi and Supriya Jagga and Elijah {Ige Ohimain} and Hatem Zayed and Siddappa N. Byrareddy and Sang-Soo Lee and Zhi-Hong Wen and Govindasamy Agoramoorthy and Prosun Bhattacharya and Chiranjib Chakraborty},
keywords = {ChatGPT, Accuracy, Reproducibility, Plagiarism, Answer length},
abstract = {Recently, researchers have shown concern about the ChatGPT-derived answers. Here, we conducted a series of tests using ChatGPT by individual researcher at multi-country level to understand the pattern of its answer accuracy, reproducibility, answer length, plagiarism, and in-depth using two questionnaires (the first set with 15 MCQs and the second 15 KBQ). Among 15 MCQ-generated answers, 13 ± 70 were correct (Median : 82.5; Coefficient variance : 4.85), 3 ± 0.77 were incorrect (Median: 3, Coefficient variance: 25.81), and 1 to 10 were reproducible, and 11 to 15 were not. Among 15 KBQ, the length of each question (in words) is about 294.5 ± 97.60 (mean range varies from 138.7 to 438.09), and the mean similarity index (in words) is about 29.53 ± 11.40 (Coefficient variance: 38.62) for each question. The statistical models were also developed using analyzed parameters of answers. The study shows a pattern of ChatGPT-derive answers with correctness and incorrectness and urges for an error-free, next-generation LLM to avoid users’ misguidance.}
}
@article{OZTURK2025216,
title = {Artificial intelligence as author: Can scientific reviewers recognize GPT-4o-generated manuscripts?},
journal = {The American Journal of Emergency Medicine},
volume = {97},
pages = {216-219},
year = {2025},
issn = {0735-6757},
doi = {https://doi.org/10.1016/j.ajem.2025.07.034},
url = {https://www.sciencedirect.com/science/article/pii/S0735675725004954},
author = {Ahmet Öztürk and Anılcan Tahsin Karahan and Serkan Günay and Abdul Samed Erdal and Seval Komut and Erdal Komut and Yavuz Yiğit},
keywords = {ChatGPT, Artificial intelligence, Journal, Editor, Reviewer},
abstract = {Introduction
Chat Generative Pre-Trained Transformer (ChatGPT) is a natural language processing model. It can be argued that ChatGPT has recently begun to assume the role of a technological assistant capable of supporting academics in the process of scientific writing. ChatGPT may contribute to the spread of incorrect or incomplete information within academic literature, leading to conceptual confusion and potential academic misconduct. The aim of this study is to determine whether a scientific article entirely generated by an AI application such as ChatGPT can be detected by an academic journal editor or peer reviewer.
Methods
This study was conducted between November 1, 2024, and December 1, 2024. GPT-4o, was utilized in this study. ChatGPT was instructed to write a scientific article focused on predicting mortality and return of spontaneous circulation (ROSC) in OHCA cases. The manuscript written by ChatGPT-4o was sent to 14 different reviewers who had previously served as reviewers or editors. The reviewers were asked to evaluate the manuscript as if they were an SCI-E journal editor or peer reviewer. The reviewers were informed that the article had been written by ChatGPT and were asked whether they had identified this during their review.
Results
Among the reviewers, 42.9 % (n = 6) decided to reject the manuscript at the editorial stage, whereas another 42.9 % (n = 6) opted to forward it to a peer reviewer. During the peer review stage, 42.9 % (n = 6) of the reviewers recommended rejection, while 28.6 % (n = 4) suggested major revisions. 78.6 % (n = 11) of the reviewers did not realize that the manuscript had been generated by an artificial intelligence model.
Conclusion
The findings of our study highlight the necessity for journal editors and peer reviewers to be well-informed about ChatGPT and to develop systems capable of identifying whether a manuscript has been written by a human or generated by artificial intelligence.}
}
@article{CHOI20242616,
title = {Leveraging Generative Artificial Intelligence in Diagnosis of Thrombotic Microangiopathies: Focus on Thrombotic Thrombocytopenic Purpura},
journal = {Blood},
volume = {144},
pages = {2616},
year = {2024},
note = {66th ASH Annual Meeting Abstracts},
issn = {0006-4971},
doi = {https://doi.org/10.1182/blood-2024-194769},
url = {https://www.sciencedirect.com/science/article/pii/S0006497124053692},
author = {Eunhee Choi and Jung-Hyun Lee and Robert McDougal and William W Lytton},
abstract = {Introduction Thrombotic microangiopathies (TMA), with etiologies ranging from benign to life-threatening, necessitates rapid and accurate diagnosis, particularly for thrombotic thrombocytopenic purpura (TTP), to initiate timely plasmapheresis preventing severe outcomes. Diagnosing TTP is challenging due to overlapping clinical features with other causes of TMA, such as disseminated intravascular coagulation (DIC), immune thrombocytopenic purpura (ITP), and atypical hemolytic uremic syndrome (aHUS), compounded by that specific diagnostic tests such as biopsies or ADAMTS13 activity assays do not result immediately. This study explored GPT-4's capability in suggesting differential diagnoses for TMA patients and identifying a provisional diagnosis of TTP based on clinical presentation and basic diagnostic workup to determine the need for prompt plasmapheresis, assessing its potential as a diagnostic support tool. Method We utilized open-access case reports from PubMed Central that provided a comprehensive list of cases with diagnosis of TMA. The exclusion criteria included cases with no access, copyright permission issues, preprints, insufficient description, non-case reports, non-English language, and no established diagnosis for TMA. Each case input including only the history and physical examination (H&P) and basic diagnostic workup excluding the confirmatory diagnosis was presented to GPT-4 in three separate trials and was prompted to provide clinical reasoning that both favored or rejected the diagnosis of TTP, create a top three differential diagnoses list selected from a comprehensive list of TMA diagnoses, and determine the necessity of plasmapheresis. Generated results were subsequently compared with the confirmed case diagnosis and management provided within the case report. Result An initial PubMed Central search identified 424 cases; 326 were excluded, resulting in 98 eligible cases. The top three differential diagnoses generated for each case in all three trials exhibited relatively higher F1-scores for ITP, TTP, HUS, and HELLP syndrome, with values of 0.58, 0.59, 0.53, and 0.7, respectively. Other causes of TMA scored below 0.5. Overall performance metrics indicated a specificity of 0.85, sensitivity of 0.80, precision of 0.28, and an F1-score of 0.42. When grouped into TTP versus non-TTP cases, the sensitivity was notably high at 0.98, showing that GPT-4 could adequately rule out TTP, although the specificity was 0.76. When comparing the case diagnosis with the primary diagnosis within the top three differential diagnoses, the overall specificity was 0.96, sensitivity was 0.56, precision was 0.58, and the F1-score was 0.57. The match rate of GPT-4 suggesting plasmapheresis compared to the case report was 76%. In cases confirmed as TTP, GPT-4 demonstrated 100% accuracy in recommending plasmapheresis. For non-TTP cases, GPT-4 showed a 66% match rate compared to the case report's decision to initiate plasmapheresis, indicating a 34% reduction in suggesting plasmapheresis for these cases. Error analysis revealed that errors were primarily due to GPT-4 ignoring pertinent findings, inaccurate knowledge, and confounding symptoms or findings within the case report itself. Discussion This study demonstrated that GPT-4 could adequately assist in the diagnosis of TMA and provide suggestions for early management of TTP based on clinical presentation and basic diagnostic workup. GPT-4 appropriately recommended plasmapheresis for TTP cases and showed a comparable performance of that of a clinically commonly used tool in these settings, PLASMIC score. However, in our study, GPT-4 made errors such as ignoring pertinent findings and demonstrating incomplete knowledge, highlighting the need for pretraining and areas to improve regarding diagnosis of TMA. The study suggested that GPT-4 could be integrated as a diagnostic support tool, especially for complex, time-sensitive conditions, while emphasizing that it should complement, not replace, clinical judgment.}
}
@article{EDAKKANAMBETHVARAYIL20251018,
title = {Artificial intelligence (AI) in nutrition: A case-based comparison of generative AI models},
journal = {Clinical Nutrition ESPEN},
volume = {69},
pages = {1018},
year = {2025},
issn = {2405-4577},
doi = {https://doi.org/10.1016/j.clnesp.2025.07.620},
url = {https://www.sciencedirect.com/science/article/pii/S240545772502371X},
author = {J. {Edakkanambeth Varayil} and O. {Mohamed Elfadil} and M. Mundi and G. Kolar and R. Hurt}
}
@article{PERES2023269,
title = {On ChatGPT and beyond: How generative artificial intelligence may affect research, teaching, and practice},
journal = {International Journal of Research in Marketing},
volume = {40},
number = {2},
pages = {269-275},
year = {2023},
issn = {0167-8116},
doi = {https://doi.org/10.1016/j.ijresmar.2023.03.001},
url = {https://www.sciencedirect.com/science/article/pii/S0167811623000162},
author = {Renana Peres and Martin Schreier and David Schweidel and Alina Sorescu},
keywords = {ChatGPT, Generative AI, Artificial intelligence, LLMs},
abstract = {How does ChatGPT, and other forms of Generative Artificial Intelligence (GenAI) affect the way we have been conducting—and evaluating—academic research, teaching, and business practice? What are the implications for the theory and practice of marketing? What are the opportunities and threats, and what are some interesting avenues for future research? This editorial aims to kick off an initial discussion and stimulate research that will help us better understand how the marketing field can fully exploit the potential of GenAI and effectively cope with its challenges.}
}
@article{POIRRIER2023S398,
title = {MSR26 The Use of Copilot, a Generative Artificial Intelligence Tool, as VBA Programming Assistant in Excel-Based Health Economic Models},
journal = {Value in Health},
volume = {26},
number = {12, Supplement },
pages = {S398},
year = {2023},
note = {ISPOR Europe 2023 Abstracts},
issn = {1098-3015},
doi = {https://doi.org/10.1016/j.jval.2023.09.2085},
url = {https://www.sciencedirect.com/science/article/pii/S1098301523052154},
author = {J.E. Poirrier and R. Bergemann}
}
@article{2024S154,
title = {500 Hyponatremia Virtual Patient Simulator: An innovative educational tool with generative artificial intelligence and physiologic models},
journal = {American Journal of Kidney Diseases},
volume = {83},
number = {4, Supplement 2},
pages = {S154},
year = {2024},
note = {National Kidney Foundation 2024 Spring Clinical Meeting Abstracts},
issn = {0272-6386},
doi = {https://doi.org/10.1053/j.ajkd.2024.01.503},
url = {https://www.sciencedirect.com/science/article/pii/S027263862400550X}
}
@article{BANAD2025101329,
title = {Artificial intelligence and machine learning for smart grids: from foundational paradigms to emerging technologies with digital twin and large language model-driven intelligence},
journal = {Energy Conversion and Management: X},
volume = {28},
pages = {101329},
year = {2025},
issn = {2590-1745},
doi = {https://doi.org/10.1016/j.ecmx.2025.101329},
url = {https://www.sciencedirect.com/science/article/pii/S2590174525004611},
author = {Yaser M. Banad and Sarah S. Sharif and Zahra Rezaei},
keywords = {Artificial intelligence, Machine learning, Smart grids, Renewable energy, Digital twin, Generative AI, Large language models, Energy management},
abstract = {The evolution of modern power systems into smart grids is increasingly powered by Artificial Intelligence (AI) and Machine Learning (ML), which provide effective solutions for managing renewable intermittency, dynamic demand, and cybersecurity challenges. This paper presents a comprehensive review of AI/ML applications in smart grids, tracing their development from foundational paradigms to cutting-edge technologies such as Federated Learning (FL), Generative AI (GenAI), Large Language Models (LLMs), the Artificial Intelligence of Things (AIoT), and Digital Twin (DT)-driven intelligence. Enabling infrastructures, including IoT, 5G, edge–cloud ecosystems, and ML-based smart sensors, are discussed alongside advanced approaches such as multi-agent systems. Key applications explored include load forecasting, predictive maintenance, anomaly and cyber-attack detection, demand-side management, and electric vehicle integration. Special emphasis is placed on Digital Twin and LLM architectures, which enable real-time cyber-physical replicas and context-aware reasoning, thus improving predictive analytics, resilience, and autonomous decision-making. Despite notable advancements, challenges remain in interoperability, data privacy, computational scalability, adversarial robustness, and ethical constraints. By synthesizing these insights, the study highlights the transformative role of AI in creating resilient, sustainable, and intelligent energy systems, and outlines future research trajectories toward standardized DT frameworks, active learning paradigms, and LLM-driven energy intelligence.}
}
@article{GOMES2025A39,
title = {Graduate Students’ Use and Perceptions of Generative Artificial Intelligence (GenAI) in Higher Education},
journal = {Journal of the Academy of Nutrition and Dietetics},
volume = {125},
number = {10, Supplement },
pages = {A39},
year = {2025},
note = {2025 Food & Nutrition Conference & Expo},
issn = {2212-2672},
doi = {https://doi.org/10.1016/j.jand.2025.06.303},
url = {https://www.sciencedirect.com/science/article/pii/S2212267225006409},
author = {A. Gomes}
}
@article{SIMSEK2025e806,
title = {The predictive effect of nursing students' attitudes and acceptance towards artificial intelligence on their clinical competencies},
journal = {Teaching and Learning in Nursing},
volume = {20},
number = {3},
pages = {e806-e814},
year = {2025},
issn = {1557-3087},
doi = {https://doi.org/10.1016/j.teln.2025.02.036},
url = {https://www.sciencedirect.com/science/article/pii/S1557308725000824},
author = {Enes Şimşek and Aslı Akdeniz Kudubeş and Remziye {Semerci Şahin}},
keywords = {Acceptance, Artificial intelligence, Attitude, Clinical competency, Nursing student},
abstract = {Background
AI integration in education is gaining interest, including in nursing, as students seek formal training on its healthcare applications and limitations.
Aim
To evaluate the predictive effect of nursing students' attitudes and acceptance of artificial intelligence on their clinical competencies.
Methods
This descriptive-correlational study was conducted at 2 universities (February–June 2024) with 441 nursing students. Full-time students in clinical practice participated; those absent or on leave were excluded. The Nursing Students Competency Scale, General Attitudes to Artificial Intelligence Scale, and Generative Artificial Intelligence Acceptance Scale were used. Descriptive statistics and linear regression were used.
Results
The main factors affecting nursing students' clinical competence were “facilitating conditions,” “social influence,” and “negative attitudes” toward AI. A weak correlation was found between positive AI attitudes and acceptance, which explained 8.6% of the competency levels.
Conclusion
Positive perceptions of AI may increase competence, while skepticism may deepen engagement and critical learning. Strategies to improve the acceptance and use of AI are crucial to maximize its benefits in nursing education and practice.}
}
@article{RODLER2024S947,
title = {A0193 - Exploring the efficiency of generative artificial intelligence in rapidly and accurately producing patient information for urological malignancy treatments aligned with the latest EAU guidelines},
journal = {European Urology},
volume = {85},
pages = {S947-S948},
year = {2024},
note = {Abstracts EAU24 - 39th Annual EAU Congress},
issn = {0302-2838},
doi = {https://doi.org/10.1016/S0302-2838(24)00773-5},
url = {https://www.sciencedirect.com/science/article/pii/S0302283824007735},
author = {S. Rodler and L.S. Ramacciotti and E. Checcucci and P. {De Backer} and I.R. Belenchon and M. Taraktin and S. Pulliatti and A. Veccia and P. Piazza and L. Baekelandt and K-F. Kowalewski and J.G. Rivas and A.L. Abreu and I.S. Gill and G.E. Cacciamani}
}
@article{THANGARAJ20242340,
title = {EVIDENCE FROM RANDOMIZED CONTROLLED TRIAL TO REAL-WORLD PATIENTS USING ELECTRONIC HEALTH RECORD-ADAPTED DIGITAL TWINS: A NOVEL APPLICATION OF GENERATIVE ARTIFICIAL INTELLIGENCE},
journal = {Journal of the American College of Cardiology},
volume = {83},
number = {13, Supplement },
pages = {2340},
year = {2024},
note = {ACC.24},
issn = {0735-1097},
doi = {https://doi.org/10.1016/S0735-1097(24)04330-4},
url = {https://www.sciencedirect.com/science/article/pii/S0735109724043304},
author = {Phyllis Thangaraj and Sumukh Vasisht Shankar and Evangelos K. Oikonomou and Rohan Khera}
}
@article{HALL2024100256,
title = {Generative Artificial Intelligence, Large Language Models, and JID Innovations},
journal = {JID Innovations},
volume = {4},
number = {2},
pages = {100256},
year = {2024},
issn = {2667-0267},
doi = {https://doi.org/10.1016/j.xjidi.2024.100256},
url = {https://www.sciencedirect.com/science/article/pii/S2667026724000018},
author = {Russell P. Hall}
}
@article{LUBOWITZ2024651,
title = {Guidelines for the Use of Generative Artificial Intelligence Tools for Biomedical Journal Authors and Reviewers},
journal = {Arthroscopy: The Journal of Arthroscopic & Related Surgery},
volume = {40},
number = {3},
pages = {651-652},
year = {2024},
issn = {0749-8063},
doi = {https://doi.org/10.1016/j.arthro.2023.10.037},
url = {https://www.sciencedirect.com/science/article/pii/S0749806323008812},
author = {James H. Lubowitz},
abstract = {Authors are permitted to use generative artificial intelligence (AI) large language models (LLM) to improve the readability of their own writing. However, authors must review and edit the output resulting from generative AI and are accountable for the accuracy of their publications. AI may not be listed, or cited, as an author. Authors who use AI in the scientific writing process must disclose the use of AI LLM in their manuscript including a description of the tool and reason for use. Authors are not permitted to use AI to create or alter images or videos, (unless this is part of the research design in which case a statement is required explaining what was created or altered, with what tools, how, and for what reason). Finally, AI use by reviewers and editors is not permitted and violates confidentiality and proprietary rights and may breach data privacy rights. In conclusion, scientific writing and peer review is the responsibility of humans.}
}
@article{JONES2025100557,
title = {I gotta use words when I talk to you: Primed suspension of disbelief in views on agency in relation to Artificial Intelligence},
journal = {Information and Organization},
volume = {35},
number = {1},
pages = {100557},
year = {2025},
issn = {1471-7727},
doi = {https://doi.org/10.1016/j.infoandorg.2025.100557},
url = {https://www.sciencedirect.com/science/article/pii/S147177272500003X},
author = {Matthew Jones},
keywords = {Agency, Artificial intelligence},
abstract = {The public launch of generative AI systems in 2022 has prompted considerable popular interest in their potential to transform work and to achieve the long-sought goal of machine intelligence. While the uncanny abilities of Large Language Models to produce fluent text on almost any subject lends these ideas some plausibility, they are based on debatable, if not erroneous, claims about the capabilities of generative AI. Although rarely presented in these terms, these claims may be seen to reflect a limited, substantive conception of the agency of AI systems. Alternative conceptualisations of agency from other disciplines are presented that may offer potentially more fruitful ways of thinking about agency in relation to AI. The way that conceptions of the agency of AI systems is shaped by the language used to describe their behaviour is highlighted and opportunities for alternative conceptions of agency to inform a more critical analysis of generative AI are identified.}
}
@article{GARG2024178,
title = {Generative artificial intelligence ChatGPT-4: A transformative epoch in the realm of psychiatric care of children with intellectual developmental disorders},
journal = {General Hospital Psychiatry},
volume = {90},
pages = {178-180},
year = {2024},
issn = {0163-8343},
doi = {https://doi.org/10.1016/j.genhosppsych.2024.05.004},
url = {https://www.sciencedirect.com/science/article/pii/S0163834324000859},
author = {Sunny Garg and Alka Chauhan},
keywords = {ChatGPT-4, Children, Educational scenarios, Generative artificial intelligence, Intellectual developmental disorders, Personalized learning}
}
@article{NIGRO20252390,
title = {Artificial Intelligence–Generated Answers to Patients’ Questions on Asthma: The Artificial Intelligence Responses on Asthma Study},
journal = {The Journal of Allergy and Clinical Immunology: In Practice},
volume = {13},
number = {9},
pages = {2390-2396},
year = {2025},
issn = {2213-2198},
doi = {https://doi.org/10.1016/j.jaip.2025.04.051},
url = {https://www.sciencedirect.com/science/article/pii/S2213219825004209},
author = {Mattia Nigro and Andrea Aliverti and Alessandra Angelucci and Fulvio Braido and Giorgio W. Canonica and Apostolos Bossios and Hilary Pinnock and Jeanette Boyd and Pippa Powell and Stefano Aliberti},
keywords = {Asthma, Artificial intelligence, AI, Reliability, Accuracy, Comprehensiveness, Understandability, Disease awareness, Personalized medicine},
abstract = {Background
Asthma is a prevalent chronic respiratory disease requiring ongoing patient education and individualized management. The increasing reliance on digital tools, particularly generative artificial intelligence (AI), to answer health-related questions has raised concerns about the accuracy, reliability, and comprehensibility of AI-generated information for people living with asthma.
Objective
To evaluate systematically the reliability, accuracy, comprehensiveness, and understandability of responses generated by three widely used artificial intelligence–based chatbots (ChatGPT, Bard, and Copilot) to common questions formulated by people with asthma.
Methods
In this cross-sectional study, 15 questions regarding asthma management were formulated by patients and categorized by difficulty. Responses from ChatGPT, Bard, and Copilot were evaluated by international experts for accuracy and comprehensiveness, and by patient representatives for understandability. Reliability was assessed through consistency testing across devices. We conducted a blinded evaluation.
Results
A total of 21 experts and 16 patient representatives participated in the evaluation. ChatGPT demonstrated the highest reliability (15 of 15 responses), accuracy (median score, 9.0; interquartile range [IQR], 7.0-9.0), and comprehensiveness (median score, 8.0; IQR, 8.0-9.0) compared with Bard and Copilot (P < .0001). Bard achieved superior scores in understandability (median score, 9.0; IQR, 8.0-10.0; P < .0001). Performance differences were consistent across question difficulty levels.
Conclusions
Artificial intelligence–driven chatbots can provide generally accurate and understandable responses to asthma-related questions. Variability in reliability and accuracy underscores the need for caution in clinical contexts. Artificial intelligence tools may complement but cannot replace professional medical advice in asthma management.}
}
@article{KRUIDERING2024224,
title = {Can Generative Artificial Intelligence (AI) Reliably Score Open-Ended Questions (OEQs) in the Assessment of Medical Knowledge},
journal = {The Journal of Pharmacology and Experimental Therapeutics},
volume = {389},
pages = {224},
year = {2024},
issn = {0022-3565},
doi = {https://doi.org/10.1124/jpet.224.126248},
url = {https://www.sciencedirect.com/science/article/pii/S002235652417454X},
author = {Marieke Kruidering and Bao Bao Truongb and Kumiko Endo and Doreen M. Olvet and Tracy B. Fulton and Jeffrey B. Bird and Judith Brenner and Joanne M. Willey},
abstract = {Abstract ID 126248 Poster Board 224 Purpose: The objective of this study is to establish the accuracy of generative artificial intelligence (AI) when scoring medical student exam questions in an open-ended format (OEQ) compared to a faculty content expert. Background: Despite the numerous benefits to including OEQs in assessment of medical knowledge1,2, only 39% of US allopathic medical schools use them3. Faculty report that the biggest barrier is the time it takes to grade student responses1,2. Natural language processing has been explored to automate scoring of clinical reasoning4, but no study has evaluated the use of generative AI to score OEQ responses in the pre-clerkship curriculum. Methods: OEQ responses from two questions administered at the Zucker School of Medicine (ZSOM) and the University of California at San Francisco School of Medicine (UCSF) were used for the current study5. Responses from 54 students per site were analyzed. Content experts scored the responses using an analytic (ZSOM) or holistic rubric (UCSF). Questions, rubrics, and student responses were fed into the GPT-4 model via the Med2Lab platform. Once finalized, scores for each student’s response were generated. Cohen’s weighted kappa (kw) was used to evaluate inter-rater reliability (IRR) between the content expert and generative AI scores, with kw scores between 0.60 and 0.80 being considered substantial6. Prompt engineering was employed for question 1 (analytic rubric) to evaluate its impact on IRR. Results: IRR between the content expert and generative AI scores was substantial using the analytic rubric (question 1: kw = 0.71; question 2: kw = 0.63) and the holistic rubric (question 1: kw = 0.66; question 2: kw = 0.68). IRR for question 1 (analytic rubric) was initially kw = 0.61 but was increased to kw = 0.71 after adjustments with prompt engineering and re-run in GPT-4. Conclusions: Generative AI can score OEQs with substantial reliability. With the potential to alleviate grading burden, AI scoring will allow medical schools to broadly implement OEQs for assessment.}
}
@article{RUSSELL2025102483,
title = {Toward amplifying the good in nursing education: A quality improvement study on implementing artificial intelligence-based assistants in a learning system},
journal = {Nursing Outlook},
volume = {73},
number = {5},
pages = {102483},
year = {2025},
issn = {0029-6554},
doi = {https://doi.org/10.1016/j.outlook.2025.102483},
url = {https://www.sciencedirect.com/science/article/pii/S0029655425001368},
author = {Regina G. Russell and Jules White and Allen Karns and Karely Rodriguez and Pamela R. Jeffries and Patricia Sengstack},
keywords = {Nursing education, Artificial intelligence, Generative AI, Large language models, Innovation, Systems thinking, Leadership, Change management, Quality improvement, Interprofessional education},
abstract = {ABSTRACT
Effective integration of artificial intelligence-based tools into nursing care and science will depend on aligned integration in nursing education. Our quality improvement study documents the process and short-term outcomes of introducing a generative AI-based tool into a nursing education system. Nursing school faculty and staff at one private, southeastern university (n = 364) piloted an internally constrained chatbot system for 2 months in 2024. Data were captured to evaluate the (a) costs of implementation, (b) use cases in nursing education, and (c) projected system impact. Costs were lower than $2 per month, per user. There were 148 diverse case reports from 35 unique users. On a separate survey, 35 respondents rated technology acceptability as 5.2/7.0. Projected impact is high (6.3/7.0), but not entirely positive (5.9/7.0). Benefits and challenges were identified. Nursing will need to invest expert time and community resources to evolve education systems along with these evolving technologies.}
}
@article{WAMBATAGUIMDJE2024,
title = {Why Should Users Take the Risk of Sustainable Use of Generative Artificial Intelligence Chatbots:},
journal = {Journal of Global Information Management},
volume = {32},
number = {1},
year = {2024},
issn = {1062-7375},
doi = {https://doi.org/10.4018/JGIM.365600},
url = {https://www.sciencedirect.com/science/article/pii/S106273752400043X},
author = {Serge-Lopez Wamba-Taguimdje and Samuel Fosso Wamba and Hossana Twinomurinzi},
keywords = {ChatGPT, GenAI-Chatbot, Artificial Intelligence, Risks, User Satisfaction, Sustainable Use},
abstract = {ABSTRACT
Despite the risks associated with generative AI (GenAI) chatbots, people increasingly use these technologies, which may seem contradictory. This study identified and explored factors and risks related to trust, perceived values, satisfaction, and sustainable use of GenAI chatbots. Relying on IS theories to build a stimulus-organism-response model, the authors tested a model using PLS-SEM with data from 393 ChatGPT users. The results show that user competence and autonomy dramatically increase a user's trust in ChatGPT, and trust improves hedonic value (HV), utilitarian value (UV), value-in-use, perceived task-technology fit (TTF), information accuracy, knowledge acquisition, perceived informativeness, and user satisfaction. In addition to trust, user satisfaction depends on HV, UV, and TTF. The sustainability use of ChatGPT depends on HV and satisfaction. However, perceived privacy concerns, perceived privacy risks, and privacy awareness do not affect consumer trust. There is a complete mediation between trust and sustainability, as well as HV and sustainability.}
}
@article{LACK2025,
title = {Therapy Without a Therapist: Chatbots and Artificial Intelligence in Mental Health},
journal = {Psychiatric Clinics of North America},
year = {2025},
issn = {0193-953X},
doi = {https://doi.org/10.1016/j.psc.2025.08.018},
url = {https://www.sciencedirect.com/science/article/pii/S0193953X25000887},
author = {Caleb W. Lack and J. Kyle Haws},
keywords = {Chatbots, Artificial intelligence, Large language model, Natural language processing, Psychotherapy, Mental health}
}
@article{NEVIERE2024S474,
title = {MSR184 Leveraging Generative Artificial Intelligence for Assessing the Quality of Network Meta-Analysis: Methodological Considerations and Early Findings},
journal = {Value in Health},
volume = {27},
number = {12, Supplement },
pages = {S474-S475},
year = {2024},
note = {ISPOR Europe 2024},
issn = {1098-3015},
doi = {https://doi.org/10.1016/j.jval.2024.10.2418},
url = {https://www.sciencedirect.com/science/article/pii/S1098301524052811},
author = {A Nevière and G Friedrich and K Papadimitropoulou and P {Le Nouveau} and A Gauthier}
}
@article{SCHLESSINGER2025585,
title = {Artificial Intelligence in Cosmetic Dermatology and Dermatologic Surgery},
journal = {Dermatologic Clinics},
volume = {43},
number = {4},
pages = {585-591},
year = {2025},
note = {Artificial Intelligence in Dermatology},
issn = {0733-8635},
doi = {https://doi.org/10.1016/j.det.2025.05.009},
url = {https://www.sciencedirect.com/science/article/pii/S0733863525000488},
author = {Daniel Isaac Schlessinger},
keywords = {Artificial intelligence, Large language model, Dermatologic surgery, Robotic surgery, Mohs surgery, Laser surgery, Hair transplantation, Basal cell carcinoma}
}
@incollection{SZABO2025239,
title = {Chapter 16 - Acceptance and commitment training in applied behavior analysis: Competency-based training with generative artificial intelligence},
editor = {Henry S. Roane and Joel E. Ringdahl and Terry S. Falcomata and William E. Sullivan},
booktitle = {Clinical and Organizational Applications of Applied Behavior Analysis (Second Edition)},
publisher = {Academic Press},
edition = {Second Edition},
pages = {239-253},
year = {2025},
series = {Practical Resources for the Mental Health Professional},
isbn = {978-0-443-22365-5},
doi = {https://doi.org/10.1016/B978-0-443-22365-5.00027-5},
url = {https://www.sciencedirect.com/science/article/pii/B9780443223655000275},
author = {Thomas G. Szabo and Michael J. Cameron and Zimeng Ma and Ziyao Yang and Zhixin Yao},
keywords = {Acceptance and commitment training, Applied behavior analysis, Artificial intelligence, Autism, Genertive AI},
abstract = {Many have returned to a question that Skinner asked toward the end of his career, why are we not acting to save the world (Skinner, 1987). At least two recent papers (Dixon et al., 2018; Rehfeldt & Tyndall, 2021) have posited that we can make substantial progress by furthering research on derived stimulus relations and making use of acceptance and commitment training (ACTr; Szabo, 2023; Szabo et al., 2019b; Tarbox et al., 2020). We enthusiastically endorse these recommendations, but we offer (a) a caveat and (b) solutions that are not at not new in principle but which we propose can be accomplished with surprisingly novel approaches. In this chapter, we offer a brief outline of ACTr in ABA, caveats to using ACTr, and strategies for training BCBAs to the level of competence and sensitivity to scope of practice required. Specifically, we introduce the concept of programmed instruction in ACTr using generative artificial intelligence (GenAI) and provide examples of GenAI as it is used in medical research. Finally, we offer a list of recommendations to researchers and practitioners interested in pursuing this approach to realizing Skinner’s dream.}
}
@article{SEZGIN2022,
title = {Operationalizing and Implementing Pretrained, Large Artificial Intelligence Linguistic Models in the US Health Care System: Outlook of Generative Pretrained Transformer 3 (GPT-3) as a Service Model},
journal = {JMIR Medical Informatics},
volume = {10},
number = {2},
year = {2022},
issn = {2291-9694},
doi = {https://doi.org/10.2196/32875},
url = {https://www.sciencedirect.com/science/article/pii/S2291969422000643},
author = {Emre Sezgin and Joseph Sirrianni and Simon L Linwood},
keywords = {natural language processing, artificial intelligence, generative pretrained transformer, clinical informatics, chatbot},
abstract = {Generative pretrained transformer models have been popular recently due to their enhanced capabilities and performance. In contrast to many existing artificial intelligence models, generative pretrained transformer models can perform with very limited training data. Generative pretrained transformer 3 (GPT-3) is one of the latest releases in this pipeline, demonstrating human-like logical and intellectual responses to prompts. Some examples include writing essays, answering complex questions, matching pronouns to their nouns, and conducting sentiment analyses. However, questions remain with regard to its implementation in health care, specifically in terms of operationalization and its use in clinical practice and research. In this viewpoint paper, we briefly introduce GPT-3 and its capabilities and outline considerations for its implementation and operationalization in clinical practice through a use case. The implementation considerations include (1) processing needs and information systems infrastructure, (2) operating costs, (3) model biases, and (4) evaluation metrics. In addition, we outline the following three major operational factors that drive the adoption of GPT-3 in the US health care system: (1) ensuring Health Insurance Portability and Accountability Act compliance, (2) building trust with health care providers, and (3) establishing broader access to the GPT-3 tools. This viewpoint can inform health care practitioners, developers, clinicians, and decision makers toward understanding the use of the powerful artificial intelligence tools integrated into hospital systems and health care.}
}
@article{THANG2025503,
title = {The Current State and Future Prospects for Artificial Intelligence in Dermatology},
journal = {Dermatologic Clinics},
volume = {43},
number = {4},
pages = {503-514},
year = {2025},
note = {Artificial Intelligence in Dermatology},
issn = {0733-8635},
doi = {https://doi.org/10.1016/j.det.2025.05.001},
url = {https://www.sciencedirect.com/science/article/pii/S0733863525000403},
author = {Christopher J. Thang and Caitlyn Duffy and Sara Khattab and Yevgeniy R. Semenov},
keywords = {Artificial intelligence, Machine learning, Deep learning, Medical dermatology, Dermatopathology, Artificial intelligence for health care, Artificial intelligence for dermatology}
}
@article{VIJAYAN2025e68,
title = {The state of generative artificial intelligence (GAI) in radiology and dentistry},
journal = {Oral Surgery, Oral Medicine, Oral Pathology and Oral Radiology},
volume = {139},
number = {3},
pages = {e68},
year = {2025},
issn = {2212-4403},
doi = {https://doi.org/10.1016/j.oooo.2024.11.003},
url = {https://www.sciencedirect.com/science/article/pii/S221244032400796X},
author = {Dr. Suvendra Vijayan and Dr. Anitha Potluri},
abstract = {Objective
This oral presentation proposes to explain the current state of generative artificial intelligence (GAI) in health care and education. We will also showcase a research project that used GAI to create radiographic images and another ongoing project exploring the potential of GAI in dental education and research.
Study Design
Research 1—A pilot study was conducted to enhance ultra-low dose cone beam computed tomographic images of dry skulls to diagnostically acceptable standards. The images were trained using a pix2pix deep generative model. Research 2—A pilot study is being conducted exploring the accuracy of case reports generated by ChatGPT. We queried ChatGPT to create hypothetical case reports and modified the queries to get the best possible output.
Results
Research 1—Preliminary results indicated that the synthesized images are comparable with images made with normal exposure. Research 2—Preliminary results indicate that ChatGPT can create a convincing and accurate case report. Limitations in use of citations were observed.
Conclusion
GAI like Open AI's ChatGPT, Google's Bard, and Microsoft's CoPilot have caused a massive shift in public knowledge of AI. GAI will have major impact in health care and education. GAI tools like ChatGPT have huge potential for use and misuse in educational and research spheres. Creating questions and explanation on complex topics can be done on these tools. Websites like MidJourney can create interesting and novel images. Radiographic images can be created using specific algorithms. We intend to demonstrate how to effectively use GAI like ChatGPT, describe ethical concerns and how to address and regulate them in academia, and identify innovative uses for AI and ChatGPT in dental care and education. GAI is a freight train with no breaks and as educators and healthcare practitioners we need to discuss and propose policies and safeguards for responsible use of AI.}
}
@article{GUERRA2023S410,
title = {MSR92 Can Artificial Intelligence (AI) Large Language Models (LLMS) Such as Generative Pre-Trained Transformer (GPT) Be Used to Automate Literature Reviews?},
journal = {Value in Health},
volume = {26},
number = {12, Supplement },
pages = {S410-S411},
year = {2023},
note = {ISPOR Europe 2023 Abstracts},
issn = {1098-3015},
doi = {https://doi.org/10.1016/j.jval.2023.09.2151},
url = {https://www.sciencedirect.com/science/article/pii/S1098301523052816},
author = {I. Guerra and J. Gallinaro and K. Rtveladze and A. Lambova and E. Asenova}
}
@article{ALCALAY2025105237,
title = {Can artificial intelligence models provide reliable medical counselling to fertility patients?},
journal = {Reproductive BioMedicine Online},
pages = {105237},
year = {2025},
issn = {1472-6483},
doi = {https://doi.org/10.1016/j.rbmo.2025.105237},
url = {https://www.sciencedirect.com/science/article/pii/S1472648325004444},
author = {Idan Alcalay and Ariel Weissman and Hadas Ganer Herman and Avi Tsafrir and Matan Friedman and Eran Weiner and Raoul Orvieto and Nikolaos P Polyzos and Michael H Dahan and Alex Polyakov and Robert Fischer and Sandro C Esteves and Baris Ata and Jason M Franasiak and Yossi Mizrachi},
keywords = {Artificial intelligence, experts, fertility, ART, counseling},
abstract = {Research question
Can generative AI models provide reliable counselling to fertility patients regarding real-world clinical questions.
Design
In this cross-sectional study, 12 clinical questions were developed to reflect common, real-life dilemmas encountered during fertility workup and treatment. Responses to each question were generated by two experienced fertility specialists, ChatGPT, and Gemini. Eight leading internationally recognized fertility experts, blinded to the source of each reply, independently rated all responses on a scale from 1 (strongly disagree) to 10 (strongly agree). Ratings were compared across all four repliers using non-parametric statistical tests.
Results
Replies authored by physicians received significantly higher overall scores than those generated by AI models (p<0.001). Median scores were highest for Doctor A (9.0), followed by Doctor B (8.0), then ChatGPT (7.0), and finally Gemini received the lowest score (4.5). The proportion of high-scoring responses (≥8) was greatest for Doctor A (70.8%), followed by Doctor B (56.3%), then ChatGPT (47.9%), and finally Gemini (35.4%) (p<0.001).
Conclusion
Experienced fertility specialists outperformed generative AI models in providing accurate responses to complex clinical questions. Despite the growing accessibility and sophistication of AI tools, their use for individualized fertility counseling remains limited. Continued refinement and clinical validation of AI tools are essential before they can be considered reliable for patient-specific guidance. At present, AI should be viewed as a complementary resource rather than a substitute for expert clinical judgment.}
}
@article{LI2025150926,
title = {Artificial Intelligence and Machine Learning in Transfusion Practice: An Analytical Assessment},
journal = {Transfusion Medicine Reviews},
volume = {39},
number = {4},
pages = {150926},
year = {2025},
note = {Horizons in Transfusion Medicine: Perspectives after the first quarter of the 21st century},
issn = {0887-7963},
doi = {https://doi.org/10.1016/j.tmrv.2025.150926},
url = {https://www.sciencedirect.com/science/article/pii/S0887796325000513},
author = {Na Li and Ruchika Goel and Sheharyar Raza and Kiarash Riazi and Jie Pan and Huong Quynh Nguyen and Andrew W. Shih and Adam D’Souza and Rounak Dubey and Aaron A.R. Tobian and Donald M. Arnold},
keywords = {Transfusion medicine, Artificial intelligence, Clinical decision support, Supervised learning, Unsupervised learning, Reinforcement learning, Generative artificial intelligence},
abstract = {Transfusion medicine is vital to healthcare and affects clinical outcomes, patient safety, and system resilience while addressing challenges such as blood shortages, donor variability, and rising costs. The integration of artificial intelligence (AI) and machine learning (ML) presents new opportunities to improve clinical decision-making and operational effectiveness in this field. This structured narrative review identified and evaluated studies applying AI and ML in transfusion medicine. A search of PubMed and Scopus for articles published between January 2018 and April 2025 yielded 565 publications. Studies were included if they applied AI or ML techniques, focused on transfusion management or decision support, and were evaluated using electronic health records or expert review. Four exemplar studies were selected, each representing a distinct AI paradigm: supervised, unsupervised, reinforcement, and generative learning. These studies were critically appraised for methodological rigor, clinical relevance, and potential for implementation in practice. The reviewed studies reflected a clear shift from traditional analytic methods toward more advanced computational approaches to improve prediction accuracy, optimize resource allocation, and support clinical decision-making. Three overarching themes emerged: the need to balance model complexity with interpretability and clinical feasibility; the impact of data quality and preprocessing on model performance and fairness; and the barriers to broader applicability and cross-institutional deployment. As technological barriers continue to decline, future challenges will increasingly center on privacy regulations, infrastructure constraints, and aligning model complexity with practical utility. Thoughtful integration of these considerations through scalable, clinical-grade, and transparent solutions will be critical in realizing the full potential of AI and ML in transfusion medicine.}
}
@article{CHIU2024100239,
title = {Erratum to “Future research recommendations for transforming higher education with generative AI” [Computers and Education: Artificial Intelligence 6 (June 2024) 100197]},
journal = {Computers and Education: Artificial Intelligence},
volume = {6},
pages = {100239},
year = {2024},
issn = {2666-920X},
doi = {https://doi.org/10.1016/j.caeai.2024.100239},
url = {https://www.sciencedirect.com/science/article/pii/S2666920X24000420},
author = {Thomas K.F. Chiu}
}
@article{DIEN2023108595,
title = {Generative artificial intelligence in publishing - Reflection and discussion},
journal = {Biological Psychology},
volume = {181},
pages = {108595},
year = {2023},
issn = {0301-0511},
doi = {https://doi.org/10.1016/j.biopsycho.2023.108595},
url = {https://www.sciencedirect.com/science/article/pii/S0301051123001126},
author = {Joseph Dien and Thomas Ritz},
keywords = {Plagiarism, Large Language Models, ChatGPT, Artificial Intelligence, Academic Misconduct}
}
@article{JAISWAL202057,
title = {Towards an Artificial Intelligence Aided Design Approach: Application to Anime Faces with Generative Adversarial Networks},
journal = {Procedia Computer Science},
volume = {168},
pages = {57-64},
year = {2020},
note = {“Complex Adaptive Systems”Malvern, PennsylvaniaNovember 13-15, 2019},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2020.02.257},
url = {https://www.sciencedirect.com/science/article/pii/S1877050920303963},
author = {Devendra Prakash Jaiswal and Srishti Kumar and Youakim Badr},
keywords = {Generative Adversarial Networks, Super-Resolution, Image Generation, Artificial Neural Networks, Engineering Design},
abstract = {Ever since the inception of Machine Learning and Artificial Intelligence, the basic motto for most of research works has been to bring the machines at par with human intelligence. Designing new products and artifacts is one of the many fields where it is very difficult to enable computing machines replicate human creativity and innovativeness. Design processes in engineering fields as well as in arts follow methodical series of steps to create new products. Due to high demands of customized products and services, competitors tend to shorten the time-to-market periods, using advanced Computer-Aided Design programs. These programs play important roles to assist designers in digitizing blueprints and automating repetitive tasks. However, they fail to boost designer creativity by generating or suggesting new ideas or designs based on existing products or their variants. In order to boost creativity in the entertainment industry, we propose in this paper a new approach based on unsupervised learning techniques to create variants of a given artifact or product blueprints. Within the field of designing new cartoon characters, our proposed approach relies on Generative Adversarial Neural Networks [1] to create new anime or cartoon faces on their own without any human intervention. It learns features and characteristics from an image training dataset and combines them to create new features and thus builds a new image which is not present in the training dataset. This applied approach attempts to not only help artists and designers to have a preview of the possible new and unique avatars but also would prevent any copyright infringements.}
}
@article{IBARRAMUNOZ2025100818,
title = {Artificial intelligence in the food and bioprocess industries: Addressing food security challenges},
journal = {Food and Humanity},
volume = {5},
pages = {100818},
year = {2025},
issn = {2949-8244},
doi = {https://doi.org/10.1016/j.foohum.2025.100818},
url = {https://www.sciencedirect.com/science/article/pii/S2949824425003222},
author = {Lizbeth Alejandra Ibarra-Muñoz and Giselle Guadalupe Resendiz-Acosta and Roberto Muñoz-García and Litzy Yazmin Alvarado-Mata and Jazel Doménica Sosa-Martínez and Lourdes Morales-Oyervides and Julio Montañez and Nagamani Balagurusamy},
keywords = {Generative artificial intelligence, Predictive artificial intelligence, Bioprocess optimization, Food safety, Food security},
abstract = {Exponential population growth and increasing global food demand present significant challenges to food security, including risk of food shortages, declining quality and adverse environmental consequences associated with food production. Thus, emerging technologies are being applied to enhance and address challenges within production and safety of food. In this review, the potential of Artificial Intelligence (AI) is being explored as an emerging tool towards food industry and bioprocess concerns such as fermentation parameters, quality control contamination detection, food safety management and bioprocess optimization. By leveraging advanced AI techniques, such as Machine Learning (ML), Deep Learning (DL), Artificial Neural Networks (ANN), and Generative Adversarial Networks (GAN). However ethical implications, such as transparency, liability, AI autonomy and corporation’s awareness, remain critical. Despite its transformative potential, challenges like scalability, data availability, and public perception must be addressed for AI full integration into the food industry. Future perspectives highlight AI’s expanding role in preproduction, processing, and distribution, additionally AI is supported by advancements in synthetic biology and predictive modeling.}
}
@article{DIPAOLA2018158,
title = {Informing artificial intelligence generative techniques using cognitive theories of human creativity},
journal = {Procedia Computer Science},
volume = {145},
pages = {158-168},
year = {2018},
note = {Postproceedings of the 9th Annual International Conference on Biologically Inspired Cognitive Architectures, BICA 2018 (Ninth Annual Meeting of the BICA Society), held August 22-24, 2018 in Prague, Czech Republic},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2018.11.024},
url = {https://www.sciencedirect.com/science/article/pii/S187705091832310X},
author = {Steve DiPaola and Liane Gabora and Graeme McCaig},
keywords = {Deep Learning, Computational Creativity, Cognitive Science},
abstract = {The common view that our creativity is what makes us uniquely human suggests that incorporating research on human creativity into generative deep learning techniques might be a fruitful avenue for making their outputs more compelling and human-like. Using an original synthesis of DeepDream-based convolutional neural networks and cognitive based computational art rendering systems, we show how honing theory, intrinsic motivation, and the notion of a “seed incident” can be implemented computationally, and demonstrate their impact on the resulting generative art. Conversely, we discuss how explorations in deep learning convolutional neural net generative systems can inform our understanding of human creativity. We conclude with ideas for further cross-fertilization between AI based computational creativity and psychology of creativity.}
}
@article{MAGDIN2025107309,
title = {Literature review: Current trends and advances in the use of artificial intelligence for ensuring the safety and efficiency of gas pipeline operations},
journal = {Results in Engineering},
volume = {28},
pages = {107309},
year = {2025},
issn = {2590-1230},
doi = {https://doi.org/10.1016/j.rineng.2025.107309},
url = {https://www.sciencedirect.com/science/article/pii/S259012302503364X},
author = {Martin Magdin},
keywords = {Artificial intelligence, Machine learning, Leak detect, Predictive maintenance, Gas pipeline},
abstract = {The use of artificial intelligence (AI) in gas pipeline monitoring and maintenance represents a significant advancement in the energy industry. This article provides an overview of current trends and AI technologies applied in fault detection, failure prediction, and gas transportation optimization. Key methods include machine learning, deep neural networks, numerical simulations, and digital twins. Research highlights the importance of integrating AI with the physical properties of materials for localizing and assessing corrosion defects. A bibliometric analysis reveals that most studies focus on the application of neural networks, support vector machines, and Bayesian networks in predictive maintenance. Despite significant progress, challenges remain, such as the lack of high-quality datasets, high implementation costs, and regulatory barriers. Future research trends focus on the integration of AI with SCADA systems, improving predictive models, and the broader use of generative neural networks for data synthesis. This review of research trends from 2020 to 2025 underscores the importance of artificial intelligence in the transportation sector and highlights its potential for further development in enhancing the reliability and safety of energy infrastructures.}
}
@article{DIEN2023108621,
title = {Editorial: Generative artificial intelligence as a plagiarism problem},
journal = {Biological Psychology},
volume = {181},
pages = {108621},
year = {2023},
issn = {0301-0511},
doi = {https://doi.org/10.1016/j.biopsycho.2023.108621},
url = {https://www.sciencedirect.com/science/article/pii/S0301051123001382},
author = {Joseph Dien},
keywords = {Plagiarism, Large language models, ChatGPT, Artificial intelligence, Academic misconduct},
abstract = {There is increasing concern and consternation about generative artificial intelligence (AI) programs and its potential impact on academia. This editorial addresses the potential impact of such programs on scientific publishing as it relates to the journal Biological Psychology. Using chatGPT as an example, it makes the case that a prime concern is its implications for facilitating plagiarism. It briefly outlines what is known about the algorithm of the GPT text model, and also the implications of its chatGPT front end, on being able to establish appropriate credit for ideas in text that it outputs. It is concluded that, at least for Biological Psychology, the expectation is that authors will be transparent about AI usage, will declare when AI is the source of an idea, and will redouble efforts to seek out and cite prior claims to ideas in the published literature when AI is involved.}
}
@article{RUKADIKAR202427,
title = {Leadership development through self-upskilling: role of generative artificial intelligence},
journal = {Development and Learning in Organizations: An International Journal},
volume = {38},
number = {4},
pages = {27-30},
year = {2024},
issn = {1477-7282},
doi = {https://doi.org/10.1108/DLO-01-2024-0005},
url = {https://www.sciencedirect.com/science/article/pii/S1477728224000170},
author = {Aaradhana Rukadikar and Komal Khandelwal},
keywords = {Leadership development, Leaders, Learning, Upskilling, Generative AI},
abstract = {Purpose
This viewpoint paper investigates the changing role of leadership in a dynamic, technologically driven society, and the vital requirement for leaders to engage in continuous self-upskilling to remain effective. It emphasizes the importance of generative artificial intelligence (GAI) in transforming personalized learning experiences for leaders and allowing them to adapt to an ever-changing world.
Design/methodology/approach
A review of current research papers, articles, and case studies is conducted to evaluate the integration of generative AI in leadership self-upskilling. It examines the possibilities and possible benefits of generative AI, and the issues it offers regarding data privacy, algorithmic bias, and learning requirements.
Findings
The findings highlight the transformational potential of GAI in self-upskilling for leaders. It demonstrates how GAI can build personalized learning materials, provide real-time feedback, and adapt content to individual learning styles. It identifies notable executives who have effectively embraced GAI for their self-upskilling journeys, resulting in increased productivity and competitiveness.
Practical implications
The paper investigates the application of GAI for self-improvement, addressing challenges such as data privacy and algorithmic bias while suggesting responsible AI use tactics.
Originality/value
This study investigates the relationship between leadership and AI, emphasizing the importance of leaders in self-improvement as well as the possibility of AI-powered self-upskilling to democratize leadership development while also promoting ethical use.}
}
@article{BIRKHOLZ2025102520,
title = {Navigating artificial intelligence in nursing: An ethical exploration of benefits, risks, and educational shifts},
journal = {Nursing Outlook},
volume = {73},
number = {5},
pages = {102520},
year = {2025},
issn = {0029-6554},
doi = {https://doi.org/10.1016/j.outlook.2025.102520},
url = {https://www.sciencedirect.com/science/article/pii/S0029655425001733},
author = {Lorri Birkholz and Michael Martin and Brenda Barnum and Linda Breslin and Shika Kalevor},
keywords = {Artificial intelligence, Nursing, Nursing ethics, Nursing care, Academic integrity},
abstract = {A significant challenge of generative artificial intelligence (AI) is the gap between technological advancements and policies to guide their ethical use. The integration of AI in all aspects of nursing is poised to revolutionize the delivery of nursing care to patients. As such, nursing practice and educational programs will be required to adapt to these advancing technologies while maintaining the core tenets and ethical values inherent in the profession. Schools, colleges, and universities will be called upon to act to safeguard the value of education and the sanctity of the nursing profession Ultimately, it will be the responsibility of nurses to make sure technological advances, including AI, do not compromise learning or the human interactions and relationships that are essential to providing patient-centered care. The purpose of this article is to explore the ethical implications for the nursing profession of these advances as currently known and understood.}
}
@article{MARTIN2025,
title = {Artificial intelligence in personalized prescription: A narrative review of promise, peril, and practicality},
journal = {Therapies},
year = {2025},
issn = {0040-5957},
doi = {https://doi.org/10.1016/j.therap.2025.10.001},
url = {https://www.sciencedirect.com/science/article/pii/S0040595725001131},
author = {Guillaume L. Martin and Louis Létinier},
keywords = {Artificial intelligence, Large language models, Clinical decision support system, -prescribing, Medical devices},
abstract = {Summary
The integration of artificial intelligence (AI), particularly large language models (LLMs), into clinical prescription practices represents a transformative shift in healthcare, promising to offer enhanced therapeutic precision, reduced errors, and personalized care. However, rapid adoption is outpacing validation and governance. This narrative review critically examines the benefits, risks, and implementation challenges of AI in pharmacology, with an emphasis on prescribing use cases, highlighting the rapid adoption driven by physician constrained time and increasing complexity of medical knowledge, yet outpaced by validation frameworks. Key benefits include optimized decision support, as suggested by real-world systems like the Penda Health AI Copilot. However, inherent risks such as hallucinations, lack of explainability, spending inflation, and clinical de-skilling pose significant threats, potentially eroding trust and patient safety. We contrast regulatory philosophies [European Union (EU) precaution under the medical devices regulation (MDR) and AI Act vs U.S. flexibility via Food and Drug predetermined change control plans (FDA PCCP)] and spotlight a persistent grey zone in which general-purpose LLMs are used clinically without medical-device oversight. To operationalize trustworthy use, we foreground rigorous evaluation and outline an “architecture of trustworthy clinical AI” (retrieval-augmented generation, structured clinical prompting with abstention/uncertainty, and hybrid LLM–rule safety layers). Finally, we propose an outcomes-first paradigm adapted from French health technologies assessment (HTA)—service rendered by AI (SR-AI) and improvement of service rendered by AI (ISR-AI), with patient outcomes and system resilience as primary endpoints—and recommend a default stance that any generative AI used in health be treated as a medical device, with general-purpose LLMs permitted only via certified clinical wrappers that close the MDR-inconsistent gap.}
}
@article{ALI2022,
title = {Combating COVID-19 Using Generative Adversarial Networks and Artificial Intelligence for Medical Images: Scoping Review},
journal = {JMIR Medical Informatics},
volume = {10},
number = {6},
year = {2022},
issn = {2291-9694},
doi = {https://doi.org/10.2196/37365},
url = {https://www.sciencedirect.com/science/article/pii/S2291969422001740},
author = {Hazrat Ali and Zubair Shah},
keywords = {augmentation, artificial intelligence, COVID-19, diagnosis, generative adversarial networks, diagnostic, lung image, imaging, data augmentation, X-ray, CT scan, data scarcity, image data, neural network, clinical informatics},
abstract = {Background
Research on the diagnosis of COVID-19 using lung images is limited by the scarcity of imaging data. Generative adversarial networks (GANs) are popular for synthesis and data augmentation. GANs have been explored for data augmentation to enhance the performance of artificial intelligence (AI) methods for the diagnosis of COVID-19 within lung computed tomography (CT) and X-ray images. However, the role of GANs in overcoming data scarcity for COVID-19 is not well understood.
Objective
This review presents a comprehensive study on the role of GANs in addressing the challenges related to COVID-19 data scarcity and diagnosis. It is the first review that summarizes different GAN methods and lung imaging data sets for COVID-19. It attempts to answer the questions related to applications of GANs, popular GAN architectures, frequently used image modalities, and the availability of source code.
Methods
A search was conducted on 5 databases, namely PubMed, IEEEXplore, Association for Computing Machinery (ACM) Digital Library, Scopus, and Google Scholar. The search was conducted from October 11-13, 2021. The search was conducted using intervention keywords, such as “generative adversarial networks” and “GANs,” and application keywords, such as “COVID-19” and “coronavirus.” The review was performed following the Preferred Reporting Items for Systematic Reviews and Meta-Analyses Extension for Scoping Reviews (PRISMA-ScR) guidelines for systematic and scoping reviews. Only those studies were included that reported GAN-based methods for analyzing chest X-ray images, chest CT images, and chest ultrasound images. Any studies that used deep learning methods but did not use GANs were excluded. No restrictions were imposed on the country of publication, study design, or outcomes. Only those studies that were in English and were published from 2020 to 2022 were included. No studies before 2020 were included.
Results
This review included 57 full-text studies that reported the use of GANs for different applications in COVID-19 lung imaging data. Most of the studies (n=42, 74%) used GANs for data augmentation to enhance the performance of AI techniques for COVID-19 diagnosis. Other popular applications of GANs were segmentation of lungs and superresolution of lung images. The cycleGAN and the conditional GAN were the most commonly used architectures, used in 9 studies each. In addition, 29 (51%) studies used chest X-ray images, while 21 (37%) studies used CT images for the training of GANs. For the majority of the studies (n=47, 82%), the experiments were conducted and results were reported using publicly available data. A secondary evaluation of the results by radiologists/clinicians was reported by only 2 (4%) studies.
Conclusions
Studies have shown that GANs have great potential to address the data scarcity challenge for lung images in COVID-19. Data synthesized with GANs have been helpful to improve the training of the convolutional neural network (CNN) models trained for the diagnosis of COVID-19. In addition, GANs have also contributed to enhancing the CNNs’ performance through the superresolution of the images and segmentation. This review also identified key limitations of the potential transformation of GAN-based methods in clinical applications.}
}
@article{MILES2024S478,
title = {MSR201 Optimising Performance of Generative Artificial Intelligence (GenAI) in Systematic Literature Review (SLR) Screening Using PICOS Criteria},
journal = {Value in Health},
volume = {27},
number = {12, Supplement },
pages = {S478},
year = {2024},
note = {ISPOR Europe 2024},
issn = {1098-3015},
doi = {https://doi.org/10.1016/j.jval.2024.10.2435},
url = {https://www.sciencedirect.com/science/article/pii/S1098301524052987},
author = {G Miles and L Giles and B.C. Kerr and B Norman and GC Sibbring}
}
@article{ZHAO2025106245,
title = {Artificial intelligence in rock mechanics},
journal = {International Journal of Rock Mechanics and Mining Sciences},
volume = {195},
pages = {106245},
year = {2025},
issn = {1365-1609},
doi = {https://doi.org/10.1016/j.ijrmms.2025.106245},
url = {https://www.sciencedirect.com/science/article/pii/S1365160925002229},
author = {Gao-Feng Zhao and Yuhang Wu},
keywords = {Artificial intelligence, Machine learning, Rock mechanics, Large language model},
abstract = {Artificial Intelligence (AI) has great potential to transform rock mechanics by tackling its inherent complexities, such as anisotropy, nonlinearity, discontinuousness, and multiphase nature. This review explores the evolution of AI, from basic neural networks like the BP model to advanced architectures such as Transformers, and their applications in areas like microstructure reconstruction, prediction of mechanical parameters, and addressing engineering challenges such as rockburst prediction and tunnel deformation. Machine learning techniques, particularly Convolutional Neural Networks (CNNs) and Generative Adversarial Networks (GANs), have been crucial in automating tasks like fracture detection and efficiently generating 3D digital rock models. However, the effectiveness of AI in rock mechanics is limited by data scarcity and the need for high-quality datasets. Hybrid approaches, such as combining physics-informed neural networks (PINNs) with traditional numerical methods, offer promising solutions for solving governing equations. Additionally, Large Language Models (LLMs) are emerging as valuable tools for code generation and decision-making support. Despite these advancements, challenges remain, including issues with reproducibility, model interpretability, and adapting AI models to specific domains. Future progress will hinge on the availability of improved datasets, greater interdisciplinary collaboration, and the integration of spatial intelligence frameworks to bridge the gap between AI's theoretical potential and its practical application in rock engineering.}
}
@article{LEE20241318,
title = {Generative Artificial Intelligence},
journal = {Journal of the American College of Radiology},
volume = {21},
number = {8},
pages = {1318-1320},
year = {2024},
note = {Focus on Global Radiology},
issn = {1546-1440},
doi = {https://doi.org/10.1016/j.jacr.2024.01.020},
url = {https://www.sciencedirect.com/science/article/pii/S1546144024001303},
author = {Christoph I. Lee and Jonathan H. Chen and Marc D. Kohli and Andrew D. Smith and Joshua M. Liao}
}
@article{TRIANARODRIGUEZ20241158,
title = {Generative Artificial Intelligence: A Promising Instrument for Daily Living and Clinical Practice},
journal = {Journal of the American College of Radiology},
volume = {21},
number = {8},
pages = {1158-1159},
year = {2024},
note = {Focus on Global Radiology},
issn = {1546-1440},
doi = {https://doi.org/10.1016/j.jacr.2023.12.030},
url = {https://www.sciencedirect.com/science/article/pii/S1546144024000577},
author = {Gustavo Adolfo {Triana Rodriguez} and María M. Rojas-Rojas and Katherine Sotomayor and Juan P. Ovalle and José David {Cardona Ortegón}}
}
@article{CHAUHAN20241802,
title = {The Impact of Generative Artificial Intelligence on the External Review of Scientific Manuscripts and Editorial Peer Review Processes},
journal = {The American Journal of Pathology},
volume = {194},
number = {10},
pages = {1802-1806},
year = {2024},
issn = {0002-9440},
doi = {https://doi.org/10.1016/j.ajpath.2024.08.002},
url = {https://www.sciencedirect.com/science/article/pii/S0002944024002864},
author = {Chhavi Chauhan and George Currie}
}
@article{NING2025100900,
title = {How can artificial intelligence transform the training of medical students and physicians?},
journal = {The Lancet Digital Health},
pages = {100900},
year = {2025},
issn = {2589-7500},
doi = {https://doi.org/10.1016/j.landig.2025.100900},
url = {https://www.sciencedirect.com/science/article/pii/S2589750025000822},
author = {Yilin Ning and Jasmine Chiat Ling Ong and Haoran Cheng and Haibo Wang and Daniel Shu Wei Ting and Yih Chung Tham and Tien Yin Wong and Nan Liu},
abstract = {Summary
Advances in artificial intelligence (AI), particularly generative AI, hold promise for transforming medical education and physician training in response to increasing health-care demands and shortages in the global health-care workforce. Meanwhile, challenges remain in the effective and equitable integration of AI technology into medical education and physician training worldwide. This Viewpoint explores the opportunities and challenges of such an integration. We study the evolving role of AI in medical education, its potential to enhance high-fidelity clinical training, and its contribution to research training using real-world examples. We also highlight ethical concerns, particularly the unclear boundaries of appropriate use of AI and call for clear guidelines to govern the integration of AI into medical education and physician training. Furthermore, this Viewpoint discusses practical constraints, including human, financial, and resource constraints, in AI integration, and emphasises the need for comprehensive cost evaluations and collaborative funding models to support the sustainable implementation of AI integration. A tight collaborative network between health-care institutions and systems, medical schools and universities, industry partners, and education and health-care regulatory agencies could lead to an AI-transformed medical education and physician training scheme that ultimately supports the adoption and integration of AI into clinical medicine and potentially brings about tangible improvements in global health-care delivery.}
}
@article{ISLEEM202427,
title = {Can generative artificial intelligence pass the orthopaedic board examination?},
journal = {Journal of Orthopaedics},
volume = {53},
pages = {27-33},
year = {2024},
issn = {0972-978X},
doi = {https://doi.org/10.1016/j.jor.2023.10.026},
url = {https://www.sciencedirect.com/science/article/pii/S0972978X23002593},
author = {Ula N. Isleem and Bashar Zaidat and Renee Ren and Eric A. Geng and Aonnicha Burapachaisri and Justin E. Tang and Jun S. Kim and Samuel K. Cho},
abstract = {Background
Resident training programs in the US use the Orthopaedic In-Training Examination (OITE) developed by the American Academy of Orthopaedic Surgeons (AAOS) to assess the current knowledge of their residents and to identify the residents at risk of failing the Amerian Board of Orthopaedic Surgery (ABOS) examination. Optimal strategies for OITE preparation are constantly being explored. There may be a role for Large Language Models (LLMs) in orthopaedic resident education. ChatGPT, an LLM launched in late 2022 has demonstrated the ability to produce accurate, detailed answers, potentially enabling it to aid in medical education and clinical decision-making. The purpose of this study is to evaluate the performance of ChatGPT on Orthopaedic In-Training Examinations using Self-Assessment Exams from the AAOS database and approved literature as a proxy for the Orthopaedic Board Examination.
Methods
301 SAE questions from the AAOS database and associated AAOS literature were input into ChatGPT's interface in a question and multiple-choice format and the answers were then analyzed to determine which answer choice was selected. A new chat was used for every question. All answers were recorded, categorized, and compared to the answer given by the OITE and SAE exams, noting whether the answer was right or wrong.
Results
Of the 301 questions asked, ChatGPT was able to correctly answer 183 (60.8%) of them. The subjects with the highest percentage of correct questions were basic science (81%), oncology (72.7%, shoulder and elbow (71.9%), and sports (71.4%). The questions were further subdivided into 3 groups: those about management, diagnosis, or knowledge recall. There were 86 management questions and 47 were correct (54.7%), 45 diagnosis questions with 32 correct (71.7%), and 168 knowledge recall questions with 102 correct (60.7%).
Conclusions
ChatGPT has the potential to provide orthopedic educators and trainees with accurate clinical conclusions for the majority of board-style questions, although its reasoning should be carefully analyzed for accuracy and clinical validity. As such, its usefulness in a clinical educational context is currently limited but rapidly evolving.
Clinical relevance
ChatGPT can access a multitude of medical data and may help provide accurate answers to clinical questions.}
}
@article{XIAO20232973,
title = {Generative Artificial Intelligence GPT‑4 Accelerates Knowledge Mining and Machine Learning for Synthetic Biology},
journal = {ACS Synthetic Biology},
volume = {12},
number = {10},
pages = {2973-2982},
year = {2023},
issn = {2161-5063},
doi = {https://doi.org/10.1021/acssynbio.3c00310},
url = {https://www.sciencedirect.com/science/article/pii/S2161506323000323},
author = {Zhengyang Xiao and Wenyu Li and Hannah Moon and Garrett W. Roell and Yixin Chen and Yinjie J. Tang},
keywords = {feature selection, natural language processing, human intervention, prompt engineering, transfer learning,   },
abstract = {Knowledge mining from synthetic biology journal articles for machine learning (ML) applications is a labor-intensive process. The development of natural language processing (NLP) tools, such as GPT-4, can accelerate the extraction of published information related to microbial performance under complex strain engineering and bioreactor conditions. As a proof of concept, we proposed prompt engineering for a GPT-4 workflow pipeline to extract knowledge from 176 publications on two oleaginous yeasts (Yarrowia lipolytica and Rhodosporidium toruloides). After human intervention, the pipeline obtained a total of 2037 data instances. The structured data sets and feature selections enabled ML approaches (e.g., a random forest model) to predict Yarrowia fermentation titers with decent accuracy (R 2 of 0.86 for unseen test data). Via transfer learning, the trained model could assess the production potential of the engineered nonconventional yeast, R. toruloides, for which there are fewer published reports. This work demonstrated the potential of generative artificial intelligence to streamline information extraction from research articles, thereby facilitating fermentation predictions and biomanufacturing development.
}
}
@article{DAUNGSUPAWONG2024361,
title = {Generative Artificial Intelligence in Dental Licensing Examinations: Comment},
journal = {International Dental Journal},
volume = {74},
number = {2},
pages = {361},
year = {2024},
issn = {0020-6539},
doi = {https://doi.org/10.1016/j.identj.2024.01.021},
url = {https://www.sciencedirect.com/science/article/pii/S0020653924000431},
author = {Hinpetch Daungsupawong and Viroj Wiwanitkit}
}
@article{ALMEIDA2025100196,
title = {Artificial intelligence tools for project management: A knowledge-based perspective},
journal = {Project Leadership and Society},
volume = {6},
pages = {100196},
year = {2025},
issn = {2666-7215},
doi = {https://doi.org/10.1016/j.plas.2025.100196},
url = {https://www.sciencedirect.com/science/article/pii/S2666721525000213},
author = {Pedro M. Almeida and Gabriela Fernandes and José M.R.C.A. Santos},
keywords = {Artificial intelligence, Project management, Systematic literature review, Integration, Tools},
abstract = {The rapid evolution of artificial intelligence is pressing the need to understand how organisations can integrate it into namely project management to enhance performance and outcomes. Through a systematic literature review, this paper explores artificial intelligence's potential use in project management. The thematic analysis of relevant literature identified key project management knowledge areas, such as integration, scope, communication, risk and stakeholder management, were as domains where artificial intelligence holds significant potential. The study further investigates the relationship between these knowledge areas and the most suitable types of artificial intelligence tools, such as generative artificial intelligence, and machine learning algorithms for optimisation and automation, based on the dominant knowledge type each knowledge area requires, namely formal, data-driven, or tacit knowledge. Based on the main findings, the study proposes a conceptual framework for the integration of artificial intelligence tools in project management, offering valuable insights for scholars and practitioners. Moreover, guidelines for future research to accelerate the wide adoption of artificial intelligence in the field are proposed.}
}
@article{RAY20231457,
title = {Generative Artificial Intelligence (AI) and Medical Ethics: A Symbiotic Dance for the Future},
journal = {Journal of Oral and Maxillofacial Surgery},
volume = {81},
number = {12},
pages = {1457-1459},
year = {2023},
issn = {0278-2391},
doi = {https://doi.org/10.1016/j.joms.2023.09.015},
url = {https://www.sciencedirect.com/science/article/pii/S0278239123011588},
author = {Partha Pratim Ray}
}
@article{WENGREEN2024A70,
title = {Dietetic Students' Knowledge and Perceptions of Their Use of Generative Artificial Intelligence Now and in the Future},
journal = {Journal of the Academy of Nutrition and Dietetics},
volume = {124},
number = {10, Supplement },
pages = {A70},
year = {2024},
note = {2024 Food & Nutrition Conference & Expo},
issn = {2212-2672},
doi = {https://doi.org/10.1016/j.jand.2024.07.064},
url = {https://www.sciencedirect.com/science/article/pii/S2212267224006245},
author = {H. Wengreen and S. Bevan and K. Kraus}
}
@article{WANG2025100606,
title = {Opportunities and perspectives of artificial intelligence in electrocatalysts design for water electrolysis},
journal = {Energy and AI},
volume = {22},
pages = {100606},
year = {2025},
issn = {2666-5468},
doi = {https://doi.org/10.1016/j.egyai.2025.100606},
url = {https://www.sciencedirect.com/science/article/pii/S2666546825001387},
author = {Qing Wang and Lizhen Wu and Qiang Zheng and Liang An},
keywords = {Artificial intelligence, Electrocatalysts, Water electrolysis, Multiscale design, Automated experimentation},
abstract = {As a key pathway for green hydrogen production, water electrolysis is expected to play a central role in the future energy landscape. However, its large-scale deployment is hindered by challenges related to cost, performance, and durability. The emergence of artificial intelligence (AI) has transformed this field by offering powerful and efficient tools for the design and optimization of electrocatalysts. This review outlines an AI-driven multiscale design framework, highlighting its role at the microscopic scale for identifying atomic-level active sites and key descriptors, at the mesoscopic scale for structural and morphological characterization, and at the macroscopic scale for multi-objective optimization and intelligent control. This multiscale framework demonstrates the potential of AI to accelerate the development of next-generation electrocatalysts. In addition, the integration of generative AI and automated experimental techniques is highlighted as promising strategies to further enhance electrocatalyst discovery and promote the practical implementation of water electrolysis technologies.}
}
@article{SENGUL2025104516,
title = {The effect of artificial intelligence literacy on self-directed learning skills: The mediating role of attitude towards artificial intelligence: A study on nursing and midwifery students},
journal = {Nurse Education in Practice},
volume = {88},
pages = {104516},
year = {2025},
issn = {1471-5953},
doi = {https://doi.org/10.1016/j.nepr.2025.104516},
url = {https://www.sciencedirect.com/science/article/pii/S1471595325002732},
author = {Tuba SENGUL and Seda SARIKOSE and Betül UNCU and Nurten KAYA},
keywords = {Artificial intelligence, Artificial intelligence literacy, Self-directed learning, Nursing education, Midwifery education, Attitude to artificial intelligence},
abstract = {Aim
This study investigates the impact of generative artificial intelligence literacy (GAIL) on self-directed learning skills (SDL) among nursing and midwifery students. Additionally, it examines whether general attitudes toward artificial intelligence (GAAI) mediate this relationship.
Background
Artificial intelligence (AI) has the potential to support the development of clinical decision-making and problem-solving skills in nursing and midwifery education, particularly by enhancing students’ self-directed learning abilities.
Methods
A cross-sectional, descriptive and correlational study design was used. The study was conducted in three universities in Türkiye between January and February 2025. 656 nursing and midwifery students participated, selected through cluster sampling. Data were collected using the GAIL, GAAI and SDL scales. The survey form included descriptive questions regarding participants' socio-demographic characteristics and AI usage patterns. Structural equation modeling was conducted to analyze direct and indirect relationships among variables.
Results
A significant positive effect of GAILS on GAAIS was found (β = 0.75, p < .01). GAILS also had a direct and significant effect on SDLS (β = 0.60, p < .01). However, GAAIS did not mediate the relationship between GAILS and SDLS (β = 0.02, p > .05).
Conclusions
AI literacy significantly enhances SDL in nursing and midwifery students. However, positive attitudes toward AI do not independently foster SDL, highlighting the need for structured AI education in healthcare curricula. Future studies should explore long-term AI literacy interventions to assess their impact on academic outcomes and their potential contributions to clinical reasoning and decision-making skills.}
}
@article{LEWALLEN2025,
title = {Impact of artificial intelligence in vision science: A systematic review of progress, emerging trends, data domain quantification, and critical gaps},
journal = {Survey of Ophthalmology},
year = {2025},
issn = {0039-6257},
doi = {https://doi.org/10.1016/j.survophthal.2025.09.014},
url = {https://www.sciencedirect.com/science/article/pii/S0039625725001717},
author = {Colby F. Lewallen and Davide Ortolan and Dominik Reichert and Ruchi Sharma and Kapil Bharti},
keywords = {Artificial intelligence, Vision science, Ophthalmic imaging, Multimodal AI, Generative AI, Diabetic Retinopathy, Age-related Macular Degeneration},
abstract = {The prominence of artificial intelligence (AI) is growing exponentially, yet its implementation across research domains is uneven. To quantify AI trends in vision science, we evaluated over 100,000 PubMed article metadata spanning 35 years. Using Medical Subject Headings (MeSH) terms, we analyzed trends across four prominent ocular diseases: age-related macular degeneration, diabetic retinopathy, glaucoma, and cataract. Most articles utilized research techniques from at least one of the following domains: biological models, molecular profiling, image-based analysis, and clinical outcomes. Our quantification reveals that AI prominence is disproportionally concentrated in the image-based analysis domain, and, additionally, among 4 diseases evaluated, AI prevalence in cataract research is lagging. Contributing factors towards these disparities include insufficient data standardization, complex data structures, limited data availability, unresolved ethical concerns, and not gaining meaningful improvements over human-based interpretations. By mapping where AI thrives and where it lags, we offer a quantitative reference for funding agencies, clinicians, and vision scientists. Connecting various research domains with multimodal and generative AI could improve diagnostic utility; enabling earlier diagnosis, personalized therapy, reduced healthcare costs, and accelerate innovation. Future work should move AI in vision science beyond image-centric pattern recognition toward integrative, mechanistic analyses that explain – rather than merely detect – disease.}
}
@article{VLACHOPOULOS2024120,
title = {Generative artificial intelligence tools in scientific writing: entering a brave new world?},
journal = {Hellenic Journal of Cardiology},
volume = {77},
pages = {120-121},
year = {2024},
issn = {1109-9666},
doi = {https://doi.org/10.1016/j.hjc.2024.05.014},
url = {https://www.sciencedirect.com/science/article/pii/S1109966624001180},
author = {Charalambos Vlachopoulos and Alexios Antonopoulos and Dimitrios Terentes-Printzios}
}
@article{ZHU2024114132,
title = {OpenAI’s GPT-4o in surgical oncology: Revolutionary advances in generative artificial intelligence},
journal = {European Journal of Cancer},
volume = {206},
pages = {114132},
year = {2024},
issn = {0959-8049},
doi = {https://doi.org/10.1016/j.ejca.2024.114132},
url = {https://www.sciencedirect.com/science/article/pii/S0959804924007883},
author = {Ning Zhu and Nan Zhang and Qipeng Shao and Kunming Cheng and Haiyang Wu}
}
@article{BAGENAL20241118,
title = {Generative artificial intelligence and scientific publishing: urgent questions, difficult answers},
journal = {The Lancet},
volume = {403},
number = {10432},
pages = {1118-1120},
year = {2024},
issn = {0140-6736},
doi = {https://doi.org/10.1016/S0140-6736(24)00416-1},
url = {https://www.sciencedirect.com/science/article/pii/S0140673624004161},
author = {Jessamy Bagenal}
}
@article{SHASTRI20247668,
title = {Use of Generative Artificial Intelligence for Development of Plain Language Summaries: A Blinded Assessment of Education Preferences of the Sickle Cell Disease Community},
journal = {Blood},
volume = {144},
pages = {7668},
year = {2024},
note = {66th ASH Annual Meeting Abstracts},
issn = {0006-4971},
doi = {https://doi.org/10.1182/blood-2024-206965},
url = {https://www.sciencedirect.com/science/article/pii/S0006497124104934},
author = {Oliver Shastri and Orlando Agrippa and Valerie Moss and Eleanor Millard and Lianne More and Eleanor Rose Brown and Seraj Sharif and Chris Finch},
abstract = {Introduction: Sickle cell disease (SCD) is an inherited condition that reduces life expectancy and has a profound impact on quality of life. Assessment of social media conversations in the SCD community in the UK highlighted health inequities, including issues with access to emergency care, low levels of healthcare professional empathy, and racial bias/stigmatization (Shastri O, et al. ASH 2023; abstract 1057). This emphasizes the urgent unmet need for additional education. Use of generative artificial intelligence (GenAI) to facilitate the development of medical content, including plain language summaries (PLS) of research may increase efficiency, reduce resource cost and ultimately improve accessibility to educational information across a range of audiences. We assessed the ability of GenAI to develop a PLS of our social media listening study. Methods: We developed 3 written versions of a PLS of this study: human-written by a medical writer, AI-generated, and hybrid AI-human, where a person living with SCD edited the AI version for readability. Each was ~300-400 words and with a target reading age of 12 years. The AI PLS was developed using Pfizer's GenAI tool, MAIA (Medical AI assistant). A video version of each written PLS was developed using the AI tool, Synthesia. People with SCD and their carers (≥18 years of age) were recruited via telephone to complete an online survey to assess the understandability of the 3 written PLS and preference for written versus video PLS. Participants were presented with 1 of the 3 written PLS at random and asked to assess how easily they understood it on a 5-point scale (1=very difficult; 2=difficult; 3=neither difficult nor easy; 4=easy; 5=very easy). They were then asked 3 multiple-choice questions to gauge their understanding. Participants then rated the other 2 written PLS and were asked to rank all 3 in order of most easily understood. Finally, participants watched the video version of their top-rated written PLS and stated which format they preferred. Participants were blinded to PLS source. The Flesch-Kincaid calculator (https://goodcalculators.com/flesch-kincaid-calculator/) was used to provide an objective measure of readability for each PLS. Results: Of 93 participants, there were 88 living with SCD and 5 caring for someone with SCD. The AI versions of the PLS achieved similar scores for understandability to the human-written version: mean ± standard deviation understandability scores were 4.1 ± 0.9 (human), 4.0 ± 0.9 (AI), and 3.9 ± 0.8 (AI-hybrid). Overall, 81% of participants identified the human PLS as easy or very easy to read, similar to 76% for the AI PLS, and 74% for the AI-hybrid PLS. Overall, 41 participants (44%) ranked the human PLS in first place for understandability, 31 (33%) the AI PLS, and 21 (23%) the AI-hybrid PLS. For the multiple-choice questions, results were similar regardless of which PLS participants saw first, with over 85% correctly identifying the main findings of the study and the conclusions of the author; however, 63% incorrectly thought the data on which the PLS was based were obtained from interviewing people affected by SCD rather than social media listening. Fifty-four participants (58%) preferred the video PLS over the written PLS, 27 participants (29%) preferred the written PLS and 12 (13%) had no preference. Flesch-Kincaid scores for the three PLS were as follows: human (reading ease score, 62; reading level, 8th to 9th grade); AI (reading ease score, 58; reading level, 10th to 12th grade); AI-hybrid (reading ease score, 63; reading level, 8th to 9th grade). Conclusion: There is a clear need for additional resources and education in SCD, which may be supported by the development of PLS. The limited studies that have assessed the capabilities of AI to generate PLS to date have focussed on clinical research. We have now expanded this to assess use of AI to develop PLS from a social media listening study that evaluated real-world experiences of the UK SCD community. Our study suggests that GenAI can generate PLS that are as informative as conventional, human-written PLS, and achieve similar readability scores as judged by people living with SCD in the UK (mean 4.1 for human-written, 4.0 for AI and 3.9 for AI-hybrid). We propose that GenAI may offer an alternative to conventional human-written PLS, providing a time- and resource-efficient solution to increase accessibility to educational resources.}
}
@article{BAKER2024101054,
title = {Student Perceptions of Generative Artificial Intelligence in Didactic Patient Presentations},
journal = {American Journal of Pharmaceutical Education},
volume = {88},
number = {9},
pages = {101054},
year = {2024},
issn = {0002-9459},
doi = {https://doi.org/10.1016/j.ajpe.2024.101054},
url = {https://www.sciencedirect.com/science/article/pii/S0002945924107735},
author = {Carrie N. Baker and Jordan Powe and Sophia Jones and Emily Ghassemi and Riley Bowers}
}
@article{KHENE2024160,
title = {Development of a Personalized Chat Model Based on the European Association of Urology Oncology Guidelines: Harnessing the Power of Generative Artificial Intelligence in Clinical Practice},
journal = {European Urology Oncology},
volume = {7},
number = {1},
pages = {160-162},
year = {2024},
issn = {2588-9311},
doi = {https://doi.org/10.1016/j.euo.2023.06.009},
url = {https://www.sciencedirect.com/science/article/pii/S2588931123001396},
author = {Zine-Eddine Khene and Pierre Bigot and Romain Mathieu and Morgan Rouprêt and Karim Bensalah}
}
@article{DHAWAN202447,
title = {Generative artificial intelligence in surgery: balancing innovation with ethical challenges},
journal = {Journal of Plastic, Reconstructive & Aesthetic Surgery},
volume = {90},
pages = {47-48},
year = {2024},
issn = {1748-6815},
doi = {https://doi.org/10.1016/j.bjps.2024.02.007},
url = {https://www.sciencedirect.com/science/article/pii/S1748681524000731},
author = {Ravi Dhawan and Akshay Nair and Denys Shay}
}
@article{AGARWAL20241121,
title = {Ethics of using generative pretrained transformer and artificial intelligence systems for patient prior authorizations},
journal = {Journal of the American Academy of Dermatology},
volume = {90},
number = {5},
pages = {1121-1122},
year = {2024},
issn = {0190-9622},
doi = {https://doi.org/10.1016/j.jaad.2023.04.030},
url = {https://www.sciencedirect.com/science/article/pii/S0190962223007284},
author = {Aneesh Agarwal and Benjamin Stoff},
keywords = {AI, artificial intelligence, dermatology, ethics, generative pretrained transformer, GPT, prior authorization}
}
@article{SOHN202061,
title = {Artificial intelligence in the fashion industry: consumer responses to generative adversarial network (GAN) technology},
journal = {International Journal of Retail & Distribution Management},
volume = {49},
number = {1},
pages = {61-80},
year = {2020},
issn = {0959-0552},
doi = {https://doi.org/10.1108/IJRDM-03-2020-0091},
url = {https://www.sciencedirect.com/science/article/pii/S0959055220000820},
author = {Kwonsang Sohn and Christine Eunyoung Sung and Gukwon Koo and Ohbyung Kwon},
keywords = {Artificial intelligence (AI), Generative adversarial networks (GANs), Consumption value theory, AI aversion, Fashion consumer behaviour},
abstract = {Purpose
This study examines consumers' evaluations of product consumption values, purchase intentions and willingness to pay for fashion products designed using generative adversarial network (GAN), an artificial intelligence technology. This research investigates differences between consumers' evaluations of a GAN-generated product and a non-GAN-generated product and tests whether disclosing the use of GAN technology affects consumers' evaluations.
Design/methodology/approach
Sample products were developed as experimental stimuli using cycleGAN. Data were collected from 163 members of Generation Y. Participants were assigned to one of the three experimental conditions (i.e. non-GAN-generated images, GAN-generated images with disclosure and GAN-generated images without disclosure). Regression analysis and ANOVA were used to test the hypotheses.
Findings
Functional, social and epistemic consumption values positively affect willingness to pay in the GAN-generated products. Relative to non-GAN-generated products, willingness to pay is significantly higher for GAN-generated products. Moreover, evaluations of functional value, emotional value and willingness to pay are highest when GAN technology is used, but not disclosed.
Originality/value
This study evaluates the utility of GANs from consumers' perspective based on the perceived value of GAN-generated product designs. Findings have practical implications for firms that are considering using GANs to develop products for the retail fashion market.}
}
@article{HASAN2025545,
title = {Generative Versus Nongenerative Artificial Intelligence},
journal = {Arthroscopy: The Journal of Arthroscopic & Related Surgery},
volume = {41},
number = {3},
pages = {545-546},
year = {2025},
issn = {0749-8063},
doi = {https://doi.org/10.1016/j.arthro.2024.12.001},
url = {https://www.sciencedirect.com/science/article/pii/S0749806324010181},
author = {Sayyida S. Hasan and Joshua J. Woo and Mark P. Cote and Prem N. Ramkumar},
abstract = {Abstract
Artificial intelligence (AI) is a colossal buzzword, a confusing subject matter, but also an inevitable reality. Generative and nongenerative AI are the 2 core subtypes of AI. Generative AI uses current data to understand patterns and generate new information, and it is especially valuable in producing synthetic medical images, enhancing surgical simulations, and expanding training datasets. Techniques such as generative adversarial networks (GANs), large language models (LLMs), and variational autoencoders (VAEs) allow for the creation of realistic simulations, text, and models that can be used for perioperative communication and planning. Conversely, nongenerative AI is centered on the examination and categorization of pre-existing data to formulate predictions or decisions—the most popular denomination namely machine learning. This approach is instrumental in tasks such as forecasting surgical outcomes, segmenting medical images, and determining patient risk profiles. Models such as convolutional neural networks (CNNs), random forests, and support vector machines (SVMs) are widely used for these purposes, demonstrating high accuracy and reliability in clinical decision making. Although generative AI offers innovative tools for creating new data and simulations, nongenerative AI excels in analyzing existing data to inform patient care. Both approaches have the potential of supporting clinical workflows to automate redundancies and improve efficiencies. However, there are also limitations in the application of AI in orthopaedics, including the potential for bias in models, the challenge of interpreting AI-driven insights, and the ethics of oversight. As the integration of AI in orthopaedics continues to grow, it is essential for practitioners to understand these technologies' capabilities and limitations to harness their full potential and establish appropriate governance.}
}
@article{MATSUBARA2025172,
title = {Research misconduct: Use of generative artificial intelligence in writing may lower the threshold},
journal = {European Journal of Obstetrics & Gynecology and Reproductive Biology},
volume = {304},
pages = {172-173},
year = {2025},
issn = {0301-2115},
doi = {https://doi.org/10.1016/j.ejogrb.2024.11.038},
url = {https://www.sciencedirect.com/science/article/pii/S030121152400650X},
author = {Shigeki Matsubara and Daisuke Matsubara}
}
@article{MACKENZIE20239,
title = {Surprising Advances in Generative Artificial Intelligence Prompt Amazement—and Worries},
journal = {Engineering},
volume = {25},
pages = {9-11},
year = {2023},
issn = {2095-8099},
doi = {https://doi.org/10.1016/j.eng.2023.04.004},
url = {https://www.sciencedirect.com/science/article/pii/S2095809923001613},
author = {Dana Mackenzie}
}
@article{WEBBER2025781,
title = {The Future of Artificial Intelligence in Medical Education and Continuing Medical Education},
journal = {Primary Care: Clinics in Office Practice},
volume = {52},
number = {4},
pages = {781-797},
year = {2025},
note = {AI in Primary Care},
issn = {0095-4543},
doi = {https://doi.org/10.1016/j.pop.2025.07.010},
url = {https://www.sciencedirect.com/science/article/pii/S0095454325000715},
author = {Chase J. Webber and Pat Whitworth and Shane P. Stenner},
keywords = {Artificial intelligence, Medical education, Continuing medical education, Generative AI, Large language models, Competency-based education, AI literacy}
}
@article{DINAPOLI2024S2935,
title = {1871: Generative artificial intelligence for toxicity detection in radiotherapy},
journal = {Radiotherapy and Oncology},
volume = {194},
pages = {S2935-S2936},
year = {2024},
note = {ESTRO 2024, 3-7 May 2024, Glasgow, UK},
issn = {0167-8140},
doi = {https://doi.org/10.1016/S0167-8140(24)02186-8},
url = {https://www.sciencedirect.com/science/article/pii/S0167814024021868},
author = {Nicola Dinapoli and Francesco Esposito and Martina D'Antoni and Vito Lanzotti and Luca Tagliaferri and Mariangela Massaccesi and Francesco Miccichè and Vincenzo Valentini and Maria Antonietta Gambacorta}
}
@article{MARTEL2025,
title = {Artificial intelligence for precision medicine},
journal = {Therapies},
year = {2025},
issn = {0040-5957},
doi = {https://doi.org/10.1016/j.therap.2025.10.003},
url = {https://www.sciencedirect.com/science/article/pii/S0040595725001155},
author = {Marie-Elise Martel and Adan José-Garcia and Celine Vens and Maarten De Vos and Vincent Sobanski},
keywords = {Precision medicine, Healthcare, Artificial intelligence, Review},
abstract = {Summary
Introduction: Precision medicine aims to tailor healthcare decisions and interventions to the unique biological and clinical characteristics of each patient. The recent convergence of artificial intelligence (AI) with advances in digital health, omics, and big data analytics has accelerated progress toward this goal. AI technologies - particularly machine learning, deep learning, natural language processing and generative large language models - enable the rapid and meaningful analysis of complex biomedical datasets, supporting more individualized care. Purpose of review: In this narrative review, we provide an accessible overview of the core principles of AI for healthcare professionals and explore its practical applications across the spectrum of precision medicine. Real-world examples highlight how AI is being used to enhance early diagnosis, guide treatment selection, support disease prevention, and even contribute directly to therapeutic interventions. Alongside these advances, we discuss critical limitations and challenges, including ethical considerations, algorithmic bias, data privacy concerns, environmental impact, and practical barriers to clinical implementation. Conclusion: This review offers both an introduction to AI and a practical overview of how it is being used, and where its limitations lie, in precision medicine, with the goal of helping healthcare professionals understand these evolving tools and use them efficiently and responsibly in clinical practice.}
}
@article{HEIKKILA202518,
title = {Human intelligence versus artificial intelligence in classifying economics research articles: exploratory evidence},
journal = {Journal of Documentation},
volume = {81},
number = {7},
pages = {18-30},
year = {2025},
issn = {0022-0418},
doi = {https://doi.org/10.1108/JD-05-2024-0104},
url = {https://www.sciencedirect.com/science/article/pii/S0022041825000050},
author = {Jussi T.S. Heikkilä},
keywords = {JEL codes, Artificial intelligence, Large language models, Search costs, Bounded rationality},
abstract = {Purpose
We compare human intelligence to artificial intelligence (AI) in the choice of appropriate Journal of Economic Literature (JEL) codes for research papers in economics.
Design/methodology/approach
We compare the JEL code choices related to articles published in the recent issues of the Journal of Economic Literature and the American Economic Review and compare these to the original JEL code choices of the authors in earlier working paper versions and JEL codes recommended by various generative AI systems (OpenAI’s ChatGPT, Microsoft’s Copilot, Google’s Gemini) based on the abstracts of the articles.
Findings
There are significant discrepancies and often limited overlap between authors’ choices of JEL codes, editors’ choices as well as the choices by contemporary widely used AI systems. However, the observations suggest that generative AI can augment human intelligence in the micro-task of choosing the JEL codes and, thus, save researchers time.
Research limitations/implications
Rapid development of AI systems makes the findings quickly obsolete.
Practical implications
AI systems may economize on classification costs and (semi-)automate the choice of JEL codes by recommending the most appropriate ones. Future studies may apply the presented approach to analyze whether the JEL code choices between authors, editors and AI systems converge and become more consistent as humans increasingly interact with AI systems.
Originality/value
We assume that the choice of JEL codes is a micro-task in which boundedly rational decision-makers rather satisfice than optimize. This exploratory experiment is among the first to compare human intelligence and generative AI in choosing and justifying the choice of optimal JEL codes.}
}
@article{KANG2025100245,
title = {Evaluatology-driven artificial intelligence},
journal = {BenchCouncil Transactions on Benchmarks, Standards and Evaluations},
pages = {100245},
year = {2025},
issn = {2772-4859},
doi = {https://doi.org/10.1016/j.tbench.2025.100245},
url = {https://www.sciencedirect.com/science/article/pii/S2772485925000584},
author = {Guoxin Kang and Wanling Gao and Jianfeng Zhan},
keywords = {Evaluatology, Artificial intelligence},
abstract = {The prevailing data-driven paradigm in AI has largely neglected the generative nature of data. All data, whether observational or experimental, are produced under specific conditions, yet current approaches treat them as context-free artifacts. This neglect results in uneven data quality, limited interpretability, and fragility when models face novel scenarios. Evaluatology reframes evaluation as the process of inferring the influence of an evaluated object on the affected factors and attributing the evaluation outcome to specific ones. Among these factors, a minimal set of indispensable elements determines how changes in conditions propagate to outcomes. This essential set constitutes the evaluation conditions. Together, the evaluated object and its evaluation conditions form a self-contained evaluation system — a structured unit that anchors evaluation to its essential context. We propose an evaluatology-based paradigm, which spans the entire AI lifecycle — from data generation to training and evaluation. Within each self-contained evaluation system, data are generated and distilled into their invariant informational structures. These distilled forms are abstracted into reusable causal-chain schemas, which can be instantiated as training examples. By explicitly situating every learning instance within such condition-aware systems, evaluation is transformed from a passive, post-hoc procedure into an active driver of model development. This evaluation-based paradigm enables the construction of causal training data that are interpretable, traceable, and reusable, while reducing reliance on large-scale, unstructured datasets. This paves the way toward scalable, transparent, and epistemically grounded AI.}
}
@article{MAY2024155,
title = {Would Uro_Chat, a Newly Developed Generative Artificial Intelligence Large Language Model, Have Successfully Passed the In-Service Assessment Questions of the European Board of Urology in 2022?},
journal = {European Urology Oncology},
volume = {7},
number = {1},
pages = {155-156},
year = {2024},
issn = {2588-9311},
doi = {https://doi.org/10.1016/j.euo.2023.08.013},
url = {https://www.sciencedirect.com/science/article/pii/S2588931123001785},
author = {Matthias May and Katharina Körner-Riffard and Martin Marszalek and Klaus Eredics}
}
@article{ECKARDT20232268,
title = {Mimicking Clinical Trials with Synthetic Acute Myeloid Leukemia Patients Using Generative Artificial Intelligence},
journal = {Blood},
volume = {142},
pages = {2268},
year = {2023},
note = {65th ASH Annual Meeting Abstracts},
issn = {0006-4971},
doi = {https://doi.org/10.1182/blood-2023-179817},
url = {https://www.sciencedirect.com/science/article/pii/S0006497123088705},
author = {Jan-Niklas Eckardt and Waldemar Hahn and Christoph Röllig and Sebastian Stasik and Uwe Platzbecker and Carsten Müller-Tidow and Hubert Serve and Claudia D Baldus and Christoph Schliemann and Kerstin Schäfer-Eckart and Maher Hanoun and Martin Kaufmann and Andreas Burchert and Christian Thiede and Johannes Schetelig and Martin Bornhäuser and Markus Wolfien and Jan Moritz Middeke},
abstract = {Data sharing is often hindered by concerns of patient privacy, regulatory aspects, and proprietary interests thereby impeding scientific progress and establishing a gatekeeping mechanism in clinical medicine since obtaining large data sets is costly and time-consuming. We employed two different generative artificial intelligence (AI) technologies: CTAB-GAN+ and Normalizing Flows (NFlow) to synthesize clinical trial data based on pooled patient data from four previous multicenter clinical trials of the German Study Alliance Leukemia (AML96, AML2003, AML60+, SORAML) that enrolled adult patients (n=1606) with acute myeloid leukemia (AML) who received intensive induction therapy. As a generative adversarial network (GAN), CTAB-GAN+ consists of two adversarial networks: a generator producing synthetic samples from random noise and a discriminator aiming to distinguish between real and synthetic samples. The model converges as the discriminator can no longer reliably differentiate between real or synthetic data. Contrastingly, NFlow consists of a sequence of invertible transformations (flows) starting from a simple base distribution and gradually adding complexity to better mirror the training data. Both models were trained on tabular data including demographic, laboratory, molecular genetic and cytogenetic patient variables. Detection of molecular alterations in the original cohort was performed via next-generation sequencing (NGS) using the TruSight Myeloid Sequencing Panel (Illumina, San Diego, CA, USA) with a 5% variant-allele frequency (VAF) mutation calling cut-off. For cytogenetics, standard techniques for chromosome banding and fluorescence-in-situ-hybridization (FISH) were used. Hyperparameter tuning of generative models was conducted using the Optuna Framework. For each model, we used a total of 70 optimization trials to optimize a custom score inspired by TabSynDex which assesses both the resemblance of the synthetic data to real training data and its utility. Pairwise analyses were conducted between the original and both synthetic data sets, respectively. All tests were carried out as two-sided tests using a significance level α of 0.05. Table 1 summarizes baseline patient characteristics and outcome for both synthetic cohorts compared to the original cohort. Firstly, we found both models to adequately represent patient features, albeit that some individual variables showed a statistically significant deviation from the original cohort. It is important to note that for such a large sample size (n=1606 for each cohort), even miniscule differences can be rendered statistically significant notwithstanding any meaningful clinical difference. Interestingly, variables that deviated from the original distribution were different for both models indicating model architecture to play a vital role in sample representation: While CTAB-GAN+ showed significant deviations for both age and sex, NFlow showed significant deviations for AML status. Complete remission rate was similar between original (70.7%, odds ratio [OR]: 2.41) and CTAB-GAN+ (73.7%, OR: 2.81, p=0.059) and NFlow (69.1%, OR: 2.24, p=0.356). For event-free survival (EFS), which was not included as a target in hyperparameter tuning, both networks deviated significantly from the original cohort (original: median 7.2 months, HR: 1.36; CTAB-GAN+: median 12.8 months, HR 0.74, p<0.001; NFlow: median 9.0 months, HR: 0.87, p=0.001). Overall survival (OS) was well represented by NFlow compared to the original cohort, while CTAB-GAN+ showed a significant deviation (original: median 17.5 months, HR: 1.14; CTAB-GAN+: median 19.5 months, HR 0.88, p<0.001; NFlow: median 16.2 months, HR: 1.00, p=0.055). Both models showed an adequate graph representation in Kaplan-Meier analysis (Figure 1). Here, we demonstrate using two different generative AI technologies that synthetic data generation provides an attractive solution to circumvent issues in current standards of data collection and sharing. It effectively allows for bypassing logistical, organizational, and financial burdens, as well as regulatory and ethical concerns. Ultimately, this enables explorative research inquiries into previously inaccessible data sets and offers the prospect of fully synthetic control arms in prospective clinical trials.}
}
@article{GARCIARUDOLPH2026101121,
title = {Comment on “Applying artificial intelligence to clinical decision support in mental health: What have we learned?”},
journal = {Health Policy and Technology},
volume = {15},
number = {1},
pages = {101121},
year = {2026},
issn = {2211-8837},
doi = {https://doi.org/10.1016/j.hlpt.2025.101121},
url = {https://www.sciencedirect.com/science/article/pii/S2211883725001492},
author = {Alejandro García-Rudolph and David Sanchez-Pinsach and Eloy Opisso and Beatriz Castaño},
keywords = {Artificial intelligence, ChatGPT, Large language models, Mental health, Clinical decision support system, Depression}
}
@article{COLBRAN2023105008,
title = {Generative artificial intelligence in Journal of Biological Chemistry},
journal = {Journal of Biological Chemistry},
volume = {299},
number = {8},
pages = {105008},
year = {2023},
issn = {0021-9258},
doi = {https://doi.org/10.1016/j.jbc.2023.105008},
url = {https://www.sciencedirect.com/science/article/pii/S0021925823020367},
author = {Roger J. Colbran and Alex Toker}
}
@article{KSHETRI2024102716,
title = {Generative artificial intelligence in marketing: Applications, opportunities, challenges, and research agenda},
journal = {International Journal of Information Management},
volume = {75},
pages = {102716},
year = {2024},
issn = {0268-4012},
doi = {https://doi.org/10.1016/j.ijinfomgt.2023.102716},
url = {https://www.sciencedirect.com/science/article/pii/S026840122300097X},
author = {Nir Kshetri and Yogesh K. Dwivedi and Thomas H. Davenport and Niki Panteli},
keywords = {ChatGPT, Customer engagement, Customer experience, Generative AI, Personalization},
abstract = {While all functional areas in organizations are benefiting from the recent development in generative artificial intelligence (GAI), marketing has been particularly affected positively by this breakthrough innovation. However, scholars have not paid attention to the transformative impacts GAI has on marketing activities. This editorial article aims to fill this void. It outlines the current state of generative artificial intelligence in marketing. The article discusses the facilitators and barriers for the use of generative artificial intelligence in marketing. It highlights the effectiveness of insights generated by GAI in personalizing content and offerings and argues that marketing content generated by GAI is likely to be more personally relevant than that produced by earlier generations of digital technologies. The article explains how higher efficiency and productivity of marketing activities can be achieved by using GAI to create marketing content. It also describes the roles of insights and marketing content generated by GAI to improve the sales lead generation process. Implications for research, practice and policy are also discussed.}
}
@article{DABBAGH2025389,
title = {The Role of Artificial Intelligence in Medicine with a Special Focus on Anesthesiology and Perioperative Care},
journal = {Anesthesiology Clinics},
volume = {43},
number = {3},
pages = {389-403},
year = {2025},
note = {Artificial Intelligence in Anesthesiology},
issn = {1932-2275},
doi = {https://doi.org/10.1016/j.anclin.2025.04.002},
url = {https://www.sciencedirect.com/science/article/pii/S1932227525000278},
author = {Ali Dabbagh and A. Sassan Sabouri},
keywords = {Intelligence, Artificial learning, Turing test, Machine learning, Learning models, Generative AI, Large language mode, Prediction model}
}
@article{SALMAN2024S776,
title = {ID: 4120624 Building Patient Archetypes to Analyze Willingness to Change using New Technologies: Generative Artificial Intelligence with the Goal of More Optimally Influencing Change in Patient Behaviors with Atrial Fibrillation},
journal = {Heart Rhythm},
volume = {21},
number = {9, Supplement },
pages = {S776-S777},
year = {2024},
note = {HRX AbstracX 2024},
issn = {1547-5271},
doi = {https://doi.org/10.1016/j.hrthm.2024.07.043},
url = {https://www.sciencedirect.com/science/article/pii/S1547527124029904},
author = {S. Salman and I. Tripuraneni and K. Lingineni and A. Vemulapalli and S. Venigalla and A. Tripuraneni}
}
@article{MULAT2025107232,
title = {Application of artificial intelligence in microbial drug discovery: Unlocking new frontiers in biotechnology},
journal = {Journal of Microbiological Methods},
volume = {237},
pages = {107232},
year = {2025},
issn = {0167-7012},
doi = {https://doi.org/10.1016/j.mimet.2025.107232},
url = {https://www.sciencedirect.com/science/article/pii/S0167701225001484},
author = {Mulugeta Mulat and Riza Jane S. Banicod and Nazia Tabassum and Aqib Javaid and Tae-Hee Kim and Young-Mog Kim and Fazlurrahman Khan},
keywords = {Artificial intelligence, Antimicrobial resistance, Microbial pathogens, Genomics, Drug discovery},
abstract = {Artificial intelligence (AI) is revolutionizing antimicrobial drug discovery by delivering major improvements in precision, innovation, and efficiency for combating bacterial, fungal, and viral pathogens. Traditional approaches to developing treatments for microbial infections are often hampered by high costs, lengthy timelines, and frequent failures. Modern AI technologies, particularly deep learning, machine learning, computational biology, and big data analytics, provide robust solutions to these challenges by analyzing large-scale biological datasets to predict molecular interactions, identify promising treatment candidates, and expedite both preclinical and clinical development. Innovative techniques such as generative adversarial networks for novel compound discovery, reinforcement learning for optimizing antimicrobial candidates, and natural language processing for extracting knowledge from biomedical literature are now vital to infectious disease research. These approaches facilitate early toxicity prediction, microbial target identification, virtual screening, and the development of more individualized therapies. Notwithstanding these advances, challenges remain, including inconsistent data quality, limited interpretability, and unresolved ethical or legal concerns. This review examines recent advancements in AI applications for microbial drug discovery, with a focus on de novo molecular design, ligand- and structure-based screening, and AI-enabled biomarker identification. Remaining application barriers and promising future directions in AI-driven antimicrobial drug development are also elucidated. Collectively, these innovations are poised to accelerate the discovery of new therapies, reduce costs, and enhance patient outcomes in the fight against infectious diseases.}
}
@article{GUO2024102408,
title = {Letter to the editor “A review of top cardiology and cardiovascular medicine journal guidelines regarding the use of generative artificial intelligence tools in scientific writing”},
journal = {Current Problems in Cardiology},
volume = {49},
number = {3},
pages = {102408},
year = {2024},
issn = {0146-2806},
doi = {https://doi.org/10.1016/j.cpcardiol.2024.102408},
url = {https://www.sciencedirect.com/science/article/pii/S0146280624000471},
author = {Dongke Guo and Yonghua Fu and Zhongxin Zhu}
}
@article{RICHTER2023385,
title = {Foot and Ankle Surgery declares use of generative artificial intelligence like Chat Generative Pre-trained Transformer (ChatGPT) for scientific publications},
journal = {Foot and Ankle Surgery},
volume = {29},
number = {5},
pages = {385-386},
year = {2023},
issn = {1268-7731},
doi = {https://doi.org/10.1016/j.fas.2023.05.002},
url = {https://www.sciencedirect.com/science/article/pii/S1268773123000802},
author = {Martinus Richter}
}
@article{ALDREABI2025100456,
title = {Unveiling the dynamics of generative AI adoption: A business intelligence analysis through topic modeling-based bibliometric study},
journal = {Computers and Education: Artificial Intelligence},
volume = {9},
pages = {100456},
year = {2025},
issn = {2666-920X},
doi = {https://doi.org/10.1016/j.caeai.2025.100456},
url = {https://www.sciencedirect.com/science/article/pii/S2666920X25000967},
author = {Hanadi Aldreabi and Mohammad Alhur and Manaf Al-Okaily and Dhia Qasim and Nisreen K. Dahdoul and Fadi S. Shiyyab},
keywords = {AI tools, ChatGPT, Generative AI, Educational technology, Business intelligence, Bibliometric study},
abstract = {Generative Artificial Intelligence (GenAI) has gained notable attention in educational literature, with supporters and critics expressing varying opinions. Despite its popularity, only a few reviews are available on the subject, with limitations such as small sample sizes and limited scope. This study aims to clarify the major themes influencing the discussion on GenAI in educational contexts. It employs a strong Business Intelligence paradigm and uses bibliometric analysis and topic modeling focusing on the R program's structural topic model (STM) Package, VOSviewer, and bibliometric software. The results highlight the esteem of GenAI in education and evidence of international collaboration in the research process dedicated to enhancing the rapidly evolving field of GenAI. The scientometric indexes indicate that the diversity of journals has the significant impact on GenAI in education. While Lotka's Law suggests that the field is still in its early stages, the collaborative network demonstrates strong connections among researchers, a positive indicator of future progress. Moreover, the STM method has identified nine pivotal topics grouped into three categories relating to GenAI in education. By shedding light on these emerging themes, this study provides educators and researchers with valuable insights into the future of GenAI in education.}
}
@article{ZHENG2025106211,
title = {Antitrust in artificial intelligence infrastructure – between regulation and innovation in the EU, the US, and China},
journal = {Computer Law & Security Review},
volume = {59},
pages = {106211},
year = {2025},
issn = {2212-473X},
doi = {https://doi.org/10.1016/j.clsr.2025.106211},
url = {https://www.sciencedirect.com/science/article/pii/S2212473X25000835},
author = {Kena Zheng},
keywords = {Artificial intelligence infrastructure, Access data, Assess computational resources, Antitrust law, Innovation, Regulation},
abstract = {The enormous amount of data and the substantial computational resources are crucial inputs of artificial intelligence (AI) infrastructure, enabling the development and training of AI models. Incumbent firms in adjacent technology markets hold significant advantages in AI development, due to their established large user bases and substantial financial resources. These advantages facilitate the accumulation of enormous amounts of data, and the establishment of computational infrastructure necessary for sufficient data processing and high-performance computing. By controlling data and computational resources, incumbents raise entry barriers, leverage advantages to favour their own AI services, and drive significant vertical integration across the AI supply chain, thereby entrenching their market dominance and shielding themselves from competition. This article examines regulatory responses to these antitrust risks in the European Union (EU), the United States (US), and China, given their leadership in digital regulation and AI development. It demonstrates that the EU’s Digital Markets Act, and China’s Interim Measures for the Management of Generative Artificial Intelligence Services introduce broadly framed yet applicable rules to address challenges related to data and computational resources in AI markets. Conversely, the US lacks both AI regulations and digital-specific competition laws, instead adopting innovation-centric policies aimed at ensuring its AI dominance globally. Given the strategic importance of AI development, all three jurisdictions have adopted a cautious approach in investigating potential abusive practices.}
}
@article{WALTERS2024S626,
title = {SA62 Evaluating Generative Artificial Intelligence (GenAI) in Health Technology Assessment (HTA) Content Generation: A Proof-of-Concept Using Canadian Agency for Drugs and Technologies in Health (CADTH) Reimbursement Dossier Forms},
journal = {Value in Health},
volume = {27},
number = {12, Supplement },
pages = {S626},
year = {2024},
note = {ISPOR Europe 2024},
issn = {1098-3015},
doi = {https://doi.org/10.1016/j.jval.2024.10.3143},
url = {https://www.sciencedirect.com/science/article/pii/S1098301524060066},
author = {J. Walters and I. Guerra and K. Rtveladze and J. Joseph and R. Shankar and T. Wiemken and P.A. Dubé and T.C. Woodward}
}
@article{DISSANAYAKE2025101222,
title = {Artificial intelligence and management Education: Bibliometric analysis},
journal = {The International Journal of Management Education},
volume = {23},
number = {3},
pages = {101222},
year = {2025},
issn = {1472-8117},
doi = {https://doi.org/10.1016/j.ijme.2025.101222},
url = {https://www.sciencedirect.com/science/article/pii/S1472811725000928},
author = {Hiranya Dissanayake and Otilia Manta and Anuradha Iddagoda and Maria Palazzo},
keywords = {Artificial intelligence, Management education, Bibliometric analysis, ChatGPT, Collaborative analysis, Thematic analysis},
abstract = {A group of technologies known as artificial intelligence allow computers to carry out a number of sophisticated tasks, including as seeing, comprehending, and translating spoken and written language, analyzing data, and formulating suggestions. The significance of AI lies in its ability to boost productivity, automate processes, better decision-making, and stimulate innovation in a variety of sectors. Education is essential for societal advancement, economic success, and personal development because it promotes critical thinking and creativity while providing chances for better employment, informed citizenship, and a satisfying existence. This study aims to assess the development and application of AI in management education through a bibliometric analysis. It explores publication trends, author influence, collaborative networks, keyword evolution, and thematic structures to uncover intellectual landscape and future directions of this emerging field. The study offers insights into the transformative role of AI, especially generative technologies like ChatGPT, in reshaping business and management education worldwide.}
}
@article{ENCARNACAO2025106872,
title = {Artificial intelligence in wound care education: Scoping review},
journal = {Nurse Education Today},
volume = {155},
pages = {106872},
year = {2025},
issn = {0260-6917},
doi = {https://doi.org/10.1016/j.nedt.2025.106872},
url = {https://www.sciencedirect.com/science/article/pii/S0260691725003090},
author = {Rúben Encarnação and José Alves and Ana Marques and João Neves-Amado and Paulo Alves},
keywords = {Artificial intelligence, Education, Health Education, Nursing Education Research, Review, Wounds, Injuries},
abstract = {Background
Artificial intelligence is transforming healthcare education, offering innovative teaching and skill development approaches. However, its implementation and effectiveness in wound care education remain unclear.
Objective
To map and analyze the available evidence on the potential impact of artificial intelligence in wound care education, identify knowledge gaps, and provide recommendations for future research.
Design/methods
This scoping review followed the Joanna Briggs Institute guidelines for scoping reviews and the PRISMA-ScR guidelines. The search was first conducted in December 2023 and updated on 30 November 2024 across the following databases: CINAHL Ultimate, MEDLINE, Cochrane Library, Academic Search Complete, Scientific Electronic Library Online (Scielo), Scopus, and Web of Science. Grey literature was accessed through Scientific Open Access Scientific Repositories of Portugal (RCAAP), ProQuest Dissertations and Theses, OpenAIRE, and Open Dissertations. Additional searches were performed in Google Scholar and specific journals, including the International Wound Journal, Skin Research and Technology, Journal of Wound Care, and Wound Repair and Regeneration. Eligibility criteria encompassed any study design exploring the use of artificial intelligence in wound care education, published in English, Portuguese, or Spanish, with no restrictions on publication date.
Results
This review revealed diverse artificial intelligence applications in wound care education, including adaptive e-learning platforms, virtual and augmented reality simulations, generative artificial intelligence for educational content, and diagnostic and treatment tools. These technologies offer personalized learning experiences, real-time feedback, and interactive engagement to enhance clinical skills. Despite their promise, most studies lacked empirical validation, highlighting significant gaps in integrating artificial intelligence into wound care education.
Conclusions
This review highlights artificial intelligence's transformative potential to revolutionize wound care education by fostering interactive and evidence-based learning environments. This work highlights the need for collaboration among educators, policymakers, and researchers. Future research is needed to ensure effective, ethical, and equitable integration of artificial intelligence in wound care education.}
}

@article{STIDHAM2025432,
title = {Artificial Intelligence–Enabled Clinical Trials in Inflammatory Bowel Disease: Automating and Enhancing Disease Assessment and Study Management},
journal = {Gastroenterology},
volume = {169},
number = {3},
pages = {432-443},
year = {2025},
note = {Shaping the Future of Gastroenterology and Hepatology With Artificial Intelligence},
issn = {0016-5085},
doi = {https://doi.org/10.1053/j.gastro.2025.02.039},
url = {https://www.sciencedirect.com/science/article/pii/S0016508525005414},
author = {Ryan W. Stidham and Louis R. Ghanem and Joel G. Fletcher and David H. Bruining},
keywords = {Artificial Intelligence, Inflammatory Bowel Disease, Crohn's Disease, Ulcerative Colitis, Computer Vision, Automation, Large Language Models, Natural Language Processing, Digital Twin},
abstract = {Artificial intelligence (AI) will fundamentally improve how we perform clinical trials by addressing issues of standardizing disease scoring, improving the sensitivity and precision of activity and phenotype assessments, and automating laborious and time-consuming study functions. Progress in AI image analysis is quickly proving to replicate expert judgment in endoscopy, histology, and cross-sectional imaging with speed, reproducibility, and reduced bias. However, AI analytics offer the ability to quantify disease characteristics with more detail and precision than human experts. Large language models and generative AI are automating the collection of high-quality data from electronic records and improving our ability to predict patient outcomes. This narrative review will focus on AI tools available today, their expected implementation, and future-facing opportunities for AI to reimagine inflammatory bowel disease clinical trials.}
}
@article{LIU2025682,
title = {Interactive Design of Dynamic Visual Communication Driven by Artificial Intelligence Algorithms},
journal = {Procedia Computer Science},
volume = {261},
pages = {682-690},
year = {2025},
note = {The 5th International Conference on Machine Learning and Big Data Analytics for IoT Security and Privacy (SPIoT2024)},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2025.04.321},
url = {https://www.sciencedirect.com/science/article/pii/S1877050925014231},
author = {Shen Liu and Li Ding},
keywords = {Dynamic visual communication design, artificial intelligence algorithm, spatial attention mechanism, channel attention mechanism, generative adversarial network},
abstract = {Dynamic visual communication design usually needs to process multimodal information. How to effectively integrate these multi-dimensional features and establish stable associations between different modalities remains a technical challenge. To this end, this article explores the application of artificial intelligence algorithms, especially spatial attention and channel attention mechanisms, in dynamic image and video generation to achieve more accurate semantic consistency between text and images. This article introduces a spatial attention mechanism, which dynamically focuses on the spatial area related to the text description by calculating the similarity between text and image features; at the same time, the channel attention mechanism further optimizes the match with the text description by adjusting the channel weights in the image feature map. In addition, the study introduces user interaction design, and users can influence the generation target of the generator through real-time feedback and adjustment, making it more personalized and in line with needs. The optimization process of the generator and the discriminator further improves the realism and quality of dynamic image and video generation through GAN (Generative Adversarial Network). Experiments show that the proposed method can effectively enhance the semantic consistency in the image generation process and provide new technical support for dynamic visual communication design.}
}
@article{GUNTUKA2025215,
title = {Generative AI in minimizing cyber-attacks: Developing the Vehicular Threat Intelligence Flowchart},
journal = {Procedia Computer Science},
volume = {257},
pages = {215-224},
year = {2025},
note = {The 16th International Conference on Ambient Systems, Networks and Technologies Networks (ANT)/ the 8th International Conference on Emerging Data and Industry 4.0 (EDI40)},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2025.03.030},
url = {https://www.sciencedirect.com/science/article/pii/S1877050925007665},
author = {Sony Guntuka and Elhadi Shakshuki and Haroon Malik},
keywords = {Cyber attacks, GenAI, Vehicular Networks, Cybersecurity, Threat Detection},
abstract = {This paper delves into the innovative applications of Generative Artificial Intelligence (GenAI) in enhancing the cybersecurity of vehicular networks, a critical area given the increasing integration of intelligent transport systems and autonomous vehicles. As vehicular networks become more sophisticated, they also become more susceptible to cyber-attacks that can compromise vehicle control systems, endangering public safety and personal privacy. GenAI offers advanced capabilities for automating defences, improving threat intelligence, and creating dynamic security frameworks that can adapt to emerging threats. This research is a comprehensive overview of the current state of GenAI in the context of vehicular network cybersecurity, highlighting the development and implementation of the Vehicular Threat Intelligence Flowchart (VTIF). The VTIF features a threat detection rule algorithm that automates the identification of cyber threats, significantly improving detection accuracy. While the integration of GenAI presents substantial benefits, it also introduces new risks, necessitating robust ethical, legal, and technical oversight. This paper outlines the potential advantages and challenges of employing GenAI in vehicular cybersecurity and proposes future research directions aimed at developing resilient and ethical cybersecurity mechanisms.}
}
@article{ACAMPORA2026100807,
title = {Quantum artificial intelligence: A survey},
journal = {Computer Science Review},
volume = {59},
pages = {100807},
year = {2026},
issn = {1574-0137},
doi = {https://doi.org/10.1016/j.cosrev.2025.100807},
url = {https://www.sciencedirect.com/science/article/pii/S1574013725000838},
author = {Giovanni Acampora and Angela Chiatto and Roberto Schiattarella and Autilia Vitiello},
keywords = {Artificial intelligence, Quantum computing, Quantum artificial intelligence},
abstract = {Quantum computing and artificial intelligence are two highly topical fields of research that can benefit from each other’s discoveries by opening a completely new scenario in computation, that of quantum artificial intelligence. Indeed, on the one hand, artificial intelligence algorithms can be made computationally more efficient due to the potential speedup enabled by quantum phenomena; on the other hand, the complex development of quantum computing technologies and methodologies can be properly supported by the use of classical artificial intelligence approaches. The “entanglement” of these two disciplines is opening up completely new directions in computer science research, and this survey aims to provide a systematic and taxonomic overview of the work that has already been done and that which will begin in the near future.}
}
@article{HAGIU2025103134,
title = {Artificial intelligence and competition policy},
journal = {International Journal of Industrial Organization},
pages = {103134},
year = {2025},
issn = {0167-7187},
doi = {https://doi.org/10.1016/j.ijindorg.2025.103134},
url = {https://www.sciencedirect.com/science/article/pii/S0167718725000013},
author = {Andrei Hagiu and Julian Wright},
keywords = {Antitrust, Data, Feedback loops, Generative AI, Network effects},
abstract = {This paper examines competition policy implications of the rapidly expanding Artificial Intelligence (AI) sector. We analyze the vertical AI technology stack and data feedback loops to address three key questions: the potential for market concentration in core AI services, AI's likely impact on existing market structures, and emerging competition policy challenges. We identify key risks to competition in the AI sector, ways in which AI may disrupt some existing platforms, how AI could lead to new types of gatekeepers, and some novel competition policy concerns raised by AI.}
}
@article{YAO2025100100,
title = {Artificial Intelligence for Sustainable Architectural Design},
journal = {Nexus},
pages = {100100},
year = {2025},
issn = {2950-1601},
doi = {https://doi.org/10.1016/j.ynexs.2025.100100},
url = {https://www.sciencedirect.com/science/article/pii/S2950160125000476},
author = {Jiawei Yao and Yixin Jian and Chenyu Huang and Liang Yuan and Jiahong Ye and Zewei Shi and John Kaiser Calautit and Shen Wei and Xi Deng and Tim Broyd and Qingrui Minyag Jiang and Philip F. Yuan},
keywords = {Artificial Intelligence, Sustainable Building, Architectural Design, Systematic Review},
abstract = {Amid global challenges of resource depletion, climate risk, and urban health inequality, Artificial Intelligence for Sustainable Architectural Design (AI4SAD) has become a key driver of the shift from experience-based to intelligence-driven design. Drawing on a systematic review of 408 studies, this work is the first to map the global spatiotemporal profile of AI4SAD across design stages, sustainability goals, and algorithmic applications. The findings indicate a significant transparency deficit: only a few studies disclose data sources, model parameters, or performance gains. This gap constrains reproducibility, cross-scenario transfer, and cumulative knowledge. We propose a three-stage development framework and identify an ongoing transition from Level 2 (specialized models) to Level 3 (foundation models). Furthermore, a roadmap is established to guide future advancements in generalizability, autonomy, and interpretability, promoting the responsible application of AI in sustainable architectural design.}
}
@article{PUCHADES202523,
title = {Artificial intelligence in clinical practice: Quality and evidence},
journal = {Revista Clínica Española (English Edition)},
volume = {225},
number = {1},
pages = {23-27},
year = {2025},
issn = {2254-8874},
doi = {https://doi.org/10.1016/j.rceng.2024.11.001},
url = {https://www.sciencedirect.com/science/article/pii/S2254887424001425},
author = {R. Puchades and L. Ramos-Ruperto},
keywords = {Artificial intelligence, Quality, Evidence, Inteligencia artificial, Calidad, Evidencia},
abstract = {A revolution is taking place within the field of artificial intelligence (AI) with the emergence of generative AI. Although we are in an early phase at the clinical level, there is an exponential increase in the number of scientific articles that use AI (discriminative and generative) in their methodology. According to the current situation, we may be in an “AI bubble” stage; requiring filters and tools to evaluate its application, based on the quality and evidence provided. In this sense, initiatives have been developed to determine standards and guidelines for the use of discriminative AI (CONSORT AI, STARD AI and others), and more recently for generative AI (the CHART collaborative). As a new technology, AI requires scientific regulation to guarantee the efficacy and safety of its applications, while maintaining the quality of care; an evidence-based AI (IABE).
Resumen
Dentro del campo de la inteligencia artificial (IA) se está produciendo una revolución con la aparición de la IA generativa. Si bien estamos en una fase precoz a nivel clínico, se observa un incremento exponencial del número de artículos científicos que utilizan la IA (discriminativa y generativa) en su metodología. De acuerdo con la situación actual, tal vez nos encontremos en una etapa de «burbuja de la IA»; precisando filtros y herramientas para evaluar su aplicación, en base a la calidad y evidencia aportada. En este sentido, se han desarrollado iniciativas para determinar estándares y guías para el uso de IA discriminativa (CONSORT AI, STARD AI y otras), y más recientemente para la IA generativa (the CHART collaborative). Como nueva tecnología, la IA requiere una regulación científica para garantizar la eficacia y seguridad en sus aplicaciones, manteniendo la calidad de la atención; una IA basada en la evidencia (IABE).}
}
@article{SCHWENDICKE2025315,
title = {Artificial Intelligence in Prosthodontics},
journal = {Dental Clinics of North America},
volume = {69},
number = {2},
pages = {315-326},
year = {2025},
note = {Updates in Prosthodontics},
issn = {0011-8532},
doi = {https://doi.org/10.1016/j.cden.2024.11.009},
url = {https://www.sciencedirect.com/science/article/pii/S0011853224000958},
author = {Falk Schwendicke and Hossein {Mohammad Rahimi} and Antonin Tichy},
keywords = {AI, Computer vision, Deep learning, Intraoral scan, Image analysis, Prosthesis}
}
@article{UKWANDU2025103616,
title = {The future of teaching and learning in the context of emerging artificial intelligence technologies},
journal = {Futures},
volume = {171},
pages = {103616},
year = {2025},
issn = {0016-3287},
doi = {https://doi.org/10.1016/j.futures.2025.103616},
url = {https://www.sciencedirect.com/science/article/pii/S0016328725000783},
author = {Elochukwu Ukwandu and Omobolanle Omisade and Karl Jones and Simon Thorne and Mike Castle},
keywords = {Generative artificial intelligence, Prompt technologies, Artificial intelligence, ChatGPT, AI-Agents, Future of teaching and learning, Emerging AI disruptive technologies},
abstract = {In the context of emerging artificial intelligence technologies (AI) such as AI-Bots (ChatGPT) and AI-Agents, it is imperative that adequate adjustment be made, and also seen to be made. However, this has to be done from an informed positions. There is no doubt that these disruptive technologies are changing the way we live, conduct our day-to-day businesses, teach, learn and conduct research. There are also emerging concerns that these dynamics may result in a paradigm shift from student-teacher relationship to student-AI-Tutor-based relationship within the academic circle. Besides, there are foreseeable dangers of compromising academic integrity through high-technology plagiarism and the potentials of students avoiding learning through AI deployment and utilisation in their academic pursuits. But something worth considering is how applying these tools in education will potentially change the entire classroom experience of students, their knowledge and skills outcomes that are relevant in this AI era. This position paper is an effort to put into context what the authors of this paper forecast as the future of teaching and learning in the context of these inevitable disruptions to education activities and its subsectors as we currently know it. The authors found it necessary to take these positions to help bring to fore some practical use cases of AI in education; recent developments and theoretical frameworks in literature, technical reports, as well as experts opinions that can help assuage stakeholder’s concerns despite some obvious existing challenges. It is our view that this paper will be found useful by educators, stakeholders and administrators in the areas of curriculum design, classroom administration and entire academic planning and reviews.}
}
@article{MATOS2025100571,
title = {A systematic review of artificial intelligence applications in education: Emerging trends and challenges},
journal = {Decision Analytics Journal},
volume = {15},
pages = {100571},
year = {2025},
issn = {2772-6622},
doi = {https://doi.org/10.1016/j.dajour.2025.100571},
url = {https://www.sciencedirect.com/science/article/pii/S277266222500027X},
author = {Tomás Matos and Walter Santos and Eftim Zdravevski and Paulo Jorge Coelho and Ivan Miguel Pires and Filipe Madeira},
keywords = {Artificial intelligence, ChatGPT, Educational technology, Machine learning, Adaptive learning, Systematic review},
abstract = {The academic world is becoming increasingly interested in the applications of Artificial Intelligence technology in education. A systematic review examines AI applications in education, focusing on their effectiveness, challenges, and implications. A comprehensive analysis of studies published between 2011 and 2024 encompassed 45 research articles from major databases, such as PubMed Central, IEEE Xplore, Elsevier, Springer, MDPI, ACM, and PMC. The findings highlight the predominant use of generative AI tools like ChatGPT (30%), followed by other advanced technologies, such as GPT-4, machine learning, and virtual reality. Research across global regions, particularly in Canada (18%), the United States (12%), and China (8%), highlights the multifaceted applications of AI in enhancing personalized learning, fostering critical thinking, and supporting professional education. Tools such as ChatGPT have demonstrated strong performance in theoretical knowledge delivery and medical education, while augmented and virtual reality excels in practical skill development. Despite these advances, challenges such as data privacy concerns, algorithmic bias, and the need for specialized educator training remain critical.}
}
@article{KOX2025105817,
title = {Perceptions, hopes, and concerns regarding the possibilities of artificial intelligence in weather warning contexts},
journal = {International Journal of Disaster Risk Reduction},
volume = {130},
pages = {105817},
year = {2025},
issn = {2212-4209},
doi = {https://doi.org/10.1016/j.ijdrr.2025.105817},
url = {https://www.sciencedirect.com/science/article/pii/S2212420925006417},
author = {Thomas Kox and Sara Harrison and Ferdinand Ziegler and Lars Gerhold},
keywords = {Human-AI collaboration, Delphi, Risk communication, Weather forecasting, Warning systems},
abstract = {Artificial intelligence (AI) is increasingly used in disaster risk reduction, including early warning systems (EWS) for weather hazards. While AI promises faster data processing and improved forecast accuracy, concerns remain about automation bias, reduced human oversight, or accountability, and erosion of professional judgment. Despite rapid technological advances, the perceptions of the weather warning community remain underrepresented in current research. To address this, we conducted an Argumentative Delphi study with experts from the 2024 WMO HIWeather Final Conference. Participants assessed AI's impact on 13 key aspects of weather warnings – including quality, interpretability, accountability, and social bias – and shared hopes and concerns. Overall, participants expressed cautious optimism. AI is expected to improve the goodness of warnings, potentially cascading into broader dimensions of warning efficacy, public trust, and institutional responsibility. However, concerns include over-reliance on AI, erosion of human involvement, and challenges in maintaining a single authoritative voice in warning communication. Rather than viewing AI as replacement for human decision-making, it is seen as decision-support tool that augments professional expertise. Tailored warnings and multilingual communication emerged as promising areas for AI application, though issues of data bias and accessibility remain. Thus, ethical implementation is vital to ensure inclusiveness and alignment global disaster risk reduction goals. Finally, the introduction of AI touches the ‘professional core’ of weather warning as an occupation and prompts experts to define their evolving roles and core competencies in the face of technological advancements. Future research should explore how generative AI may reshape forecasting and the profession itself.}
}
@article{LEITE2025124115,
title = {Artificial intelligence in higher education: Research notes from a longitudinal study},
journal = {Technological Forecasting and Social Change},
volume = {215},
pages = {124115},
year = {2025},
issn = {0040-1625},
doi = {https://doi.org/10.1016/j.techfore.2025.124115},
url = {https://www.sciencedirect.com/science/article/pii/S0040162525001465},
author = {Higor Leite},
keywords = {Generative artificial intelligence, Higher education, Innovation, Technology, Transformative service research},
abstract = {Generative artificial intelligence (GenAI) has disrupted traditional educational approaches. Students are applying GenAI tools to access and create new content. However, the emergence of GenAI in higher education comes with caveats and academics and university administrators are learning to navigate this uncharted territory. GenAI is treated as a double-edged sword, with several benefits, such as innovation and productivity, but also drawbacks regarding ethics and academic misconduct. Therefore, our study aims to understand the impact of GenAI on students' experiences in the higher education ecosystem as students move to a new AI-enhanced job market. This research note article presents preliminary results from a 12-month longitudinal study with students interacting with GenAI. We conducted 35 semi-structured interviews and collected private diary entries (n = 108). Our results show six meaningful themes: Harnessing AI for Enhanced Academic Performance, AI Ethics and Trust Impact on Learning, GenAI as a Supplement to Human Work, Integration and Versatility of GenAI Tools, Balancing GenAI Limitations, and Navigating the AI Adoption Journey. The study also uses the transformative service research lens to present the transformative impact of GenAI in higher education. To contribute to practice and policymakers, we designed a research agenda to inform future studies on GenAI.}
}
@article{SPIEGLER2025103109,
title = {Images of AI: How AI practitioners view the impact of Artificial Intelligence on society, now and in the future},
journal = {Technology in Society},
pages = {103109},
year = {2025},
issn = {0160-791X},
doi = {https://doi.org/10.1016/j.techsoc.2025.103109},
url = {https://www.sciencedirect.com/science/article/pii/S0160791X25002994},
author = {Simone Spiegler and Rashina Hoda and Aastha Pant},
keywords = {Artificial intelligence, AI, Societal impact, Human control, Future, Responsible AI, Large language models, LLMs, AI practitioners, Images, AI psychosis, Generative AI, Agentic AI},
abstract = {Despite unprecedented technological advancement, intense commercial investment, international agreements, and growing societal concerns with Artificial Intelligence (AI), there is little insight into how those driving the field – the everyday AI practitioners – perceive AI and its impact on society, now and in the future. We address this critical gap by conducting a broad-based survey with 100 AI practitioners, followed by in-depth interviews with 20 AI practitioners, including developers, managers, and consultants. Using socio-technical grounded theory (STGT) for data analysis, we inductively identified six images of AI which capture six ways in which AI practitioners view AI, now and in the future, and their implications for impact on society and human control: Parrot captures AI that mimics human behaviour, including biases; Companion surrounds humans in daily life and supports decision making with empathy-like traits; Wolf in Sheep’s Clothing highlights AI misused by humans, causing societal harms; Saviour envisions AI solving complex problems beyond human capacity; Wizard portrays AI as powerful yet unpredictable and inexplicable; and Pinocchio imagines AI as gaining free will, learning from mistakes, and possibly harming humans. These images of AI provide a novel framework for understanding how AI practitioners perceive and shape AI solutions. Our findings and recommendations will assist AI practitioners, companies, and users with a shared vocabulary and understanding to explicitly and critically examine the intended and unintended impacts of AI solutions on human society, contributing to more responsible and human controlled AI design and use.}
}
@article{ARADYA20251749,
title = {Artificial intelligence for maxillofacial prosthodontics: A technological shift in craniofacial rehabilitation- a scoping review},
journal = {Journal of Oral Biology and Craniofacial Research},
volume = {15},
number = {6},
pages = {1749-1766},
year = {2025},
issn = {2212-4268},
doi = {https://doi.org/10.1016/j.jobcr.2025.10.006},
url = {https://www.sciencedirect.com/science/article/pii/S2212426825002490},
author = {Anupama Aradya and Koduru Sravani and M.B. Ravi and K.N. {Raghavendra Swamy} and S. Ganesh and K. {Pradeep Chandra} and H.K. Sowmya and B.V. Jayashankar and Nisarga {Vinod Kumar} and K.M. Sangeeta},
keywords = {Artificial intelligence, Maxillofacial prosthesis, CAD/CAM, Deep learning, Digital dentistry, Facial rehabilitation},
abstract = {Introduction
Artificial intelligence (AI) transforms dentistry and holds considerable promise for maxillofacial prosthodontics (MFP). Applications in imaging, computer-aided design and manufacturing (CAD/CAM), and additive manufacturing are improving diagnosis, treatment planning, and prosthetic rehabilitation for patients with craniofacial abnormalities. Despite advances in materials and digital workflows, challenges remain in achieving optimal accuracy, efficiency, and customisation in prosthetic design. The integration of AI in maxillofacial prosthodontics is still in its early stages. Currently, there is no review detailing the scope, trends, potential, and limitations of AI in this field. A scoping review is therefore necessary to consolidate existing evidence, identify knowledge gaps, and suggest directions for future research and clinical application. This review objective is to systematically map and analyse the current literature on AI in maxillofacial prosthodontics, focusing on its role in craniofacial rehabilitation.
Methods
This scoping review adhered to the methodological framework of Arksey and O'Malley (2005) and was guided by the Joanna Briggs Institute (JBI) Manual for Evidence Synthesis (2020). Reporting complied with PRISMA-ScR (Preferred Reporting Items for Systematic reviews and Meta-Analyses extension for Scoping Reviews) guidelines to ensure clarity and reproducibility. The review was registered with the Open Science Framework (registration number: www.osf.io/3b9jr). Electronic databases, including Medline via PubMed, Scopus, Cochrane Database, Science Direct, Google Scholar, and Semantic Scholar, were searched up to 7 June 2025. Full-text English articles containing the keywords “Artificial Intelligence and Maxillofacial Prosthodontics” and related terms were included.
Results
This scoping review included 35 articles from diverse geographic regions. The studies addressed several specific applications of AI in maxillofacial prosthodontics, including the production of implant-supported auricular prostheses, coloration of maxillofacial prostheses, evaluation of facial attractiveness in patients with clefts, capture of 3D impressions of cleft palates, identification of hypernasality, assessment of lip symmetry, and detection of teeth in cleft lip and palate cases.
Conclusion
Artificial intelligence offers significant opportunities for maxillofacial prosthodontics, especially in imaging, digital design, and prosthesis production. Progress in this area requires interdisciplinary teamwork, large-scale clinical trials, and the development of standardized validation methods to ensure safe and effective clinical application.}
}
@article{KING2025,
title = {The Promise and Perils of Artificial Intelligence in Advancing Participatory Science and Health Equity in Public Health},
journal = {JMIR Public Health and Surveillance},
volume = {11},
year = {2025},
issn = {2369-2960},
doi = {https://doi.org/10.2196/65699},
url = {https://www.sciencedirect.com/science/article/pii/S2369296025000365},
author = {Abby C King and Zakaria N Doueiri and Ankita Kaulberg and Lisa {Goldman Rosas}},
keywords = {digital health, artificial intelligence, community-based participatory research, citizen science, health equity, societal trends, public health, viewpoint, policy makers, public participation, information technology, micro-level data, macro-level data, LLM, natural language processing, machine learning, language model, Our Voice},
abstract = {Current societal trends reflect an increased mistrust in science and a lowered civic engagement that threaten to impair research that is foundational for ensuring public health and advancing health equity. One effective countermeasure to these trends lies in community-facing citizen science applications to increase public participation in scientific research, making this field an important target for artificial intelligence (AI) exploration. We highlight potentially promising citizen science AI applications that extend beyond individual use to the community level, including conversational large language models, text-to-image generative AI tools, descriptive analytics for analyzing integrated macro- and micro-level data, and predictive analytics. The novel adaptations of AI technologies for community-engaged participatory research also bring an array of potential risks. We highlight possible negative externalities and mitigations for some of the potential ethical and societal challenges in this field.}
}
@article{ABBAS2025101551,
title = {Management accounting and artificial intelligence: A comprehensive literature review and recommendations for future research},
journal = {The British Accounting Review},
pages = {101551},
year = {2025},
issn = {0890-8389},
doi = {https://doi.org/10.1016/j.bar.2025.101551},
url = {https://www.sciencedirect.com/science/article/pii/S0890838925000010},
author = {Khalid Abbas},
keywords = {Artificial intelligence, Machine learning, Explainable AI, Management accounting, Large language models, Digitalization},
abstract = {Digitalization and artificial intelligence (AI) technologies have the potential to disrupt and transform the management accounting domain and the role of accountants. The study systematically reviews 91 articles, synthesizing scholarly work on digitalization, AI, machine learning (ML), deep learning (DL), explainable AI, generative AI, and large language models (LLMs) in management accounting. In this context, the value of the paper is multi-fold. First, we argue that these technologies transform accounting information and organizational structures, affecting the accounting function's relationship with other organizational functions. Second, they present new challenges for management accountants, including data privacy, confidentiality, security and ethical concerns. Third, digital technologies automate basic accounting tasks and decision-making processes, potentially reshaping management accountants' roles and skills in terms of job elimination, upskilling, deskilling and reskilling. Fourth, these technologies create new opportunities for multidisciplinary collaboration and redefine professional boundaries. This paper contributes by discussing the impact of digitalization and the latest AI technologies on management accounting, illustrating how they can create business value, and highlighting associated challenges and risks for the profession. It proposes research agendas and potential research questions for future studies, providing insight into the potential impacts and implications for the accounting profession and the role of accountants.}
}
@article{JOBSTREIBIZER2025372,
title = {The impact of artificial intelligence on business models: a bibliometric-systematic literature review},
journal = {Management Decision},
volume = {63},
number = {13},
pages = {372-396},
year = {2025},
issn = {0025-1747},
doi = {https://doi.org/10.1108/MD-10-2024-2309},
url = {https://www.sciencedirect.com/science/article/pii/S0025174725000084},
author = {Joshua Jobstreibizer and Tatiana Beliaeva and Marcos Ferasso and Sascha Kraus and Andreas Kallmuenzer},
keywords = {Artificial intelligence, AI, Business models, Bibliometric-systematic literature review, Network analysis},
abstract = {Purpose
This study aims to conduct a bibliometric-Systematic Literature Review’ (B-SLR) to trace the impact of artificial intelligence (AI) on business models (BM). It explores the intellectual structure, key thematic clusters and the evolution of this emerging field, with the aim of identifying current trends and future research directions.
Design/methodology/approach
The analysis covers 87 journal articles retrieved from the Scopus database. It follows the guidelines of a multi-method literature review, combining a bibliometric analysis and a systematic literature review. Co-citation, co-occurrence and timeline analyses were performed to uncover intellectual foundations, map key research areas and track recent developments.
Findings
The study highlights the central role of AI in reshaping BM, particularly in areas such as customer engagement, innovation, sustainability, Industry 4.0 and digitalization. Recent developments emphasize AI’s applications in narrow fields, circular BM and the growing influence of generative AI. A framework of AI adoption in BM is developed, suggesting promising directions for future research.
Research limitations/implications
This study suggests that future research should explore AI’s role in BM more deeply by integrating interdisciplinary perspectives. It highlights the need for more empirical studies on AI-driven innovation and its long-term effects on business strategies, particularly in emerging areas such as generative AI and circular economy models.
Practical implications
This review provides managers with insights into how AI can drive BM innovation and highlights emerging areas of AI applications. It offers a roadmap for integrating AI technologies into BM to gain competitive advantages.
Originality/value
This study provides an up-to-date, comprehensive analysis of AI’s impact on BM, contributing to both academic literature and practical business strategies by synthesizing recent developments and suggesting future research directions.}
}
@article{JEONG2025110855,
title = {Application of Explainable Artificial Intelligence for personalized childhood weight management using IoT data},
journal = {Computers in Biology and Medicine},
volume = {196},
pages = {110855},
year = {2025},
issn = {0010-4825},
doi = {https://doi.org/10.1016/j.compbiomed.2025.110855},
url = {https://www.sciencedirect.com/science/article/pii/S0010482525012065},
author = {Jaemin Jeong and Ji-Hoon Jeong and Gee-Myung Moon and Young-Duk Seo and Euijong Lee},
keywords = {Healthcare, Shapley additive explanation (SHAP), Tabnet, Explainable artificial intelligence (XAI), Generative adversarial networks (GAN)},
abstract = {Childhood obesity is a growing global health concern as it is correlated with an increased risk of adult-onset and chronic diseases. Recent advances in digital healthcare technologies have enhanced the efficiency of health data analysis and diagnosis, leading to increased interest in artificial intelligence (AI) applications in childhood obesity research; however, several challenges remain, such as data limitations, class-imbalance issues, and difficulties in model interpretability. This study addresses these challenges through a comprehensive framework that utilizes wearable devices for real-time lifestyle data collection and employs Wasserstein generative adversarial networks (WGANs) to address data imbalance concerns. The proposed framework incorporates an explainable model architecture combining tabular attention network (TabNet) with eXtreme Gradient Boosting (XGBoost), complemented by SHapley Additive exPlanations (SHAP) analysis for enhanced interpretability. The framework was validated using data collected from 362 elementary school students over six months, with an additional external validation set of 82 students. The results demonstrated exceptional performance with 98.0% accuracy on the test dataset and 85.2% accuracy on the external validation data. Therefore, the framework can provide personalized health guidance by identifying and explaining individual factors that contribute to weight change, thereby enabling targeted intervention strategies for childhood obesity prevention.}
}
@article{ELSAYED2025518,
title = {Clinical Implementation of Artificial Intelligence in Gastroenterology: Current Landscape, Regulatory Challenges, and Ethical Issues},
journal = {Gastroenterology},
volume = {169},
number = {3},
pages = {518-530},
year = {2025},
note = {Shaping the Future of Gastroenterology and Hepatology With Artificial Intelligence},
issn = {0016-5085},
doi = {https://doi.org/10.1053/j.gastro.2025.01.254},
url = {https://www.sciencedirect.com/science/article/pii/S0016508525005384},
author = {Ahmed El-Sayed and Laurence B. Lovat and Omer F. Ahmad},
keywords = {Endoscopy, Artificial Intelligence, Regulation, Implementation, Gastroenterology},
abstract = {Artificial intelligence (AI) is set to rapidly transform gastroenterology, particularly in the field of endoscopy, where algorithms have demonstrated efficacy in addressing human operator variability. However, implementing AI in clinical practice presents significant challenges. The regulatory landscape for AI as a medical device continues to evolve with areas of uncertainty. More robust studies generating real-world evidence are required to ultimately demonstrate impacts on patient outcomes. Cost-effectiveness data and reimbursement models will be pivotal for widespread adoption. Novel challenges are posed by emerging technologies, such as generative AI. Ethical and medicolegal concerns exist relating to data governance, patient harm, liability, and bias. This review provides an overview for clinical implementation of AI in gastroenterology and offers potential solutions to current barriers.}
}
@article{CHEN2025113575,
title = {Computational design of indoor lighting supported by artificial intelligence: Recent advances and future prospects},
journal = {Building and Environment},
volume = {285},
pages = {113575},
year = {2025},
issn = {0360-1323},
doi = {https://doi.org/10.1016/j.buildenv.2025.113575},
url = {https://www.sciencedirect.com/science/article/pii/S0360132325010479},
author = {Peng Chen and Lixiong Wang and Yuting Wu and Zelin Liang and Juan Yu and Tianyi Chen},
keywords = {Interior lighting, Computational design, Artificial intelligence, Generative design},
abstract = {The growing complexity of indoor lighting requirements demands innovative design approaches. AI-supported computational design has demonstrated potential in generating design solutions under complex constraints, yet the lighting society lacks a comprehensive understanding of this approach. Seventy-nine publications were collected for bibliometric analysis. Then a three-domain framework was proposed and reviewed. For lighting environment integration, (deep) neural networks enable analysis of light intensity, spectrum, and spatial distribution patterns through sparse sensors or RGB images. For lighting performance modeling, ML and ANN achieve real-time, personalized, and environment-aware prediction of lighting performance. For lighting design support, heuristic algorithm-dominated systems intelligently generate luminaire layouts, dimming strategies, and spectral compositions while balancing functional, perceptual, and energy-saving objectives. Deep learning demonstrates end-to-end generative capabilities but is limited by data availability. “Perception-as-generation” is proposed as the future direction for computational lighting design, emphasizing responsiveness to the individual and temporal diversity of perceptual needs. A roadmap is proposed to establishing a lighting decision-making pivot centered on large language models. The associated technical challenges and opportunities are outlined too. This research will help practitioners better understand and apply AI, promote interdisciplinary collaboration in the lighting industry, and inspire lighting design paradigm innovation under the "good lighting" vision.}
}
@article{ALKAN2025112033,
title = {Comparison of the performances of artificial intelligence bots using continuous intuitionistic fuzzy evaluation based on distance from average solution method},
journal = {Engineering Applications of Artificial Intelligence},
volume = {161},
pages = {112033},
year = {2025},
issn = {0952-1976},
doi = {https://doi.org/10.1016/j.engappai.2025.112033},
url = {https://www.sciencedirect.com/science/article/pii/S095219762502041X},
author = {Nurşah Alkan and Umut Aydın and Akın Menekşe and Cengiz Kahraman},
keywords = {Evaluation based on distance from average solution, Continuous intuitionistic fuzzy sets, Multi-criteria decision-making, Artificial intelligence, Chatbot, Chat generative pre-trained transformer},
abstract = {The rapid evolution of artificial intelligence (AI) has introduced novel opportunities and challenges in various fields. In this study, we present a pioneering approach known as Continuous Intuitionistic Fuzzy (CINFU) Evaluation based on Distance from Average Solution (EDAS), an innovative extension of the EDAS method tailored to Continuous Intuitionistic Fuzzy Sets. This methodology is designed to compare the performance of AI tools. The capabilities of AI bots have been examined through their success rates in various tasks and uncertainty levels in decision-making processes. The study aims to evaluate the effectiveness of different models in decision-making processes by analyzing the performances of AI bots such as Chat Generative Pre-trained Transformer (ChatGPT), Bard, and Claude based on both objective measurements and fuzzy evaluation criteria. The comparison focuses on key performance criteria such as Bots Triggered, User Engagement, Message Click-Through Rate, Chat Handoff, User Retention, Bounce Rate & Dwell Time, Leads Captured, and Customer Satisfaction Score. Ultimately, the validity and robustness of the approach have been tested with sensitivity analysis.}
}
@article{BUCZYNSKI2025106111,
title = {Future themes in regulating artificial intelligence in investment management},
journal = {Computer Law & Security Review},
volume = {56},
pages = {106111},
year = {2025},
issn = {2212-473X},
doi = {https://doi.org/10.1016/j.clsr.2025.106111},
url = {https://www.sciencedirect.com/science/article/pii/S0267364925000068},
author = {Wojtek Buczynski and Felix Steffek and Mateja Jamnik and Fabio Cuzzolin and Barbara Sahakian},
keywords = {AI, Artificial intellogence, Investments, investment management, Finance, Financial services, Regulations, law, Laws, Regulation},
abstract = {We are witnessing the emergence of the “first generation” of AI and AI-adjacent soft and hard laws such as the EU AI Act or South Korea's Basic Act on AI. In parallel, existing industry regulations, such as GDPR, MIFID II or SM&CR, are being “retrofitted” and reinterpreted from the perspective of AI. In this paper we identify and analyze ten novel, “second generation” themes which are likely to become regulatory considerations in the near future: non-personal data, managerial accountability, robo-advisory, generative AI, privacy enhancing techniques (PETs), profiling, emergent behaviours, smart contracts, ESG and algorithm management. The themes have been identified on the basis of ongoing developments in AI, existing regulations and industry discussions. Prior to making any new regulatory recommendations we explore whether novel issues can be solved by existing regulations. The contribution of this paper is a comprehensive picture of emerging regulatory considerations for AI in investment management, as well as broader financial services, and the ways they might be addressed by regulations – future or existing ones.}
}
@article{BIGNAMI2025101078,
title = {Artificial intelligence in healthcare: Tailoring education to meet EU AI-Act standards},
journal = {Health Policy and Technology},
volume = {14},
number = {6},
pages = {101078},
year = {2025},
issn = {2211-8837},
doi = {https://doi.org/10.1016/j.hlpt.2025.101078},
url = {https://www.sciencedirect.com/science/article/pii/S2211883725001066},
author = {Elena Bignami and Luigino Jalale Darhour and Wolfgang Buhre and Maurizio Cecconi and Valentina Bellini},
keywords = {Artificial intelligence, AI-Act, Education, Policy},
abstract = {The integration of Artificial Intelligence (AI) in Intensive Care Units (ICUs) has the potential to transform critical care by enhancing diagnosis, management, and clinical decision-making. Generative and Predictive AI technologies offer new opportunities for personalized care and risk stratification, but their implementation must prioritize ethical standards, patient safety, and the sustainability of care delivery. With the EU AI-Act entering into force in February 2025, a structured and responsible adoption of AI is now imperative. This article outlines a strategic framework for ICU AI integration, emphasizing the importance of a formal declaration of intent by each unit, detailing current AI-use, implementation plans, and governance strategies. Central to this approach is the development of tailored AI education programs adapted to four distinct professional profiles, ranging from experienced clinicians with limited AI knowledge to new intensivists with strong AI backgrounds but limited clinical experience. Training must foster critical thinking, contextual interpretation, and a balanced relationship between AI tools and human judgment. A multidisciplinary support team should oversee ethical AI-use and continuous performance monitoring. Ultimately, aligning regulatory compliance with targeted education and practical implementation could enable a safe, effective, and ethically grounded use of AI in intensive care. This balanced approach would support a culture of transparency and accountability, while preserving the central role of human clinical reasoning and improving the overall quality of ICU care.}
}
@article{SURI2025818,
title = {An artificial intelligence-generated interactive carbon footprint calculator for anaesthesia},
journal = {British Journal of Anaesthesia},
volume = {135},
number = {3},
pages = {818-820},
year = {2025},
issn = {0007-0912},
doi = {https://doi.org/10.1016/j.bja.2025.05.053},
url = {https://www.sciencedirect.com/science/article/pii/S0007091225003848},
author = {Aditi Suri and Gaurav Sindwani},
keywords = {anaesthesia, artificial intelligence, carbon footprint, climate change, generative artificial intelligence, global warming potential, sustainability}
}
@article{BERLINSKI2024102723,
title = {Artificial imaginaries: Generative AIs as an advanced form of capitalism},
journal = {Critical Perspectives on Accounting},
volume = {99},
pages = {102723},
year = {2024},
issn = {1045-2354},
doi = {https://doi.org/10.1016/j.cpa.2024.102723},
url = {https://www.sciencedirect.com/science/article/pii/S1045235424000224},
author = {Elise Berlinski and Jérémy Morales and Samuel Sponem},
keywords = {Generative AI, ChatGPT, Social imaginaries, Standardization, Domination},
abstract = {In this essay, we characterize three paradoxical imaginaries that structure the development of generative artificial intelligence (genAI). At the institutional level, these technologies develop in a context that celebrates openness and liberality. Yet, both in the US and in Europe, they serve to centralize power and resources. At the organizational level, while the imaginary is that these technologies make work more interesting, we show that they rather produce anxiety and a new class of precarious workers. At the epistemic level, generative artificial intelligence promises access to unlimited knowledge. This knowledge may appear robust, as these technologies become performative. However, the knowledge they produce is doubtful. Overall, these technologies centralize power and exclude, they standardize knowledge, and they produce, reproduce, amplify and extend various structures of domination.}
}
@article{KIM20252214,
title = {Enzyme functional classification using artificial intelligence},
journal = {Trends in Biotechnology},
volume = {43},
number = {9},
pages = {2214-2231},
year = {2025},
issn = {0167-7799},
doi = {https://doi.org/10.1016/j.tibtech.2025.03.003},
url = {https://www.sciencedirect.com/science/article/pii/S0167779925000885},
author = {Ha Rim Kim and Hongkeun Ji and Gi Bae Kim and Sang Yup Lee},
keywords = {deep learning, EC number, enzyme, GO term, machine learning, metabolism},
abstract = {Enzymes are essential for cellular metabolism, and elucidating their functions is critical for advancing biochemical research. However, experimental methods are often time consuming and resource intensive. To address this, significant efforts have been directed toward applying artificial intelligence (AI) to enzyme function prediction, enabling high-throughput and scalable approaches. In this review, we discuss advances in AI-driven enzyme functional annotation, transitioning from traditional machine learning (ML) methods to state-of-the-art deep learning approaches. We highlight how deep learning enables models to automatically extract features from raw data without manual intervention, leading to enhanced performance. Finally, we discuss the discovery of novel enzyme functions and generation of de novo enzymes through the integration of generative AIs and bio big data as future research directions.}
}
@article{ALNUSAIR2025101340,
title = {Artificial intelligence in myeloid malignancies: Clinical applications of machine learning in myelodysplastic syndromes and acute myeloid Leukemia},
journal = {Blood Reviews},
pages = {101340},
year = {2025},
issn = {0268-960X},
doi = {https://doi.org/10.1016/j.blre.2025.101340},
url = {https://www.sciencedirect.com/science/article/pii/S0268960X25000852},
author = {Jowan Al-Nusair and Luca Lanino and Arda Durmaz and Matteo Giovanni Della Porta and Amer M. Zeidan and Tariq Kewan},
keywords = {Myelodysplastic syndromes, Acute myeloid leukemia, Artificial intelligence, Machine learning, Prognostication, Digital twins},
abstract = {This review summarizes applications of machine learning (ML) in acute myeloid leukemia (AML) and myelodysplastic syndrome (MDS), spanning diagnosis, prognostication, treatment prediction, and research tools. In diagnostics, deep learning applied to bone marrow smears, peripheral blood films, and flow cytometry has shown high sensitivity and specificity, outperforming conventional methods. ML-driven unsupervised clustering and consensus classification have refined disease taxonomies, identifying genomic subtypes with prognostic value. Prognostic models and neural networks enable dynamic, personalized survival predictions. In treatment, ML assists in predicting responses to hypomethylating agents and venetoclax-based regimens, supporting clinical decision-making. In research, generative approaches create privacy-preserving synthetic cohorts and digital twins, facilitating trial design and overcoming data limitations. Future integration into clinical practice will require rigorous validation, explainable algorithms, seamless workflow incorporation, and regulatory oversight to ensure trust, equity, and safety. ML has potential to enhance multiple aspects of AML and MDS management.}
}
@article{ZHOU2025114970,
title = {Artificial intelligence-assisted next-generation biomaterials: From design and preparation to medical applications},
journal = {Colloids and Surfaces B: Biointerfaces},
volume = {255},
pages = {114970},
year = {2025},
issn = {0927-7765},
doi = {https://doi.org/10.1016/j.colsurfb.2025.114970},
url = {https://www.sciencedirect.com/science/article/pii/S0927776525004771},
author = {Bixia Zhou and Xin Li and Yuchen Pan and Bingfang He and Bingbing Gao},
keywords = {Artificial Intelligence, Biomaterials, Machine Learning, Materials Design, Biomedical Applications},
abstract = {The Fourth Industrial Revolution (Industry 4.0) has marked a shift from traditional materials to the era of smart materials. The integration of artificial intelligence (AI) with biomaterials is transforming the biosensing and biomedical fields. Although AI-assisted biomaterial manufacturing holds significant promise, the design and synthesis of smart materials remain in the early stages. To accelerate the implementation of AI-assisted biomaterials in fields such as biomedicine and biological intelligent systems, various algorithms have been developed to predict material properties, enable material de novo design, and establish a foundation for the development of next-generation multifunctional biomaterials. This review presents a comprehensive overview of AI-assisted biomaterial design, property prediction, fabrication, and potential biomedical applications. Recent advances in AI-driven protein engineering relevant to materials science are summarized, followed by an analysis of AI's role in designing, predicting, and optimizing next-generation biomaterials. The influence of AI-assisted systems on the structural and functional properties of biosmart materials is also explored. Applications such as therapeutic diagnostics, electronic skin (e-skin), biosensing, and other biomedical technologies are highlighted. Finally, current challenges and future perspectives are discussed, with emphasis on the transformative potential of AI in advancing materials science and biomedicine, as well as its ability to address previously intractable problems.}
}
@article{JIANG2026116321,
title = {Artificial intelligence in wind turbine fault diagnosis: A systematic knowledge mapping and trend analysis},
journal = {Renewable and Sustainable Energy Reviews},
volume = {226},
pages = {116321},
year = {2026},
issn = {1364-0321},
doi = {https://doi.org/10.1016/j.rser.2025.116321},
url = {https://www.sciencedirect.com/science/article/pii/S1364032125009943},
author = {Ruolin Jiang and Fang Fang and Juan José Rodríguez-Andina and Ziqiu Song and Jizhen Liu and Yuanye Chen and Hua Wang},
keywords = {Fault diagnosis, Artificial intelligence, Digital twin, Generative large model, Predictive maintenance, Sustainable energy system, Wind turbine},
abstract = {Over the past decade, fault diagnosis technology in the wind energy sector has advanced rapidly, yet existing reviews exhibit methodological and data source fragmentation. This study employs bibliometrics and content analysis to systematically trace the conceptual evolution and technological trajectory of intelligent fault diagnosis for wind turbines. Based on 1736 fault diagnosis papers published in mainstream journals and conferences between 2016 and 2025, it quantitatively reveals trends in research themes, methodologies, and focal points. This study critically examines the strengths, limitations, and application boundaries of existing diagnostic frameworks, highlighting practical challenges such as data imbalance, insufficient open benchmarking, and obstacles to digital twin deployment. It also evaluates emerging trends in integrating foundational models with digital twins, noting their potential for enhancing component-level precision diagnostics. The proposed roadmap centers on deep learning and multimodal models, leveraging robust shared data, unified industry standards, and comprehensive security–privacy protection mechanisms. It emphasizes causal inference and lightweight edge deployment technologies. By tracing historical developments and evaluating existing diagnostic approaches, this study aims to accelerate data-driven practices in wind power operations and maintenance while establishing reliable intelligent fault diagnosis systems—critical for ensuring stable power generation from wind turbines.}
}
@article{ZHANG2025101244,
title = {How can artificial intelligence help college students develop entrepreneurial ability? Evidence from China},
journal = {The International Journal of Management Education},
volume = {23},
number = {3},
pages = {101244},
year = {2025},
issn = {1472-8117},
doi = {https://doi.org/10.1016/j.ijme.2025.101244},
url = {https://www.sciencedirect.com/science/article/pii/S1472811725001144},
author = {Qianjun Zhang and Lixu Li and Chenli Xu and Yuanyuan Qi and Xiaorong Zhao},
keywords = {AI knowledge, Generative AI, Entrepreneurship, Creativity, College students},
abstract = {With AI rapidly transforming industries and creating new opportunities, college students are uniquely positioned to leverage artificial intelligence (AI) for entrepreneurial ventures. Nevertheless, despite the growing significance of AI knowledge, students frequently face challenges in connecting theoretical knowledge with practical use, which impedes their capacity to transform AI-driven insights into effective business strategies. Drawing on data from a survey of 1021 Chinese university students, this study investigates the connections between AI knowledge, two modes of generative AI usage (GAU), and entrepreneurial ability, with a special emphasis on the moderating influence of individual creativity. The results indicate that AI knowledge positively influences entrepreneurial ability. Interestingly, two GAU modes (i.e., depth and breadth) serve as important mediators in the relationship between AI knowledge and entrepreneurial ability. Surprisingly, individual creativity enhances the mediation effect of GAU depth between AI knowledge and entrepreneurial ability but does not enhance the mediation effect of GAU breadth between AI knowledge and entrepreneurial ability. This study advances existing research by uncovering the mechanisms and boundary conditions that facilitate the transformation of AI knowledge into substantive entrepreneurial ability. The findings also offer insights into improving instructional design in the age of AI.}
}
@article{TSIAVOS2025103021,
title = {The digital transformation of the film industry: How Artificial Intelligence is changing the seventh art},
journal = {Telecommunications Policy},
volume = {49},
number = {8},
pages = {103021},
year = {2025},
issn = {0308-5961},
doi = {https://doi.org/10.1016/j.telpol.2025.103021},
url = {https://www.sciencedirect.com/science/article/pii/S0308596125001181},
author = {Vasilis Tsiavos and Fotis Kitsios},
keywords = {Digital transformation, Artificial intelligence, Film industry},
abstract = {Although artificial intelligence has played a dominant role in the digital transformation of many industries and has been the focus of multiple academic studies, only a few researchers have explored the impact of AI on the film industry, even after the advances in large language models like ChatGPT and generative AI tools such as Sora. Questions regarding how the use of AI has affected the core functions of the film industry's value chain (Creation, Production, Dissemination and Exhibition) have only been partially or inadequately explored. This paper intends to address this research gap by conducting a systematic literature review of 74 relevant articles based on the Webster & Watson methodology, to be followed by a conceptual analysis of AI-related themes in the film industry. Our findings reveal that artificial intelligence has long played a role in the film industry, and its influence has only grown with recent advancements in AI, having an impact across the film industry's value chain. We also highlight emerging ethical concerns, such as authorship, creative integrity, and labor displacement that accompany AI's expanding role. Whilst our work contributes to the body of research on AI in the film industry, we also identify potential avenues of research that allow room for future exploration.}
}
@article{PALOMARES2025,
title = {The Impact of Artificial Intelligence Technologies on Nutritional Care in Patients With Chronic Kidney Disease: A Systematic Review},
journal = {Journal of Renal Nutrition},
year = {2025},
issn = {1051-2276},
doi = {https://doi.org/10.1053/j.jrn.2025.06.002},
url = {https://www.sciencedirect.com/science/article/pii/S1051227625001268},
author = {Sara Morales Palomares and Gaetano Ferrara and Marco Sguanci and Domenica Gazineo and Lea Godino and Addolorata Palmisano and Alberto Paderno and Giada Vrenna and Eleonora Faraglia and Fabio Petrelli and Giovanni Cangelosi and Francesco Gravante and Stefano Mancin},
keywords = {artificial intelligence, nutrition, chronic kidney disease, dietetic, systematic review},
abstract = {Objectives
Chronic kidney disease is a global health challenge, and effective, individualized nutritional management is crucial for slowing progression and improving quality of life. Artificial intelligence (AI) offers innovative tools to optimize and personalize nutritional care. This review explores AI applications in nutritional management, assessing their impact on clinical outcomes, quality of life, and care efficiency.
Methods
A systematic review was conducted, reported according to the Preferred Reporting Items for Systematic Reviews and Meta-Analyses guidelines. Searches were performed on 5 databases, namely MEDLINE, Embase, Cochrane Library, Cumulative Index to Nursing and Allied Health Literature, and integrated with gray literature sources between September and November 2024. The methodological quality assessment was conducted independently by 2 researchers using the Joanna Briggs Institute methodology.
Results
Of 2,053 initial records, 7 studies met inclusion criteria. AI showed significant potential in personalizing dietary recommendations using machine learning, clinical decision support systems, and generative AI tools. These systems tailored nutritional advice based on patient-specific clinical data, reducing complications such as hyperkalemia and improving adherence. AI also facilitated early risk detection and proactive care by monitoring nutritional parameters and predicting complications. In addition, AI-powered platforms enhanced patient education through culturally relevant, intuitive dietary plans and multilingual materials, increasing engagement. AI also improved health care efficiency by automating tasks and integrating with electronic health records.
Conclusions
AI technologies show promise in enhancing nutritional care for patients with chronic kidney disease. Evidence supports their role in improving care quality and dietary adherence. Further research is needed to validate these technologies in clinical practice and ensure integration into routine care pathways.}
}
@article{HUANG2026106527,
title = {Artificial Intelligence in urban design: A systematic review},
journal = {Cities},
volume = {169},
pages = {106527},
year = {2026},
issn = {0264-2751},
doi = {https://doi.org/10.1016/j.cities.2025.106527},
url = {https://www.sciencedirect.com/science/article/pii/S0264275125008303},
author = {Tianchen Huang and Xinyue Ye and Tan Yigitcanlar and Boqian Xu and Galen Newman and Bo Zhao and Benjamin Ennemoser and Dayong Wu and Junghwan Kim and Dongjie Wang},
keywords = {Artificial Intelligence, Generative AI, Urban Design, Design generation, AI-human collaboration},
abstract = {Artificial Intelligence (AI) is playing an increasingly transformative role in urban design by enhancing the efficiency, scalability, and adaptability of design processes. This study presents a systematic review of AI applications in urban design, with a particular focus on the design generation phase, encompassing data analysis, scheme generation and optimization, and design visualization. AI-driven methodologies facilitate rapid data processing, automated design iterations, and advanced visualizations, thereby mitigating some key limitations in conventional urban design workflows that often rely on manual and time-consuming processes. Despite these advancements, several challenges persist. These include the fragmented integration of AI tools into existing workflows, the incomplete automation of the design process, and the potential for algorithmic bias in AI-generated outcomes. Such shortcomings underscore the importance of developing structured AI workflows, fostering effective human-AI collaboration, and curating diverse, inclusive datasets to promote equitable and context-sensitive design solutions. This review advocates for a balanced approach that leverages AI's computational power while retaining human creativity and contextual judgment. By doing so, AI-enhanced urban design holds the potential to support the creation of more sustainable, efficient, and resilient cities, better equipped to meet the complex challenges of contemporary urbanization.}
}
@article{DENIA2025103266,
title = {AI narratives model: Social perception of artificial intelligence},
journal = {Technovation},
volume = {146},
pages = {103266},
year = {2025},
issn = {0166-4972},
doi = {https://doi.org/10.1016/j.technovation.2025.103266},
url = {https://www.sciencedirect.com/science/article/pii/S0166497225000987},
author = {Elena Denia},
keywords = {Artificial intelligence, Science communication, Science fiction, Storytelling, Public attitudes, Public engagement, Public understanding, Public narratives},
abstract = {Narratives surrounding Artificial Intelligence (AI) shape its societal reception, technological development, and regulatory framing. This article proposes a theoretical model to interpret these narratives, especially in the context of growing public engagement with generative AI technologies. The model is structured along three key coordinates: apocalypse, assistance and transcendence. Transitions between them are understood through two dominant narrative frames: the Pandora's Box frame (associated with loss of control), and the Social Progress frame (associated with the improvement of human life), each tending toward dystopian and utopian extremes, respectively. Based on this model, two questions are addressed: What types of AI stories predominate in popular culture? And do audiences actually align with them? To answer these, two empirical analyses are conducted. First, a review of the 300 highest-grossing science fiction films in North America reveals a rich variety of narratives across the entire spectrum, rather than clustering around opposing extremes. Second, focus group discussions with categorized audiences of varying levels of familiarity with AI technology show that they align progressively along the narrative spectrum: the general public tends toward apocalyptic framings, the interested public (in science and technology) focuses on assistance narratives, and the engaged public embraces improvement scenarios. This sequential distribution suggests a strong correlation between AI proximity and narrative positioning, with greater engagement associated with more positive —yet nuanced— views of AI. The model opens multiple avenues for future research, including the use of wider data sources, cross-cultural comparisons, longitudinal studies, tracking of narrative shifts, and focused analyses of more complex representations.}
}
@article{KIM2025101123,
title = {Exploring the potential of acupuncture practice education using artificial intelligence},
journal = {Integrative Medicine Research},
volume = {14},
number = {1},
pages = {101123},
year = {2025},
issn = {2213-4220},
doi = {https://doi.org/10.1016/j.imr.2025.101123},
url = {https://www.sciencedirect.com/science/article/pii/S2213422025000034},
author = {Kyeong Han Kim and Hyein Jeong and Gyeong Seo Lee and Seung-Hee Lee},
keywords = {Artificial intelligence, Acupuncture, Education},
abstract = {Generative artificial intelligence (AI) is being applied in various areas such as education, clinical practice, and research within the medical field. This review explores the potential use of AI models in acupuncture practice education. Recent and relevant findings were searched from literature. Active research on the use of AI in acupuncture education, particularly in areas such as acupoint selection and acupuncture manipulation, is ongoing. Additionally, AI-powered educational tools are being developed in the field of traditional medicine. The development of AI-driven educational tools for acupuncture education holds significant potential to enhance the effectiveness and efficiency of traditional medicine education.}
}
@article{PAWLICKI2025131231,
title = {A meta-survey of adversarial attacks against artificial intelligence algorithms, including diffusion models},
journal = {Neurocomputing},
volume = {653},
pages = {131231},
year = {2025},
issn = {0925-2312},
doi = {https://doi.org/10.1016/j.neucom.2025.131231},
url = {https://www.sciencedirect.com/science/article/pii/S0925231225019034},
author = {Marek Pawlicki and Aleksandra Pawlicka and Rafał Kozik and Michał Choraś},
keywords = {Adversarial attacks, Artificial intelligence, Deep learning},
abstract = {Deep neural networks have revolutionized artificial intelligence, solving complex issues in areas like healthcare or law enforcement and security. However, they are susceptible to adversarial attacks where small data manipulations can compromise system reliability and security. This paper conducts an umbrella review of the literature on these attacks, synthesizing results from various systematic reviews to assess attack strategies, defense effectiveness, and research gaps. Guided by the PICO framework, this review categorizes and examines adversarial attacks, identifying key challenges in the field. The review finds that even though adversarial vulnerabilities were first explored in computer vision, analogous threats have expanded to domains like graph neural networks, natural language processing, federated learning, and text-to-image models. Despite varied attack surfaces, commonalities can be found.}
}
@article{KHOURY2025,
title = {Preparing Allergists to Practice in 2050 Using Artificial Intelligence},
journal = {The Journal of Allergy and Clinical Immunology: In Practice},
year = {2025},
issn = {2213-2198},
doi = {https://doi.org/10.1016/j.jaip.2025.09.012},
url = {https://www.sciencedirect.com/science/article/pii/S2213219825009067},
author = {Paneez Khoury and John Oppenheimer and Supinda Bunyavanich and Christina E. Ciaccio and Jay Portnoy},
keywords = {Artificial intelligence, Large language models, Machine learning, Electronic health record, Medical education},
abstract = {As artificial intelligence (AI) becomes deeply embedded in clinical practice, the field of allergy and immunology is poised for transformation by 2050. Artificial intelligence is expected to evolve from a decision support tool to a collaborative partner in diagnostics, treatment personalization, and medical education. Allergy training programs will need to prepare fellows for a technologically advanced landscape by integrating AI literacy, data science, and virtual simulation into curricula. Fellowship programs will need to adopt adaptive learning platforms, high-fidelity simulations, and AI-powered clinical decision support to improve diagnostic acumen, procedural competency, and patient care. This evolution also demands attention to the ethical and legal challenges of AI implementation, including preserving patient autonomy, addressing algorithmic bias, and safeguarding data privacy. Fellows must develop skills to evaluate AI outputs critically and uphold transparent, human-centered care. Artificial intelligence will probably also reshape research practices through predictive analytics, digital twins, and automated trial matching, accelerating discovery in allergic and immunologic disease. Despite these advances, limitations such as the black box problem, lack of emotional intelligence, and misinformed patient self-diagnoses pose challenges. Clinicians will require new communication strategies, including brief cognitive behavioral interventions, to address AI-derived misconceptions and maintain trust. Rather than replacing allergists, AI is likely to expand their roles, freeing time for patient interaction while reinforcing their responsibility as interpreters, educators, and ethical stewards of digital tools. This review explores how graduate medical education and clinical practice in allergy and immunology must evolve to ensure that future allergists remain competent, compassionate, and technologically fluent in a dynamic AI-enhanced health care environment.}
}
@article{MARZI2025103254,
title = {Artificial intelligence and the reconfiguration of NPD Teams: Adaptability and skill differentiation in sustainable product innovation},
journal = {Technovation},
volume = {145},
pages = {103254},
year = {2025},
issn = {0166-4972},
doi = {https://doi.org/10.1016/j.technovation.2025.103254},
url = {https://www.sciencedirect.com/science/article/pii/S0166497225000860},
author = {Giacomo Marzi and Marco Balzano},
keywords = {Sustainable development goals, Sustainable product innovation, Generative artificial intelligence, New product development teams, Team adaptability, Team skill diversity, Sustainability, Green Innovation},
abstract = {Sustainable product innovation (SPI) is increasingly central to New Product Development (NPD) teams, aligning with global sustainability goals and industry expectations. However, the factors associated with SPI at team level remain underexplored. This study examines the roles of team skill differentiation and team adaptability in fostering SPI, proposing that these factors support teams in the pursuit of sustainability-oriented innovation more effectively. Furthermore, we investigate the moderating role of generative artificial intelligence (GenAI) in shaping the strength of these relationships. Drawing on the double diamond framework and its AI-augmented adaptation, we hypothesize that skill differentiation expands the range of potential solutions in the divergent phase of innovation, while adaptability enhances responsiveness in the convergent phase. GenAI is posited to enhance these effects by augmenting knowledge recombination and real-time strategic adaptation. To test our hypotheses, we conducted a multi-industry survey of NPD teams engaged in sustainability initiatives, applying multiple regression analysis to assess the proposed relationships. All our hypotheses were empirically supported. Overall, this study contributes to SPI research by integrating team capability theory with AI-driven innovation frameworks. The findings highlight the need for firms to cultivate multidisciplinary teams with adaptive capacities while leveraging GenAI as an amplifier rather than a substitute for human expertise. The results also underscore that effective SPI requires both internal knowledge diversity and external responsiveness, alongside AI tools that enhance creativity and sustainability-driven decision-making. Finally, this research provides insights into how NPD teams can enhance their engagement in sustainable innovation, aligning with the broader objectives of Sustainable Development Goals (SDGs) 9 and 12.}
}
@article{MA2025200589,
title = {Artificial intelligence-driven green innovation in packaging: A systematic review of adoption and diffusion challenges},
journal = {Intelligent Systems with Applications},
volume = {28},
pages = {200589},
year = {2025},
issn = {2667-3053},
doi = {https://doi.org/10.1016/j.iswa.2025.200589},
url = {https://www.sciencedirect.com/science/article/pii/S2667305325001152},
author = {Ye Ma and Nor Hidayati Zakaria and Basheer Al-Haimi and Chen Wu},
keywords = {Artificial intelligence (AI), Green innovation, Packaging industry, Machine learning, Sustainable packaging, Systematic literature review},
abstract = {Global concern about environmental protection has intensified the demand for sustainable packaging solutions. Integrating artificial intelligence (AI) into green innovation offers a transformative way to address these challenges. This study applies a systematic literature review (SLR) guided by the PRISMA 2020 framework to examine recent AI-powered packaging innovations. Forty-eight peer-reviewed articles, published between 2020 and 2025, were analyzed. The findings show that Machine Learning, Deep Learning, and general AI applications are the most frequently adopted technologies. Biodegradable packaging materials and smart packaging systems represent the main sustainable packaging types. AI applications are concentrated in process optimization, smart packaging monitoring, fraud detection, computer vision, and natural language processing. However, widespread adoption faces obstacles such as high costs, technical complexity, and regulatory uncertainty. Future trends highlight the importance of scalable technologies, advanced AI models, integration with the circular economy, and interdisciplinary collaboration. This review provides a structured framework to guide academics, industry practitioners, and policymakers in adopting AI-driven green innovation for sustainable packaging.}
}
@article{DAVE2026106122,
title = {Enhancing healthcare worker mental health via artificial intelligence-driven work process improvements: a scoping review},
journal = {International Journal of Medical Informatics},
volume = {205},
pages = {106122},
year = {2026},
issn = {1386-5056},
doi = {https://doi.org/10.1016/j.ijmedinf.2025.106122},
url = {https://www.sciencedirect.com/science/article/pii/S1386505625003399},
author = {Bhavyaa Dave and Priya Martin and Sharel Singh David and Saravana Kumar and Tanmoy Chakraborty},
keywords = {Artificial intelligence (AI), Healthcare workers (HCWs), Mental health, Burnout, Workflow optimisation, Clinical documentation},
abstract = {Background
Healthcare workers (HCWs) are exposed to higher rates of mental health issues, such as burnout, anxiety, cognitive overload, and stress, compared to the general population. These may be exacerbated by administrative activities like extensive paperwork and disintegrated work processes. The implementation of artificial intelligence (AI) in healthcare holds the potential to combat these challenges by streamlining workflow processes, lowering administrative load, and increasing efficiency. The role of AI in supporting HCWs’ mental health is yet to be fully explored. This scoping review mapped the current evidence on how AI can enhance HCWs’ mental health through workflow optimisation.
Methods
This scoping review was informed by best practice in the conduct and reporting of scoping reviews. A comprehensive search of academic and grey literature was performed without date restrictions. A two-stage dual screening process was employed using Covidence. A customised data extraction tool was developed to systematically extract data, which was then summarised descriptively.
Results
Twenty articles were included in the review, most of which were published between 2020 and 2024. These comprised empirical studies, literature reviews, position papers, as well as selected grey literature. The studies explored various AI applications such as Natural Language Processing (NLP), AI-integrated Electronic Health Records (EHR), Machine Learning (ML), Clinical Decision Support Systems (CDSS), and Generative AI-driven tools such as ChatGPT. Burnout was the most frequently addressed mental health issue, followed by stress and cognitive load. Clinical documentation emerged as the most frequently addressed workflow, followed by clinical decision-making and diagnostics. Literature indicated that AI was capable of streamlining workflows, reducing administrative burden, and improving job satisfaction among HCWs. However, challenges such as data integration, algorithmic bias, and increased oversight demands were noted as potential barriers to effective implementation.
Conclusion
AI holds significant potential to improve HCWs’ mental health and well-being by addressing workflow inefficiencies and reducing administrative burden. While available evidence highlights its benefits in enhancing job satisfaction and mitigating burnout, challenges such as data standardisation and user trust must be addressed for successful adoption. Future research should focus on evaluating the long-term impacts of AI on HCWs’ mental well-being and developing strategies to mitigate unintended consequences.}
}
@article{SARIKAYA2025101021,
title = {Path to Artificial General Intelligence: Past, present, and future},
journal = {Annual Reviews in Control},
volume = {60},
pages = {101021},
year = {2025},
issn = {1367-5788},
doi = {https://doi.org/10.1016/j.arcontrol.2025.101021},
url = {https://www.sciencedirect.com/science/article/pii/S1367578825000367},
author = {Ruhi Sarikaya},
keywords = {Artificial General Intelligence, Artificial Super Intelligence, Generative AI, Foundational Models, LLMs, Transformers},
abstract = {During the past decade, there has been remarkable progress in Artificial Intelligence (AI). More recently, the emergence of Generative AI was an inflection point in cognitive pattern understanding and generation across multiple modalities including speech, text, imagery, and vision, where AI systems are increasingly matching or surpassing human performance on a growing array of cognitive tasks. These models have been seamlessly integrated into numerous applications and products, reaching hundreds of millions of users. As a result, discussions regarding the achievement of Artificial General Intelligence (AGI) have shifted from theoretical speculation to a plausible near to mid-term objective. In this paper, we present a comprehensive review of the evolution of AI from its inception to the present day. We then examine how advances in computational infrastructure, algorithms, and large-scale modeling are converging to drive the generative AI revolution and shaping the trajectory toward AGI, potentially within the next 5-to-10 years. Specifically, we analyze recent progress in compute capabilities, learning algorithms, and model architectures across a broad spectrum of cognitive tasks. We also share our perspective on the key challenges that remain to be solved, and discuss the critical risks that must be addressed to ensure the safe and beneficial development of AI systems that may eventually exceed human-level performance in perception, reasoning, and general cognition.}
}
@article{DHAIGUDE2025100640,
title = {Mapping responsible artificial intelligence in business and management: Trends, influence, and emerging research directions},
journal = {Journal of Open Innovation: Technology, Market, and Complexity},
volume = {11},
number = {4},
pages = {100640},
year = {2025},
issn = {2199-8531},
doi = {https://doi.org/10.1016/j.joitmc.2025.100640},
url = {https://www.sciencedirect.com/science/article/pii/S2199853125001751},
author = {Amol S. Dhaigude and Giridhar B. Kamath},
keywords = {Responsible Artificial Intelligence, Innovation management, Responsible innovation, Business and management, Bibliometric analysis, Bibliographic coupling, VOSviewer, Biblioshiny, Research clusters},
abstract = {The rapid integration of AI into business and management demands ethical and responsible technology design and deployment. While various policies and frameworks exist, there is limited understanding of operationalizing responsible artificial intelligence (RAI). The literature remains fragmented, lacking cohesion and clarity. This bibliometric analysis quantitatively evaluates RAI literature’s research trends, key authors, collaborations, and thematic evolution in the business and management domain. A carefully designed search protocol based on an extensive literature review was used to retrieve 1942 research papers from the Scopus database (1981–2025), reflecting a 13.12 % annual growth rate and an average of 25.79 citations per paper. The study applied bibliographic coupling, keyword co-occurrence, and thematic mapping techniques using VOSviewer and Biblioshiny to identify intellectual structures and conceptual linkages. The results reveal four key clusters: "Ethics and Social Impacts of AI", "AI Adoption and Human-AI Interaction", "Auditing, Explainability, and Accountability in AI", and "Corporate Governance and Data Responsibility in AI". Future research directions for each cluster are proposed, providing valuable insights for practitioners and academicians. The paper highlights critical implications for developing responsible AI strategies in business and offers guidance for advancing scholarly work in this growing field.}
}
@article{ZHAO2025106245,
title = {Artificial intelligence in rock mechanics},
journal = {International Journal of Rock Mechanics and Mining Sciences},
volume = {195},
pages = {106245},
year = {2025},
issn = {1365-1609},
doi = {https://doi.org/10.1016/j.ijrmms.2025.106245},
url = {https://www.sciencedirect.com/science/article/pii/S1365160925002229},
author = {Gao-Feng Zhao and Yuhang Wu},
keywords = {Artificial intelligence, Machine learning, Rock mechanics, Large language model},
abstract = {Artificial Intelligence (AI) has great potential to transform rock mechanics by tackling its inherent complexities, such as anisotropy, nonlinearity, discontinuousness, and multiphase nature. This review explores the evolution of AI, from basic neural networks like the BP model to advanced architectures such as Transformers, and their applications in areas like microstructure reconstruction, prediction of mechanical parameters, and addressing engineering challenges such as rockburst prediction and tunnel deformation. Machine learning techniques, particularly Convolutional Neural Networks (CNNs) and Generative Adversarial Networks (GANs), have been crucial in automating tasks like fracture detection and efficiently generating 3D digital rock models. However, the effectiveness of AI in rock mechanics is limited by data scarcity and the need for high-quality datasets. Hybrid approaches, such as combining physics-informed neural networks (PINNs) with traditional numerical methods, offer promising solutions for solving governing equations. Additionally, Large Language Models (LLMs) are emerging as valuable tools for code generation and decision-making support. Despite these advancements, challenges remain, including issues with reproducibility, model interpretability, and adapting AI models to specific domains. Future progress will hinge on the availability of improved datasets, greater interdisciplinary collaboration, and the integration of spatial intelligence frameworks to bridge the gap between AI's theoretical potential and its practical application in rock engineering.}
}
@article{GOLEC2025100265,
title = {Artificial Intelligence (AI): Foundations, trends and future directions},
journal = {Telematics and Informatics Reports},
pages = {100265},
year = {2025},
issn = {2772-5030},
doi = {https://doi.org/10.1016/j.teler.2025.100265},
url = {https://www.sciencedirect.com/science/article/pii/S2772503025000799},
author = {Muhammed Golec and Emir Sahin Hatay and Sukhpal Singh Gill and Rajkumar Buyya},
keywords = {AI, Computing, Quantum computing, Artificial intelligence, Machine learning},
abstract = {Developments in artificial intelligence (AI) technology have revolutionized many areas, from health to education, and from defense to commercial applications, both civilian and military. This article provides a comprehensive overview of the foundations, theoretical, and technological developments of AI, and the application areas it has enabled. It also examines the industrial impact of AI, including recent trending applications such as DeepSeek, ChatGPT, Google Lens, Face ID, and Tesla, as well as the areas of Natural Language Processing, Autonomous Vehicles, and Computer Vision. Beyond these, it highlights on future aspects of AI, such as next-generation Large Language Models (LLMs) and Artificial General Intelligence (AGI), and explores its impact on social ethics. The investigation of all these aspects aims to equip the reader with a comprehensive understanding of the current impact and potential future directions of AI.}
}
@article{HERRERATAPIAS20251184,
title = {Legal Hallucinations and the Adoption of Artificial Intelligence in the Judiciary},
journal = {Procedia Computer Science},
volume = {257},
pages = {1184-1189},
year = {2025},
note = {The 16th International Conference on Ambient Systems, Networks and Technologies Networks (ANT)/ the 8th International Conference on Emerging Data and Industry 4.0 (EDI40)},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2025.03.158},
url = {https://www.sciencedirect.com/science/article/pii/S1877050925008956},
author = {Beliña Annery Herrera-Tapias and Diego {Hernández Guzmán}},
keywords = {Artificial Intelligence, AI, Generative Pretrained Transformers, GPTs, Large Language Models, LLMs, Judiciary, Due Process},
abstract = {This article analyses the use of artificial intelligence in the judiciary, with a focus on Judgment T-343/24 of the Constitutional Court of Colombia. The judgment validates the use of artificial intelligence tools in judicial decision-making, provided they serve as supportive rather than substitutive instruments for judges. This paper highlights the potential of artificial intelligence in improving judicial efficiency and accuracy while also technically addressing the challenges posed by AI-generated "legal hallucinations," where large language models produce credible but incorrect outputs. Through qualitative legal analysis, the study explores the implications of integrating artificial intelligence in the judiciary in addressing those challenges while emphasizing the preservation of the right to a due process.}
}
@article{ENSLIN2025265,
title = {Past, Present, and Future: A History Lesson in Artificial Intelligence},
journal = {Gastrointestinal Endoscopy Clinics of North America},
volume = {35},
number = {2},
pages = {265-278},
year = {2025},
note = {Artificial Intelligence in Endoscopy},
issn = {1052-5157},
doi = {https://doi.org/10.1016/j.giec.2024.09.003},
url = {https://www.sciencedirect.com/science/article/pii/S1052515724000850},
author = {Sarah Enslin and Vivek Kaul},
keywords = {Artificial intelligence, Machine learning, Deep learning, Computer-aided detection, Computer-aided diagnosis, Generative artificial intelligence}
}
@article{PROUMEN2025563,
title = {Artificial Intelligence in Medical Education},
journal = {Anesthesiology Clinics},
volume = {43},
number = {3},
pages = {563-576},
year = {2025},
note = {Artificial Intelligence in Anesthesiology},
issn = {1932-2275},
doi = {https://doi.org/10.1016/j.anclin.2025.05.008},
url = {https://www.sciencedirect.com/science/article/pii/S1932227525000382},
author = {LT. Adrian Proumen and Santiago Uribe-Marquez and LCDR. Gregory J. Booth and John D. Mitchell},
keywords = {Artificial intelligence (AI), Machine learning, Education, Technology, Feedback, Precision medical education}
}
@article{GLAZER2025,
title = {Artificial Intelligence in Adrenal Imaging},
journal = {Magnetic Resonance Imaging Clinics of North America},
year = {2025},
issn = {1064-9689},
doi = {https://doi.org/10.1016/j.mric.2025.06.007},
url = {https://www.sciencedirect.com/science/article/pii/S1064968925000613},
author = {Daniel I. Glazer and Bernardo C. Bizzo and David T. Fuentes and William W. Mayo-Smith},
keywords = {Adrenal, Artificial intelligence, Machine learning, Adrenal incidentaloma}
}
@article{ABBARA2025105131,
title = {Artificial intelligence and infectious diseases: Scope and perspectives},
journal = {Infectious Diseases Now},
volume = {55},
number = {7},
pages = {105131},
year = {2025},
issn = {2666-9919},
doi = {https://doi.org/10.1016/j.idnow.2025.105131},
url = {https://www.sciencedirect.com/science/article/pii/S2666991925001101},
author = {S. Abbara and Y. Crabol and J. Goupil {de Bouillé} and A. Dinh and D. Morquin},
keywords = {Infectious diseases, Artificial intelligence, Generative artificial intelligence, Machine learning, Clinical decision support},
abstract = {Artificial intelligence (AI) is set to permeate every facet of infectious disease practice—from prevention and public health surveillance to epidemic management and bedside care. Routine care data (laboratory results, medication orders, progress notes) and research-generated datasets now fuel state-of-the-art machine-learning (ML) pipelines that sharpen diagnosis, prognosis, antimicrobial stewardship, and, by combining both sources, accelerate drug discovery. In diagnostics, deep networks that now flag pneumonia or tuberculosis on chest images are increasingly able to identify—and localize—virtually more infectious processes throughout the body, while simultaneously predicting pathogen identity and antimicrobial resistance from routine microbiology. Prognostic models trained on Electronic Health Records surpass traditional scores in anticipating clinical deterioration or postoperative sepsis, enabling earlier targeted interventions. Predictive analytics can also personalize antimicrobial dosing by fusing real-time drug-monitoring data. Large language models (LLMs) build upon these advances by transforming unstructured clinical narratives into structured phenotypes suitable for predictive modeling, automatically summarizing patient encounters, generating synthetic cohorts for rare conditions, and providing real-time conversational decision support at the patient’s bedside. Despite rapid progress, real-world deployment faces hurdles: high computational and licensing costs, vendor-specific implementation constraints, limited cross-site model transferability, and fragmented governance of safety, bias, and cybersecurity risks. Rigorous, lifecycle-based evaluation frameworks—covering external validation, cost-effectiveness analysis, and post-deployment monitoring—are required to ensure safe, equitable, and sustainable AI adoption. This review synthesizes current applications, evidential strengths, and unresolved challenges, and proposes a translational roadmap aligning technical innovation with clinical and regulatory realities.}
}
@article{NAZHA2025,
title = {Artificial Intelligence in Hematology},
journal = {Blood},
year = {2025},
issn = {0006-4971},
doi = {https://doi.org/10.1182/blood.2025029876},
url = {https://www.sciencedirect.com/science/article/pii/S0006497125020129},
author = {Aziz Nazha and Olivier Elemento and Sanjay Ahuja and Barbara Lam and Moses Miles and Roni Shouval and Shannon McWeeney and Shireen Sirhan and Andrew Srisuwananukorn and Torsten Haferlach},
abstract = {Artificial intelligence (AI) and its sub-discipline, machine learning (ML), have the potential to revolutionize healthcare, including hematology. The diagnosis and treatment of hematologic disorders depend on the integration of diverse data sources, such as imaging, pathology, omics, and laboratory parameters. The increasing volume and complexity of patient data have made clinical decision-making more challenging. AI/ML hold significant potential for enhancing diagnostic accuracy, risk stratification, and treatment response prediction through advanced modeling techniques. Generative AI, a recent advancement within the broader field of AI, is poised to have a profound impact on healthcare and hematology. Generative AI can enhance the development of novel therapeutic strategies, improve diagnostic workflows by generating high-fidelity images or pathology reports, and facilitate more personalized approaches to patient management. Its ability to augment clinical decision-making and streamline research represents a significant leap forward in the field. However, despite this potential, few AI/ML tools have been fully implemented in clinical practice due to challenges related to data quality, equity, advanced infrastructure, and the establishment of robust evaluation metrics. Despite its promise, AI implementation in hematology faces critical challenges, including bias, data quality issues, and a lack of regulatory frameworks and safety standards that keep pace with rapid technological advancements. In this review, we provide an overview of the current state of AI/ML in hematology as of 2025, identify existing gaps, and offer insights into future developments.}
}
@article{HARKEY2025100687,
title = {Artificial intelligence in osteoarthritis research: summary of the 2025 OARSI pre-congress workshop},
journal = {Osteoarthritis and Cartilage Open},
volume = {7},
number = {4},
pages = {100687},
year = {2025},
issn = {2665-9131},
doi = {https://doi.org/10.1016/j.ocarto.2025.100687},
url = {https://www.sciencedirect.com/science/article/pii/S2665913125001232},
author = {Matthew S. Harkey and Kerry E. Costello and Bella Mehta and Chunyi Wen and Anne-Marie Malfait and Henning Madry and Brooke Patterson},
keywords = {Generative AI, Biomechanics, Imaging biomarkers, Large language models, Ethics},
abstract = {Objective
Artificial intelligence (AI) is transforming musculoskeletal research, offering new approaches to diagnosis, prognosis, and patient management in osteoarthritis (OA). However, implementation and ethical challenges persist. This manuscript summarizes insights from the OARSI 2025 Pre-Congress Workshop on Artificial Intelligence in Osteoarthritis Research, highlighting opportunities and challenges in applying AI across biomechanics, imaging, and clinical research domains.
Design
The workshop, organized by the OARSI Early Career Investigator Committee and co-chaired by Drs. Matthew Harkey and Brooke Patterson, convened experts to discuss the use of AI in real-world biomechanics data collection, radiomics for imaging-based biomarkers, and large language models (LLMs) for clinical and research applications. Emphasis was placed on the need for interdisciplinary collaboration and ethical oversight.
Results
In biomechanics, AI-driven markerless motion capture and wearable sensors enable scalable, ecologically valid data collection, though issues such as class imbalance, data privacy, and model interpretability remain. In imaging, radiomics and deep learning models show promise for early OA detection and progression prediction but face challenges in domain adaptation and external validation. In clinical research, LLMs can streamline documentation and thematic analysis but must address concerns around bias, data security, and transparency. Across domains, transparency, reproducibility, and ethical use of AI were emphasized as critical for maintaining scientific rigor.
Conclusions
Cross-disciplinary collaboration and AI literacy are essential to responsibly advance AI integration in OA research. The workshop's collective insights call for ethical, patient-centered approaches that leverage AI's strengths while preserving research integrity and trust.}
}
@article{HUNT2025e00575,
title = {Font of innovation or algorithmic deforestation? The ecosystem impacts of artificial intelligence in entrepreneurship},
journal = {Journal of Business Venturing Insights},
volume = {24},
pages = {e00575},
year = {2025},
issn = {2352-6734},
doi = {https://doi.org/10.1016/j.jbvi.2025.e00575},
url = {https://www.sciencedirect.com/science/article/pii/S2352673425000629},
author = {Richard A. Hunt and Rasim Serdar Kurdoglu},
keywords = {Entrepreneurial ecosystems, Artificial intelligence, Generative AI, Algorithms, Variance minimization, Homogenization, Mutations, Selection, Creativity, Innovation, Techno-social impacts on business venturing, AI ethics},
abstract = {Artificial intelligence (AI) is increasingly embedded in the infrastructures, practices, and decision-making routines of founders, firms, and entrepreneurial ecosystems. For entrepreneurship, this appears to be a tremendous boon to value creation. By widening the aperture of individual entrepreneurs beyond the narrow limits of human cognition, assistive algorithms – and particularly the ground-breaking, readily accessible capabilities of Generative AI (Gen AI) – appear poised to deliver game-changing exploratory tools, enhanced predictive insights, operational efficiencies, and resource-preserving decision-support tools. Yet, the long-term, society-wide impacts are far less clear. One cause for concern is the variance-minimizing features of AI, a foundational design principle that reduces deviation and enhances the predictive stability of AI tools. In this, we identify a paradox wherein AI tools often enhance the individual creativity of entrepreneurs but, at scale, may erode collective entrepreneurial dynamism by filtering out non-algorithmic, highly serendipitous, mutation-generating, and variance-maximizing behaviors. Drawing upon the principles of rainforest logics, we theorize how AI's growing influence on entrepreneurial judgment, strategy, and ecosystem design may lead to a system-wide homogenization in decision-making and a decline in radical experimentation. With this, there is the danger of a corresponding increase in what we have dubbed algorithmic deforestation, involving systemic risks to the vitality and mutation-generating capacity of entrepreneurial ecosystems through the unintentional suppression of cognitive and behavioral diversity.}
}
@article{SEZGIN2025,
title = {Era of Generalist Conversational Artificial Intelligence to Support Public Health Communications},
journal = {Journal of Medical Internet Research},
volume = {27},
year = {2025},
issn = {1438-8871},
doi = {https://doi.org/10.2196/69007},
url = {https://www.sciencedirect.com/science/article/pii/S143888712500086X},
author = {Emre Sezgin and Ahmet Baki Kocaballi},
keywords = {messaging apps, public health communication, language models, artificial intelligence, AI, generative AI, conversational AI},
abstract = {The integration of artificial intelligence (AI) into health communication systems has introduced a transformative approach to public health management, particularly during public health emergencies, capable of reaching billions through familiar digital channels. This paper explores the utility and implications of generalist conversational artificial intelligence (CAI) advanced AI systems trained on extensive datasets to handle a wide range of conversational tasks across various domains with human-like responsiveness. The specific focus is on the application of generalist CAI within messaging services, emphasizing its potential to enhance public health communication. We highlight the evolution and current applications of AI-driven messaging services, including their ability to provide personalized, scalable, and accessible health interventions. Specifically, we discuss the integration of large language models and generative AI in mainstream messaging platforms, which potentially outperform traditional information retrieval systems in public health contexts. We report a critical examination of the advantages of generalist CAI in delivering health information, with a case of its operationalization during the COVID-19 pandemic and propose the strategic deployment of these technologies in collaboration with public health agencies. In addition, we address significant challenges and ethical considerations, such as AI biases, misinformation, privacy concerns, and the required regulatory oversight. We envision a future with leverages generalist CAI in messaging apps, proposing a multiagent approach to enhance the reliability and specificity of health communications. We hope this commentary initiates the necessary conversations and research toward building evaluation approaches, adaptive strategies, and robust legal and technical frameworks to fully realize the benefits of AI-enhanced communications in public health, aiming to ensure equitable and effective health outcomes across diverse populations.}
}
@article{RUIZ2025104293,
title = {Artificial intelligence-created personal statements compared with applicant-written personal statements: a survey of obstetric anesthesia fellowship program directors in the United States},
journal = {International Journal of Obstetric Anesthesia},
volume = {61},
pages = {104293},
year = {2025},
issn = {0959-289X},
doi = {https://doi.org/10.1016/j.ijoa.2024.104293},
url = {https://www.sciencedirect.com/science/article/pii/S0959289X24003054},
author = {A.M. Ruiz and M.B. Kraus and K.W. Arendt and D.R. Schroeder and E.E. Sharpe},
keywords = {Artificial intelligence, Generative AI, Medical education, Obstetric anesthesia, Personal statements, Fellowship},
abstract = {Background
A personal statement is a common requirement in medical residency and fellowship applications. Generative artificial intelligence may be used to create a personal statement for these applications.
Methods
Two personal statements were created using OpenAI’s Chat Generative Pre-trained Transformer (ChatGPT) and two applicant-written statements were collected. A survey was sent to obstetric anesthesia fellowship program directors in the United States to assess the perceived readability, authenticity, and originality of the four personal statements. In addition, the survey assessed perceptions of applicants who use artificial intelligence to write a personal statement, including their integrity, work ethic, reliability, intelligence, and English proficiency.
Results
Surveyed fellowship directors could not accurately discern whether statements were applicant-written or artificial intelligence-generated. The artificial intelligence-generated personal statements were rated as more readable and original than the applicant-written statements. Most program directors were moderately or extremely concerned about the applicant’s integrity, work ethic, and reliability if they suspected the applicant utilized ChatGPT.
Conclusions
Program directors could not accurately discern if the statements were written by a person or artificial intelligence and would have concerns about an applicant suspected of using artificial intelligence. Medical training programs may benefit from outlining their expectations regarding applicants’ use of artificial intelligence.}
}
@article{WEN2025,
title = {EdgeAIGC: Model caching and resource allocation for Edge Artificial Intelligence Generated Content},
journal = {Digital Communications and Networks},
year = {2025},
issn = {2352-8648},
doi = {https://doi.org/10.1016/j.dcan.2025.07.003},
url = {https://www.sciencedirect.com/science/article/pii/S2352864825001142},
author = {Wu Wen and Yibin Huang and Xinxin Zhao and Peiying Zhang and Kai Liu and Guowei Shi},
keywords = {Generative AI, Edge Model Caching, Resource Allocation, Edge Intelligence},
abstract = {With the rapid development of Generative Artificial Intelligence technology, the traditional cloud-based centralized model training and inference face significant limitations due to high transmission latency and costs, which restrict user-side in-situ Artificial Intelligence Generated Content (AIGC) service requests. To this end, we propose the Edge Artificial Intelligence Generated Content (EdgeAIGC) framework, which can effectively solve the problems brought by cloud computing by implementing in-situ processing of services close to the data source through edge computing. However, AIGC models usually have a large parameter scale and complex computing requirements, which poses a huge challenge to the storage and computing resources of edge devices. This paper focuses on the edge intelligence model caching and resource allocation problems in the EdgeAIGC framework, aiming to improve the cache hit rate and resource utilization of edge devices for models by optimizing the model caching strategy and resource allocation scheme, and realize in-situ AIGC service processing. With the optimization objectives of minimizing service request response time and execution cost in resource-constrained environments, we employ the Twin Delayed Deep Deterministic Policy Gradient algorithm for optimization. Experimental results show that, compared with other methods, our model caching and resource allocation strategies can effectively improve the cache hit rate by at least 41.06% and reduce the response cost.}
}
@article{LIM2025,
title = {The art of medical synthesis: Where Chinese medical wisdom intersects with artificial intelligence},
journal = {Journal of Traditional Chinese Medical Sciences},
year = {2025},
issn = {2095-7548},
doi = {https://doi.org/10.1016/j.jtcms.2025.08.001},
url = {https://www.sciencedirect.com/science/article/pii/S209575482500078X},
author = {Enoch Chi Ngai Lim and Nga Chong Lisa Cheng and Chi Eung Danforn Lim},
keywords = {Artificial intelligence, Chinese medicine, Western medicine, Regulation, Ethics},
abstract = {Generative artificial intelligence (AI), specifically large language models, such as DeepSeek, has accelerated the digital transformation of healthcare systems in both developing and developed countries. The use of AI in diagnostics, image processing and interpretation, treatment personalization, clinical documentation, and drug discovery is an example of the implementation of AI in Western medicine. The need for evidence-based studies and a standardized approach to scientific medicine aligns well with these applications. AI can leave a lasting impact on the Chinese medicine (CM) landscape by increasing expectations and presenting new challenges. The analogy between the CM-specific diagnostic methods and syndrome differentiation, which is holistic, pattern-oriented, patient-centered, and clinical data analysis, is significant at multiple levels. These qualities pose challenges for AI usage in CM, which heavily relies on structured data and pattern recognition. Despite these adversities, AI can still be used in CM through data standardization, prediction formulation, and treatment planning, provided that the integration of this tool considers the primary principles of CM and adheres to ethical and regulatory considerations. This review examines the dichotomous approach to health and medicine in the contexts of AI and CM, highlighting the evolving potential, inherent limitations, and ethical and regulatory issues associated with the application of AI to CM. It provides a foundation for developing technologically progressive yet culturally and philosophically sensitive strategies that are in harmony with traditional clinical values.}
}
@article{BURNSIDE2025577,
title = {Artificial Intelligence in Radiology: A Leadership Survey},
journal = {Journal of the American College of Radiology},
volume = {22},
number = {5},
pages = {577-585},
year = {2025},
issn = {1546-1440},
doi = {https://doi.org/10.1016/j.jacr.2025.01.006},
url = {https://www.sciencedirect.com/science/article/pii/S1546144025000419},
author = {Elizabeth S. Burnside and Thomas M. Grist and Michael R. Lasarev and John W. Garrett and Elizabeth A. Morris},
keywords = {Artificial intelligence, generative AI, leadership, radiology chairs, survey},
abstract = {Purpose
Surveys to assess views about artificial intelligence (AI) of various diagnostic radiology constituencies have revealed interesting combinations of enthusiasm, caution, and implementation priorities. We surveyed academic radiology leaders about their views on AI and how they intend to approach AI implementation in their departments.
Materials and methods
We conducted a web survey of Society of Chairs of Academic Radiology Departments members between October 5 and October 31, 2023, to solicit optimism or pessimism about AI, target use cases, planned implementation, and perceptions of their workforce. P values are provided only for descriptive purposes and have not been adjusted for multiple testing in this exploratory research.
Results
The survey was sent to the 112 Society of Chairs of Academic Radiology Departments members and 43 responded (38%). Chairs were optimistic, with no statistical difference between views of AI in general versus generative AI. Chairs plan to implement AI to improve quality and efficiency (43 of 43, 100%), burnout (41 of 43, 95%), health care costs (22 of 43, 51%), and equity (27 of 43, 63%) and most likely will target the postprocessing (26 of 43, 60%), interpretation workflow (26 of 43, 60%), and image acquisition (18 of 43, 42%) steps in the imaging value chain. Chairs perceived that radiologists (36 of 43, 84%) and technologists (38 of 43, 88%) were not particularly worried about being displaced but saw trainees as slightly less confident (31 of 43, 72%). Free text responses revealed concerns about the cost of AI and emphasized trade-offs that needed to be balanced.
Conclusion
Radiology chairs are optimistic about AI and poised to tackle departmental challenges. Concerns about generative AI and workforce replacement are minimal.}
}
@article{ROBERTS2024103081,
title = {Artificial intelligence and innovation management: Charting the evolving landscape},
journal = {Technovation},
volume = {136},
pages = {103081},
year = {2024},
issn = {0166-4972},
doi = {https://doi.org/10.1016/j.technovation.2024.103081},
url = {https://www.sciencedirect.com/science/article/pii/S0166497224001317},
author = {Deborah L. Roberts and Marina Candi},
keywords = {Artificial intelligence, Generative artificial intelligence, Innovation management, Innovation process},
abstract = {The excitement surrounding Artificial Intelligence (AI) is palpable. It is rapidly gaining prevalence in academia, business, and personal use. In particular, the emergence of generative AI, exemplified by large language models such as ChatGPT, has been marked by substantial media attention, discourse, and hype. Like most, if not all, aspects of business, innovation processes have been impacted. However, little is known about the degree of impact or the benefits that might be gained. To cut through the hype and understand the use of AI in innovation processes in businesses today, a large-scale survey amongst innovation managers in the USA was conducted, followed by interviews. The findings indicate that the use of AI in innovation processes is high and widespread, with AI being used for more than half of the surveyed firms' innovation projects. Furthermore, AI is used more in the development stage of the innovation process than in the idea or commercialization stages, which counters much of the existing discourse, which focuses on the idea stage. We uncover interesting differences by comparing the use and impact of generative AI with that of more traditional AI. Among these is a significant difference in expected benefits in making employees’ jobs more fulfilling — managers believe generative AI is more likely to confer this benefit than traditional AI. This paper offers two valuable contributions. First, it enriches the evolving dialogue at the intersection of AI and innovation management by offering much-needed empirical evidence about practical applications. Second, it provides timely managerial implications by examining relationships between the use of AI and innovation performance and understanding the benefits that AI can confer in the innovation process.}
}
@article{JU2025102955,
title = {Screening social anxiety with the Social Artificial Intelligence Picture System},
journal = {Journal of Anxiety Disorders},
volume = {109},
pages = {102955},
year = {2025},
issn = {0887-6185},
doi = {https://doi.org/10.1016/j.janxdis.2024.102955},
url = {https://www.sciencedirect.com/science/article/pii/S0887618524001312},
author = {Qianqian Ju and Zhijian Xu and Zile Chen and Jiayi Fan and Han Zhang and Yujia Peng},
keywords = {Social anxiety, Artificial Intelligence generative model, Social visual stimuli, Picture database, Screening, Machine learning, Longitudinal study},
abstract = {Social anxiety disorder (SAD) is a prevalent anxiety disorder marked by strong fear and avoidance of social scenarios. Early detection of SAD lays the foundation for the introduction of early interventions. However, due to the nature of social avoidance in social anxiety, the screening is challenging in the clinical setting. Classic questionnaires also bear the limitations of subjectivity, memory biases under repeated measures, and cultural influence. Thus, there exists an urgent need to develop a reliable and easily accessible tool to be widely used for social anxiety screening. Here, we developed the Social Artificial Intelligence Picture System (SAIPS) based on generative multi-modal foundation artificial intelligence (AI) models, containing a total of 279 social pictures and 118 control pictures. Social scenarios were constructed to represent core SAD triggers such as fear of negative evaluation, social interactions, and performance anxiety, mapping to specific dimensions of social anxiety to capture its multifaceted nature. Pictures devoid of social interactions were included as a control, aiming to reveal response patterns specific to social scenarios and to improve the system’s precision in predicting social anxiety traits. Through laboratory and online experiments, we collected ratings on SAIPS from five dimensions. Machine learning results showed that ratings on SAIPS robustly reflected and predicted an individual’s trait of social anxiety, especially social anxiety and arousal ratings. The prediction was reliable, even based on a short version with less than 30 pictures. Together, SAIPS may serve as a promising tool to support social anxiety screening and longitudinal predictions.}
}
@article{WONGVIBULSIN2025593,
title = {Educating Dermatologists for the Artificial Intelligence Era},
journal = {Dermatologic Clinics},
volume = {43},
number = {4},
pages = {593-601},
year = {2025},
note = {Artificial Intelligence in Dermatology},
issn = {0733-8635},
doi = {https://doi.org/10.1016/j.det.2025.05.010},
url = {https://www.sciencedirect.com/science/article/pii/S073386352500049X},
author = {Shannon Wongvibulsin and Ivy Lee},
keywords = {Artificial intelligence (AI) in dermatology, Medical education, Patient education, AI literacy, Learning health systems}
}
@article{LAWTON2025,
title = {Artificial intelligence in paediatric respiratory medicine},
journal = {Paediatric Respiratory Reviews},
year = {2025},
issn = {1526-0542},
doi = {https://doi.org/10.1016/j.prrv.2025.10.001},
url = {https://www.sciencedirect.com/science/article/pii/S1526054225000818},
author = {Adam Lawton and Dominic Hughes},
keywords = {Artificial intelligence, Machine learning, Paediatric respiratory medicine},
abstract = {Proponents of artificial intelligence (AI) believe that it will revolutionise the modern world, affecting how healthcare is delivered and improve both the clinical care we provide and the ease with which we perform our work. In this paper we explain what is meant by ‘artificial intelligence’ and explore how this technology has been implemented, or might be implemented, with respect to paediatric respiratory medicine. We review the current literature on how AI has been used to improve diagnostics − including examples in radiology, primary ciliary dyskinesia (PCD) diagnostics, sleep medicine, and pulmonary function tests. We also review how AI has been applied to therapeutics and drug discovery, how it will impact evidence-based medicine and literature review, and how clinician support tools will assist us in our work.}
}
@article{STEVENS2025100831,
title = {A Comparison of Artificial Intelligence Platforms in the Utility of Answering Frequently Asked Questions About Carpal Tunnel Syndrome: A Cross-Sectional Study},
journal = {Journal of Hand Surgery Global Online},
volume = {7},
number = {6},
pages = {100831},
year = {2025},
issn = {2589-5141},
doi = {https://doi.org/10.1016/j.jhsg.2025.100831},
url = {https://www.sciencedirect.com/science/article/pii/S2589514125001513},
author = {Calista Stevens and Mehreen Pasha and Dashun Liu and Andrew Block and Anthony Parrino and Craig Rodner},
keywords = {Carpal tunnel syndrome, Generative artificial intelligence, Hand, Orthopedic surgery},
abstract = {Purpose
The rise of artificial intelligence (AI) in health care comes with increasing concerns about the use and integrity of the information it generates. Chat Generative Pre-Trained Transformer (ChatGPT) 3.5, Google Gemini, and Bing Copilot are free AI chatbot platforms that may be used for answering medical questions and disseminating medical information. Given that carpal tunnel syndrome accounts for 90% of all neuropathies, it is important to understand the accuracy of the information patients may be receiving. The purpose of this study is to determine the use and accuracy of responses generated by ChatGPT, Google Gemini, and Bing Copilot in answering frequently asked questions about carpal tunnel syndrome.
Methods
Two independent authors scored responses using the DISCERN tool. DISCERN consists of 15 questions assessing health information on a five-point scale, with total scores ranging from 15 to 75 points. Then, a two-factor analysis of variance was conducted, with scorer and chatbot type as the factors.
Results
One-way analysis of variance revealed no significant difference in DISCERN scores among the three chatbots. The chatbots each scored in the “fair” range, with means of 45 for ChatGPT, 48 for Bing Copilot, and 46 for Google Gemini. The average Journal of the American Medical Association score for ChatGPT and Google Gemini surpassed that of Bing Copilot, with averages of 2.3, 2.3, and 1.8, respectively.
Conclusions
ChatGPT, Google Gemini, and Bing Copilot platforms generated relatively reliable answers for potential patient questions about carpal tunnel syndrome. However, users should continue to be aware of the shortcomings of the information provided, given the lack of citations, potential for misconstrued information, and perpetuated biases that inherently come with using such platforms. Future studies should explore the response quality for less common orthopedic pathologies and assess patient perceptions of response readability to determine the value of AI as a patient resource across the medical field.
Type of study/level of evidence
Cross-sectional study V}
}
@article{YANG2025109677,
title = {Artificial intelligence algorithms and its applications in pyrometallurgy: A review},
journal = {Minerals Engineering},
volume = {234},
pages = {109677},
year = {2025},
issn = {0892-6875},
doi = {https://doi.org/10.1016/j.mineng.2025.109677},
url = {https://www.sciencedirect.com/science/article/pii/S0892687525005059},
author = {Ling Yang and Yun Chen and Lian Lei and Yingli Liu and Qingwang Wang and Qiliang Yang and Tao Shen},
keywords = {Pyrometallurgy, Artificial intelligence, Machine learning, Deep learning, Reinforcement learning},
abstract = {The pyrometallurgical industry plays a crucial role in producing the metals. Due to the complexity of its production processes, as well as the nonlinear and dynamic characteristics of smelting, data collection systems are employed to record data during the pyrometallurgical production process to monitor real-time changes in equipment and process parameters. These systems generate vast amounts of data, which cannot be effectively analyzed through current manual processing methods involving human observer. Artificial intelligence (AI) algorithms are a data-driven technology that have demonstrated unprecedented performance in data analysis. Although AI has been applied in various fields such as healthcare, finance, and education, its use in the pyrometallurgical industry remains underexplored. This paper advocates for the necessity and potential value of AI in the pyrometallurgy by analyzing the advantages and disadvantages of AI algorithms as well as the challenges in pyrometallurgical production. It also aims to review the research progress over the past five years from both theoretical and industrial application perspectives. First, we present a classification of AI algorithms used in pyrometallurgy, covering machine learning (ML), deep learning (DL), and reinforcement learning (RL). Then, the specific applications of AI in the pyrometallurgical field are reviewed, with a focus on variable prediction, process optimization, anomaly monitoring and production planning and scheduling. Finally, we discuss the challenges and future prospects. This work combines the advancements of AI algorithms with the practical needs of pyrometallurgical production, providing a reference for researchers developing more advanced AI algorithms, while also offering support to metallurgical engineers in exploring more efficient solutions.}
}
@article{URBINA202514,
title = {Disability Ethics and Education in the Age of Artificial Intelligence: Identifying Ability Bias in ChatGPT and Gemini},
journal = {Archives of Physical Medicine and Rehabilitation},
volume = {106},
number = {1},
pages = {14-19},
year = {2025},
issn = {0003-9993},
doi = {https://doi.org/10.1016/j.apmr.2024.08.014},
url = {https://www.sciencedirect.com/science/article/pii/S0003999324011912},
author = {Jacob T. Urbina and Peter D. Vu and Michael V. Nguyen},
keywords = {Artificial intelligence, Bias, Digital health technology, Disability discrimination, Rehabilitation},
abstract = {Objective
To identify and quantify ability bias in generative artificial intelligence large language model chatbots, specifically OpenAI's ChatGPT and Google's Gemini.
Design
Observational study of language usage in generative artificial intelligence models.
Setting
Investigation-only browser profile restricted to ChatGPT and Gemini.
Participants
Each chatbot generated 60 descriptions of people prompted without specified functional status, 30 descriptions of people with a disability, 30 descriptions of patients with a disability, and 30 descriptions of athletes with a disability (N=300).
Interventions
Not applicable.
Main Outcome Measures
Generated descriptions produced by the models were parsed into words that were linguistically analyzed into favorable qualities or limiting qualities.
Results
Both large language models significantly underestimated disability in a population of people, and linguistic analysis showed that descriptions of people, patients, and athletes with a disability were generated as having significantly fewer favorable qualities and significantly more limitations than people without a disability in both ChatGPT and Gemini.
Conclusions
Generative artificial intelligence chatbots demonstrate quantifiable ability bias and often exclude people with disabilities in their responses. Ethical use of these generative large language model chatbots in medical systems should recognize this limitation, and further consideration should be taken in developing equitable artificial intelligence technologies.}
}
@article{HELD2025,
title = {Clinician Perceptions of Socrates 2.0: A Multi-Agent Artificial Intelligence Tool to Facilitate Socratic Dialogue},
journal = {Cognitive and Behavioral Practice},
year = {2025},
issn = {1077-7229},
doi = {https://doi.org/10.1016/j.cbpra.2025.10.001},
url = {https://www.sciencedirect.com/science/article/pii/S1077722925000975},
author = {Philip Held and Sarah A. Pridgen and Daniel R. Szoke and Yaozhong Chen and Zuhaib Akhtar and Darpan Amin},
keywords = {Generative artificial intelligence, cognitive behavior therapy, digital mental health, large language models, cognitive restructuring},
abstract = {Cognitive behavioral therapies (CBTs) are effective for various mental health disorders. Socratic dialogue, which helps patients examine and challenge maladaptive beliefs, is a key component of CBTs. Despite their effectiveness, CBTs often face challenges with low homework completion. Digital mental health tools that use generative artificial intelligence (AI), and specifically large language models, may enhance patients’ homework experience by engaging them in interactive Socratic dialogue. This feasibility study explored clinicians’ perceptions of Socrates 2.0, which employs a multi-agent AI approach combining an AI therapist, AI supervisor, and AI external rater. The tool was developed to engage users in Socratic dialogue to help them identify, evaluate, and potentially reframe maladaptive beliefs outside of therapy sessions, and thus reinforce skills, such as cognitive restructuring. A total of nine clinicians with at least a master’s degree were given two weeks of unlimited access to Socrates 2.0 and participated in semi-structured interviews. Transcripts were analyzed thematically. Positive themes included surprise at the tool’s sophistication, its potential as a therapy supplement, empowerment of patients, accessibility, and improved perceptions of AI in mental health care. Negative themes included concerns about repetitive questioning, potential replacement of therapists, limitations in crisis situations, and technology literacy barriers. Clinicians also desired empirical evidence of effectiveness and clarity on data privacy. Overall, clinicians recognized the potential of Socrates 2.0 to enhance CBT but emphasized the importance of careful integration and addressing identified concerns.}
}
@article{AULENBACHER2025,
title = {Development and Reliability Assessment of an Artificial Intelligence-Driven Urticaria Support (AIDUS) Chatbot},
journal = {The Journal of Allergy and Clinical Immunology: In Practice},
year = {2025},
issn = {2213-2198},
doi = {https://doi.org/10.1016/j.jaip.2025.07.047},
url = {https://www.sciencedirect.com/science/article/pii/S2213219825007585},
author = {Felix Aulenbacher and Annika Gutsche and Benedict Bihlmaier and Hanna Bonnekoh and Ivan Cherrez-Ojeda and Joachim W. Fluhr and Pavel Kolkhir and Markus Magerl and Martin Metz and Polina Pyatilova and Frank Siebenhaar and Torsten Zuberbier and Sophia Neisinger},
keywords = {Artificial intelligence, Chronic urticaria, ChatGPT},
abstract = {Background
Chronic urticaria (CU) severely impairs patients’ quality of life. Correctly diagnosing and treating CU can take years, so patients seek answers from the Internet to manage the condition.
Objective
We aimed to build a chatbot, Artificial Intelligence-Driven Urticaria Support (AIDUS) for patients with CU and treating physicians and to evaluate its reliability in providing high-quality CU-specific information compared with Chat Generative Pre-Trained Transformer (ChatGPT)-3.5 and ChatGPT-4o.
Methods
AIDUS was developed by an expert committee of urticaria and artificial intelligence specialists using JavaScript and OpenAI’s (https://www.clay.com/dossier/openai-headquarters-office-locations) ChatGPT large language model. PubMed was systematically reviewed to ensure AIDUS contained high-quality information. The chatbot was populated exclusively with selected peer-reviewed CU publications authored by the Charité University, Berlin research group, published after 2014. A total of 254 publications were integrated using ChatGPT-3.5 as the underlying algorithm. We developed A set of 100 validated questions based on current CU knowledge to evaluate the performance of AIDUS. The program was run on the same questions several times and compared for consistency. We tested performance with different chunk- and overlap-size settings to optimize AIDUS’s efficiency and accuracy.
Results
AIDUS outperformed general ChatGPT models in terms of accuracy, consistency, and stability in answering CU-specific questions. AIDUS demonstrated higher average accuracy (94.6%) across multiple test runs compared with ChatGPT-3.5 (42.6%) and ChatGPT-4o (85.7%).
Conclusions
AIDUS provides reliable, high-quality information about CU, addressing patients’ and physicians’ needs for accurate, relevant answers based on peer-reviewed medical literature. AIDUS remains a means of assistance and does not replace consultation with a physician.}
}
@article{ASHKBOUS2026103989,
title = {Artificial intelligence for eco-design: a systematic review},
journal = {Advanced Engineering Informatics},
volume = {69},
pages = {103989},
year = {2026},
issn = {1474-0346},
doi = {https://doi.org/10.1016/j.aei.2025.103989},
url = {https://www.sciencedirect.com/science/article/pii/S1474034625008821},
author = {Maryam Ashkbous and Elham Ghorbani and Samira Keivanpour},
keywords = {Artificial intelligence, Eco-design, Sustainable product development, Life cycle assessment, Circular economy},
abstract = {Eco-design integrates environmental considerations into product design, recognizing 80% of sustainability impacts determined at the design phase. Artificial intelligence (AI) provides powerful tools for optimizing designs, assessing environmental impacts, and supporting circular economy, making eco-design proactive. Despite AI use in sustainable product development, no review has synthesized these efforts. Therefore, we conducted a systematic review using the PRISMA method, covering 38 studies from 2014 to 2024 applied AI in eco-design. This is the first review to consider all life-cycle stages with eco-design practices, integrating Ellen MacArthur circularity principles, United Nations sustainable development goals (SDGs), life cycle assessment (LCA), industrial applications, and AI methods. Our findings reveal: 1- an imbalanced focus across product life-cycle stages, with most studies addressing design and end-of-life, while production, use-life, and distribution remain underexplored. 2- Common eco-design practices include recycling, energy reduction, and disassembly, with less focus on non-hazardous materials, waste minimization, and remanufacturing. 3- While neural networks and hybrid AI methods are commonly applied for material compatibility and emissions prediction, more advanced AI-based approaches such as generative AI and LLMs have yet to be used in design, LCA, and circularity analysis. 4- No study applies all four Ellen MacArthur Technosphere circular economy strategies. 5- Researchers rarely couple LCA with cradle-to-cradle assessments or embed their results in real-time design simulations. 6- Case studies mostly focus on electronics and household appliances, with limited application in automotive, aviation, maritime, and healthcare. 7- SDG consideration mainly centers on SDGs 12 and 13, with more attention neededforotherSDGs.}
}
@article{MUNIR2025102370,
title = {Taking the plunge together: A student-led faculty learning seminar series on artificial intelligence},
journal = {Currents in Pharmacy Teaching and Learning},
volume = {17},
number = {8},
pages = {102370},
year = {2025},
issn = {1877-1297},
doi = {https://doi.org/10.1016/j.cptl.2025.102370},
url = {https://www.sciencedirect.com/science/article/pii/S1877129725000917},
author = {Faria Munir and Elma Abdulbaki and Zeba Saiyad and Heather Ipema},
keywords = {Artificial intelligence, Drug information, Higher education, Pharmacy, Faculty, Pharmacy students, Learning series},
abstract = {Objective
This pilot study explored the effectiveness of a student-led faculty development series by evaluating two key outcomes: the capacity of students to deliver meaningful professional development sessions to faculty and the impact of these sessions on faculty perceptions of generative artificial intelligence (AI).
Methods
In a flipped classroom model, two pharmacy students and 12 faculty members engaged in a semester-long learning series on AI. Each week, students presented on a selected topic followed by discussions that facilitated self-directed learning, including decision-making and project management. Faculty perceptions of AI were evaluated before and after the series using an anonymous survey tool (Technology Acceptance Model Edited to Assess ChatGPT Adoption, TAME-ChatGPT). Respondents created a self-chosen code to link their responses. Additionally, students completed a questionnaire to gauge their reflective thinking after the series.
Results
Faculty participation averaged 7 members per session. Twelve faculty completed the pre-survey, while 8 faculty completed the post-survey. Among those who had used ChatGPT (n = 4 pre [33 %], n = 2 post [25 %]), scores for usefulness increased, while concerns about risks decreased. In contrast, faculty who had not used ChatGPT (n = 8 pre [67 %], n = 6 post [75 %]) reported unchanged or improved scores for ease of use and reduced anxiety. Both students responded positively to the reflective thinking questionnaire.
Conclusion
This pilot study demonstrated that a student-led faculty learning series effectively fostered mutual collaborative learning, benefiting both faculty and students. Pharmacy students, often an underutilized resource, can play a valuable role in faculty development. Colleges of pharmacy may enhance faculty engagement by integrating student-led initiatives into their programs.}
}
@article{INGASON2025100193,
title = {Personalised learning in project management education: Insights from an artificial intelligence-driven chatbot},
journal = {Project Leadership and Society},
volume = {6},
pages = {100193},
year = {2025},
issn = {2666-7215},
doi = {https://doi.org/10.1016/j.plas.2025.100193},
url = {https://www.sciencedirect.com/science/article/pii/S2666721525000183},
author = {Helgi Thor Ingason and Kirsi Aaltonen and Atli Snaer Asmundarson and Thordur Vikingur Fridgeirsson and Daniel Huemann and Martina Huemann and Jaakko Kujala and Hannele Lampela and Mauro Mancini and Costanza Mariani and Claudia Ringhofer},
abstract = {The increasing complexity of project-based work in contemporary organisations calls for a transformation in how project management is taught. Traditional teaching approaches struggle to support self-directed, context-sensitive, and motivationally engaging learning experiences—skills that are critical for preparing future project leaders. In this context, there is growing interest in the potential of artificial intelligence-powered tools to enhance the quality and adaptability of educating future project managers. This paper explores the application of artificial intelligence-driven chatbots in university-level project management education through the lens of the two-year international project ”ChatLearn” conducted across four European countries. Using an action design research methodology, the project iteratively developed and tested a chatbot in three versions, progressively integrating feedback from students and educators. The study suggests that artificial intelligence-based chatbots hold significant promise for supporting personalised learning journeys and increasing student motivation; however, their integration requires careful design, ongoing dialogue within the teaching community, and a strong alignment with pedagogical objectives.}
}
@article{LIAW2025104462,
title = {Artificial intelligence-enabled virtual reality simulation for clinical deterioration training: An effectiveness-implementation hybrid study},
journal = {Nurse Education in Practice},
volume = {87},
pages = {104462},
year = {2025},
issn = {1471-5953},
doi = {https://doi.org/10.1016/j.nepr.2025.104462},
url = {https://www.sciencedirect.com/science/article/pii/S1471595325002185},
author = {Sok Ying Liaw and Khairul Dzakirin Bin Rusli and Jian Zhi Tan and Yan Hui Celestine Wee and Nicholas Wee Siong Neo and Wei Ling Chua},
keywords = {Artificial intelligence, Clinical deterioration, Implementation science, Implementation outcome, Implementation strategies, Interprofessional education, Simulation, Virtual reality},
abstract = {Aim
This study evaluated the effectiveness of artificial intelligence in virtual reality simulation (AI-enabled VRS) in improving graduating nursing students’ knowledge on recognising and responding to clinical deterioration and its implementation outcomes.
Background
An AI-enabled VRS was adopted into a simulation-based education programme to facilitate graduating nursing students’ transition to clinical practice. There is a need to evaluate its effectiveness and implementation outcomes to facilitate the uptake of this innovative intervention into routine educational practice.
Design
This study employed a wait-list quasi-experimental, type 2 hybrid study trial.
Methods
A total of 147 graduating nursing students were recruited and assigned to experimental or control groups. The experimental groups undertook the AI-enabled VRS as part of the simulation-based program, while the control groups undertook the conventional programme. After the study intervention, a survey questionnaire was administered to measure the implementation outcomes.
Results
Despite no significant differences between groups, the experimental group reported higher mean scores for knowledge on recognising and responding to clinical deterioration and interprofessional communication than the control group. Overall, participants reported positive perceptions regarding the acceptability, adoption, appropriateness and feasibility of the AI-enabled VRS. They also recognised the benefits of the AI-enabled VRS in preparing them for clinical practice. However, participants highlighted the need to improve AI-human conversations, usability and technical stability.
Conclusion
The evaluation of the effectiveness and implementation outcomes of AI-enabled VRS identified the need for further strategies such as integrating generative AI (e.g. ChatGPT) to optimise its learning effectiveness and programme acceptance.}
}
@article{LIU2025,
title = {Leveraging Artificial Intelligence for Digital Symptom Management in Oncology: The Development of CRCWeb},
journal = {JMIR Cancer},
volume = {11},
year = {2025},
issn = {2369-1999},
doi = {https://doi.org/10.2196/68516},
url = {https://www.sciencedirect.com/science/article/pii/S2369199925000710},
author = {Darren Liu and Yufen Lin and Runze Yan and Zhiyuan Wang and Delgersuren Bold and Xiao Hu},
keywords = {colorectal cancer, health disparity, health equity, generative artificial intelligence, large language model, software engineering, artificial intelligence},
abstract = {Digital health interventions offer promise for scalable and accessible health care, but access is still limited by some participatory challenges, especially for disadvantaged families facing limited health literacy, language barriers, low income, or living in marginalized areas. These issues are particularly pronounced for patients with colorectal cancer (CRC), who often experience distressing symptoms and struggle with educational materials due to complex jargon, fatigue, or reading level mismatches. To address these issues, we developed and assessed the feasibility of a digital health platform, CRCWeb, to improve the accessibility of educational resources on symptom management for disadvantaged patients with CRC and their caregivers facing limited health literacy or low income. CRCWeb was developed through a stakeholder-centered participatory design approach. Two-phase semistructured interviews with patients, caregivers, and oncology experts informed the iterative design process. From the interviews, we developed the following 5 key design principles: user-friendly navigation, multimedia integration, concise and clear content, enhanced accessibility for individuals with vision and reading disabilities, and scalability for future content expansion. Initial feedback from iterative stakeholder engagements confirmed high user satisfaction, with participants rating CRCWeb an average of 3.98 out of 5 on the postintervention survey. Additionally, using generative artificial intelligence tools, including large language models like ChatGPT and multimedia generation tools such as Pictory, complex health care guidelines were transformed into concise, easily comprehensible multimedia content, and made accessible through CRCWeb. User engagement was notably higher among disadvantaged participants with limited health literacy or low income, who logged into the platform 2.52 times more frequently than nondisadvantaged participants. The structured development approach of CRCWeb demonstrates that generative artificial intelligence–powered multimedia interventions can effectively address health care accessibility barriers faced by disadvantaged patients with CRC and caregivers with limited health literacy or low income. This structured approach highlights how digital innovations can enhance health care.
International Registered Report Identifier (IRRID)
RR2-10.2196/48499}
}
@article{SABRI20252443,
title = {The Role of Artificial Intelligence in Improving Diagnostic Accuracy in Medical Imaging: A Review},
journal = {Computers, Materials and Continua},
volume = {85},
number = {2},
pages = {2443-2486},
year = {2025},
issn = {1546-2218},
doi = {https://doi.org/10.32604/cmc.2025.066987},
url = {https://www.sciencedirect.com/science/article/pii/S1546221825008586},
author = {Omar Sabri and Bassam Al-Shargabi and Abdelrahman Abuarqoub},
keywords = {Artificial intelligence, artificial intelligence applications, deep learning, medical imaging, diagnostic accuracy, bibliometric analysis},
abstract = {This review comprehensively analyzes advancements in artificial intelligence, particularly machine learning and deep learning, in medical imaging, focusing on their transformative role in enhancing diagnostic accuracy. Our in-depth analysis of 138 selected studies reveals that artificial intelligence (AI) algorithms frequently achieve diagnostic performance comparable to, and often surpassing, that of human experts, excelling in complex pattern recognition. Key findings include earlier detection of conditions like skin cancer and diabetic retinopathy, alongside radiologist-level performance for pneumonia detection on chest X-rays. These technologies profoundly transform imaging by significantly improving processes in classification, segmentation, and sequential analysis across diverse modalities such as X-rays, Computed Tomography (CT), Magnetic Resonance Imaging (MRI), and ultrasound. Specific advancements with Convolutional Neural Networks, Recurrent Neural Networks, and ensemble learning techniques have facilitated more precise diagnosis, prediction, and therapy planning. Notably, Generative Adversarial Networks address limited data through augmentation, while transfer learning efficiently adapts models for scarce labeled datasets, and Reinforcement Learning shows promise in optimizing treatment protocols, collectively advancing patient care. Methodologically, a systematic review (2015–2024) used Scopus and Web of Science databases, yielding 7982 initial records. Of these, 1189 underwent bibliometric analysis using the R package ‘Bibliometrix’, and 138 were comprehensively reviewed for specific findings. Research output surged over the decade, led by Institute of Electrical and Electronics Engineers (IEEE) Access (19.1%). China dominates publication volume (36.1%), while the United States of America (USA) leads total citations (5605), and Hong Kong exhibits the highest average (55.60). Challenges include rigorous validation, regulatory clarity, and fostering clinician trust. This study highlights significant emerging trends and crucial future research directions for successful AI implementation in healthcare.}
}
@article{BALODA2025112405,
title = {Future of humanity in an artificial intelligence centric world},
journal = {Engineering Applications of Artificial Intelligence},
volume = {162},
pages = {112405},
year = {2025},
issn = {0952-1976},
doi = {https://doi.org/10.1016/j.engappai.2025.112405},
url = {https://www.sciencedirect.com/science/article/pii/S0952197625024303},
author = {Sunil Baloda and Monika Sharma and Mukesh Kumar},
keywords = {Trustworthy artificial intelligence, Machine learning, Healthcare, Anomaly detection, Societal impact},
abstract = {This scholarly article rigorously investigates the transformative and disruptive roles of artificial intelligence (AI) in influencing the trajectory of human society. By concentrating on three fundamental sectors—healthcare, finance, and education—it evaluates the ways in which AI augments operational efficiency, facilitates intricate decision-making processes, and introduces innovative capabilities such as personalized medicine and automated financial systems. Concurrently, the analysis underscores urgent ethical dilemmas, encompassing algorithmic bias, accountability deficiencies, data privacy vulnerabilities, and workforce displacement. Employing real-world examples such as Deepfakes, and Neuralink, the article contextualizes emerging challenges within a dynamic socio-technical framework. The research offers a cohesive conceptual model that amalgamates technical, ethical, and governance aspects of AI, while presenting policy recommendations designed to promote transparency, equity, and human-centered AI development. The study emphasizes the necessity for reliable AI systems that humans can trust. The conclusions accentuate the immediate necessity for robust regulatory frameworks and sector-specific ethical supervision to ensure that advancements in AI are harmonized with the well-being of society.}
}
@article{MARINO20241490,
title = {The Application of mHealth and Artificial Intelligence to Chronic Rhinitis},
journal = {The Journal of Allergy and Clinical Immunology: In Practice},
volume = {12},
number = {6},
pages = {1490-1492},
year = {2024},
issn = {2213-2198},
doi = {https://doi.org/10.1016/j.jaip.2024.04.019},
url = {https://www.sciencedirect.com/science/article/pii/S2213219824004033},
author = {Michael J. Marino and Bernardo Sousa-Pinto and Devyani Lal},
keywords = {Artificial intelligence, AI, Mobile health, mHealth, Rhinitis, Machine learning, Generative AI}
}
@article{SALIDO2025101924,
title = {Integrating critical thinking and artificial intelligence in higher education: A bibliometric and systematic review of skills and strategies},
journal = {Social Sciences & Humanities Open},
volume = {12},
pages = {101924},
year = {2025},
issn = {2590-2911},
doi = {https://doi.org/10.1016/j.ssaho.2025.101924},
url = {https://www.sciencedirect.com/science/article/pii/S2590291125006527},
author = {Achmad Salido and Irman Syarif and Melyani Sari Sitepu and  Suparjan and Prima Rias Wana and Ryan Taufika and Rahyuni Melisa},
keywords = {Artificial intelligence, Higher education, Critical thinking, Personalized learning, AI literacy},
abstract = {This study examines the academic landscape on integrating artificial intelligence and critical thinking in higher education, revealing conceptualizations, competencies required by students, challenges and recommended learning strategies. The study employs a bibliometric analysis approach combined with a systematic literature review as a qualitative approach. A total of 640 documents were retrieved from the Scopus database using the query: (“critical thinking” AND (“artificial intelligence” OR AI) AND (“higher education” OR university OR college)), accessed on July 10, 2025. The dataset was limited to 2023–2025, reflecting the period following the widespread adoption of ChatGPT and similar generative AI tools in academic contexts. From this, 290 documents were selected for bibliometric analysis, and 23 were in-depth synthesized based on established inclusion criteria. The findings reveal a growing consolidation of research on AI and critical thinking, driven by a small group of highly influential authors and concentrated in prominent interdisciplinary journals. Five thematic clusters were identified: pedagogical innovation, psychological dimensions, academic ethics, systemic integration, and AI-related literacies. Emerging research directions include personalized learning, digital literacy, engineering education, and ethical AI applications. Critical thinking is conceptualized as a purposeful, evaluative, and self-regulated process that must be preserved despite increasing reliance on AI tools. Key challenges include uncritical dependence on AI, digital literacy disparities, lack of system transparency, and institutional limitations. The study highlights the need for inclusive and adaptive instructional frameworks that integrate AI in ways that support critical thinking in diverse higher education settings.}
}
@article{ARBOIT2025110525,
title = {Surgeons’ Awareness, Expectations, and Involvement with Artificial Intelligence: a Survey Pre and Post the GPT Era},
journal = {European Journal of Surgical Oncology},
pages = {110525},
year = {2025},
issn = {0748-7983},
doi = {https://doi.org/10.1016/j.ejso.2025.110525},
url = {https://www.sciencedirect.com/science/article/pii/S0748798325009539},
author = {Lorenzo Arboit and Dennis N. Schneider and Toby Collins and Daniel A. Hashimoto and Silvana Perretta and Bernard Dallemagne and Jacques Marescaux and Yoav Mintz and Kiyokazu Nakajima and Michele Diana and Tim Horeman and Manish Chand and Rosa Maria Jimenez-Rodriguez and Luigi Manfredi and Hans Fuchs and Young Woo Kim and Martin Wagner and Pieter {de Backer} and Felix Nickel and Nicolas Padoy and Pietro Mascagni},
keywords = {Surgical Data Science, Artificial Intelligence, Surgical Survey, Surgical Education},
abstract = {ABSTRACT
Objective
Artificial Intelligence (AI) is transforming medicine, with generative AI models like ChatGPT reshaping perceptions of its potential. This study examines surgeons’ awareness, expectations, and involvement with AI in surgery through comparative surveys conducted in 2021 and 2024.
Materials and Methods
Two cross-sectional surveys were distributed globally in 2021 and 2024, the first before an IRCAD webinar and the second during the annual EAES meeting. The surveys assessed demographics, AI awareness, expectations, involvement, and ethics (2024 only).
Results
The surveys collected a total of 671 responses from 98 countries, 522 and 149 in 2021 and 2024, respectively. Awareness of AI courses rose from 14.5% in 2021 to 44.6% in 2024, while course attendance increased from 12.9% to 23%. Despite this, familiarity with foundational AI concepts remained limited. Expectations for AI’s role shifted in 2024, with hospital management gaining relevance. Ethical concerns gained prominence, with 87.2% of 2024 participants emphasizing accountability and transparency. Infrastructure limitations remained the primary obstacle to the implementation of AI. Interdisciplinary collaboration and structured training were identified as critical for successful AI adoption. Optimism about AI’s transformative potential remained high, with 79.9% of respondents believing AI would positively impact surgery and 96.6% of surgeons willing to integrate AI into clinical practice.
Discussion and Conclusion
Surgeons’ perceptions of AI are evolving, driven by the rise of generative AI and the advancements in surgical data science. While enthusiasm for integration is strong, knowledge gaps and infrastructural challenges persist. Addressing these through education, ethical frameworks, and infrastructure development is essential.}
}
@article{SUBILLAGA2025103566,
title = {Artificial Intelligence-Assisted Narratives: Analysis of Surgical Residency Personal Statements},
journal = {Journal of Surgical Education},
pages = {103566},
year = {2025},
issn = {1931-7204},
doi = {https://doi.org/10.1016/j.jsurg.2025.103566},
url = {https://www.sciencedirect.com/science/article/pii/S1931720425001473},
author = {Oswaldo Subillaga and Aixa Pérez Coulter and David Tashjian and Neal Seymour and Daniel Hubbs},
keywords = {artificial intelligence, general surgery residency, personal statements, graduate medical education, NRMP match, interpersonal and communication skills},
abstract = {Objective
Personal statements (PSs) express applicants’ personal characteristics and motivations informing pursuit of a surgical career. Generative artificial intelligence (AI) is a revolutionary technology. There are currently no data to suggest how and to what extent AI is used in surgical residency applications. We examined the prevalence of AI use and applicant pool characteristics in PSs submitted to a surgical residency.
Design
PSs from US MD and DO applicants to an academic general surgery program were collected for both the 2022-23 and 2023-24 NRMP Match cycles. PSs were analyzed using 2 AI-detection tools: GPTZero and Copyleaks. Data were analyzed using T-test and Fisher’s Exact Test.
Setting
UMass Chan Medical School—Baystate general surgery residency program in Springfield, Massachusetts.
Participants
There were 1332 applications during 2022-23 NRMP Match cycle and 1221 for 2023-24. After excluding international medical graduates and incomplete applications, 1490 PSs were analyzed.
Results
1490 PS were included (758 [50.9%] for 2022-23; 732 [49.1%] for 2023-24). Demographic characteristics did not differ between the 2 cycles. GPTZero identified AI use in 77 (10.2%) PSs in 2022-23 and 268 (36.6%) in 2023-24 (p < 0.001). Copyleaks identified AI use in 20 (2.6%) PSs in 2022-23 and 165 (22.5%) in 2023-24 (p < 0.001). Concordance in AI detection with both tools was observed in 13 (1.7% of total PSs) for 2022-23 and 155 (21.2%) for 2023-24 (p < 0.001). Subgroup analysis of concordance in 2023-24 showed increased non-English native language characteristics (38.7% vs 19.6%; p < 0.001), a lower average personal statement word count (597.3 vs 645.9; p < 0.001) and shorter average sentence (10.0 vs 10.4 words; p < 0.001) in the AI group.
Conclusions
Although AI-detection tools are imperfect, demonstration of increased AI use in personal statement preparation is compelling. Implications of AI use in residency applications are unknown, and programs must develop policies anticipating ongoing and potentially increased use of AI in the upcoming application cycles.}
}
@incollection{KHALEEL20262,
title = {Future Proofing the Integrity of Assessments Within Business Management Studies for the Age of Artificial Intelligence},
editor = {Vanessa Ratten},
booktitle = {International Encyclopedia of Business Management (First Edition)},
publisher = {Academic Press},
edition = {First Edition},
address = {Oxford},
pages = {2-8},
year = {2026},
isbn = {978-0-443-13702-0},
doi = {https://doi.org/10.1016/B978-0-443-13701-3.00330-3},
url = {https://www.sciencedirect.com/science/article/pii/B9780443137013003303},
author = {Fawad Khaleel and Patrick Harte and Alija Avdukic},
keywords = {Academic dishonesty, Academic integrity, Artificial intelligence, Assessment design, Complexity of assessment design, Coursework, Plagiarism, Word count},
abstract = {The content generative artificial intelligence is developing rapidly, and it is challenging the old norms of assessment design within the HEIs. This chapter discusses the impact of AI on the academic integrity, as we argue that with a slight shift within the assessment design, we can address the academic integrity concerns that surfacing within the higher education. This chapter provides practical and useable guidelines that could be used to reduce the breaches of academic integrity within business management programmes at HEIs. These guidelines focus on word count for coursework, complexity of assessment question and social dynamics of assessment design.}
}
@article{ELSAYED2025103083,
title = {Artificial Intelligence adoption, perceptions, and ethical literacy among Arab academic librarians: A survey},
journal = {The Journal of Academic Librarianship},
volume = {51},
number = {5},
pages = {103083},
year = {2025},
issn = {0099-1333},
doi = {https://doi.org/10.1016/j.acalib.2025.103083},
url = {https://www.sciencedirect.com/science/article/pii/S0099133325000795},
author = {Amany M. Elsayed and Majed {Mohammed Abusharhah}},
keywords = {Artificial intelligence in libraries, Academic libraries, Academic librarians, Artificial intelligence literacy, Artificial intelligence in higher education, Arab countries, Artificial intelligence ethics},
abstract = {The study explored how Arab academic libraries are adopting artificial intelligence (AI) and examined the awareness of AI ethical considerations from the perspectives of Arab academic librarians. It utilized a survey-based approach, employing a snowball sampling technique across 48 academic libraries in 17 Arab countries. The research instrument was a web-based questionnaire, which received responses from a total of 272 participants. The findings revealed that 37.5 % of respondents indicated that their libraries use AI, with cataloging and generating metadata being the most common applications used by 43 % of libraries. The study highlighted several challenges to AI adoption in Arab academic libraries, including a lack of necessary infrastructure and staff training. Moreover, about 81 % of Arab academic librarians believed that intellectual property and copyright are the most important ethical considerations regarding AI. However, only 12% of participants reported having encountered ethical issues related to AI use in their library work. The results indicated that the primary actions taken by Arab academic libraries were offering face-to-face or online seminars and workshops on AI ethics, as well as providing ethical considerations and resources related to academic integrity through their websites. The study recommended that Arab academic libraries organize appropriate training programs to improve AI literacy among staff, develop the necessary infrastructure for AI adoption, and prepare relevant policy documents to guide the ethical use of AI technologies.}
}
@article{HONG2025,
title = {Radiologist Interaction with Artificial Intelligence-Generated Preliminary Reports: A Longitudinal Multireader Study},
journal = {Journal of the American College of Radiology},
year = {2025},
issn = {1546-1440},
doi = {https://doi.org/10.1016/j.jacr.2025.09.015},
url = {https://www.sciencedirect.com/science/article/pii/S1546144025005587},
author = {Eun Kyoung Hong and Chong Hyun Suh and Monika Nukala and Azadehsadat Esfahani and Andro Licaros and Rachna Madan and Andetta Hunsaker and Mark Hammer},
keywords = {Chest radiographs, generative AI, radiologist-AI interaction, report generation},
abstract = {Objectives
To investigate the integration of multimodal AI-generated reports into radiology workflow over time, focusing on their impact on efficiency, acceptability, and report quality.
Methods
A multicase, multireader study involved 756 publicly available chest radiographs interpreted by five radiologists using preliminary reports generated by a radiology-specific multimodal AI model, divided into 7 sequential batches of 108 radiographs each. Two thoracic radiologists assessed the final reports using RADPEER criteria for agreement and 5-point Likert scale for quality. Reading times, rate of acceptance without modification, agreement, and quality scores were measured, with statistical analyses evaluating trends across seven sequential batches.
Results
Radiologists’ reading times for chest radiographs decreased from 25.8 seconds in batch 1 to 19.3 seconds in batch 7 (P < .001). Acceptability increased from 54.6% to 60.2% (P < .001), with normal chest radiographs demonstrating high rates (68.9%) compared with abnormal chest radiographs (52.6%; P < .001). Median agreement and quality scores remained stable for normal chest radiographs but varied significantly for abnormal chest radiographs (all P < .05).
Discussion
The introduction of AI-generated reports improved efficiency of chest radiograph interpretation, and acceptability increased over time. However, agreement and quality scores showed variability, particularly in abnormal cases, emphasizing the need for oversight in the interpretation of complex chest radiographs.}
}
@article{EYO2025757,
title = {A Survey of Artificial Intelligence in Primary Care Fellowships—Practical Tools},
journal = {Primary Care: Clinics in Office Practice},
volume = {52},
number = {4},
pages = {757-767},
year = {2025},
note = {AI in Primary Care},
issn = {0095-4543},
doi = {https://doi.org/10.1016/j.pop.2025.07.007},
url = {https://www.sciencedirect.com/science/article/pii/S0095454325000685},
author = {Eno Eyo and Uzoma Dike},
keywords = {Addiction, Primary care fellowships, Sports medicine, Adolescent medicine, Geriatric medicine, Addiction medicine, Substance use disorder, Artificial intelligence}
}
@article{GASQUE2025100101,
title = {HPB SmartNotes: The impact of artificial intelligence on surgeon workload in the outpatient office},
journal = {EngMedicine},
volume = {2},
number = {4},
pages = {100101},
year = {2025},
issn = {2950-4899},
doi = {https://doi.org/10.1016/j.engmed.2025.100101},
url = {https://www.sciencedirect.com/science/article/pii/S2950489925000478},
author = {Rodrigo Antonio Gasque and Noelia Zaietta and Lourdes Mollard and Magali Chahdi Beltrame and Marcelo Enrique Lenz Virreira and Emilio Gastón Quiñonez and Francisco Juan Mattera},
keywords = {Artificial intelligence, Office visits, Natural language processing, HPB surgery},
abstract = {In this study, we aimed to evaluate the feasibility, linguistic accuracy, and coherence of medical notes generated by the integration of an automatic speech recognition system (ASR) and a generative pre-trained transformer (GPT) in an outpatient surgical setting and to assess their impact on documentation time. This prospective exploratory study included 20 adults who visited their first outpatient clinic due to hepatobiliary or pancreatic conditions. Consultations were audio-recorded, transcribed using Whisper-1 (OpenAI), and converted into structured Subjective, Objective, Assessment and Plan (SOAP) clinical notes using ChatGPT 3.5 (OpenAI), implemented through Python 3.11.6. The transcriptions were manually reviewed against gold-standard references, and the ASR performance was quantified using standard metrics from the Jiwer library. Descriptive statistics were computed, and the ChatGPT note quality was evaluated using a standardized checklist, before assessing for statistical significance. The median patient age was 47 years (65 % female). The average interview duration was 15.98 min. Whisper transcribed audio in a median of 59.3 s, and ChatGPT generated SOAP notes in 5.7 s. ChatGPT produced satisfactory results in 85 % of cases, with a significant performance. The ASR system demonstrated acceptable transcription quality. The integration of Whisper and ChatGPT drastically reduced the documentation time compared with manual electronic health record (EHR) entry. Despite some limitations, these results highlight the promise of artificial intelligence (AI)-powered documentation tools in outpatient practice. Further research with larger samples and direct comparisons with traditional methods is warranted to confirm these findings and address the ethical, legal, and implementation challenges associated with AI in clinical environments.}
}
@article{MILLER2025,
title = {Artificial intelligence in nuclear cardiology: Enhancing diagnostic accuracy and efficiency},
journal = {Progress in Cardiovascular Diseases},
year = {2025},
issn = {0033-0620},
doi = {https://doi.org/10.1016/j.pcad.2025.09.010},
url = {https://www.sciencedirect.com/science/article/pii/S0033062025001434},
author = {Robert J.H. Miller and Panithaya Chareonthaitawee and Piotr J. Slomka},
keywords = {Nuclear cardiology, Artificial intelligence, Deep learning, Machine learning, Review},
abstract = {Artificial intelligence (AI) is rapidly reshaping cardiovascular imaging, with nuclear cardiology uniquely positioned to benefit. By addressing the technical complexity of image acquisition, reconstruction, and interpretation, AI can enhance image quality, reduce radiation exposure, and improve efficiency. Beyond image optimization, AI enables virtual attenuation correction and automated quantification of novel risk markers that are otherwise impractical to assess manually. Machine learning models can also integrate multimodal data, including clinical, stress, and imaging features, to support more accurate diagnosis and to refine risk stratification. Deep learning can be used to provide direct diagnostic or risk stratification estimates from nuclear cardiology images. This review highlights recent advances in AI within nuclear cardiology, outlines their potential to transform clinical workflows, and discusses future directions for integrating these tools into routine practice.}
}
@article{HELGESON2025622,
title = {Human Reviewers' Ability to Differentiate Human-Authored or Artificial Intelligence–Generated Medical Manuscripts: A Randomized Survey Study},
journal = {Mayo Clinic Proceedings},
volume = {100},
number = {4},
pages = {622-633},
year = {2025},
issn = {0025-6196},
doi = {https://doi.org/10.1016/j.mayocp.2024.08.029},
url = {https://www.sciencedirect.com/science/article/pii/S0025619624004890},
author = {Scott A. Helgeson and Patrick W. Johnson and Nilaa Gopikrishnan and Tapendra Koirala and Pablo Moreno-Franco and Rickey E. Carter and Zachary S. Quicksall and Charles D. Burger},
abstract = {Objective
To assess the ability of humans to differentiate human-authored vs artificial intelligence (AI)–generated medical manuscripts.
Methods
This is a prospective randomized survey study from October 1, 2023, to December 1, 2023, from a single academic center. Artificial intelligence–generated medical manuscripts were created using ChatGPT 3.5 and were evaluated alongside randomly selected human-authored manuscripts. Participants, who were blinded from manuscript selection and creation, were randomized to receive three manuscripts that were either human-authored or AI-generated and had to fill out a survey questionnaire after review regarding who authored the manuscript. The primary outcome was accuracy of human reviewers in differentiating manuscript authors. Secondary outcomes were to identify factors that influenced prediction accuracy.
Results
Fifty-one physicians were included in the study, including 12 post-doctorates, 19 assistant professors, and 20 associate or full professors. The overall specificity of 55.6% (95% CI, 30.8% to 78.5%), sensitivity of 31.2% (95% CI,11.0% to 58.7%), positive predictive value of 38.5% (95% CI,13.9% to 68.4%) and negative predictive value of 47.6% (95% CI, 25.7% to 70.2%). A stratified analysis of human-authored manuscripts indicated that high-impact factor manuscripts were identified with higher accuracy than low-impact factor ones (P=.037). For individual-level data, neither academic rank nor prior manuscript review experience significantly predicted the accuracy. The frequency of AI interaction was a significant factor, with occasional (odds ratio [OR], 8.20; P=.016), fairly frequent (OR, 7.13; P=.033), and very frequent (OR, 8.36; P=.030) use associated with correct identification. Further analysis revealed no significant predictors among the papers' qualities.
Conclusion
Generative AI such as ChatGPT could create medical manuscripts that could not be differentiated from human-authored manuscripts.}
}
@article{GU2025,
title = {Radiology workflow assistance with artificial intelligence: establishing the link to outcomes},
journal = {Journal of the American College of Radiology},
year = {2025},
issn = {1546-1440},
doi = {https://doi.org/10.1016/j.jacr.2025.10.018},
url = {https://www.sciencedirect.com/science/article/pii/S1546144025005988},
author = {Zehui Gu and Siddhant Dogra and Mutita Siriruchatanon and Jerard Kneifati-Hayek and Stella K. Kang},
keywords = {artificial intelligence, radiology workflow, language model, reporting, outcomes},
abstract = {Artificial intelligence (AI) applications for radiology workflow have the potential to improve patient and health-system-level outcomes through more efficient and accurate diagnosis and clinical decision making. For a variety of time-intensive steps, numerous types of applications are now available with variable reported measures and degrees of success. The tools we highlight aim to accelerate imaging acquisition, reduce cognitive and manual burden on radiologists and others involved in the care pathway, improve diagnostic accuracy, and shorten the time to clinical action based on imaging results. Most existing studies have focused on intermediate outcomes, such as task duration or time to the next step in care. In this article, we present an examination of AI applications across the medical imaging exam workflow, review examples of real-world evidence on these tools, and summarize the relevant performance metrics by application type. Beyond the more immediately acquired measures, to demonstrate benefit to patient health and economic outcomes, a more integrated assessment is necessary, and in an iterative fashion. To evolve beyond early workflow gains, interoperable tools must be tied to measurable downstream impacts, such as reduced disease severity, lower mortality, and shorter hospital stays, while we acknowledge that current empirical evaluations are limited.}
}
@article{ALIER2025103940,
title = {LAMB: An open-source software framework to create artificial intelligence assistants deployed and integrated into learning management systems},
journal = {Computer Standards & Interfaces},
volume = {92},
pages = {103940},
year = {2025},
issn = {0920-5489},
doi = {https://doi.org/10.1016/j.csi.2024.103940},
url = {https://www.sciencedirect.com/science/article/pii/S0920548924001090},
author = {Marc Alier and Juanan Pereira and Francisco José García-Peñalvo and Maria Jose Casañ and Jose Cabré},
keywords = {Generative artificial intelligence, Education domain, Learning assistant, Retrieval-Augmented Generation (RAG), Large language model (LLM), IMS learning tools interoperability (LTI)},
abstract = {This paper presents LAMB (Learning Assistant Manager and Builder), an innovative open-source software framework designed to create AI-powered Learning Assistants tailored for integration into learning management systems. LAMB addresses critical gaps in existing educational AI solutions by providing a framework specifically designed for the unique requirements of the education sector. It introduces novel features, including a modular architecture for seamless integration of AI assistants into existing LMS platforms and an intuitive interface for educators to create custom AI assistants without coding skills. Unlike existing AI tools in education, LAMB provides a comprehensive framework that addresses privacy concerns, ensures alignment with institutional policies, and promotes using authoritative sources. LAMB leverages the capabilities of large language models and associated generative artificial intelligence technologies to create generative intelligent learning assistants that enhance educational experiences by providing personalized learning support based on clear directions and authoritative fonts of information. Key features of LAMB include its modular architecture, which supports prompt engineering, retrieval-augmented generation, and the creation of extensive knowledge bases from diverse educational content, including video sources. The development and deployment of LAMB were iteratively refined using a minimum viable product approach, exemplified by the learning assistant: “Macroeconomics Study Coach,” which effectively integrated lecture transcriptions and other course materials to support student inquiries. Initial validations in various educational settings demonstrate the potential that learning assistants created with LAMB have to enhance teaching methodologies, increase student engagement, and provide personalized learning experiences. The system's usability, scalability, security, and interoperability with existing LMS platforms make it a robust solution for integrating artificial intelligence into educational environments. LAMB's open-source nature encourages collaboration and innovation among educators, researchers, and developers, fostering a community dedicated to advancing the role of artificial intelligence in education. This paper outlines the system architecture, implementation details, use cases, and the significant benefits and challenges encountered, offering valuable insights for future developments in artificial intelligence assistants for any sector.}
}
@article{SRIDHARAN2025101965,
title = {Artificial intelligence in colloid and interface science: Current research, challenges and future directions},
journal = {Current Opinion in Colloid & Interface Science},
volume = {80},
pages = {101965},
year = {2025},
issn = {1359-0294},
doi = {https://doi.org/10.1016/j.cocis.2025.101965},
url = {https://www.sciencedirect.com/science/article/pii/S1359029425000718},
author = {Simha Sridharan and Tom Bailey and Agnese Marcato and Elena Simone and Nicholas Watson},
keywords = {Artificial intelligence, Machine learning, Colloid science, Interface science},
abstract = {Artificial intelligence (AI) and Machine learning (ML) are transforming colloid and interface science by enabling predictive modelling, autonomous experimentation, and accelerated material design. This review highlights recent advances organised in four topics: (1) prediction of basic physical properties; (2) image analysis; (3) process design, monitoring and optimisation; and (4) morphology and phase behaviour prediction. AI models have improved the prediction accuracy of interfacial tension, critical micelle concentration, foam stability, and complex structure–function relationships, in particular, integrated generative AI approaches support the design of new surfactants and emulsifiers. Image analysis has automated microstructural characterisation and enabled real-time quality control, while AI-enhanced process design has delivered digital twins, closed-loop optimisation, and sustainability-oriented workflows. Morphology and phase behaviour prediction has combined simulation-driven neural networks with generative approaches to accelerate material discovery. The future of AI applications in colloids will be shaped by experimental database design and standardisation, hybrid AI methods integrating physics and surrogate modelling, and AI agents leveraging large language models for literature mining, data curation, and experimental optimisation. Together, these developments promise to establish data-rich, physics informed, and increasingly autonomous research ecosystems for colloids and interface science, accelerating material understanding and design.}
}
@article{CHEEMA2025799,
title = {The Future of Artificial Intelligence and Artificial Intelligence in Primary Care: Challenges and Opportunities},
journal = {Primary Care: Clinics in Office Practice},
volume = {52},
number = {4},
pages = {799-811},
year = {2025},
note = {AI in Primary Care},
issn = {0095-4543},
doi = {https://doi.org/10.1016/j.pop.2025.07.011},
url = {https://www.sciencedirect.com/science/article/pii/S0095454325000727},
author = {Alyscia Miriam Cheema},
keywords = {Artificial intelligence in primary care, Primary care practice training with artificial intelligence, Future impacts of AI on primary care, Challenges with AI in primary care}
}
@article{LUKIC2025,
title = {Fundamentals of artificial intelligence for nursing students: Educational innovation},
journal = {Teaching and Learning in Nursing},
year = {2025},
issn = {1557-3087},
doi = {https://doi.org/10.1016/j.teln.2025.08.033},
url = {https://www.sciencedirect.com/science/article/pii/S1557308725002665},
author = {Anita Lukić and Ivan Krešimir Lukić},
keywords = {artificial intelligence, innovation, nursing, teaching, students},
abstract = {Background
In spite of interest in the use of artificial intelligence (AI) in nursing education, there are no studies on teaching nursing students' basics of AI technology.
Innovation
An elective course for undergraduate students of nursing (final year), consigning of 10 hours of lectures, covering the following topics: Basics of AI; Principles and concepts of machine learning; Evaluation of AI-based tools; and Implementation of AI in healthcare.
Results
Nineteen students attended the course and thirteen provided their feedback. Students’ evaluation was positive: 77% (10 out of 13) would pick the same elective again and recommend it to others. They suggested more live demos and dedicating more time to ChatGPT.
Implications
Our experience with a course focusing on basic principles of AI technology as well as list of resources and feedback of our students can be of use to nursing educators when planning similar courses.
Conclusions
Since nursing students’ readiness to embrace AI technology depends on understanding of the technology, educating students on foundational algorithmic principles may have a positive impact on adoption of AI in nursing practice.}
}
@article{CHRISTINA2025152040,
title = {Integrating the Caring Life Course Theory and Artificial Intelligence Applications to Enhance Cancer Care Across the Continuum},
journal = {Seminars in Oncology Nursing},
pages = {152040},
year = {2025},
issn = {0749-2081},
doi = {https://doi.org/10.1016/j.soncn.2025.152040},
url = {https://www.sciencedirect.com/science/article/pii/S0749208125002335},
author = {Juliana Christina and Kelly Ford and Bradly Menz and Michael Sorich and Ashley Hopkins and Imogen Ramsey and Maree Duddle and Alison Kitson and Catherine Paterson},
keywords = {Cancer, Artificial intelligence, Caring life course theory, Person-centred care, Care networks, Survivorship, Equity},
abstract = {Objectives
With the escalating global burden of cancer, there is an increasing imperative to adopt holistic, person-centered approaches that address the complex and evolving care needs of individuals across the cancer continuum. Integrating advanced technologies such as artificial intelligence (AI) into conventional cancer care models offers significant potential to enhance the responsiveness, inclusivity, and sustainability of cancer care delivery. This paper aimed to explore how the Caring Life Course Theory (CLCT), a comprehensive multidisciplinary framework of care, can inform and enhance the integration of AI into cancer care delivery.
Methods
A conceptual synthesis and narrative synthesis were employed to explore and understand how CLCT constructs can inform AI applications across different levels of cancer care (individual, relational/network and structural).
Results
AI technologies are being used to support personalized care planning, real-time symptom monitoring, survivorship management, and coordinated service delivery. Guided by the CLCT, these technologies offer a structured and contextually grounded approach to delivering longitudinal, life-course-informed care. Nonetheless, significant challenges remain, including ethical concerns, algorithmic bias, and implementation barriers.
Conclusions
Aligning AI technologies with the CLCT framework can promote more personalized, equitable, and relationally responsive cancer care. Future research must prioritize ethical co-design, accountability, and sustained implementation.
Implications for Nursing Practice
: The integration of CLCT and AI can support nurses in identifying care needs, facilitating remote monitoring, and coordinating personalized care. However, the integration of AI must be approached with critical attention to ethics, equity, and the preservation of fundamental nursing values.}
}
@article{HAMADA2025,
title = {Applications of artificial intelligence in tooth extraction: A systematic review},
journal = {Journal of Dental Sciences},
year = {2025},
issn = {1991-7902},
doi = {https://doi.org/10.1016/j.jds.2025.10.007},
url = {https://www.sciencedirect.com/science/article/pii/S1991790225003654},
author = {Masakazu Hamada and Ryota Nomura and Tatsuya Akitomo and Satoru Kusaka and Yuko Iwamoto and Shiori Yamamoto and Yuko Ogaya and Kazuhiko Nakano},
keywords = {Artificial intelligence, Machine learning, Deep learning, Oral surgery, Tooth extraction, Review},
abstract = {Background/purpose
Tooth extraction is a common procedure in dental treatment. In recent years, with the advancement of artificial intelligence (AI) technology, research on tooth extraction using AI has been increasing. In the present study, we consider the applicability of AI to tooth extraction through a literature review.
Materials and methods
The PubMed, Scopus, and Web of Science databases were searched for (“tooth extraction”) AND (“artificial intelligence” OR “machine learning” OR “deep learning”) in June 2024.
Results
Thirty-five articles matched the eligibility criteria and were extracted for this review. The most widely covered topics were “relationship between the root of the tooth and the inferior alveolar nerve” and “tooth extraction decision-making” with 10 and 8 articles, respectively. These two topics are considered to be important factors that determine risk and treatment options in clinical decision-making. Next, there were six articles about tooth extraction difficulty, preparation, and time, and four articles about maxillary sinus evaluation. Furthermore, there were three articles about predictive models for osteonecrosis and osteomyelitis of the jaw, and two articles each about post-extraction complications and the use of ChatGPT, which were the fewest in number.
Conclusion
Findings from these papers will contribute to improving decision-making processes, treatment strategies, and preventive measures in dental care and are expected to serve as a foundation for future research. Furthermore, the diversity of each topic reflects the complexity and evolution of dental care and suggests that further exploration is warranted in future research.}
}
@article{SADANANDAM2025,
title = {Artificial Intelligence: What Is Current in Dentistry?},
journal = {Dental Clinics of North America},
year = {2025},
issn = {0011-8532},
doi = {https://doi.org/10.1016/j.cden.2025.07.008},
url = {https://www.sciencedirect.com/science/article/pii/S0011853225000515},
author = {Santhiya Sadanandam and Gifty Francis Ruby and Steven R. Singer and Ruchira Shreevats},
keywords = {Artificial intelligence (AI), Automated screening, Deep learning (DL), Machine learning (ML), Dentistry, Digital dentistry, Clinical decision making, Applications of AI}
}
@article{STERN2025,
title = {Detecting Artificial Intelligence-Generated Text in Personal Statements of Adult Reconstruction Fellowship Applicants},
journal = {The Journal of Arthroplasty},
year = {2025},
issn = {0883-5403},
doi = {https://doi.org/10.1016/j.arth.2025.07.072},
url = {https://www.sciencedirect.com/science/article/pii/S0883540325009763},
author = {Jonathan M. Stern and Antonio M. Fernandez-Perez and Natalia Cruz-Ossa and Victor H. Hernandez and Colin A. McNamara and Michele R. D’Apuzzo},
keywords = {Artificial intelligence, ChatGPT, personal statement, fellowship applications, AI generated text, medical education},
abstract = {Background
Artificial intelligence (AI), particularly large language models such as Chat Generative Pre-Trained Transformer (ChatGPT), has expanded across various fields, including medical education and professional applications. However, the extent to which AI is utilized in writing personal statements (PSs) for adult reconstruction fellowship applications remains unclear. This study aimed to analyze the prevalence of AI-generated text in PSs submitted to our institution before and after the release of ChatGPT.
Methods
We retrospectively reviewed PSs submitted to our institution’s adult reconstruction fellowship from 2021 to 2025. The PSs were divided into two cohorts: pre-PS (2021 to 2022) and post-PS (2024 to 2025). The PSs from 2023 were excluded because of uncertainty in AI adoption. All PSs were analyzed using GPTZero, an AI detection software, to determine the proportion of AI-generated versus human-generated text. Descriptive statistics and comparative analyses were conducted.
Results
A total of 421 PSs were analyzed. The pre-PS cohort had an average GPTZero score of 99.5% (SD 1.9) human, 0.4% (SD 0.8) AI, and 0.1% (SD 1.8) mixed, while the post-PS cohort had scores of 83.8% (SD 29.9) human, 15.1% (SD 28.9) AI, and 1.1% mixed (SD 5.2) (P < 0.001). The AI-generated text was significantly more prevalent in the post-PS cohort compared to the pre-PS cohort. In addition, international medical graduates and applicants from non-US residencies demonstrated a higher proportion of AI-generated text in their PSs compared to US applicants (P < 0.001).
Conclusions
The use of AI in PS writing has increased significantly since the release of ChatGPT. Given the role of PSs in candidate selection, these findings highlight the need for transparency, standardized guidelines regarding AI-assisted writing, and re-evaluation of the importance placed on PSs in candidate selection. Further research should expand to other subspecialties and institutions to assess the broader implications of AI in postgraduate medical education.}
}
@article{HABER2025100196,
title = {CanvasHero: The role of artificial intelligence in cultivating resilience among children and youth using the 6-part story method in mass war trauma},
journal = {Computers in Human Behavior: Artificial Humans},
volume = {5},
pages = {100196},
year = {2025},
issn = {2949-8821},
doi = {https://doi.org/10.1016/j.chbah.2025.100196},
url = {https://www.sciencedirect.com/science/article/pii/S2949882125000805},
author = {Yuval Haber and Inbar Levkovich and Iftach Tzafrir and Karny Gigi and Dror Yinon and Dorit Hadar Shoval and Zohar Elyoseph},
keywords = {Resilience, Mass trauma, Displaced population, Children and youth, AI tools, Imagination},
abstract = {Background
The potential of Generative Artificial Intelligence (GenAI) to promote mental health is of great interest. Specifically, there is growing interest in integrating applied GenAI into psychotherapy or into the teacher/parent-child relationship. This paper describes CanvasHero, a GenAI tool that was developed following the devastating attacks on Israel in October 2023. It aims to promote resilience in children and adolescents who were evacuated from their homes due to the war. CanvasHero serves as a proof of concept for integrating GenAI as an additional element that can enrich and deepen interpersonal interaction.
Tool description
CanvasHero utilizes the BASIC Ph model and 6-Part Story Method for assessing and bolstering coping skills, aided by the interactive scaffolding and synthetic abilities of the GenAI. Key stages comprise (1) collaborative narrative construction between child, meaningful adult, and the GAI; (2) analysis of resilience themes; and (3) generative visualization representing the child's story through DALL-E's imaging capabilities.
Implementation protocol
The CanvasHero is optimally designed for children ages 7–16 under adult supervision, with the HEART Checklist developed to structure this process. Sessions typically occur remotely via videoconference, or in person.
Intended outcomes
CanvasHero aims to create a playful space for processing stress and trauma, identifies resilience resources, and strengthens these capabilities. At the same time, risks in GenAI integration are mitigated via human oversight and an ethics-focused design.
Conclusion
CanvasHero exemplifies a GenAI application that can assist during wartime, serving as a psycho-educational mediator and facilitating an imaginative and playful space between children and meaningful adults. Further studies are required to evaluate effectiveness and potential risks.}
}
@article{DO2025102367,
title = {Artificial intelligence (AI) performance on pharmacy skills laboratory course assignments},
journal = {Currents in Pharmacy Teaching and Learning},
volume = {17},
number = {7},
pages = {102367},
year = {2025},
issn = {1877-1297},
doi = {https://doi.org/10.1016/j.cptl.2025.102367},
url = {https://www.sciencedirect.com/science/article/pii/S1877129725000887},
author = {Vivian Do and Krista L. Donohoe and Apryl N. Peddi and Eleanor Carr and Christina Kim and Virginia Mele and Dhruv Patel and Alexis N. Crawford},
keywords = {Artificial intelligence, Pharmacy education, Pharmacy skills, Educational assessment, Generative language model},
abstract = {Objective
To compare pharmacy student scores to scores of artificial intelligence (AI)-generated results of three common platforms on pharmacy skills laboratory assignments.
Methods
Pharmacy skills laboratory course assignments were completed by four fourth-year pharmacy student investigators with three free AI platforms: ChatGPT, Copilot, and Gemini. Assignments evaluated were calculations, patient case vignettes, in-depth patient cases, drug information questions, and a reflection activity. Course coordinators graded the AI-generated submissions. Descriptive statistics were utilized to summarize AI scores and compare averages to recent pharmacy student cohorts. Interrater reliability for the four student investigators completing the assignments was assessed.
Results
Fourteen skills laboratory assignments were completed utilizing three different AI platforms (ChatGPT, Copilot, and Gemini) by four fourth-year student investigators (n = 168 AI-generated submissions). Copilot was unable to complete 12; therefore, 156 AI-generated submissions were graded by the faculty course coordinators for accuracy and scored from 0 to 100 %. Pharmacy student cohort scores were higher than the average AI scores for all of the skills laboratory assignments except for two in-depth patient cases completed with ChatGPT. Conclusion. Pharmacy students on average performed better on most skills laboratory assignments than three commonly used artificial intelligence platforms. Teaching students the strengths and weaknesses of utilizing AI in the classroom is essential.}
}
@article{DEGIORGIO2025112014,
title = {The need for balancing ’black box’ systems and explainable artificial intelligence: A necessary implementation in radiology},
journal = {European Journal of Radiology},
volume = {185},
pages = {112014},
year = {2025},
issn = {0720-048X},
doi = {https://doi.org/10.1016/j.ejrad.2025.112014},
url = {https://www.sciencedirect.com/science/article/pii/S0720048X25001007},
author = {Fabio De-Giorgio and Beatrice Benedetti and Matteo Mancino and Evis Sala and Vincenzo L. Pascali},
keywords = {Explainable artificial intelligence, Black box systems, Professional liability, Radiology, Ethics},
abstract = {Radiology is one of the medical specialties most significantly impacted by Artificial Intelligence (AI). AI systems, particularly those employing machine and deep learning, excel in processing large datasets and comparing images from similar contexts, fulfilling radiological demands. However, the implementation of AI in radiology presents notable challenges, including concerns about data privacy, informed consent, and the potential for external interferences affecting decision-making processes. Biases represent another critical issue, often stemming from unrepresentative datasets or inadequate system training, which can lead to distorted outcomes and exacerbate healthcare inequalities. Additionally, generative AI systems may produce ‘hallucinations’ arising from their reliance on probabilistic modeling without the ability to distinguish between true and false information. Such risks raise ethical and legal questions, especially when AI-induced errors harm patient health. Concerning liability for medical errors involving AI, healthcare professionals currently retain full accountability for their decisions. AI systems remain tools to support, not replace, human expertise and judgment. Nevertheless, the “black box” nature of many AI models – wherein the reasoning behind outputs remains opaque – limits the possibility of fully informed consent. We advocate for prioritizing Explainable Artificial Intelligence (XAI) in radiology. While potentially less performant than black-box models, XAI enhances transparency, allowing patients to understand how their data is used and how AI influences clinical decisions, aligning with ethical standards.}
}
@article{MOROSKY20254,
title = {Practical applications of artificial intelligence chatbots in obstetrics and gynecology medical education},
journal = {American Journal of Obstetrics and Gynecology},
volume = {233},
number = {1},
pages = {4-11},
year = {2025},
issn = {0002-9378},
doi = {https://doi.org/10.1016/j.ajog.2025.04.021},
url = {https://www.sciencedirect.com/science/article/pii/S0002937825002285},
author = {Christopher M. Morosky and Laura Baecher-Lind and Katherine T. Chen and Angela Fleming and Shireen Madani Sims and Helen Kang Morgan and Celeste S. Royce and Tammy Sonn and Alyssa Stephenson-Famy and Jill Sutton and Jonathan Schaffir and Rashmi Bhargava},
keywords = {artificial intelligence, biases, chatbot, ChatGPT, data privacy, faculty development, feedback, hallucinations, informed approach, integration, large language models, learning objectives, medical education, mentorship, responsible use, teaching},
abstract = {Generative artificial intelligence chatbots are sophisticated conversational artificial intelligence tools that have the capability to interpret natural language inputs and produce responses that closely resemble human speech. Artificial intelligence chatbots hold significant promise in revolutionizing medical education by offering invaluable support across various educational domains, including teaching, learning, and assessment. Their practical applications span a wide spectrum, from aligning learning objectives and simplifying administrative tasks to facilitating feedback, aiding faculty development, and supporting mentorship initiatives. However, alongside their potential benefits, concerns exist regarding data privacy, inherent biases, and occasional errors termed “hallucinations,” underscoring the imperative for a cautious and informed approach to their integration within educational settings. It therefore becomes essential for medical educators and academic institutions to proactively engage with artificial intelligence technologies like chatbots, not only to leverage their benefits but also to critically assess and address associated challenges such as bias, privacy, and misinformation. By thoughtfully integrating artificial intelligence tools, medical educators can determine where these technologies are most beneficial, implement safeguards against potential harms, and explore innovative applications to enhance medical education.}
}
@article{WANG2025147,
title = {Understanding users’ effective use of generative conversational AI from a media naturalness perspective: a hybrid structural equation modeling-artificial neural network (SEM-ANN) approach},
journal = {Data Science and Management},
volume = {8},
number = {2},
pages = {147-159},
year = {2025},
issn = {2666-7649},
doi = {https://doi.org/10.1016/j.dsm.2024.09.001},
url = {https://www.sciencedirect.com/science/article/pii/S266676492400047X},
author = {Kun Wang and Yaobin Lu and Zhao Pan},
keywords = {Generative conversational AI, Content naturalness, Style naturalness, Effective use, SEM-ANN method},
abstract = {Although generative conversational artificial intelligence (AI) can answer questions well and hold conversations as a person, the semantic ambiguity inherent in text-based communication poses challenges to effective use. Effective use reflects the users’ utilization of generative conversational AI to achieve their goals, which has not been previously studied. Drawing on the media naturalness theory, we examined how generative conversational AI’s content and style naturalness affect effective use. A two-wave survey was conducted to collect data from 565 users of generative conversational AI. Two techniques were used in this study. Initially, partial least squares structural equation modeling (PLS-SEM) was applied to determine the variables that significantly affected the mechanisms (i.e., cognitive effort and communication ambiguity) and effective use. Secondly, an artificial neural network model was used to evaluate the relative importance of the significant predictors of mechanisms and effective use identified from the PLS-SEM analysis. The results revealed that the naturalness of content and style differed in their effects on cognitive effort and communication ambiguity. Additionally, cognitive effort and communication ambiguity negatively affected effective use. This study advances the literature on effective use by uncovering the psychological mechanisms underlying effective use and their antecedents. In addition, this study offers insights into the design of generative conversational AI.}
}
@article{RAYAGONZALEZ2025110375,
title = {High-precision prototype for garlic apex reorientation based on artificial intelligence models},
journal = {Computers and Electronics in Agriculture},
volume = {235},
pages = {110375},
year = {2025},
issn = {0168-1699},
doi = {https://doi.org/10.1016/j.compag.2025.110375},
url = {https://www.sciencedirect.com/science/article/pii/S0168169925004818},
author = {Luis Enrique Raya-González and Víctor Alfonso Alcántar-Camarena and Alberto Saldaña-Robles and Edgar Francisco Duque-Vazquez and Guillermo Tapia-Tinoco and Noé Saldaña-Robles},
keywords = {Deep learning, Machine learning, Transfer learning, Image analysis,  L},
abstract = {Sowing and harvesting are the most expensive operations in garlic cultivation (Allium sativum L.). For mechanized sowing to be feasible, the garlic clove must be placed in the soil with the apex pointing upwards, otherwise, yield can be reduced by up to 23%. In this context, artificial intelligence (AI) emerges as a viable solution to address these issues, particularly artificial neural networks (ANN). This research presents the development and evaluation of a garlic apex orientation device, which utilizes AI models adapted to all types of garlic clove shapes. The evaluated models are support vector machine (SVM), random forest (RF), ANN, convolutional neural network (CNN), and transfer learning (TL). To increase the number of available images for training, a generative adversarial network (GAN) was used. Three different databases were used to train models to determine achieved the best performance in terms of model accuracy. The databases used are the original database, an augmentation version of the original database incorporating images generated by the GAN model, and only images generated by the GAN model. The results show that the best model (ANN) achieves a validation accuracy of 99.74% when using an augmentation of the original database with artificial images generated by the GAN model.}
}
@article{CROOK2025100793,
title = {Artificial Intelligence in Hand Surgery: The Future is Upon Us},
journal = {Journal of Hand Surgery Global Online},
volume = {7},
number = {6},
pages = {100793},
year = {2025},
issn = {2589-5141},
doi = {https://doi.org/10.1016/j.jhsg.2025.100793},
url = {https://www.sciencedirect.com/science/article/pii/S2589514125001136},
author = {Bryan S. Crook and Eoghan T. Hurley and Marc J. Richard and Suhail K. Mithani and Tyler S. Pidgeon},
keywords = {Artificial intelligence, Burnout, Internet, Machine learning, Patient education},
abstract = {In just the past few years, artificial intelligence (AI) has transformed from a potential disruptive force in health care to a technology being rapidly deployed across multiple fronts in orthopedic care. The growth in AI use and development has largely occurred as computing technology has improved in concert with the massive amounts of data generation made possible by electronic medical records. The resulting impact of these technologies, including machine learning algorithms and large language models, has yet to be fully realized, but has already begun improving patient care, offloading administrative burden, and disrupting clinical research. The purpose of this review is to highlight areas in which AI is poised to change the delivery of surgical care with respect to hand surgery.}
}

@article{JANSSEN2025101791,
title = {Barriers to breakthroughs: A scoping review of generative AI in healthcare simulation},
journal = {Clinical Simulation in Nursing},
volume = {107},
pages = {101791},
year = {2025},
issn = {1876-1399},
doi = {https://doi.org/10.1016/j.ecns.2025.101791},
url = {https://www.sciencedirect.com/science/article/pii/S1876139925001082},
author = {Erika Janssen and Rebecca McLagan and Jessica Habeck and Seon Yoon Chung and Erin C. McArthur and Polly Anderson},
keywords = {Generative pre-trained transformer, Generative artificial intelligence, Healthcare simulation, Nursing education, Review, Simulation-based learning},
abstract = {Background
Generative artificial intelligence (AI) is an emerging technology in healthcare education with potential to enhance simulation by addressing logistical barriers and by providing increased access to diverse settings in healthcare education, leading to improved learning outcomes. This rapid scoping review explores the use of generative AI in simulation-based education.
Methods
Searches were conducted in CINAHL, Medline, PsycINFO, ScienceDirect, and Web of Science using terms such as “generative artificial intelligence” and “healthcare simulation.” The review followed the World Health Organization (WHO) Rapid Review Guide and was structured using Arksey and O'Malley's five-stage framework for scoping reviews.
Results
After applying inclusion and exclusion criteria, 15 articles were included. Five themes emerged: (1) removal of logistical barriers, (2) authentic practice, (3) distinctive value, (4) limitations of generative AI, and (5) potential with human oversight. Generative AI improves access to simulation by creating cost-effective, scalable, and realistic scenarios while fostering critical thinking through reflective learning. However, challenges such as misinformation and ethical concerns remain.
Conclusions
This scoping review identified growing momentum around generative AI's role in healthcare simulation. While early studies highlight its potential to support scalable, adaptive, and authentic training experiences, effective integration requires strong governance, ethical safeguards, and human oversight.}
}
@article{WANG2026116280,
title = {Artificial intelligence in the renewable energy transition: The critical role of financial development},
journal = {Renewable and Sustainable Energy Reviews},
volume = {226},
pages = {116280},
year = {2026},
issn = {1364-0321},
doi = {https://doi.org/10.1016/j.rser.2025.116280},
url = {https://www.sciencedirect.com/science/article/pii/S1364032125009530},
author = {Qiang Wang and Siqi Zhang and Rongrong Li},
keywords = {Artificial intelligence, Renewable energy transition, Financial development, Projection pursuit, Threshold effect, Green finance},
abstract = {The rapid advancement of artificial intelligence (AI) is reshaping technological pathways in the global energy transition. While AI holds great potential to enhance the efficiency, resilience, and integration of renewable energy systems, its effective deployment depends heavily on supportive financial structures. Moreover, empirical assessments of AI’s macroeconomic impact are limited by the absence of standardized, internationally comparable measures of AI development. To address this problem, we construct a multidimensional AI composite index using the projection pursuit method, integrating eleven indicators across scientific innovation, infrastructure support, and global competitiveness. The index spans 119 countries from 2010 to 2022, offering improved spatial-temporal coverage for global analysis. Using this dataset, we empirically investigate the effect of AI on renewable energy transition and explore the mediating and threshold roles of financial development. We apply a suite of econometric models, including fixed-effect regression, mediation effect regression, dynamic threshold effect regression, and robustness check using industrial robot proxies and GMM. Results show that AI development significantly promotes the energy transition toward renewables. This finding holds true in both low-income and high-income countries. However, the role of financial development is twofold: it mediates AI’s impact, but in its current fossil fuel–biased form, may also exert a suppressive effect on green transformation. Notably, once financial development surpasses a critical threshold, the influence of AI on energy transition is amplified. Our findings offer new insights into the interaction between digital innovation and sustainable finance, and provide timely evidence for designing financial and technological policies that support AI-driven renewable energy transition.}
}
@article{KUTTY2025100258,
title = {Reimagining Pediatrics in a World of Artificial Intelligence: Will We Be Empowered or Imperiled?},
journal = {Mayo Clinic Proceedings: Digital Health},
volume = {3},
number = {4},
pages = {100258},
year = {2025},
issn = {2949-7612},
doi = {https://doi.org/10.1016/j.mcpdig.2025.100258},
url = {https://www.sciencedirect.com/science/article/pii/S2949761225000653},
author = {Shelby Kutty and Yiu-fai Cheung and Sowmya Viswanathan and David A. Danford}
}
@article{WU2026101287,
title = {Exploring the impact of artificial intelligence on business talent development in higher education:A systematic literature review and research agenda},
journal = {The International Journal of Management Education},
volume = {24},
number = {1},
pages = {101287},
year = {2026},
issn = {1472-8117},
doi = {https://doi.org/10.1016/j.ijme.2025.101287},
url = {https://www.sciencedirect.com/science/article/pii/S1472811725001570},
author = {Qinglan Wu and Lanzhen Chen and Minwei Chen and Yangjie Huang},
keywords = {Artificial intelligence, Big data, Business education, Management education},
abstract = {Against the strategic backdrop of the digital and intelligent transformation of global higher education, the emerging cluster of technologies with artificial intelligence (AI) at its core is fundamentally reshaping the operational logic and value ecosystem of business education systems. To comprehensively understand the current research landscape and progress of AI and business talent development, this study conducts a systematic literature review, retrieving 192 research articles published between 2015 and 2024 from the Scopus and Web of Science databases. Based on descriptive statistics and CiteSpace bibliometric analysis, this study summarizes the major progress and key findings of the past decade across four domains of business talent development in higher education. The study further provides practical implications for business school administrators and faculty, highlighting insufficient attention to macro-level issues such as core AI competencies, curriculum restructuring, and institutional resource support. It also notes the lack of in-depth reflection on the mechanisms through which AI is embedded in business talent development. In addition, through further analysis of theoretical frameworks and research methods, this study suggests that future academic research should explore emerging frontier topics such as artificial general intelligence and quantum algorithms, promote interdisciplinary integration of business education with neuroscience, social sciences, and environmental science, place greater emphasis on longitudinal research, and adopt research paradigms driven by both data and mechanisms.}
}
@article{FITZSIMMONS2025541,
title = {Practice Management: Artificial Intelligence in Marketing—An Application for Dental Practices},
journal = {Dental Clinics of North America},
volume = {69},
number = {4},
pages = {541-554},
year = {2025},
note = {Modern Endodontics: Focus on AI},
issn = {0011-8532},
doi = {https://doi.org/10.1016/j.cden.2025.05.004},
url = {https://www.sciencedirect.com/science/article/pii/S0011853225000369},
author = {Kimberly A. FitzSimmons},
keywords = {Artificial intelligence, Dental marketing, ChatGPT, Practice management, Video marketing}
}
@article{BIBRI2025106826,
title = {Generative AI of things for sustainable smart cities: Synergizing cognitive augmentation, resource efficiency, network traffic, cybersecurity, and anomaly detection for environmental performance},
journal = {Sustainable Cities and Society},
volume = {133},
pages = {106826},
year = {2025},
issn = {2210-6707},
doi = {https://doi.org/10.1016/j.scs.2025.106826},
url = {https://www.sciencedirect.com/science/article/pii/S2210670725006997},
author = {Simon Elias Bibri and Jeffrey Huang},
keywords = {Generative artificial intelligence, Generative internet of things, Generative artificial intelligence of things, Sustainable smart cities, Environmental sustainability, Cognitive augmentation, Resource efficiency, Cybersecurity, Network traffic, Anomaly detection},
abstract = {Artificial Intelligence of Things (AIoT) has emerged as a transformative technology driving environmental sustainability in smart city development. However, the integration of Generative Artificial Intelligence (GenAI) within AIoT ecosystems remains largely unexplored. Current research predominantly addresses conventional AIoT frameworks, overlooking the innovative potential of generative models, such as Generative Adversarial Networks, Variational Autoencoders, Diffusion Models, Transformers, and hybrid architectures, to significantly enhance situational awareness, system optimization, operational robustness, real-time responsiveness, and adaptive decision-making in complex urban environments. AIoT systems continue to face persistent challenges, including data scarcity, poor data quality, limited adaptability, imbalanced datasets, and inadequate context-awareness. This study addresses these gaps by systematically exploring how GenAI can enhance AIoT functionalities across key domains—namely cognitive augmentation, resource efficiency, network traffic, cybersecurity, and anomaly detection—while examining their synergistic potential to improve system-level environmental performance across two interconnected layers in sustainable smart cities. At the operational layer, key findings reveal that integrating GenAI with AIoT systems enhances urban efficiency, adaptability, autonomy, robustness, and resilience by conserving resources, optimizing network traffic flows, securing infrastructures, and detecting anomalies before they escalate. Specifically, the fusion of generative intelligence with federated learning promotes sustainable, energy-efficient AIoT deployments by reducing data transmission, thereby lowering communication overhead and safeguarding user privacy. In networked environments, generative models improve synthetic traffic realism and communication efficiency. They also strengthen cybersecurity through enhanced intrusion prevention and threat detection. Additionally, they enable early identification and mitigation of anomalies, boosting operational efficiency and system robustness. These improvements stabilize sustainable smart city system functioning and prevent disruptive failures. At the environmental layer, as key findings indicate, these operational gains cascade into indirect but tangible ecological benefits, while generative models advance the core pillars of AIoT by enabling proactive, autonomous, context-aware, and self-adaptive systems that further enhance the environmental performance of sustainable smart cities. Thus, while the five domains primarily underpin the operational backbone of urban systems, their cascading effects extend to ecological outcomes. The proposed conceptual framework, distilled from key findings, integrates GenAI and AIoT and highlights both domain-specific advancements and their synergistic interactions. This framework holds significant potential to drive sustainable smart city development by fostering AIoT ecosystems that are more intelligent, resource-efficient, adaptive, secure, robust, and autonomous through the strategic application of generative intelligence. The insights gained from this study provide policymakers, urban planners, system designers, and technology developers with practical guidance to harness GAIoT for enhancing smart city resilience, sustainability, and operational intelligence.}
}
@article{SUN2025105130,
title = {A catalyst for education? A study on the impact of artificial intelligence assisted learning in painting courses on college students' continuous learning intention},
journal = {Acta Psychologica},
volume = {258},
pages = {105130},
year = {2025},
issn = {0001-6918},
doi = {https://doi.org/10.1016/j.actpsy.2025.105130},
url = {https://www.sciencedirect.com/science/article/pii/S0001691825004433},
author = {Jie Sun and Xinyi Huang and Xin Sun and Qianling Jiang and Chun Yang and Wei Wei and Wei Miao and Chao Gu},
keywords = {Artificial intelligence, Continuous learning intention, Self- perceived creativity, Flow experience, Learning interest},
abstract = {This study examines artificial intelligence in college students' painting education and their potential impact on students' continuous learning intention. In this study, two surveys were conducted. The first survey included 793 valid samples, and the second survey contained 210 valid samples. Study 1 established the path influence relationship between self-perceived creativity, flow experience, learning interest, and continuous learning intention, confirming gender and educational level as moderators. Study 2 identifies 4 positive factors and 3 negative factors to continuous learning intention through exploratory factor analysis. These findings not only provide a reference for the application of artificial intelligence to art education, but also provide new ideas and approaches for the widespread promotion and application of artificial intelligence to other disciplines of education.}
}
@article{SMIT2025111813,
title = {Artificial intelligence in South African higher education: Survey data of master’s level students},
journal = {Data in Brief},
volume = {61},
pages = {111813},
year = {2025},
issn = {2352-3409},
doi = {https://doi.org/10.1016/j.dib.2025.111813},
url = {https://www.sciencedirect.com/science/article/pii/S2352340925005402},
author = {Michelle Smit and Taryn Bond-Barnard and Reinhard F. Wagner},
keywords = {Artificial intelligence, GenAI, Higher education, Postgraduate, Survey},
abstract = {This article presents findings from an online survey conducted at a South African university to explore students’ perspectives on the use of artificial intelligence (AI) and generative AI (GenAI) in higher education. A total of 102 (37% of the total cohort) master’s students in engineering management provided complete responses. This study builds on the research by Johnson et al. [1], which analyzed 2 555 foundation, undergraduate, structured postgraduate, and research postgraduate students at the University of Liverpool. It enhances their postgraduate findings by specifically examining working professionals in a part-time structured master’s program in South Africa. The differing educational and cultural contexts between this study and that of Johnson et al. [1] expand the investigation's scope and facilitate a valuable comparison of student views on AI and GenAI, thus deepening our understanding of how various institutional settings affect technology use in higher education. The findings indicate the students’ personal use of AI and GenAI, perspectives on peers’ use, and opinions on appropriate policies at the university, program, and module levels. Participants were surveyed on their confidence in academic writing, home languages, and familiarity with AI and GenAI tools. They described how they use these technologies in both personal and academic contexts, the perceived quality of AI-generated content compared to their own work, and their perspectives on others’ use of the technologies in an academic setting. Finally, respondents shared their views on the need for institutional regulations to guide ethical and responsible AI usage. Overall, the dataset serves as a valuable resource for education researchers and policymakers seeking to understand students’ perceptions and needs regarding AI and GenAI in higher education. Although this survey focused on master’s students in engineering management, the questions and findings can be readily adapted to other fields of study and potentially extended to younger student populations, offering insights into support and guidelines necessary to avoid misconduct and overreliance on AI.}
}
@article{PANTANOWITZ2024100609,
title = {Regulatory Aspects of Artificial Intelligence and Machine Learning},
journal = {Modern Pathology},
volume = {37},
number = {12},
pages = {100609},
year = {2024},
issn = {0893-3952},
doi = {https://doi.org/10.1016/j.modpat.2024.100609},
url = {https://www.sciencedirect.com/science/article/pii/S0893395224001893},
author = {Liron Pantanowitz and Matthew Hanna and Joshua Pantanowitz and Joe Lennerz and Walter H. Henricks and Peter Shen and Bruce Quinn and Shannon Bennet and Hooman H. Rashidi},
keywords = {artificial intelligence, Food and Drug Administration, laboratory-developed test, machine learning, medical device, regulations},
abstract = {In the realm of health care, numerous generative and nongenerative artificial intelligence and machine learning (AI-ML) tools have been developed and deployed. Simultaneously, manufacturers of medical devices are leveraging AI-ML. However, the adoption of AI in health care raises several concerns, including safety, security, ethical biases, accountability, trust, economic impact, and environmental effects. Effective regulation can mitigate some of these risks, promote fairness, establish standards, and advocate for more sustainable AI practices. Regulating AI tools not only ensures their safe and effective adoption but also fosters public trust. It is important that regulations remain flexible to accommodate rapid advances in this field to support innovation and also not to add additional burden to some of our preexisting and well-established frameworks. This study covers regional and global regulatory aspects of AI-ML including data privacy, software as a medical device, agency approval and clearance pathways, reimbursement, and laboratory-developed tests.}
}
@article{KRISHNAMURTHY2026116340,
title = {Recent advances in artificial intelligence-based optimization for power system applications: A review of techniques, challenges, and future directions},
journal = {Renewable and Sustainable Energy Reviews},
volume = {226},
pages = {116340},
year = {2026},
issn = {1364-0321},
doi = {https://doi.org/10.1016/j.rser.2025.116340},
url = {https://www.sciencedirect.com/science/article/pii/S1364032125010135},
author = {Senthil Krishnamurthy and Oludamilare Bode Adewuyi and Sunday Adeleke Salimon},
keywords = {Power system optimization, Artificial intelligence, Reinforcement learning, Distributed and federated learning, Grid integration technologies},
abstract = {The growing complexity of modern power systems, driven by the integration of renewable energy sources, distributed generation, and smart grid technologies, poses significant challenges to ensuring efficient and reliable operation. Traditional optimization methods often fall short in addressing the dynamic, nonlinear, and uncertain nature of present-day power system variables. This review article explores the application of Artificial Intelligence (AI)-based optimization techniques as promising solutions to enhance power system performance, stability, and flexibility. The study begins with an overview of traditional power system optimization problems and solution approaches, including economic load dispatch, optimal power flow, unit commitment, demand response, fault diagnosis, and the integration of renewable energy. It examines the classical optimization methods and their limitations, as well as the intricacies of metaheuristic techniques. The core of this review paper focuses on the application of contemporary artificial intelligence techniques, highlighting their strengths, use cases, comparative effectiveness, and discussing the implementation challenges that arise. By analyzing recent literature, tools, and real-world applications, the review identifies critical trends and challenges and provides recommendations for future work. This review task highlights the potential of AI to support resilient, adaptive, and sustainable power systems in the era of energy transition.}
}
@article{SHIN2025111393,
title = {Subthalamic nucleus or globus pallidus internus deep brain stimulation for the treatment of parkinson’s disease: An artificial intelligence approach},
journal = {Journal of Clinical Neuroscience},
volume = {138},
pages = {111393},
year = {2025},
issn = {0967-5868},
doi = {https://doi.org/10.1016/j.jocn.2025.111393},
url = {https://www.sciencedirect.com/science/article/pii/S0967586825003662},
author = {David Shin and Timothy Tang and Joel Carson and Rekha Isaac and Chandler Dinh and Daniel Im and Andrew Fay and Asael Isaac and Stephen Cho and Zachary Brandt and Kai Nguyen and Isabel Shaffrey and Vahe Yacoubian and Taha M. Taka and Samantha Spellicy and Miguel Angel Lopez-Gonzalez and Olumide Danisa},
keywords = {Artificial intelligence, Chatgpt, Deep brain stimulation, Neurosurgery, Parkinson’s disease},
abstract = {Background
Generative artificial intelligence (AI) in deep brain stimulation (DBS) is currently unvalidated in its content. This study sought to analyze AI responses to questions and recommendations from the 2018 Congress of Neurological Surgeons (CNS) guidelines on subthalamic nucleus and globus pallidus internus DBS for the treatment of patients with Parkinson’s Disease.
Methods
Seven questions were generated from CNS guidelines and asked to ChatGPT 4o, Perplexity, Copilot, and Gemini. Answers were “concordant” if they highlighted all points provided by the CNS guidelines; otherwise, answers were considered “non-concordant” and sub-categorized as either “insufficient” or “overconclusive.” AI responses were evaluated for readability via the Flesch-Kincaid Grade Level, Gunning Fog Index, Simple Measure of Gobbledygook (SMOG) Index, and Flesch Reading Ease tests.
Results
ChatGPT 4o showcased 42.9% concordance, with non-concordant responses classified as 14.3% insufficient and 42.8% over-conclusive. Perplexity displayed a 28.6% concordance rate, with 14.3% insufficient and 57.1% over-conclusive responses. Copilot showed 28.6% concordance, with 28.6% insufficient and 42.8% over-conclusive responses. Gemini demonstrated 28.6% concordance, with 28.6% insufficient and 42.8% over-conclusive responses. The Flesch-Kincaid Grade Level scores ranged from 14.44 (Gemini) to 18.94 (Copilot), Gunning Fog Index scores varied between 17.9 (Gemini) and 22.06 (Copilot), SMOG Index scores ranged from 16.54 (Gemini) to 19.67 (Copilot), and all Flesch Reading Ease scores were low, with Gemini showing the highest score of 30.91.
Conclusion
ChatGPT 4o displayed the most concordance, Perplexity displayed the highest over-conclusive rate, and Copilot and Gemini showcased the most insufficient answers. All responses showcased complex readability. Despite the possible benefits of future developments and innovation in AI capabilities, AI requires further improvement before independent clinical usage in DBS.}
}
@article{TAO2025,
title = {Artificial intelligence for radiopharmaceutical and molecular imaging},
journal = {Acta Pharmaceutica Sinica B},
year = {2025},
issn = {2211-3835},
doi = {https://doi.org/10.1016/j.apsb.2025.09.039},
url = {https://www.sciencedirect.com/science/article/pii/S2211383525006471},
author = {Jinping Tao and Ling Liang and Siqi Hao and Yan Chen and Zhi Yang and Yimao Cai and Hua Zhu},
keywords = {Artificial intelligence, Radiopharmaceuticals, Molecular imaging, Precision medicine, Deep learning, Clinical translation, Image reconstruction, Multimodal data fusion},
abstract = {Artificial intelligence (AI)-driven data-centric paradigms are catalyzing a paradigm shift in radiopharmaceutical development and molecular imaging, two pivotal technologies that underpin precision nuclear medicine. This review focuses on the cutting-edge applications of AI in radiopharmaceutical discovery and molecular image analytics, and systematically investigates the technical principles and typical cases of Deep Learning algorithms (e.g., Graph Neural Networks (GNNs), Generative Adversarial Networks (GANs), and Transformer Models) in target identification, ligand design, pharmacokinetic optimization, and image reconstruction and enhancement. By integrating multi-omics data and 3D structural information, AI can significantly improve the accuracy of target affinity prediction for radiopharmaceuticals and accelerate the design of novel ligands. In the field of molecular imaging, AI-driven low-dose single-photon emission computed tomography (SPECT) and positron emission tomography (PET) image reconstruction, tumor segmentation, and quantitative analysis techniques have significantly improved the diagnostic efficiency and accuracy, providing a reliable basis for individualized treatment. In addition, the paper discusses data privacy, model generalization, and ethical challenges faced by AI in clinical translation, and looks forward to the future direction of multidisciplinary integration (e.g., combining AI with radiochemistry and nuclear medicine) and technological innovations, which will help precision medicine leap from theory to practice.}
}
@article{SHAH2025611,
title = {Regulatory and Legal Considerations with Artificial Intelligence in Dermatology},
journal = {Dermatologic Clinics},
volume = {43},
number = {4},
pages = {611-623},
year = {2025},
note = {Artificial Intelligence in Dermatology},
issn = {0733-8635},
doi = {https://doi.org/10.1016/j.det.2025.05.011},
url = {https://www.sciencedirect.com/science/article/pii/S0733863525000506},
author = {Nisha Shah and Miranda Mourby and Rubeta N. Matin},
keywords = {Medical artificial intelligence, Medical liability, Medical device regulation}
}
@article{BENFENATI2025110847,
title = {Data centric Artificial Intelligence for agrifood domain: A systematic mapping study},
journal = {Computers and Electronics in Agriculture},
volume = {239},
pages = {110847},
year = {2025},
issn = {0168-1699},
doi = {https://doi.org/10.1016/j.compag.2025.110847},
url = {https://www.sciencedirect.com/science/article/pii/S0168169925009536},
author = {Domenico Benfenati and Domenico Amalfitano and Cristiano Russo and Cristian Tommasino and Antonio Maria Rinaldi},
keywords = {Data-Centric Artificial Intelligence, Agrifood, Agriculture, Systematic mapping study, Systematic literature review},
abstract = {The agrifood sector is progressively utilizing Artificial Intelligence to address challenges related to food production, environmental sustainability, and resource efficiency. However, the quality, availability and integration of data continue to represent significant obstacles in the development of reliable AI systems. The paradigm of Data-Centric Artificial Intelligence entails a shift in focus from solely optimizing models to prioritizing the enhancement of data quality, thus facilitating the development of robust AI solutions. To investigate the adoption of this paradigm, we conducted a systematic mapping study of data-centric artificial intelligence approaches in the agrifood domain over the past decade. Our review process identified 31 primary studies that employed Data-Centric Artificial Intelligence techniques in areas such as crop monitoring, pest detection, soil quality assessment, and yield optimization. The findings of our mapping reveal a growing use of methods such as data augmentation, dataset creation, and data quality enhancement. However, we also highlighted limited dataset standardization and challenges to reproducibility. The objective of this review is to provide a comprehensive overview of the latest advancements and prospects in Data-Centric Artificial Intelligence for agricultural and food industry applications.}
}
@article{CROSS2025,
title = {Artificial intelligence and the meta-paradigm},
journal = {Teaching and Learning in Nursing},
year = {2025},
issn = {1557-3087},
doi = {https://doi.org/10.1016/j.teln.2025.08.015},
url = {https://www.sciencedirect.com/science/article/pii/S1557308725002483},
author = {Lisa Cross and Amy Kendrick},
keywords = {Artificial intelligence, Metaparadigm, Nursing students},
abstract = {Background
Artificial intelligence is a technology that has been rapidly adopted in many disciplines, including nursing.
Major Points
The expansion in the healthcare field is particularly concerning for nurse faculty as they prepare nursing students for the workforce. The 4 domain meta-paradigm is recognized for making practical sense of research, theoretical, and practical nursing issues.
Implications
There has not been previously identified work using the meta-paradigm to guide artificial intelligence use in nursing education. This analysis reviewed artificial intelligence technology within the context of the 4 domains—nursing, patient, health, environment—with the subsequent aim of clarifying interventions for artificial intelligence in undergraduate nursing education.
Conclusions
Nurse faculty need to direct nursing students entering the profession on ethical and responsible AI use while recognizing the boundaries of their professional scope of practice. Involving nursing students in creating AI policies, creating classroom, simulation and clinical experiences incorporating AI, and ensuring that syllabi, assignments, and evaluation tools recognize AI are some interventions.}
}
@article{UBEDAGARCIA2025100809,
title = {Artificial intelligence, knowledge and human resource management: A systematic literature review of theoretical tensions and strategic implications},
journal = {Journal of Innovation & Knowledge},
volume = {10},
number = {6},
pages = {100809},
year = {2025},
issn = {2444-569X},
doi = {https://doi.org/10.1016/j.jik.2025.100809},
url = {https://www.sciencedirect.com/science/article/pii/S2444569X25001544},
author = {Mercedes Úbeda-García and Bartolomé Marco-Lajara and Patrocinio C. Zaragoza-Sáez and Esther Poveda-Pareja},
keywords = {Artificial Intelligence, Human resource management, Bibliometric analysis, SciMAT, Science mapping},
abstract = {This article studies the interaction between artificial intelligence (AI) and human resource management (HRM) through a bibliometric analysis of 203 articles published between 2002 and 2024 in the Web of Science database. The analysis identifies six fundamental strategic research themes, ranging from automation and predictive analysis to the personalisation of the employee experience. The paper illustrates the growing importance of AI and HRM, evidenced by an exponential increase in publications since 2016, with a significant peak after the COVID-19 pandemic. The conclusions highlight the need for a balanced approach that integrates technological innovation with rigorous ethical principles, particularly in critical areas such as algorithmic transparency, fairness in decision-making and personal data management. The research also provides a valuable roadmap for future research and sustainable organisational practices in the digital age, highlighting the importance of addressing emerging challenges such as technostress and the implications of personalisation in hybrid work environments. In addition to capturing the ways in which AI is transforming traditional HRM processes and the aspects covered by the literature so far, this paper also establishes a frame of reference for understanding and addressing the evolution of talent management in a rapidly changing technological context.}
}
@article{RAHMATIZADEH2025405,
title = {Foundations of Artificial Intelligence: Transforming Health Care Now and in the Future},
journal = {Anesthesiology Clinics},
volume = {43},
number = {3},
pages = {405-418},
year = {2025},
note = {Artificial Intelligence in Anesthesiology},
issn = {1932-2275},
doi = {https://doi.org/10.1016/j.anclin.2025.04.003},
url = {https://www.sciencedirect.com/science/article/pii/S193222752500028X},
author = {Shahabedin Rahmatizadeh and Ali Dabbagh and Fariba Shabani},
keywords = {Artificial intelligence, Medicine, Machine learning, Deep learning, Artificial neural networks}
}
@article{OSMAN2025102025,
title = {Impact of artificial intelligence on the future of radiology: A national cross-sectional study among medical students and radiology professionals},
journal = {Journal of Radiation Research and Applied Sciences},
volume = {18},
number = {4},
pages = {102025},
year = {2025},
issn = {1687-8507},
doi = {https://doi.org/10.1016/j.jrras.2025.102025},
url = {https://www.sciencedirect.com/science/article/pii/S168785072500737X},
author = {Hanady Elyas Osman and Mohamed Yousef and Amira Ahmed Hakami and Lin Mazen Jolha and Nawaf Albasha and Waleed Khaled Daghmash and Zainab Mohammed Takroni and Aamina Shoaib Patel and Yasir Jaffar Mohammad and Amal Alsalamah and Sara Albadri and Abbas Khalid},
keywords = {Artificial intelligence, Radiology, Medical students, Radiology professionals, AI training},
abstract = {Background
The incorporation of artificial intelligence (AI) into radiology has significantly transformed disease detection, treatment planning, and outcome forecasting. Despite its potential to revolutionize the field, the knowledge, attitudes, and practices (KAP) surrounding AI among medical students and radiology professionals in Saudi Arabia are still in the early stages of development. This study aimed to investigate the KAP of medical and radiology professionals in Saudi Arabia regarding the application of AI in radiology.
Methods
Data were collected through an electronic survey distributed via Google Forms, which reached 1582 participants during the 2024–2025 academic year. The participants included medical and radiology students, radiologists, radiology technicians, and technologists from various regions of the country.
Results
The results revealed that 57.8 % of the participants had a basic understanding of AI in radiology, with radiologists exhibiting the highest level of awareness (71.2 %). Females were more likely to recognize the benefits of AI, particularly in automated disease detection (83.5 % vs. 73.9 % in males). Concerns regarding the replacement of radiologists with AI were the most pronounced among radiology students (22.7 %). Participants from the private sector reported higher participation in AI-related courses (60.5 %) and projects (58.7 %) than their public sector counterparts. It has a 79.5 % recognition rate for its role in automated disease detection through imaging tests. Radiologists and radiology students generally expressed positive attitudes toward AI, believing that it could improve diagnostic accuracy and efficiency. However, some participants, particularly radiography students, expressed concerns regarding AI replacing human professionals.
Conclusion
This study highlights the importance of refining AI training and fostering a deeper understanding of its potential challenges in radiology. The future of AI in radiology in Saudi Arabia holds great promise, with growing interest despite some concerns.}
}
@incollection{LIU2026213,
title = {Chapter 12 - Generalization of artificial intelligence models for embryo selection},
editor = {Guanqiao Shan and Yu Sun and Hang Liu and Zhuoran Zhang},
booktitle = {Robotics and Artificial Intelligence for Reproductive Medicine},
publisher = {Academic Press},
pages = {213-228},
year = {2026},
isbn = {978-0-443-26745-1},
doi = {https://doi.org/10.1016/B978-0-443-26745-1.00012-8},
url = {https://www.sciencedirect.com/science/article/pii/B9780443267451000128},
author = {Hang Liu and Guanqiao Shan and Zhuoran Zhang and Yu Sun},
keywords = {Artificial intelligence (AI), Deep learning, Embryo evaluation, Embryo selection, Federated learning, Generative adversarial network (GAN), Model generalization, Self-supervised learning},
abstract = {This chapter provides an in-depth exploration of key strategies for improving the generalizability of artificial intelligence (AI) models in embryo selection. It begins by examining current embryo selection practices and the growing role of AI in this field. The discussion then shifts to the challenges of generalizing AI models, focusing on factors that can hinder their performance across different clinical settings. Various methods to enhance generalizability are reviewed, including advanced techniques like self-supervised learning, federated learning, and generative adversarial network. Additionally, the chapter covers essential practices during model training, such as effective data augmentation, regularization, thoughtful model design, optimized hyperparameter tuning, and ensuring model interpretability.}
}
@article{ABYANEH2025100173,
title = {An Analytical Review of Artificial Intelligence Applications in Sustainable Supply Chains},
journal = {Supply Chain Analytics},
pages = {100173},
year = {2025},
issn = {2949-8635},
doi = {https://doi.org/10.1016/j.sca.2025.100173},
url = {https://www.sciencedirect.com/science/article/pii/S2949863525000731},
author = {Amirhossein Ghasemi Abyaneh and Hossein Ghanbari and Emran Mohammadi and Amirali Amirsahami and Masoud Khakbazan},
keywords = {Artificial Intelligence, Supply chain management, Sustainable logistics, Predictive analytics, Data-driven supply chains, Environmental impact assessment},
abstract = {Sustainable supply chains are essential for promoting environmental responsibility, economic efficiency, and social well-being. They help reduce carbon footprints, optimize resource use, and support circular economy initiatives. Economically, they enhance efficiency, lower costs, and mitigate risks related to resource scarcity and environmental regulations. Socially, they ensure ethical sourcing, fair labor practices, and corporate social responsibility. By balancing these dimensions, sustainable supply chains contribute to business resilience while aligning with global sustainability goals, such as the UN Sustainable Development Goals (SDGs). In the age of Artificial Intelligence (AI), rapid technological advancements have significantly transformed supply chain operations, necessitating greater flexibility and the integration of AI-driven techniques. The application of AI in supply chain management has proven highly beneficial, offering enhanced efficiency, predictive capabilities, and improved sustainability. Recent advancements, including Large Language Models (LLMs), are also playing a transformative role in enhancing decision-making and risk management across supply chains. Numerous researchers have highlighted AI's potential in advancing circular economy initiatives by optimizing resource utilization and minimizing waste. However, despite the growing academic interest, research in this domain remains fragmented and lacks a coherent structure. To address this gap, this paper conducts a comprehensive bibliometric analysis to map the current research landscape, identify key themes, and highlight future directions. Bibliographic records were retrieved from the Web of Science database, covering the period from 1997 to 2024. A total of 1,070 records were initially gathered for analysis. The findings of this study provide valuable insights into the evolution of research in AI-driven sustainable supply chains, uncover emerging trends, and suggest potential avenues for future exploration. Specifically, the analysis reveals an annual publication growth rate of 23.37% from 1997 to 2024, with China, India, and the USA as the top contributing countries. Core research themes include AI-enabled logistics optimization, circular economy practices, and supply chain resilience under global disruptions. By offering a structured overview of the field, this study aims to support scholars and practitioners in navigating the intersection of AI and sustainability in supply chain management.}
}
@article{AMADEH2025194,
title = {Intelligent diet recommendation system powered by artificial intelligence for personalized nutritional solutions},
journal = {Clinical Nutrition ESPEN},
volume = {70},
pages = {194-203},
year = {2025},
issn = {2405-4577},
doi = {https://doi.org/10.1016/j.clnesp.2025.09.002},
url = {https://www.sciencedirect.com/science/article/pii/S2405457725029249},
author = {Tohid Amadeh and Matin Rafie and Shadmehr Radmanesh and Alireza Azizi and Ahmadreza Ahangarian and Pourya Fathollahi and Hadise Ahmadloo},
keywords = {Artificial intelligence, Diet therapy, Body composition, Food preferences, Feeding behavior, InBody},
abstract = {Summary
Background and aims
The increasing number of non-communicable diseases, such diabetes and obesity, makes it even more important to have accurate and personalized dietary solutions. Based on a lot of research, standard diet advice may not be accurate enough to meet individual health demands. The Intelligent Diet Recommendation System is an artificial intelligence-powered platform that gives personalized dietary recommendations based on extensive body composition data and cultural eating habits.
Methods
The Intelligent Diet Recommendation System gathers key measurements, including body mass index and body fat percentage, using cutting-edge body analysis tools. Customized diets were created using 3D body modeling technologies and machine learning algorithms. The system's performance was evaluated by assessing the inaccuracy rate of its dietary recommendations.
Results
The Intelligent Diet Recommendation System made personalized diet plans based on physiological and cultural factors with an error rate of less than 3 %.
Conclusions
The results show that the Intelligent Diet Recommendation System is a scalable, artificial intelligence-based way to solve global health problems that makes dietary advice much more accurate and easy to find. This system offers a new way of doing nutritional therapy that could improve health outcomes around the world.}
}
@article{CURRIE2025616,
title = {Artificial Intelligence Augmented Cerebral Nuclear Imaging},
journal = {Seminars in Nuclear Medicine},
volume = {55},
number = {4},
pages = {616-628},
year = {2025},
note = {CNS},
issn = {0001-2998},
doi = {https://doi.org/10.1053/j.semnuclmed.2025.05.005},
url = {https://www.sciencedirect.com/science/article/pii/S0001299825000625},
author = {Geoffrey M. Currie and K. Elizabeth Hawk},
abstract = {Artificial intelligence (AI), particularly machine learning (ML) and deep learning (DL), has significant potential to advance the capabilities of nuclear neuroimaging. The current and emerging applications of ML and DL in the processing, analysis, enhancement and interpretation of SPECT and PET imaging are explored for brain imaging. Key developments include automated image segmentation, disease classification, and radiomic feature extraction, including lower dimensionality first and second order radiomics, higher dimensionality third order radiomics and more abstract fourth order deep radiomics. DL-based reconstruction, attenuation correction using pseudo-CT generation, and denoising of low-count studies have a role in enhancing image quality. AI has a role in sustainability through applications in radioligand design and preclinical imaging while federated learning addresses data security challenges to improve research and development in nuclear cerebral imaging. There is also potential for generative AI to transform the nuclear cerebral imaging space through solutions to data limitations, image enhancement, patient-centered care, workflow efficiencies and trainee education. Innovations in ML and DL are re-engineering the nuclear neuroimaging ecosystem and reimagining tomorrow’s precision medicine landscape.}
}
@article{ZUGASTIMURILLO2025107157,
title = {The role of artificial intelligence in reducing obesity stigma in healthcare},
journal = {Medicina Clínica (English Edition)},
pages = {107157},
year = {2025},
issn = {2387-0206},
doi = {https://doi.org/10.1016/j.medcle.2025.107157},
url = {https://www.sciencedirect.com/science/article/pii/S2387020625005170},
author = {Ana {Zugasti Murillo} and Javier {Salvador Rodríguez}}
}
@article{NEGI2025,
title = {Artificial intelligence in simulation-based training for Health Professions Education: Navigating the rabbit hole},
journal = {Medical Journal Armed Forces India},
year = {2025},
issn = {0377-1237},
doi = {https://doi.org/10.1016/j.mjafi.2025.08.010},
url = {https://www.sciencedirect.com/science/article/pii/S0377123725002369},
author = {Rakhi Negi and Deepti Chopra and Komal Maheshwari and Anushi Mahajan and Dinesh Badyal and Padmini Venkataramani},
keywords = {Artificial intelligence, Simulation-based training, Machine learning, Deep learning, Health professions education},
abstract = {Simulation-based training (SBT) for health professions education has seen an evolution from low-fidelity trainers to technology-integrated high-fidelity trainers, which has opened doors to newer and promising prospects of integration of artificial intelligence (AI) into SBT. This review provides insights into the use of AI to augment and transform various elements of SBT like complex scenario designing, realism, feedback, student engagement, etc. This is exemplified through the successful application of AI in various SBT platforms, which have increased the efficacy of simulations. However, several challenges and barriers have been perceived in the use of AI in SBT, which include bias in AI algorithms originating due to skewed training datasets leading to inaccurate decisions, errors due to black box, cost factors, need for constant update, and ethical, legal, and cultural issues. Despite these challenges, the railroads of AI are fast-tracking with increased interest and collaborative ventures between various stakeholders like healthcare professionals, educators, technological experts, and policymakers. This article attempts to provide a comprehensive overview of the role of AI in SBT, challenges, and the way forward to amalgamating it with SBT in an optimal manner.}
}
@article{KOBEISSI2025102445,
title = {Artificial intelligence 101: Building literacy with the AI-ABCs framework},
journal = {Nursing Outlook},
volume = {73},
number = {4},
pages = {102445},
year = {2025},
issn = {0029-6554},
doi = {https://doi.org/10.1016/j.outlook.2025.102445},
url = {https://www.sciencedirect.com/science/article/pii/S0029655425000983},
author = {Mahrokh M. Kobeissi and Diane M. {Santa Maria} and Jung In Park},
keywords = {Artificial intelligence, Human intelligence, Literacy, AI-ABC framework, Education, Nursing leadership},
abstract = {The rapid advancements of artificial intelligence (AI) in healthcare have triggered a significant literacy gap among nursing professionals, raising concerns about implementation, ethical use, and impact on practice. This article introduces the AI-ABCs framework as a structured approach to building foundational AI literacy among nurse leaders, educators, and healthcare professionals. The framework was developed through a comprehensive literature synthesis and expert consultation in nursing informatics to identify essential components of AI literacy for healthcare professionals. The AI-ABCs framework provides an accessible entry point for AI literacy through three components: A—AI-Basics, B—Benefits and Challenges of AI, and C—Core Components and Terminologies in AI. The AI-ABCs framework offers nurse leaders and educators a structured approach to developing foundational AI literacy necessary for guiding policy development, curriculum integration, and ethical implementation in healthcare and educational settings, aligning with recommendations from key professional organizations.}
}
@article{QIN2025120810,
title = {Leveraging data-driven artificial intelligence in optimization design for building structures: A review},
journal = {Engineering Structures},
volume = {341},
pages = {120810},
year = {2025},
issn = {0141-0296},
doi = {https://doi.org/10.1016/j.engstruct.2025.120810},
url = {https://www.sciencedirect.com/science/article/pii/S0141029625012015},
author = {Sizhong Qin and Yifan Fei and Wenjie Liao and Xinzheng Lu},
keywords = {Intelligent optimization, Building structural design, Data-driven AI, Heuristic optimization, Generative AI},
abstract = {Applying optimization methods to design, referred to as optimization design, is a widely adopted approach in structural design of buildings. Conventional optimization methods primarily focus on enhancing the performance or reducing the cost of buildings, while ensuring that they satisfy certain structural design requirements. However, these methods often suffer from low optimization efficiencies and struggle to satisfy implicit design constraints. Recent rapid advances in data-driven artificial intelligence (AI) approaches enable the extraction of implicit design knowledge from extensive datasets and efficient handling of complex optimization tasks, thereby introducing new possibilities for optimization design. The integration of data-driven AI methods into structural optimization has led to the growth of research on intelligent optimization design for building structures, demonstrating significant potential for generating initial designs, simplifying optimization problems, solving the related models, and evaluating the results. This study systematically reviews data-driven intelligent optimization design for building structures, with the aim of classifying various optimization techniques, and summarizing the distinct roles of data-driven AI methods in intelligent optimization design. The findings indicate a significant upward trend in the application of intelligent optimization methods, while the emergence of novel AI techniques presents both opportunities and challenges. This study also aims to provide a comprehensive reference for methods and application scenarios of intelligent optimization design for building structures; this helps designers leverage the learning capabilities of data-driven AI approaches alongside the quantitative-analysis strengths of optimization methods to enhance the quality and efficiency of building structures.}
}
@article{QIAN2024100040,
title = {Societal impacts of artificial intelligence: Ethical, legal, and governance issues},
journal = {Societal Impacts},
volume = {3},
pages = {100040},
year = {2024},
issn = {2949-6977},
doi = {https://doi.org/10.1016/j.socimp.2024.100040},
url = {https://www.sciencedirect.com/science/article/pii/S2949697724000055},
author = {Yuzhou Qian and Keng L. Siau and Fiona F. Nah},
keywords = {Artificial Intelligence (AI), Generative AI, ChatGPT, Legal, Ethical, Bias and, Discrimination, AI Governance},
abstract = {Artificial intelligence (AI) is quickly changing the way we work and the way we live. The emergence of ChatGPT has thrust AI, especially Generative AI, into the spotlight. The societal impact of AI is on most people's minds. This article presents several research projects on how AI impacts work and society. Three research works are discussed in this article. The first study develops a theoretical framework structuring the legal and ethical objectives that are needed and the means to achieve them. The second study concentrates on bias and discrimination issues embedded in AI applications. It focuses on enhancing the collaboration between AI users and AI systems to alleviate bias and discrimination issues. The third study focuses on the governance of AI, and the study will design and develop an integrated AI governance framework to help guide the design and development of AI applications and facilitate the evolutions and revolutions of ethical AI systems.}
}
@article{BADAWY2025104554,
title = {Artificial intelligence in nursing practice and education: A 10-year bibliometric analysis of trends, gaps and emerging frontiers},
journal = {Nurse Education in Practice},
volume = {88},
pages = {104554},
year = {2025},
issn = {1471-5953},
doi = {https://doi.org/10.1016/j.nepr.2025.104554},
url = {https://www.sciencedirect.com/science/article/pii/S1471595325003117},
author = {Walaa Badawy and Mostafa Shaban and Haithm Zinhom},
keywords = {Artificial intelligence, Nursing, Bibliometric analysis, Nursing education, Clinical decision support, Ethics},
abstract = {Aim
To conduct a bibliometric analysis of global research on Artificial Intelligence (AI) in nursing (2014–2024), identifying publication trends, influential contributors and emerging themes.
Background
Although AI adoption in medicine is widely studied, its integration into nursing practice, education and professional identity remains limited. Bibliometric mapping helps clarify research trajectories and priorities.
Design
A descriptive bibliometric study.
Methods
Publications were retrieved from Web of Science, Scopus and PubMed/MEDLINE (2014–2024). After deduplication, 2225 records were analyzed. Descriptive statistics were performed in Excel and VOSviewer (v.1.6.20) was used for co-authorship, co-citation and keyword co-occurrence analyses. Synonyms were harmonized and author keywords prioritized.
Results
Annual publications grew from 38 in 2014–563 in 2024. The most active journals were CIN: Computers, Informatics, Nursing and Nurse Education in Practice. Leading contributors included Topaz, Lopez and Bowles, with the United States, China and Canada producing most publications. Co-citation analysis underscored foundations in nursing informatics, while recent work emphasized AI literacy, ethics and education. Keyword clustering revealed five domains: predictive analytics, decision support, nursing education, advanced techniques and ethics/equity.
Conclusions
AI in nursing has expanded from informatics toward practice, education and governance. Future research should prioritize outcome-based evaluations, curricular integration and ethical frameworks to align AI with nursing’s relational values}
}
@article{BAYRAKDAR2025,
title = {Artificial Intelligence in Temporomandibular Joint Imaging},
journal = {Neuroimaging Clinics of North America},
year = {2025},
issn = {1052-5149},
doi = {https://doi.org/10.1016/j.nic.2025.06.001},
url = {https://www.sciencedirect.com/science/article/pii/S1052514925007993},
author = {Ibrahim Sevki Bayrakdar and Alican Kuran and Ozer Celik and Kaan Orhan},
keywords = {Artificial intelligence, Deep learning, Machine learning, Radiomics, Temporomandibular joint, Anterior disc displacement, Temporomandibular joint osteoarthritis}
}
@article{WU2025,
title = {Artificial intelligence for drug delivery: Yesterday, today and tomorrow},
journal = {Acta Pharmaceutica Sinica B},
year = {2025},
issn = {2211-3835},
doi = {https://doi.org/10.1016/j.apsb.2025.09.022},
url = {https://www.sciencedirect.com/science/article/pii/S2211383525006227},
author = {Yiyang Wu and Nannan Wang and Ping Xiong and Ruifeng Wang and Jiayin Deng and Defang Ouyang},
keywords = {Drug delivery, Rational formulation design, Artificial intelligence, Machine learning, Deep learning, Formulation prediction, Rule of five, Multidisciplinary integration},
abstract = {The global pharmaceutical drug delivery market is forecasted to grow to USD 2546.0 billion by 2029. The expanding pharmaceutical market urgently needs a more efficient drug research and development paradigm. Artificial intelligence (AI) is revolutionizing drug delivery by offering alternatives to traditional trial-and-error experimental approaches. This review systematically traces the technological evolution from early simple models to current advanced AI algorithms in various applications, ranging from formulation optimization to the prediction of critical formulation parameters and de novo material design. To enhance the reliability of AI applications in drug delivery, we present comprehensive guidelines and “Rule of Five” (Ro5) principles to systematically direct researchers in utilizing AI in formulation development. This “Ro5” includes the following criteria: a formulation dataset containing at least 500 entries, coverage of a minimum of 10 drugs and all significant excipients, appropriate molecular representations for both drugs and excipients, inclusion of all critical process parameters, and utilization of suitable algorithms and model interpretability. The review concludes with insights into emerging trends and future directions, including the utilization of large language models, multidisciplinary collaboration opportunities, talent development, and culture transformation, aimed at facilitating a paradigm shift toward AI-driven drug formulation development.}
}
@article{FUDHOLI2026107915,
title = {Artificial intelligence for source code understanding tasks: A systematic mapping study},
journal = {Information and Software Technology},
volume = {189},
pages = {107915},
year = {2026},
issn = {0950-5849},
doi = {https://doi.org/10.1016/j.infsof.2025.107915},
url = {https://www.sciencedirect.com/science/article/pii/S095058492500254X},
author = {Dzikri Rahadian Fudholi and Andrea Capiluppi},
keywords = {Natural language processing, Embedding, Text preprocessing, Machine learning, Program semantics},
abstract = {Context:
Artificial intelligence (AI) techniques, particularly natural language processing (NLP) and machine learning (ML), are increasingly used to support source code understanding, an essential activity in software engineering.
Objective:
This systematic mapping study investigates how these techniques are applied, guided by four Research Questions (RQs) focusing on the types of tasks, embedding methods & preprocessing techniques used, machine learning models employed, and existing research gaps.
Methods:
A review of 227 peer-reviewed studies identifies trends and provides a structured mapping addressing each RQ.
Results:
The findings reveal a dominant shift toward deep learning, especially transformer-based and graph-based models, highlighting underexplored areas such as explainability.
Conclusion:
This study provides a task-based classification and offers insights and directions for future research in AI-enabled source code understanding, supporting both researchers and practitioners.}
}
@article{BRAGA2025128034,
title = {Towards a methodology for ethical artificial intelligence system development: A necessary trustworthiness taxonomy},
journal = {Expert Systems with Applications},
volume = {286},
pages = {128034},
year = {2025},
issn = {0957-4174},
doi = {https://doi.org/10.1016/j.eswa.2025.128034},
url = {https://www.sciencedirect.com/science/article/pii/S0957417425016550},
author = {Carlos Mario Braga and Manuel A. Serrano and Eduardo Fernández-Medina},
keywords = {Artificial Intelligence, Methodology, Trustworthy, Ethics, Generative AI, Taxonomy, Sociotechnical system},
abstract = {Recently, generative artificial intelligence (GenAI) has arisen and been rapidly adopted; due to its emergent abilities, there is a significantly increased need for risk management in the implementation of such systems. At the same time, many proposals for translating ethics into AI, as well as the first agreements by regulators governing the use of artificial intelligence (AI), have surfaced. This underscores the need for Trustworthy AI, which implies reliability, compliance, and ethics. However, there is still a lack of unified criteria, and more critically, a lack of systematic methodologies for operationalizing trustworthiness within AI development processes. Trustworthiness is crucial, as it ensures that the system performs consistently under expected conditions while adhering to moral and legal standards. The problem of ensuring trustworthiness must be addressed as a preliminary step in creating a methodology for building AI systems with these desirable features. Based on a systematic literature review (SLR), we analyze the ethical, legal, and technological challenges that AI projects face, identifying key considerations and gaps in current approaches. This article presents a detailed and structured sociotechnical taxonomy related to the concept of Trustworthy AI, grounded in the analysis of all relevant texts on the topic, and designed to enable the systematic integration of ethical, legal, and technological principles into AI development processes. The taxonomy establishes a sociotechnical foundation that reflects the interconnected nature of technological, ethical, and legal considerations, and serves as the conceptual basis for CRISP-TAI, a proposed specialized development lifecycle currently under validation, aimed at systematically operationalizing trustworthiness principles across all phases of AI system engineering.}
}
@article{KONG2025,
title = {Artificial intelligence for design strategies of tissue engineering materials},
journal = {Fundamental Research},
year = {2025},
issn = {2667-3258},
doi = {https://doi.org/10.1016/j.fmre.2025.09.010},
url = {https://www.sciencedirect.com/science/article/pii/S2667325825004832},
author = {Mingru Kong and Yuting Zeng and Zhen Wu and Hao Deng and Binrui Zhang and Dongyi Feng and Yuxiang Zhang and Wenjun Zhang and Xiaodong Fu and Leyu Wang},
keywords = {Artificial intelligence, Design of biomaterials, Machine learning, Deep learning, Tissue engineering},
abstract = {In recent years, artificial intelligence (AI), driven by machine learning (ML) and deep learning (DL) algorithms, has fundamentally transformed the design and performance prediction of tissue engineering materials. By analyzing large amounts of biomaterial data, ML has demonstrated remarkable effectiveness in optimizing mechanical properties, assessing biocompatibility, and enhancing the structural design of tissue engineering materials, while also accurately predicting the complex interactions between materials and cells. Due to its exceptional ability to process nonlinear data, DL is particularly effective in analyzing complex biological data, such as interactions between tissue engineering materials, cells, and proteins, as well as promoting tissue regeneration. This review systematically examines ML- and DL-based design methods for tissue engineering materials and their important applications in recent years. It also explores their technical advantages, challenges, and future directions, providing insights for advancing regenerative medicine.}
}
@article{NIU2025311,
title = {Typhoon science meets artificial intelligence: A roundtable on bridging physics-based and data-driven paradigms},
journal = {Tropical Cyclone Research and Review},
volume = {14},
number = {3},
pages = {311-316},
year = {2025},
issn = {2225-6032},
doi = {https://doi.org/10.1016/j.tcrr.2025.08.006},
url = {https://www.sciencedirect.com/science/article/pii/S2225603225000384},
author = {Zeyi Niu and Zhe-Min Tan and Hui Yu and Jian-Feng Gu and Guomin Chen and Wei Huang},
keywords = {Artificial intelligence, Typhoon, Roundtable},
abstract = {This paper summarizes the ‘Artificial Intelligence (AI) + Typhoon’ session and a subordinated roundtable forum at the 21st China National Workshop on Tropical Cyclones (NWTC-XXI, 16–18 April. 2025, Changsha China), highlighting recent advances in AI techniques for typhoon monitoring, forecasting, and impact assessment, as well as the deep integration of state-of-the-art artificial-intelligence weather prediction (AIWP) models with traditional physics-based numerical weather prediction (NWP) models. Key insights from the round-table forum are synthesized, emphasizing the strengths, limitations, and future development directions for AI models in typhoon forecasting. As a forward-looking perspective, we should be ready for embracing the emerging AI for research (AI4R) paradigm to advance typhoon science and technology.}
}
@article{NYBERG2026101119,
title = {Algorithm-Based Pay-for-Performance (APFP) systems: Paradoxes in artificial intelligence's influence on pay-for-performance theories},
journal = {Human Resource Management Review},
volume = {36},
number = {1},
pages = {101119},
year = {2026},
issn = {1053-4822},
doi = {https://doi.org/10.1016/j.hrmr.2025.101119},
url = {https://www.sciencedirect.com/science/article/pii/S1053482225000440},
author = {Anthony J. Nyberg and Dhuha Abdulsalam and Ormonde Cragun and Vijayesvaran Arumugam},
keywords = {Pay-for-performance, Artificial intelligence, Compensation, Incentives, Human resource management, Algorithms},
abstract = {Although artificial intelligence (AI) and generative AI (GenAI) are increasingly used to assess and reward employees, their implications for foundational pay-for-performance (PFP) theories remain underexplored. Traditional PFP systems are effective in an era of static evaluations and infrequent feedback, but they lack the intelligence and flexibility needed for today's dynamic work environments. In response, we introduce algorithm-based PFP (APFP) systems—PFP systems that leverage AI and GenAI to enable real-time adaptability, predictive capabilities, customization, automated algorithmic recommending, and measurement sophistication. We then use the APFP framework to assess its implications for three foundational PFP theories (equity theory, expectancy theory, and tournament theory). The APFP framework integrates established PFP principles with AI and GenAI capabilities, reassessing how employees perceive, respond to, and engage with PFP systems. By conceptualizing how AI and GenAI influence the theoretical mechanisms of PFP, we offer a lens for understanding their influence on foundational PFP theories. Our theoretical contributions bridge existing PFP theories with emerging AI- and GenAI-driven environments to advance the literature and lay a foundation for future research that highlights inherent benefits and risks of APFP systems.}
}
@article{JAIN20242487,
title = {Artificial Intelligence in Cardiovascular Care—Part 2: Applications: JACC Review Topic of the Week},
journal = {Journal of the American College of Cardiology},
volume = {83},
number = {24},
pages = {2487-2496},
year = {2024},
issn = {0735-1097},
doi = {https://doi.org/10.1016/j.jacc.2024.03.401},
url = {https://www.sciencedirect.com/science/article/pii/S0735109724067445},
author = {Sneha S. Jain and Pierre Elias and Timothy Poterucha and Michael Randazzo and Francisco {Lopez Jimenez} and Rohan Khera and Marco Perez and David Ouyang and James Pirruccello and Michael Salerno and Andrew J. Einstein and Robert Avram and Geoffrey H. Tison and Girish Nadkarni and Vivek Natarajan and Emma Pierson and Ashley Beecy and Deepa Kumaraiah and Chris Haggerty and Jennifer N. {Avari Silva} and Thomas M. Maddox},
keywords = {artificial intelligence, cardiac imaging, clinical trials, deep learning, digital health, generative AI, implementation science, innovation, large language models, health equity, machine learning},
abstract = {Recent artificial intelligence (AI) advancements in cardiovascular care offer potential enhancements in effective diagnosis, treatment, and outcomes. More than 600 U.S. Food and Drug Administration–approved clinical AI algorithms now exist, with 10% focusing on cardiovascular applications, highlighting the growing opportunities for AI to augment care. This review discusses the latest advancements in the field of AI, with a particular focus on the utilization of multimodal inputs and the field of generative AI. Further discussions in this review involve an approach to understanding the larger context in which AI-augmented care may exist, and include a discussion of the need for rigorous evaluation, appropriate infrastructure for deployment, ethics and equity assessments, regulatory oversight, and viable business cases for deployment. Embracing this rapidly evolving technology while setting an appropriately high evaluation benchmark with careful and patient-centered implementation will be crucial for cardiology to leverage AI to enhance patient care and the provider experience.}
}
@article{HU2025104963,
title = {Artificial intelligence enabled tumor diagnosis and treatment: Status, breakthroughs and challenges},
journal = {Critical Reviews in Oncology/Hematology},
volume = {216},
pages = {104963},
year = {2025},
issn = {1040-8428},
doi = {https://doi.org/10.1016/j.critrevonc.2025.104963},
url = {https://www.sciencedirect.com/science/article/pii/S1040842825003518},
author = {Yani Hu and Shuai Liang and Xu Zhou and Zhipeng Zeng and Junli Ding and Dong Hua},
keywords = {Artificial intelligence, Machine learning, Tumor diagnosis, Cancer treatment},
abstract = {In recent years, cancer has emerged as a leading threat to global health, underscoring the critical need for early detection, precise diagnosis, and effective treatment to enhance patient outcomes. Against this backdrop, the rapid adoption of artificial intelligence (AI) in oncology has been driven by three key factors: the proliferation of large-scale datasets, breakthroughs in computational hardware and algorithms, and the development of innovative deep learning (DL) architectures. Specifically, AI applications now span the entire oncology workflow, including image-based screening, pathological diagnosis, intelligent decision support, treatment outcome prediction, and personalized therapy design. Hence, we aim to synthesize the recent explosive growth in AI applications across the oncology continuum and to critically examine the translational challenges that hinder clinical deployment. More importantly, this article provides a timely update on cutting-edge advancements (e.g., multimodal learning, explainable AI and AI-driven drug discovery) and offers a forward-looking perspective on future directions, consolidating actionable insights for researchers and clinicians and paving the way for next-generation AI-driven precision oncology.}
}
@article{LEE2025507,
title = {Current Perspectives on the Artificial Intelligence in Critical Care Medicine},
journal = {Anesthesiology Clinics},
volume = {43},
number = {3},
pages = {507-525},
year = {2025},
note = {Artificial Intelligence in Anesthesiology},
issn = {1932-2275},
doi = {https://doi.org/10.1016/j.anclin.2025.05.005},
url = {https://www.sciencedirect.com/science/article/pii/S1932227525000357},
author = {Jongmin Lee and Joo Heung Yoon},
keywords = {Artificial intelligence, Deep learning, Large language model, Foundation model, Critical care medicine}
}
@article{CANILLASDELREY2025T38,
title = {[Translated article] Exploring the potential of artificial intelligence in traumatology: Conversational answers to specific questions},
journal = {Revista Española de Cirugía Ortopédica y Traumatología},
volume = {69},
number = {1},
pages = {T38-T46},
year = {2025},
issn = {1888-4415},
doi = {https://doi.org/10.1016/j.recot.2024.11.005},
url = {https://www.sciencedirect.com/science/article/pii/S1888441524001802},
author = {F. {Canillas del Rey} and M. {Canillas Arias}},
keywords = {Generative artificial intelligence, Chatbot, Multi-choice question answering, ChatGPT, Bard, Perplexity, Inteligencia artificial generativa, Robot conversacional, Respuesta a preguntas de opción múltiple, ChatGPT, Bard, Perplexity},
abstract = {Background and objective
Generative artificial intelligence is a technology that provides greater connectivity with people through conversational bots (“chatbots”). These bots can engage in dialogue using natural language indistinguishable from humans and are a potential source of information for patients. The aim of this study is to examine the performance of these bots in solving specific issues related to orthopedic surgery and traumatology using questions from the Spanish MIR exam between 2008 and 2023.
Material and methods
Three “chatbot” models (ChatGPT, Bard and Perplexity) were analyzed by answering 114 questions from the MIR. Their accuracy was compared, the readability of their responses was evaluated, and their dependence on logical reasoning and internal and external information was examined. The type of error was also evaluated in the failures.
Results
ChatGPT obtained 72.81% correct answers, followed by Perplexity (67.54%) and Bard (60.53%). Bard provides the most readable and comprehensive responses. The responses demonstrated logical reasoning and the use of internal information from the question prompts. In 16 questions (14%), all three applications failed simultaneously. Errors were identified, including logical and information failures.
Conclusions
While conversational bots can be useful in resolving medical questions, caution is advised due to the possibility of errors. Currently, they should be considered as a developing tool, and human opinion should prevail over generative artificial intelligence.
Resumen
Antecedentes y objetivo
La inteligencia artificial generativa es una tecnología que ofrece su mayor conectividad con las personas gracias a los bots conversacionales («chatbot»). Estos pueden mantener un diálogo con un lenguaje natural indistinguible del humano y son una fuente potencial de información para los pacientes. El objetivo de este trabajo es estudiar el rendimiento de estos bots en la resolución de cuestiones específicas de cirugía ortopédica y traumatología empleando las preguntas del examen MIR español entre 2008 y 2023.
Material y métodos
Se analizaron 3 modelos de «chatbots» (ChatGPT, Bard y Perplexity) respondiendo a 114 preguntas del MIR. Se compararon aciertos, se valoró la legibilidad de las respuestas y se examinó su dependencia con el razonamiento lógico y la información interna y externa. En los fallos también se evaluó el tipo de error.
Resultados
ChatGPT obtuvo un 72,81% de aciertos, seguido por Perplexity (67,54%) y Bard (60,53%). Las respuestas más legibles y completas las ofrece Bard. Las respuestas demostraron un razonamiento lógico y el uso de información interna de los enunciados de preguntas. En 16 preguntas (14%) las 3 aplicaciones fallaron simultáneamente. Se identificaron errores, que incluían fallos lógicos y de información.
Conclusiones
Aunque los bots conversacionales pueden ser útiles en la resolución de preguntas médicas, se señala la necesidad de precaución debido a la posibilidad de errores. Actualmente deben considerarse como una herramienta en desarrollo, y la opinión humana debe prevalecer sobre la inteligencia artificial generativa.}
}
@article{SWAMI2025112553,
title = {Artificial intelligence technology in materials selection, device engineering and parameter optimisation for triboelectric nanogenerator},
journal = {Materials Today Communications},
volume = {46},
pages = {112553},
year = {2025},
issn = {2352-4928},
doi = {https://doi.org/10.1016/j.mtcomm.2025.112553},
url = {https://www.sciencedirect.com/science/article/pii/S2352492825010657},
author = {Ashok Kumar Swami and Deepak Verma and Richa Soni and Dweipayan Goswami},
keywords = {Artificial Intelligence, AI material selection, Triboelectric nanogenerator, Machine learning, Deep learning, AI integrated TENGs, TENG material, Output performance},
abstract = {In recent times, the world has been looking towards more sustainability and the advancement in technologies such as the Internet of Things (IoT), smart wearable devices, big data, smart sensing systems, 5G, and the upcoming 6G developments demand sustainable, flexible and self-powered devices. Triboelectric nanogenerators (TENGs) a device that uses the basic physics of friction, electrostatics, and induction to convert mechanical energy into electrical energy. It is a cost and environmentally friendly device for energy production. Integrating Artificial intelligence (AI), Machine Learning (ML), and Deep Learning (DL) algorithms into TENG devices may overcome the challenges of material selection, output performance prediction, structural design optimization, and durability. AI, (ML/DL) techniques algorithms, such as supervised learning, unsupervised learning, decision trees (DT), random forest (RF), support vector machine (SVM), k-means clustering, principal component analysis (PCA), artificial neural networks (ANNs), convolutional neural networks (CNNs), recurrent neural networks (RNNs), generative adversarial networks (GANs), reinforcement learning (RL) can resolve the challenges of material selection, enhancement of output performance, device parameter optimization and structural optimization. These algorithms can help in analysing the data of SEM, TEM, AFM images that can help in understanding the output voltage, current and charge density and simultaneously, able to predict the output performance of TENG devices. This study explores the transformative potential of AI-driven TENGs to revolutionize the future energy systems by improving charge density, durability, and structural design. The integration of AI and advanced materials such as biodegradable polymers, 2D nanomaterials, high dielectric materials and perovskites has further enabled the development of next-generation self-powered devices. Although the integration of artificial intelligence (AI) with triboelectric nanogenerators (TENGs) has been explored in numerous high-quality research articles across various applications, there is a surprising lack of comprehensive review articles dedicated to this emerging field. This review aims to fill that gap by highlighting the synergistic relationship between TENG technology and AI methodologies, particularly machine learning and deep learning. The focus of this paper is on the role of AI in material selection for TENGs and the optimization of device parameters—including output performance, structural design, and long-term stability—through advanced AI techniques.}
}
@article{DHAWAN2024368,
title = {Artificial intelligence in plastic surgery: Implications and limitations of text-to-image models for clinical practice},
journal = {JPRAS Open},
volume = {41},
pages = {368-371},
year = {2024},
issn = {2352-5878},
doi = {https://doi.org/10.1016/j.jpra.2024.07.008},
url = {https://www.sciencedirect.com/science/article/pii/S2352587824001086},
author = {Ravi Dhawan and Denys Shay},
keywords = {Artificial intelligence, LLMs, Generative AI, Text-to-Image AI}
}
@article{LEE2025105648,
title = {Artificial intelligence in dentistry: Exploring emerging applications and future prospects},
journal = {Journal of Dentistry},
volume = {155},
pages = {105648},
year = {2025},
issn = {0300-5712},
doi = {https://doi.org/10.1016/j.jdent.2025.105648},
url = {https://www.sciencedirect.com/science/article/pii/S0300571225000934},
author = {Sang J. Lee and Jessica Poon and Apissada Jindarojanakul and Chu-Chi Huang and Oliver Viera and Chan W. Cheong and Jason D. Lee},
keywords = {Artificial intelligence, Technologies, Healthcare, Dentistry, Dental education, Dental patient care, Dental practice management, Digital dentistry, Dental technology},
abstract = {Objectives
This narrative review aimed to explore the evolution and advancements of artificial intelligence technologies, highlighting their transformative impact on healthcare, education, and specific aspects within dentistry as a field.
Data and sources
Subtopics within artificial intelligence technologies in dentistry were identified and divided among four reviewers. Electronic searches were performed with search terms that included: artificial intelligence, technologies, healthcare, education, dentistry, restorative, prosthodontics, periodontics, endodontics, oral surgery, oral pathology, oral medicine, implant dentistry, dental education, dental patient care, dental practice management, and combinations of the keywords.
Study
selection: A total of 120 articles were included for review that evaluated the use of artificial intelligence technologies within the healthcare and dental field. No formal evidence-based quality assessment was performed due to the narrative nature of this review. The conducted search was limited to the English language with no other further restrictions.
Results
The significance and applications of artificial intelligence technologies on the areas of dental education, dental patient care, and dental practice management were reviewed, along with the existing limitations and future directions of artificial intelligence in dentistry as whole. Current artificial intelligence technologies have shown promising efforts to bridge the gap between theoretical knowledge and clinical practice in dental education, as well as improved diagnostic information gathering and clinical decision-making abilities in patient care throughout various dental specialties. The integration of artificial intelligence into patient administration aspects have enabled practices to develop more efficient management workflows.
Conclusions
Despite the limitations that exist, the integration of artificial intelligence into the dental profession comes with numerous benefits that will continue to evolve each day. While the challenges and ethical considerations, mainly concerns about data privacy, are areas that need to be further addressed, the future of artificial intelligence in dentistry looks promising, with ongoing research aimed at overcoming current limitations and expanding artificial intelligence technologies.}
}
@article{LOPES2025313,
title = {The Evolution of Artificial Intelligence in Nuclear Medicine},
journal = {Seminars in Nuclear Medicine},
volume = {55},
number = {3},
pages = {313-327},
year = {2025},
note = {Artificial Intelligence},
issn = {0001-2998},
doi = {https://doi.org/10.1053/j.semnuclmed.2025.01.006},
url = {https://www.sciencedirect.com/science/article/pii/S0001299825000054},
author = {Leonor Lopes and Alejandro Lopez-Montes and Yizhou Chen and Pia Koller and Narendra Rathod and August Blomgren and Federico Caobelli and Axel Rominger and Kuangyu Shi and Robert Seifert},
abstract = {Nuclear medicine has continuously evolved since its beginnings, constantly improving the diagnosis and treatment of various diseases. The integration of artificial intelligence (AI) is one of the latest revolutionizing chapters, promising significant advancements in diagnosis, prognosis, segmentation, image quality enhancement, and theranostics. Early AI applications in nuclear medicine focused on improving diagnostic accuracy, leveraging machine learning algorithms for disease classification and outcome prediction. Advances in deep learning, including convolutional and more recently transformer-based neural networks, have further enabled more precise diagnosis and image segmentation as well as low-dose imaging, and patient-specific dosimetry for personalized treatment. Generative AI, driven by large language models and diffusion techniques, is now allowing the process, interpretation, and generation of complex medical language and images. Despite these achievements, challenges such as data scarcity, heterogeneity, and ethical concerns remain barriers to clinical translation. Addressing these issues through interdisciplinary collaboration will pave the way for a broader adoption of AI in nuclear medicine, potentially enhancing patient care and optimizing diagnosis and therapeutic outcomes.}
}
@article{HOELSCHER2024763,
title = {Charting the Path: Nursing Leadership in Artificial Intelligence Integration into Healthcare},
journal = {Nurse Leader},
volume = {22},
number = {6},
pages = {763-772},
year = {2024},
note = {December 2024},
issn = {1541-4612},
doi = {https://doi.org/10.1016/j.mnl.2024.07.011},
url = {https://www.sciencedirect.com/science/article/pii/S1541461224001800},
author = {Stephanie H. Hoelscher and Katherine Taylor-Pearson and Holly Wei},
abstract = {Artificial intelligence, including generative AI, rapidly transforms health care by enhancing diagnostic accuracy, patient monitoring, and personalized care. Nurse leaders are pivotal in overseeing AI's ethical implementation and utilization to help ensure patient safety and maintain human-centered care. As AI integration increases, nurse leaders must thoughtfully consider usage training and effective governance. Exploring AI's multifaceted, powerful nature, this article delves into the potential to optimize health care delivery and streamline administrative processes while tangling the importance of data privacy, security, and fairness. All hold vital significance for nurse leaders, enabling them to steer the responsible integration of AI in health care.}
}
@article{LEYPOLD2025123753,
title = {Evaluating ChatGPT o1’s Capabilities in Peripheral Nerve Surgery: Advancing Artificial Intelligence in Clinical Practice},
journal = {World Neurosurgery},
volume = {196},
pages = {123753},
year = {2025},
issn = {1878-8750},
doi = {https://doi.org/10.1016/j.wneu.2025.123753},
url = {https://www.sciencedirect.com/science/article/pii/S1878875025001093},
author = {Tim Leypold and Jörg Bahm and Justus P. Beier and Vincent GJ. Guillaume and Tekoshin Ammo and Henrik Lauer and Jonas Kolbenschlag and Benedikt Schäfer},
keywords = {Artificial intelligence, ChatGPT, Large language model, o1, Peripheral nerve surgery},
abstract = {Objective
Artificial intelligence (AI) continues to advance in healthcare, offering innovative approaches to enhance clinical decision-making and patient management. Peripheral nerve surgery poses unique challenges due to the complexity of cases and the need for precise diagnostic and therapeutic strategies. This study investigates the application of OpenAI's generative AI model, o1, in assisting with intricate decision-making processes in peripheral nerve surgery.
Methods
Using advanced prompt engineering techniques, o1 was configured as a virtual medical assistant (Generative Pretrained Transformer–Nerve Surgery [GPT-NS]) to process 5 simulated clinical scenarios modeled after real-world cases. The AI guided surgeons through medical history, diagnostics, and treatment planning, culminating in case summaries. A panel of nerve surgery specialists and residents evaluated the AI's performance using a Likert scale across 7 criteria.
Results
GPT-NS demonstrated strong capabilities, achieving an average score of 4.3. High ratings were observed for understanding clinical issues and case presentation clarity. However, areas for improvement were noted in diagnostic sequencing and treatment recommendations. Despite a lower score indicating human evaluators’ perception of their superiority over the AI in handling cases, GPT-NS showed promise as a supportive tool in clinical practice.
Conclusions
As the performance of large language model AI continues to improve, it is becoming increasingly important that absolute experts assess the accuracy of the answers to ensure reliable and clinically sound integration into healthcare practices. This study underscores the potential of large language model AI in augmenting clinical decision-making in highly specialized fields like peripheral nerve surgery while demonstrating the ongoing importance of human expertise. Future research should explore ways to further refine AI capabilities and assess its integration into routine surgical workflows.}
}
@article{GUO2025619,
title = {Application of artificial intelligence technologies in library services at the top 100 US universities},
journal = {The Electronic Library},
volume = {43},
number = {4},
pages = {619-648},
year = {2025},
issn = {0264-0473},
doi = {https://doi.org/10.1108/EL-12-2024-0386},
url = {https://www.sciencedirect.com/science/article/pii/S0264047325000074},
author = {Rui Guo and Yiwei Pang and Yuanxi Xu and Zhenyang Liu and Yanchen Chen and Yajun Guo},
keywords = {Artificial intelligence, University libraries, Library services, Intelligent services, Content analysis, USA},
abstract = {Purpose
Through a systematic content analysis, this paper aims to examine the current use of artificial intelligence (AI) in the services of the top 100 US university libraries and explores the key factors that influence the adoption of this technology. It seeks to provide actionable strategic recommendations for library administrators. These recommendations aim to help libraries accelerate their intelligent service transformation while maintaining their academic resource advantages and humanistic traditions, and to establish a solid theoretical and empirical foundation for future research.
Design/methodology/approach
The authors analyse the current status of libraries adopting AI technologies and applying them to patron services, which include intelligent retrieval services, intelligent reference services, intelligent guided tour services and intelligent ID recognition services, among others. Firstly, the authors visit the official websites of the top 100 US university libraries to collect information. Subsequently, the prevalence of AI technologies is statistically analysed, and several excellent practice cases are selected. Finally, based on the data obtained from the content analysis, the impact of university rankings on the adoption of AI technologies in US university libraries is analysed.
Findings
The study finds that AI technologies are widely applied in the services of US university libraries, but there are differences in the adoption rates across different services. Almost all libraries have adopted intelligent retrieval and recommendation technology (99%). In terms of intelligent reference services, more than half of the libraries have used AI technologies (53%). Intelligent guided tour technology is also widely adopted (95%). The application of intelligent ID recognition technology in libraries is equally common (98%). Furthermore, more than half of the libraries have begun to explore generative AI technologies (61%). Additionally, the study further discovers that there is a significant negative correlation between university rankings and the number of AI technologies adopted by libraries. This indicates that top-ranked universities are more likely to introduce a variety of AI technologies in their library services.
Research limitations/implications
The study’s implications include constructing an analytical framework to assess AI in library services and identifying key adoption factors. It explores AI’s impact on service diversity and the popularity of different services. Notably, it finds a link between university rankings and AI adoption, offering insights into the relationship between tech adoption and institutional reputation.
Originality/value
This paper provides the latest statistical data on the use of AI technologies in US university libraries. It aims to help librarians understand the overall application situation and best practices. With these insights, librarians can develop corresponding plans to better use AI to serve patrons.}
}
@article{PERRSAUER20252217,
title = {Applications of explainable artificial intelligence in renewable energy research},
journal = {Energy Reports},
volume = {14},
pages = {2217-2235},
year = {2025},
issn = {2352-4847},
doi = {https://doi.org/10.1016/j.egyr.2025.08.046},
url = {https://www.sciencedirect.com/science/article/pii/S2352484725005116},
author = {Jordan Perr-Sauer and Juliette Ugirumurera and Jamil Gafur and Erik A. Bensen and Truc Nguyen and Shuva Paul and Joseph Severino and Ambarish Nag and Sanjana Vijayshankar and Paul Gasper and Donal P. Finegan and Jacob Holden and Juliane Mueller and Peter Graf and Charles Tripp and Hilary Egan},
keywords = {Renewable energy, Explainable artificial intelligence, Interpretable machine learning, Trustworthy artificial intelligence, Deep learning, Energy systems},
abstract = {Researchers in renewable energy are applying deep learning (DL) to a variety of problems from diverse renewable energy domains, such as biofuels, wind, solar, power systems, buildings, vehicles, and transportation systems. Improvements in accuracy may be demonstrated using DL in laboratory settings. However, the lack of interpretability of DL models poses a practical limitation to their utility in advancing scientific knowledge and in the deployment of DL models in safety-critical energy systems. In this article, we discuss explainable artificial intelligence (XAI) as one pathway toward more interpretable DL models. We explore a brief timeline of U.S. national laboratory interest in XAI, an overview and taxonomy of methods in the field of XAI, and a selection of applications across renewable energy research domains. We conclude by highlighting pivotal areas where XAI can accelerate innovation in artificial intelligence for renewable energy research and other essential future directions.}
}
@article{LUSCHI2025608,
title = {Design and development of a systematic validation protocol for synthetic melanoma images for responsible use in medical artificial intelligence},
journal = {Biocybernetics and Biomedical Engineering},
volume = {45},
number = {4},
pages = {608-616},
year = {2025},
issn = {0208-5216},
doi = {https://doi.org/10.1016/j.bbe.2025.09.001},
url = {https://www.sciencedirect.com/science/article/pii/S020852162500066X},
author = {Alessio Luschi and Linda Tognetti and Alessandra Cartocci and Elisa Cinotti and Giovanni Rubegni and Laura Calabrese and Martina D’onghia and Martina Dragotto and Elvira Moscarella and Gabriella Brancaccio and Giulia Briatico and Camila Scharf and Dario Buononato and Vittorio Tancredi and Carmen Cantisani and Camilla Chello and Luca Ambrosio and Pietro {Scribani Rossi} and Marco Virone and Giovanni Pellacani and Gabriele Cevenini and Pietro Rubegni and Ernesto Iadanza},
keywords = {Data augmentation, Generative AI, Dermatology, Melanoma, Validation protocol},
abstract = {Malignant melanoma is the deadliest form of skin cancer, and artificial intelligence could help address its diagnostic challenges. Generative Adversarial Networks (GANs) can generate synthetic dermoscopic images to augment limited real datasets, but the lack of standardised validation protocols holds back models’ reliability and clinicians’ trust. This study aims to design and develop a systematic validation protocol combining quantitative metrics and qualitative expert assessments to evaluate the realism, fidelity, diversity, and usefulness of synthetic dermoscopic melanoma images. A StyleGAN2 model, designed and trained in a previous study, was selected for its superior quantitative performance and exploited to generate 25 synthetic melanoma images, matched with 25 real images. A panel of 17 dermoscopists assessed the images using a 7-point Likert scale, across multiple qualitative attributes (real vs. synthetic, skin texture, visual realism, and confidence) and pattern analysis. Accuracy, sensitivity, specificity, Fleiss’ Kappa, and Krippendorff’s Alpha were calculated to analyse inter-rater agreement and evaluation outcomes. Accuracy in real vs synthetic images classification was moderate (64 %), with sensitivity at 73 % and specificity at 56 %, with poor inter-rater concordance over qualitative attributes. Synthetic images obtained superior scores in medium visual and overall realism, and confidence level, while the frequency of recognition of pigment network-patterns was comparable with real images. The proposed holistic validation protocol can effectively estimate the quality level of synthetic dermoscopic images, regardless of the architecture of the model used for generation, offering an objective and reliable evaluation tool, as qualitative evaluations remain crucial to ensure their safe deployment in clinical settings.}
}
@incollection{VINTER2025,
title = {Artificial intelligence in GPCR drug discovery: A paradigm shift in computational pharmacology},
booktitle = {Reference Module in Chemistry, Molecular Sciences and Chemical Engineering},
publisher = {Elsevier},
year = {2025},
isbn = {978-0-12-409547-2},
doi = {https://doi.org/10.1016/B978-0-443-29808-0.00047-9},
url = {https://www.sciencedirect.com/science/article/pii/B9780443298080000479},
author = {Adrijana Vinter and Ivan Grgičević},
keywords = {G protein-coupled receptors, Artificial intelligence, Drug discovery, Machine learning, Deep learning, Graph neural networks, Reinforcement learning, AlphaFold2, Biased signaling, Allosteric modulators, Multi-omics integration, Virtual screening, De novo drug design, Precision medicine, Explainable AI (XAI)},
abstract = {This Chapter explores the transformative role of artificial intelligence in GPCR-targeted drug discovery, highlighting how machine learning, deep learning, and reinforcement learning are reshaping ligand screening, structure prediction, and personalized medicine. AI models such as AlphaFold2, graph neural networks, and generative adversarial networks have significantly accelerated hit identification, improved functional selectivity, and enabled allosteric modulator discovery. Integrated with multi-omics data, AI enhances the precision and efficiency of therapeutic development while reducing cost and time. The Chapter also addresses the challenges of data scarcity, model interpretability, and experimental validation, offering potential solutions through explainable AI and hybrid workflows. These advancements position AI not just as a supportive tool but as a central driver in next-generation GPCR pharmacology and precision drug design.}
}
@article{RIZZO2025116063,
title = {To be Artificial Intelligence for sustainability or not to be sustainable Artificial Intelligence},
journal = {Renewable and Sustainable Energy Reviews},
volume = {223},
pages = {116063},
year = {2025},
issn = {1364-0321},
doi = {https://doi.org/10.1016/j.rser.2025.116063},
url = {https://www.sciencedirect.com/science/article/pii/S1364032125007361},
author = {Santi Agatino Rizzo},
keywords = {Artificial intelligence, Electrical energy, Energy transition, Life cycle assessment, Sustainable development},
abstract = {Sustainable electrical energy (SEE) represents a direct and indirect critical enabling factor for sustainable development. Artificial Intelligence (AI) has emerged as a disruptive technology that accelerates the transition toward full SEE, but concurrently, presents a fatal issue. This study inspects the benefits and limitations of AI applications in the context of SEE. The primary finding highlights a common assumption: AI utilization in areas such as green power generation, electric vehicles, and so on is often deemed, per se, sufficient to achieve full SEE. However, the study highlights a critical shortcoming of this perspective: the absence of a holistic SEE. Achieving full SEE requires integrating the life cycle assessment, which evaluates the environmental impact from raw material extraction to end-of-life management. This ensures considering the environmental adverse effects of green technologies such as renewables and electric transportation, thus embracing a real technology neutrality. Additionally, a thorough consideration of electrical energy production and consumption is necessary. Moreover, it emerged that AI-based holistic planning enabling a fully green-supplied power system has not been sufficiently investigated so far. In conclusion, the first part of the study has brought out that a transition toward fully sustainable electricity imposes that AI considers the design for sustainability paradigm and a holistic view of sustainability that combines life cycle assessment and exploitable electrical energy. The large room for improvement in the adoption of AI for full SEE and its imperative priority ask for an urgent research effort of academia and industry. With this in mind, some figures of merit have been discussed. The second part of this study investigates the main sustainability challenges of AI. The analysis of the (e−)waste, pollution, and energy demand has highlighted that AI widespread use is untenable with the current technologies. The key issue is the unsustainable growth of electrical energy consumption due to AI, which incontrovertibly emerges as the core challenge, because the research effort has focused on achieving even-increasing accuracy regardless of the energy consumption. Large diffusion of humanoids that would exploit various AI tools to face different problems while using large language models and generative AI systems will skyrocket energy demand. Natural evolution has inherently optimized the human brain for energy efficiency, while the evolution of AI has led, conversely, to energy-inefficient outcomes. Therefore, a worldwide research effort must be lavished on developing low-energy-demand AI while keeping sufficient accuracy. In conclusion, all the research efforts have focused so far on providing AI with human skills until reaching super-human abilities, overlooking the crucial one: very low-energy-demand high-computing aptitude.}
}
@incollection{CHOU202661,
title = {Chapter 3 - Application of machine learning and artificial intelligence methods in predictions of absorption, distribution, metabolism, and excretion properties of chemicals∗},
editor = {Zhoumeng Lin and Wei-Chun Chou},
booktitle = {Machine Learning and Artificial Intelligence in Toxicology and Environmental Health},
publisher = {Academic Press},
pages = {61-97},
year = {2026},
isbn = {978-0-443-30010-3},
doi = {https://doi.org/10.1016/B978-0-443-30010-3.00012-X},
url = {https://www.sciencedirect.com/science/article/pii/B978044330010300012X},
author = {Wei-Chun Chou and Miao Li and Srijit Seal and Zhoumeng Lin},
keywords = {Absorption, distribution, metabolism, and excretion (ADME), Artificial intelligence (AI), Generative AI, Machine learning (ML)},
abstract = {Accurately predicting absorption, distribution, metabolism, and excretion (ADME) properties is essential for modern drug discovery and development, as these profiles directly impact the therapeutic efficacy and safety of new chemical entities. Poor ADME characteristics are a leading cause of drug candidate failure, emphasizing the need for efficient early-stage assessment. While traditional experimental methods are reliable, they are often time-consuming and resource-intensive. Recent advancements in machine learning (ML) and artificial intelligence (AI) have transformed ADME prediction, improving efficiency in the early stages of drug development. This chapter overviews the ML models that are commonly used in ADME predictions, including random forests, support vector machines, and artificial neural networks, and predicts key ADME properties such as oral bioavailability, plasma protein binding, and hepatic clearance using large datasets. Deep neural networks, including convolutional neural networks and recurrent neural networks, further enhance the ability to model complex, nonlinear relationships in ADME data. Additionally, generative AI techniques, such as variational autoencoders and generative adversarial networks, are expanding the discovery of novel compounds with optimized ADME profiles. Additionally, we discuss the integration of public and proprietary databases, in vitro models, and challenges in data quality and standardization. Case studies demonstrate the transformative potential of AI-driven models in optimizing pharmacokinetic profiles and accelerating drug development.}
}
@article{HO2025100145,
title = {Gender biases within Artificial Intelligence and ChatGPT: Evidence, Sources of Biases and Solutions},
journal = {Computers in Human Behavior: Artificial Humans},
volume = {4},
pages = {100145},
year = {2025},
issn = {2949-8821},
doi = {https://doi.org/10.1016/j.chbah.2025.100145},
url = {https://www.sciencedirect.com/science/article/pii/S2949882125000295},
author = {Jerlyn Q.H. Ho and Andree Hartanto and Andrew Koh and Nadyanna M. Majeed},
keywords = {Artificial intelligence, Chatbots, Gender bias, ChatGPT, Generative AI},
abstract = {The growing adoption of Artificial Intelligence (AI) in various sectors has introduced significant benefits, but also raised concerns over biases, particularly in relation to gender. Despite AI's potential to enhance sectors like healthcare, education, and business, it often mirrors reality and its societal prejudices and can manifest itself through unequal treatment in hiring decisions, academic recommendations, or healthcare diagnostics, systematically disadvantaging women. This paper explores how AI systems and chatbots, notably ChatGPT, can perpetuate gender biases due to inherent flaws in training data, algorithms, and user feedback loops. This problem stems from several sources, including biased training datasets, algorithmic design choices, and human biases. To mitigate these issues, various interventions are discussed, including improving data quality, diversifying datasets and annotator pools, integrating fairness-centric algorithmic approaches, and establishing robust policy frameworks at corporate, national, and international levels. Ultimately, addressing AI bias requires a multi-faceted approach involving researchers, developers, and policymakers to ensure AI systems operate fairly and equitably.}
}
@article{TIGGELOVEN2025113689,
title = {The Role of Artificial Intelligence for Early Warning Systems: Status, Applicability, Guardrails and Ways Forward},
journal = {iScience},
pages = {113689},
year = {2025},
issn = {2589-0042},
doi = {https://doi.org/10.1016/j.isci.2025.113689},
url = {https://www.sciencedirect.com/science/article/pii/S2589004225019509},
author = {Timothy Tiggeloven and Samira Pfeiffer and Alessia Matanó and Marc {van den Homberg} and Lisa Thalheimer and Markus Reichstein and Silvia Torresan},
keywords = {Early warning systems, early warning, natural hazard, multi-hazard, artificial intelligence, machine learning, deep learning, responsible AI, hydrometeorological hazards, geohazards},
abstract = {SUMMARY
Artificial intelligence (AI) is gaining momentum in earth science and policy as a tool to analyse complex natural hazards and their impacts. Such analyses are critical for effective Early Warning Systems (EWS), which aim to generate timely and actionable risk information to protect sectors, systems, and people. Despite advancements in AI, its role in EWS remains underexplored across the four pillars of the Early Warning for All (EW4All) framework- risk knowledge, forecasting, warning dissemination and communication and response preparedness. This study draws on a systematic literature review to assess AI methods utilized in the context of EWS, examines their challenges and opportunities and discusses guiding questions for responsible use. Our study highlights key gaps across knowledge, application and policy. Moreover, we call for coordinated efforts to develop responsible AI frameworks that enhance EWS while ensuring they remain inclusive, accessible, and people-centred - ultimately supporting the goal of EW4All by 2027.}
}
@article{STACEY2025112548,
title = {A responsible artificial intelligence framework for forensic science},
journal = {Forensic Science International},
volume = {375},
pages = {112548},
year = {2025},
issn = {0379-0738},
doi = {https://doi.org/10.1016/j.forsciint.2025.112548},
url = {https://www.sciencedirect.com/science/article/pii/S0379073825001860},
author = {Janet Stacey and Rachel Fleming and Dion Sheppard and Jan Sheppard and Gillian Dobbie and Deepak Karunakaran},
keywords = {Artificial intelligence, Responsible AI},
abstract = {As artificial intelligence and automated workflows become embedded in forensic science, there is a need for a comprehensive framework to ensure that they are fit for purpose. A review of existing AI guidelines and policies has identified a commonality of principles but an absence of the level of detail required for an organisation to implement these expectations at an operational level. In response to this, a Responsible AI Framework (RAIF) to support the safe and reliable development and implementation of AI projects within a forensic organisation has been developed. The RAIF consists of three components: a Questionnaire, a Guidelines document, and a Project Register. When used in combination, the RAIF enables organisations to have confidence when undertaking AI projects and to balance the opportunities and risks of this evolving technology. A fully worked example illustrating the application of the RAIF to Lumi Drug Scan, a forensic AI solution to detect illict drugs in real time, is included.}
}
@article{SCUOTTO2025124330,
title = {Tackling the empowerment of Artificial Intelligence for humanitarian intervention from Save the Children},
journal = {Technological Forecasting and Social Change},
volume = {221},
pages = {124330},
year = {2025},
issn = {0040-1625},
doi = {https://doi.org/10.1016/j.techfore.2025.124330},
url = {https://www.sciencedirect.com/science/article/pii/S0040162525003610},
author = {Veronica Scuotto and Kingsley Obi Omeihe and Valentina Cillo and Del Giudice Manlio},
keywords = {Artificial Intelligence, Humanitarian interventions, Save the Children, Knowledge based view},
abstract = {The growing needs of humanitarian organisations have intensified discussions around the use of Artificial Intelligence (AI) to enhance humanitarian interventions. While concerns about the costs and time required to adopt AI technologies persist, there is a strong willingness within the sector to leverage AI to become more flexible, adaptive to local conditions, and deliver assistance more efficiently and effectively. Drawing on the Knowledge-Based View (KBV), this study examines the application of AI within one of the world's largest humanitarian organisations, Save the Children. Based on a qualitative analysis conducted in 2024, several key insights emerge. First, AI has the potential to significantly empower and improve humanitarian interventions. Second, although the use of AI remains at an early stage, there is a growing commitment to integrating it across a wide range of humanitarian activities, from assisting refugees to supporting their integration into new communities. Third, individual knowledge remains critical for complementing and enhancing the capabilities of AI, particularly in developing human skills and expertise. Finally, AI acts as a facilitator, in amplifying the impact of humanitarian efforts on a global scale.}
}
@article{BARRIOS2025268,
title = {Ethical Considerations in the Deployment of Artificial Intelligence in Surgery},
journal = {Journal of Surgical Research},
volume = {315},
pages = {268-274},
year = {2025},
issn = {0022-4804},
doi = {https://doi.org/10.1016/j.jss.2025.08.019},
url = {https://www.sciencedirect.com/science/article/pii/S0022480425005529},
author = {Paola A. Barrios and Nicole Meredyth and Rachel Morris and Krista Haines and Grace J. Kim and Carrie Y. Peterson},
keywords = {AI, Artificial intelligence, Bias, Ethics, Integration, Safety, Transparency},
abstract = {Artificial intelligence (AI) is an attractive option to optimize surgical decision-making. However, multiple ethical concerns exist when applying AI to clinical care. We must consider the benefits of increased efficiency and potential accuracy of using AI against the principles of medical ethics, notably patient autonomy, beneficence, nonmaleficence, and justice. Discrepancies can result in concerns with bias, inequality, transparency, and patient safety as the medical field learns and begins to integrate this new technology. This manuscript is an extension of our 2024 meeting symposium on the topic and provides a review of the current literature around the ethical challenges of AI in academic surgery. We consider accountability, consent, notification, and bias in the setting of patient care and surgical education. Our goal is to equip physicians with a clear understanding of the ethical challenges and considerations surrounding AI to help them make informed decisions about integrating the technology into their practice and careers.}
}
@article{NUNES2025106057,
title = {Impact of artificial intelligence on hospital admission prediction and flow optimization in health services: a systematic review},
journal = {International Journal of Medical Informatics},
volume = {204},
pages = {106057},
year = {2025},
issn = {1386-5056},
doi = {https://doi.org/10.1016/j.ijmedinf.2025.106057},
url = {https://www.sciencedirect.com/science/article/pii/S1386505625002746},
author = {Aline Lucas Nunes and Thiago Lisboa and Bruna Nichele {da Rosa} and Carine Raquel Blatt},
keywords = {Artificial intelligence, Hospital admission prediction, Machine learning, Patient admission, Resource allocation, Emergency service},
abstract = {Background
Artificial Intelligence (AI)-assisted prediction of hospital admission is an innovative tool that optimizes resource allocation and improves patient flow within emergency departments. Health institutions need to decongest these departments to maintain sustainability and become efficient. Increasing demand and excessive competition for limited resources directly contribute to these challenges.
Objective
This systematic review aims to evaluate the use of artificial intelligence in the prediction of hospital admissions, evaluating the accuracy of machine learning models, their impact on clinical decision- making, and their role in the optimization and allocation of resources.
Methods
A systematic review of studies published between 2019 and 2024 followed the Preferred Reporting Items for Systematic Reviews and Meta-Analyses (PRISMA) guidelines. Studies were selected based on a pre-defined Population, Intervention, Comparison, and Outcome (PICO) framework, and methodological quality was assessed using the Quality In Prognosis Studies (QUIPS) and the Checklist for Artificial Intelligence in Medical Imaging (ChAMAI) tools.
Results
A total of 20 studies were included; most of the studies evaluated were retrospective. AI-based models demonstrated superior accuracy (85 % to 95 %) compared to traditional methods, with Random Forest (RF) and Neural Networks outperforming classical statistical models. Studies incorporating unstructured data through Natural Language Processing (NLP) have significantly improved patient flow and resource allocation. The integration of predictive analytics resulted in a reduction in avoidable hospitalizations, optimized bed occupancy, and a decrease in emergency room overcrowding.
Conclusion
AI-driven admission prediction is promising in the hospital setting, as it improves efficiency and allows for proactive and rapid decision-making, optimizing available resources. Future research is promising and should focus on prospective studies to validate practical applicability.}
}
@article{CIACCIO2025881,
title = {Emerging Technology: Artificial Intelligence and Celiac Disease},
journal = {Gastrointestinal Endoscopy Clinics of North America},
volume = {35},
number = {4},
pages = {881-892},
year = {2025},
note = {Celiac Disease},
issn = {1052-5157},
doi = {https://doi.org/10.1016/j.giec.2025.02.011},
url = {https://www.sciencedirect.com/science/article/pii/S1052515725000315},
author = {Edward J. Ciaccio and Govind Bhagat and Peter H. Green},
keywords = {Artificial intelligence, Autoimmune disease, Celiac disease, Deep learning, Machine learning}
}
@article{ABDALLA20251073,
title = {The Future of Artificial Intelligence in the Face of Data Scarcity},
journal = {Computers, Materials and Continua},
volume = {84},
number = {1},
pages = {1073-1099},
year = {2025},
issn = {1546-2218},
doi = {https://doi.org/10.32604/cmc.2025.063551},
url = {https://www.sciencedirect.com/science/article/pii/S1546221825005375},
author = {Hemn Barzan Abdalla and Yulia Kumar and Jose Marchena and Stephany Guzman and Ardalan Awlla and Mehdi Gheisari and Maryam Cheraghy},
keywords = {Data scarcity, artificial intelligence, application of artificial intelligence, ethical considerations, artificial general intelligence, synthetic data},
abstract = {Dealing with data scarcity is the biggest challenge faced by Artificial Intelligence (AI), and it will be interesting to see how we overcome this obstacle in the future, but for now, “THE SHOW MUST GO ON!!!” As AI spreads and transforms more industries, the lack of data is a significant obstacle: the best methods for teaching machines how real-world processes work. This paper explores the considerable implications of data scarcity for the AI industry, which threatens to restrict its growth and potential, and proposes plausible solutions and perspectives. In addition, this article focuses highly on different ethical considerations: privacy, consent, and non-discrimination principles during AI model developments under limited conditions. Besides, innovative technologies are investigated through the paper in aspects that need implementation by incorporating transfer learning, few-shot learning, and data augmentation to adapt models so they could fit effective use processes in low-resource settings. This thus emphasizes the need for collaborative frameworks and sound methodologies that ensure applicability and fairness, tackling the technical and ethical challenges associated with data scarcity in AI. This article also discusses prospective approaches to dealing with data scarcity, emphasizing the blend of synthetic data and traditional models and the use of advanced machine learning techniques such as transfer learning and few-shot learning. These techniques aim to enhance the flexibility and effectiveness of AI systems across various industries while ensuring sustainable AI technology development amid ongoing data scarcity.}
}
@article{GAN2025104630,
title = {Artificial intelligence policy uncertainty and corporate Greenwashing: Evidence from China},
journal = {International Review of Economics & Finance},
volume = {104},
pages = {104630},
year = {2025},
issn = {1059-0560},
doi = {https://doi.org/10.1016/j.iref.2025.104630},
url = {https://www.sciencedirect.com/science/article/pii/S1059056025007932},
author = {Yufei Gan and Luxueting Pi},
keywords = {Artificial intelligence policy uncertainty, Corporate greenwashing, CEO'S IT background, China},
abstract = {While the economic consequences of general policy uncertainty are well-documented, little is known about how uncertainty surrounding the governance of transformative technologies like Artificial Intelligence (AI) shapes corporate non-market strategies. This study investigates whether and how AI Policy Uncertainty (AIPU) drives corporate greenwashing. Using a large panel of Chinese listed firms from 2010–Q1 2025 and a novel text-based index of AIPU, we establish a causal link through a multi-pronged identification strategy that includes Propensity Score Matching (PSM), a multi-period Difference-in-Differences (DID) design, and an Instrumental Variable (IV) analysis. We find robust evidence that AIPU significantly increases corporate greenwashing. Crucially, this effect is attenuated for firms led by CEOs with strong IT backgrounds, who can better navigate technological turbulence. We further unveil the micro-foundations of this effect, showing that AIPU fuels greenwashing through three distinct mediating pathways: splitting managerial attention toward external risks (a cognitive channel), increasing precautionary cash holdings (a financial channel), and directly inhibiting substantive green innovation (a strategic channel). Heterogeneity analysis also shows the effect is more pronounced for non-state-owned enterprises and non-high-tech firms. Our findings reveal an important unintended consequence of technology governance and offer crucial insights for managers, investors, and policymakers.}
}
@article{LI2024205469,
title = {Artificial general intelligence for the upstream geoenergy industry: A review},
journal = {Gas Science and Engineering},
volume = {131},
pages = {205469},
year = {2024},
issn = {2949-9089},
doi = {https://doi.org/10.1016/j.jgsce.2024.205469},
url = {https://www.sciencedirect.com/science/article/pii/S2949908924002656},
author = {Jimmy Xuekai Li and Tiancheng Zhang and Yiran Zhu and Zhongwei Chen},
keywords = {Artificial general intelligence (AGI), ChatGPT, Large language models (LLMs), Generative AI, Multimodal, Upstream geoenergy industry},
abstract = {Artificial General Intelligence (AGI) is set to profoundly impact the traditional upstream geoenergy industry (i.e., geothermal energy, oil and gas industry) by introducing unprecedented efficiencies and innovations. This paper explores AGI's foundational principles and its transformative applications, particularly focusing on the advancements brought about by large language models (LLMs) and extensive computer vision systems in the upstream sectors of the industry. The integration of Artificial Intelligence (AI) has already begun reshaping the upstream geoenergy landscape, offering enhancements in production optimization, downtime reduction, safety improvements, and advancements in exploration and drilling techniques. These technologies streamline logistics, minimize maintenance costs, automate monotonous tasks, refine decision-making processes, foster team collaboration, and amplify profitability through error reduction and actionable insights extraction. Despite these advancements, the deployment of AI technologies faces challenges, including the necessity for skilled professionals for implementation and the limitations of model training on constrained datasets, which affects the models' adaptability across different contexts. The advent of generative AI, exemplified by innovations like ChatGPT and the Segment Anything Model (SAM), heralds a new era of high-density innovation. These developments highlight a shift towards natural language interfaces and domain-knowledge-driven AI, promising more accessible and tailored solutions for the upstream geoenergy industry. This review articulates the vast potential AGI holds for tackling complex operational challenges within the upstream geoenergy industry, requiring near-human levels of intelligence. We discussed the promising applications, the hurdles of large-scale AGI model deployment, and the necessity for domain-specific knowledge in maximizing the benefits of these technologies.}
}
@article{TRIMAILLE2025,
title = {Unveiling facilitators and barriers to artificial intelligence implementation in cardiac healthcare: Rationale and design of the INSIGHT-AI France study, from the Artificial Intelligence Working Group and the National College of Cardiologists in Training of the French Society of Cardiology},
journal = {Archives of Cardiovascular Diseases},
year = {2025},
issn = {1875-2136},
doi = {https://doi.org/10.1016/j.acvd.2025.06.078},
url = {https://www.sciencedirect.com/science/article/pii/S1875213625004449},
author = {Antonin Trimaille and Stéphane Lafitte and Floran Begue and Gauthier Beuque and Orianne Weizman and Paul Lucain and Nabil Bouali and Thierry Garban and Marc Villaceque and Jérémie Barraud and Cyril Ferdynus and Louis-Marie Desroche},
keywords = {Artificial intelligence, Cardiology, Survey, Healthcare professionals, Longitudinal study},
abstract = {Background
Artificial intelligence has emerged as a promising tool to optimize patient care in the field of cardiovascular medicine. However, data on its adoption and utilization by healthcare professionals are scarce.
Aim
To explore the factors that support or hinder the adoption of artificial intelligence in cardiology in France.
Methods
The INSIGHT-AI France study is a two-wave longitudinal panel survey recontacting the same individuals after 12 months, targeting professionals involved in the management of patients with cardiovascular diseases, including senior cardiologists, residents, nurses, technicians, engineers and decision-makers involved in artificial intelligence development. Participants from academic, public non-academic and private hospitals were recruited using a stratified sampling approach to capture diverse perspectives. Data were collected via SKEZIA, a platform compliant with the General Data Protection Regulation, with secure authentication and longitudinal tracking capabilities. The baseline survey, distributed from December 2024 to March 2025, assessed knowledge, attitudes, beliefs and practices related to artificial intelligence in cardiology. A follow-up survey will be conducted 12 months later to evaluate changes over time. The survey was developed by a scientific committee, with feedback from artificial intelligence and cardiology experts, and was pilot-tested for feasibility. Statistical analyses will include mixed-effects models and regression analyses.
Conclusions
This is the first study designed to explore the acceptance and limitation of artificial intelligence use in cardiovascular medicine in France. By identifying key facilitators and barriers, this study aims to inform strategic initiatives for more effective and equitable artificial intelligence implementation in French-speaking healthcare systems.}
}
@article{LEYPOLD20241078,
title = {Artificial Intelligence-Powered Hand Surgery Consultation: GPT-4 as an Assistant in a Hand Surgery Outpatient Clinic},
journal = {The Journal of Hand Surgery},
volume = {49},
number = {11},
pages = {1078-1088},
year = {2024},
issn = {0363-5023},
doi = {https://doi.org/10.1016/j.jhsa.2024.06.002},
url = {https://www.sciencedirect.com/science/article/pii/S0363502324002612},
author = {Tim Leypold and Benedikt Schäfer and Anja M. Boos and Justus P. Beier},
keywords = {Artificial intelligence, ChatGPT, GPT-4, hand surgery, large language models},
abstract = {Purpose
Exploring the integration of artificial intelligence in clinical settings, this study examined the feasibility of using Generative Pretrained Transformer 4 (GPT-4), a large language model, as a consultation assistant in a hand surgery outpatient clinic.
Methods
The study involved 10 simulated patient scenarios with common hand conditions, where GPT-4, enhanced through specific prompt engineering techniques, conducted medical history interviews, and assisted in diagnostic processes. A panel of expert hand surgeons, each board-certified in hand surgery, evaluated GPT-4’s responses using a Likert Scale across five criteria with scores ranging from 1 (lowest) to 5 (highest).
Results
Generative Pretrained Transformer 4 achieved an average score of 4.6, reflecting good performance in documenting a medical history, as evaluated by the hand surgeons.
Conclusions
These findings suggest that GPT-4 can effectively document medical histories to meet the standards of hand surgeons in a simulated environment. The findings indicate potential for future application in patient care, but the actual performance of GPT-4 in real clinical settings remains to be investigated.
Clinical relevance
This study provides a preliminary indication that GPT-4 could be a useful consultation assistant in a hand surgery outpatient clinic, but further research is required to explore its reliability and practicality in actual practice.}
}
@article{DESROCHE2025,
title = {Artificial intelligence in cardiovascular medicine: An exoskeleton for perception, reasoning and action},
journal = {Archives of Cardiovascular Diseases},
year = {2025},
issn = {1875-2136},
doi = {https://doi.org/10.1016/j.acvd.2025.07.012},
url = {https://www.sciencedirect.com/science/article/pii/S1875213625004607},
author = {Louis-Marie Desroche and Antonin Trimaille and Thierry Garban and Claire Bouleti},
keywords = {Artificial intelligence, Cardiology, Data acquisition, Machine learning, Clinical decision support},
abstract = {Cardiovascular diseases are a leading cause of morbidity and death, necessitating advanced tools for early diagnosis and personalized care. Artificial intelligence could contribute to transform cardiology through a Perception, Reasoning and Action framework. In the Perception phase, artificial intelligence can improve data acquisition. The Reasoning stage involves artificial intelligence-driven data analysis, integrating large datasets to support clinical decision-making and personalized treatment plans. In the Action phase, artificial intelligence optimizes therapeutic interventions, automates clinical workflows and enhances patient engagement. Artificial intelligence might therefore free up time for cardiologists to focus more on direct patient care and less on data acquisition and analysis, although their supervision remains essential. This review also addresses the technical and ethical challenges of artificial intelligence, including quality of datasets, algorithmic bias, the need for explainable artificial intelligence and data privacy, while exploring future perspectives, such as quantum computing and interdisciplinary collaboration. By addressing these challenges, artificial intelligence has the potential to revolutionize cardiology by enhancing diagnostic precision, advancing risk prediction, optimizing healthcare delivery and improving therapeutic outcomes on a global scale.}
}
@incollection{LUO2026443,
title = {Chapter 23 - Ethical and regulatory of artificial intelligence in drug design},
editor = {Qifeng Bai and Tingyang Xu and Junzhou Huang},
booktitle = {Deep Learning in Drug Design},
publisher = {Academic Press},
pages = {443-458},
year = {2026},
isbn = {978-0-443-32908-1},
doi = {https://doi.org/10.1016/B978-0-44-332908-1.00032-5},
url = {https://www.sciencedirect.com/science/article/pii/B9780443329081000325},
author = {Xufei Luo and Fengxian Chen and Yaolong Chen and Qingguo Zhou},
keywords = {Artificial intelligence, Large language model, ChatGPT, Ethical review, Regulatory, Drug design},
abstract = {The integration of artificial intelligence (AI) in new drug development has attracted widespread attention and is considered a potential means to revolutionize the pharmaceutical industry in recent years. Traditionally, drug development is a complex and time-consuming process that relies heavily on repetitive labor-intensive techniques such as trial-and-error experiments. However, the advancements in AI technology, especially recent developments in generative AI (GenAI), machine learning (ML), natural language processing, and other AI technologies are expected to accelerate and improve drug development by analyzing vast amounts of data more efficiently, accurately, and transparently. Nonetheless, as an emerging technology, AI faces numerous challenges and difficulties in drug development, such as ethical and regulatory issues. These challenges may hinder the progress of drug development, limit its applicability, and introduce unnecessary complications. Therefore ethical considerations are essential, and further research is required to gain a more detailed understanding of AI's mechanisms and roles in this process, thereby contributing more significantly to new drug development in the coming years. Based on this, this chapter primarily introduces the current state of ethics and regulations regarding AI involvement in new drug development, detailing specific approaches and suggestions for future research.}
}
@article{SAUNDERS2025270,
title = {From Turing Test to Chinese Room Argument: How to Apply Artificial Intelligence in Aviation},
journal = {Transportation Research Procedia},
volume = {88},
pages = {270-277},
year = {2025},
note = {VSI: TRPRO_EAAP 35},
issn = {2352-1465},
doi = {https://doi.org/10.1016/j.trpro.2025.05.033},
url = {https://www.sciencedirect.com/science/article/pii/S2352146525004120},
author = {Declan Saunders and Wen-Chin Li and Thomas Wang},
keywords = {Accident Analysis, Artifical Intelligence, Chinese Room Argument, Human Factors Analysis, Classification System, Large Language Model},
abstract = {The emergence of artificial intelligence (AI) with advanced large language model (LLM) offers promising approaches for enhancing the capacity of textual analysis. Both the Turing Test and Chinese Room Argument explore AI’s understanding of human language, although both methodologies have dissimilar interpretation on AI’s ‘intelligence’. Current AI systems have demonstrated the capacity for achieving defined test goals for ‘intelligence’. The aviation industry is increasingly interested in adopting AI to improve efficiency, safety, and cost efficiency; with the Generative Pre-trained Transformers’ (GPT) capability to reduce resource-intensive analytics in accident causation classification. This study investigates the potential and challenges of using AI to analyze human factors involved in aviation accidents based on the Human Factors Analysis and Classification System (HFACS). Six subject-matter experts in aviation human factors and AI domain participated in this research. All participants were familiar with the HFACS framework to analyze aviation accident reports and the output of GPT which were based on the prompt engineering developed by the research team. This research creates a framework to perform its initial generation and training using GE 235 accident investigation report from Taiwan Transportation Safety Board (TTSB). Initial discoveries demonstrated that the AI model could populate the sub-dimensions of Level 1 HFACS framework with moderate accuracy, although there remains a high presence of hallucinations in generated outputs, with a lack of reproducibility in consecutive outputs with consistent input data. There are still different opinions on AI applications in real-world operations with ethics and safety concerns. While there is clear potential for GPT models to supplement accident analysis within the HFACS framework, there is still more work to integrate HFACS framework into GPT modelling for effective generation to accident data.}
}
@article{ODONE2025,
title = {Artificial intelligence and infectious diseases: an evidence-driven conceptual framework for research, public health, and clinical practice},
journal = {The Lancet Infectious Diseases},
year = {2025},
issn = {1473-3099},
doi = {https://doi.org/10.1016/S1473-3099(25)00412-8},
url = {https://www.sciencedirect.com/science/article/pii/S1473309925004128},
author = {Anna Odone and Chiara Barbati and Silvia Amadasi and Tanja Schultz and David B Resnik},
abstract = {Summary
As artificial intelligence (AI) is projected to radically shape health care, its role in infectious disease prevention and management is drawing attention. AI offers promising opportunities to help tackle infectious disease threats and improve clinical management, outbreak detection, and infection control. As part of a dedicated Series on AI and infectious diseases, this paper sets the scene by proposing a conceptual framework that, building upon available AI models and data sources related to pathogens, human hosts, and the environment, comprehensively identifies selected domains where AI can be applied across infectious disease research, public health, and clinical practice. Building on this foundation, the two companion papers in the Series follow with an in-depth exploration of AI applications in diagnostics and antimicrobial resistance. We provide an overview of current and future applications of AI in infectious disease prevention and management, exploring the broad potential, available experimental evidence, real-life implementation examples, and technical normative, ethical, and policy barriers.}
}
@article{LIU2025,
title = {Artificial Intelligence-Driven Personalized Medicine},
journal = {Hand Clinics},
year = {2025},
issn = {0749-0712},
doi = {https://doi.org/10.1016/j.hcl.2025.08.008},
url = {https://www.sciencedirect.com/science/article/pii/S0749071225000745},
author = {Zhi-Yong Liu and Chang-Fu Kuo},
keywords = {Personalized medicine, Precision medicine, Artificial intelligence, Genomic medicine, Predictive analytics, Drug discovery and development}
}
@article{ZHU2025100942,
title = {The next-generation digital twin: from advanced sensing towards artificial intelligence-assisted physical-virtual system},
journal = {Journal of Industrial Information Integration},
volume = {48},
pages = {100942},
year = {2025},
issn = {2452-414X},
doi = {https://doi.org/10.1016/j.jii.2025.100942},
url = {https://www.sciencedirect.com/science/article/pii/S2452414X25001657},
author = {Jianxiong Zhu and Yaxin Yang and Mingxuan Xi and Shanling Ji and Luyu Jia and Tao Hu},
keywords = {Digital twin, Physical-virtual model, Functional materials, Artificial intelligence, Internet of things},
abstract = {Due to the emerging technologies of the metaverse and the growth of the Internet of Things(IoTs), digital twin has became compelling research topics along with the field of industrial automation, robotics, etc. To understand the advancement of digital twin relating elements, three issues need to be mentioned. The first technology is the advanced sensing component mainly aiming to objects status identification, functional electronic materials to break detection limitation, and data-enhancement by virtual sensors. Among them, sensing with the ability of self-powered, high-sensitivity, and soft electronic dramatically facilitates digital twin in high-accuracy and fast response. Secondly, the physical-virtual model towards intelligent system in digital twin is summerized to utilize simulating real prototype and virtual reality, especially physical-virtual prototype, subsystems, and artificial intelligent-enhanced digital twin system. Finally, owing to the machine learning and artificial intelligence, the next-generation digital twin system with advnaced sensing, physical-virtual system, and artificial intelligent-enhanced in various applications in one system would be the future trend. This review not only systemly reports digital twin from sensing component, the fundamental theory to the physical-virtual prototype, and artificial intelligence-enhanced technologies, it also presnets the future trajectory of the next-generation of digital twin as well as the challenges for various potential applications.}
}
@article{YI2025,
title = {Artificial intelligence in HFpEF: Diagnosis, prognosis, and management strategies},
journal = {Journal of Cardiology},
year = {2025},
issn = {0914-5087},
doi = {https://doi.org/10.1016/j.jjcc.2025.08.018},
url = {https://www.sciencedirect.com/science/article/pii/S0914508725002229},
author = {Jeong-Eun Yi and Jung Sun Cho},
keywords = {Artificial intelligence, Machine learning, Heart failure with preserved ejection fraction},
abstract = {Heart failure with preserved ejection fraction (HFpEF) accounts for more than half of all HF cases and its incidence and prevalence continue to increase, with a substantial burden of morbidity and mortality. Despite advances in our understanding of heterogeneous pathophysiology underlying HFpEF, the diagnosis, risk assessment, and management of this disease entity remain challenging in everyday practice. Artificial intelligence (AI) algorithm can handle large amounts of complex data and machine learning (ML), a subfield of AI, allows for the identification of relevant patterns by learning from big data. Considering the vast datasets generated from patients with HFpEF over the course of their illness, the application of AI and ML algorithms in HFpEF has the potential to improve patient care through enhancing early and precise diagnosis, personalized treatment based on phenotypes, and efficient monitoring. In this review, we provide an overview of the use of AI and ML in patients with HFpEF, focusing on diagnosis, phenotyping, risk stratification and prognosis, and management. Additionally, we discuss the limitations in the clinical adaptability of AI and suggest the future research directions for developing novel and feasible AI-based HFpEF model.}
}
@article{MORELLI2025661,
title = {Foundations of Artificial Intelligence: AI, Medicine, and Primary Care},
journal = {Primary Care: Clinics in Office Practice},
volume = {52},
number = {4},
pages = {661-669},
year = {2025},
note = {AI in Primary Care},
issn = {0095-4543},
doi = {https://doi.org/10.1016/j.pop.2025.07.001},
url = {https://www.sciencedirect.com/science/article/pii/S0095454325000624},
author = {Vincent Morelli},
keywords = {Artificial intelligence, AI, Primary care}
}
@article{JUNGHERR2025102079,
title = {Artificial Intelligence in deliberation: The AI penalty and the emergence of a new deliberative divide},
journal = {Government Information Quarterly},
volume = {42},
number = {4},
pages = {102079},
year = {2025},
issn = {0740-624X},
doi = {https://doi.org/10.1016/j.giq.2025.102079},
url = {https://www.sciencedirect.com/science/article/pii/S0740624X25000735},
author = {Andreas Jungherr and Adrian Rauchfleisch},
keywords = {Deliberation, Artificial intelligence, Survey experiment, Political behavior, Participation},
abstract = {Advances in Artificial Intelligence (AI) promise help for democratic deliberation, such as processing information, moderating discussion, and fact-checking. But public views of AI's role remain underexplored. Given widespread skepticism, integrating AI into deliberative formats may lower trust and willingness to participate. We report a preregistered within-subjects survey experiment with a representative German sample (n = 1850) testing how information about AI-facilitated deliberation affects willingness to participate and expected quality. Respondents were randomly assigned to descriptions of identical deliberative tasks facilitated by either AI or humans, enabling causal identification of information effects. Results show a clear AI penalty: participants were less willing to engage in AI-facilitated deliberation and anticipated lower deliberative quality than for human-facilitated formats. The penalty shrank among respondents who perceived greater societal benefits of AI or tended to anthropomorphize it, but grew with higher assessments of AI risk. These findings indicate that AI-facilitated deliberation currently faces substantial public skepticism and may create a new “deliberative divide.” Unlike traditional participation gaps linked to education or demographics, this divide reflects attitudes toward AI. Efforts to realize AI's affordances should directly address these perceptions to offset the penalty and avoid discouraging participation or exacerbating participatory inequalities.}
}
@article{QIAN2025105243,
title = {Emotional support powered by artificial intelligence in healthcare settings: A scoping review of technologies, contents, and outcomes},
journal = {International Journal of Nursing Studies},
volume = {172},
pages = {105243},
year = {2025},
issn = {0020-7489},
doi = {https://doi.org/10.1016/j.ijnurstu.2025.105243},
url = {https://www.sciencedirect.com/science/article/pii/S0020748925002536},
author = {Yingjia Qian and Wenjuan Tang and Tingting Xu and Daqiao Zhu and Wenzhe Hua},
keywords = {Artificial Intelligence, Robotics, Chatbot, Emotions, Psychosocial support systems, Scoping review},
abstract = {Background
In recent years, the application of artificial intelligence technologies for emotional support in healthcare settings has increased. However, less is known about the quality and effectiveness of artificial intelligence-based emotional support.
Objectives
This scoping review aimed to investigate the characteristics, supporting content, and outcomes (usability, acceptability, and effectiveness) of artificial intelligence-based emotional support in healthcare settings.
Methods
The scoping review followed the five-stage framework proposed by Arksey and O'Malley and the reporting standards established in the Preferred Reporting Items for Systematic Reviews and Meta-Analyses extension for Scoping Reviews. In July 2025, literature searches were conducted across 10 databases without restrictions on study design. The Mixed Methods Appraisal Tool was used to assess quality. Results were synthesized narratively.
Results
A total of 20 studies involving 4703 participants were included. Some studies exhibited methodological limitations, including insufficient blinding and inadequate control of confounding factors. Artificial intelligence-based emotional support systems varied in their technical characteristics, with cognitive-behavioral therapy and mindfulness being the most common foundation for the design of supportive content. Among patients, caregivers, and healthcare providers, these systems demonstrated a degree of usability and acceptability and were effective in improving a range of emotional states and emotion-related capacities. However, limitations persisted regarding technology, supportive content, specific emotional indicators, and sustained effectiveness.
Conclusion
This review identified substantial heterogeneity in the technologies and supportive content of artificial intelligence-based emotional support in healthcare settings. While these systems show promising potential, their limitations must be carefully considered in practice. Future research should adopt more rigorous experimental designs and increase nurse involvement in both technology development and study implementation. This review can help nursing professionals better understand and utilize artificial intelligence to provide emotional support and improve patients' emotional well-being.
Registration
This review has been registered in PROSPERO (CRD42025645966).}
}
@article{FUTTERER2025100483,
title = {Artificial intelligence in classroom management: A systematic review on educational purposes, technical implementations, and ethical considerations},
journal = {Computers and Education: Artificial Intelligence},
volume = {9},
pages = {100483},
year = {2025},
issn = {2666-920X},
doi = {https://doi.org/10.1016/j.caeai.2025.100483},
url = {https://www.sciencedirect.com/science/article/pii/S2666920X25001237},
author = {Tim Fütterer and Patricia Goldberg and Babette Bühler and Vlasta Sikimić and Ulrich Trautwein and Peter Gerjets and Kathleen Stürmer and Enkelejda Kasneci},
keywords = {Artificial intelligence, Classroom management, Attention, Ethics, Multimodal data},
abstract = {Artificial intelligence (AI) is increasingly shaping education, including classroom management. This systematic review analyzes 104 studies (2000–2022) on the use of AI in classroom management, focusing on educational purposes, technical implementations, and ethical considerations. Our findings show a growing use of AI technologies—particularly machine learning and deep learning—for tasks such as attendance tracking, behavior monitoring, and engagement assessment. These tools can streamline classroom management and offer detailed insights into student behavior. However, only a minority of studies leveraged AI's full potential, such as real-time feedback or multimodal data. Ethical issues, particularly privacy, data security, and algorithmic bias, were often underreported: only 22 % of studies addressed ethical concerns, and just 13 % implemented privacy-preserving measures. Our review underscores the importance of balancing technological innovation with ethical responsibility. It offers a comprehensive overview of AI's current applications and highlights future challenges and directions for responsible AI use in classrooms.}
}
@article{GANGWAL20253948,
title = {Artificial Intelligence in Natural Product Drug Discovery: Current Applications and Future Perspectives},
journal = {Journal of Medicinal Chemistry},
volume = {68},
number = {4},
pages = {3948-3969},
year = {2025},
issn = {1520-4804},
doi = {https://doi.org/10.1021/acs.jmedchem.4c01257},
url = {https://www.sciencedirect.com/science/article/pii/S1520480425001826},
author = {Amit Gangwal and Antonio Lavecchia},
abstract = {Drug discovery, a multifaceted process from compound identification to regulatory approval, historically plagued by inefficiencies and time lags due to limited data utilization, now faces urgent demands for accelerated lead compound identification. Innovations in biological data and computational chemistry have spurred a shift from trial-and-error methods to holistic approaches to medicinal chemistry. Computational techniques, particularly artificial intelligence (AI), notably machine learning (ML) and deep learning (DL), have revolutionized drug development, enhancing data analysis and predictive modeling. Natural products (NPs) have long served as rich sources of biologically active compounds, with many successful drugs originating from them. Advances in information science expanded NP-related databases, enabling deeper exploration with AI. Integrating AI into NP drug discovery promises accelerated discoveries, leveraging AI’s analytical prowess, including generative AI for data synthesis. This perspective illuminates AI’s current landscape in NP drug discovery, addressing strengths, limitations, and future trajectories to advance this vital research domain.
}
}
@article{PINO2025127725,
title = {Artificial intelligence and multispectral imaging in coffee production: A systematic literature review},
journal = {European Journal of Agronomy},
volume = {170},
pages = {127725},
year = {2025},
issn = {1161-0301},
doi = {https://doi.org/10.1016/j.eja.2025.127725},
url = {https://www.sciencedirect.com/science/article/pii/S1161030125002217},
author = {Andrés Felipe Solis Pino and Laura Sofia Caicedo Apraez},
keywords = {Coffee production, Artificial intelligence, Multispectral imaging, Precision agriculture},
abstract = {Integrating multispectral imaging and artificial intelligence in coffee production is a promising approach to optimize farming practices and improve crop management. This systematic literature review analyzes the current status, challenges, and future directions for combining these technologies in the coffee sector. Following the PRISMA protocol, 455 papers were reviewed in six scientific databases, identifying 27 primary studies that met the inclusion and exclusion criteria. The analysis reveals a significant increase in research activity since 2020, with a relationship between time and frequency of publication. Machine learning techniques, particularly regression analysis and random forests, emerged as the predominant artificial intelligence approaches for multispectral data processing. The review identified several key applications, such as coffee quality assessment, disease detection, and yield prediction. However, significant challenges remain, such as limited biometric variability within coffee plants, the influence of environmental factors, and the need for high-quality training data. The effectiveness of these technologies varies across geographic regions and soil and climatic conditions, underscoring the importance of application in specific contexts. Future research points toward the development of more robust artificial intelligence models, the integration of multiple data sources, and the need to employ hybrid artificial intelligence approaches. This review provides an understanding of the current landscape and valuable information for researchers, industry professionals, and stakeholders interested in creating more efficient and sustainable coffee farming practices using these technologies.}
}
@article{CAMPOVERDEMOLINA2026104055,
title = {Artificial intelligence in web accessibility: A systematic mapping study},
journal = {Computer Standards & Interfaces},
volume = {96},
pages = {104055},
year = {2026},
issn = {0920-5489},
doi = {https://doi.org/10.1016/j.csi.2025.104055},
url = {https://www.sciencedirect.com/science/article/pii/S0920548925000844},
author = {Milton Campoverde-Molina and Sergio Luján-Mora},
keywords = {Artificial intelligence, Disabilities, Language models, Literature review, Systematic mapping, WCAG, Web accessibility},
abstract = {The popularization and new renaissance of artificial intelligence (AI) have inspired the creation of new applications that help developers improve website accessibility that benefits users with and without disabilities. Therefore, this research presents a systematic mapping study (SMS) because AI in web accessibility has been gaining more interest nowadays with the exposure of works that require an SMS to systematize and consolidate the literature. Through a literature review using the Preferred Reporting Items for Systematic Reviews and Meta-Analyses (PRISMA), 53 studies from ACM Digital Library, IEEE Xplore, Scopus, and Web of Science were identified for inclusion in this review. The main results of this SMS are APIs with AI, web applications and plugins with AI, image and voice recognition with AI, limitations and challenges of AI in web accessibility, correction and testing of web accessibility with AI, automatic correction of web accessibility with AI, web navigation with conversational agents with AI, web and mobile application accessibility with AI, good practices in web accessibility for AI, accessibility of web forms and elements with AI. According to the results, in the studies, alternative texts were created for the images of the websites, AI helped generate accessible HTML code using well-defined prompts, AI tools must comply with Web Content Accessibility Guidelines (WCAG), machine learning was the most used approach, the most used language models were large language models (LLM) and accessibility barrier correction using ChatGPT. The primary contribution of this SMS lies in its analysis of the current state of AI research related to web accessibility and the identification of trends and gaps in this research area. This SMS is intended for researchers, programmers, and software development companies that may use language models, AI tools, or emerging technologies in web accessibility to mitigate website accessibility barriers.}
}
@article{PEIVASTE2025119419,
title = {Artificial intelligence in materials science and engineering: Current landscape, key challenges, and future trajectories},
journal = {Composite Structures},
volume = {372},
pages = {119419},
year = {2025},
issn = {0263-8223},
doi = {https://doi.org/10.1016/j.compstruct.2025.119419},
url = {https://www.sciencedirect.com/science/article/pii/S0263822325005847},
author = {Iman Peivaste and Salim Belouettar and Francesco Mercuri and Nicholas Fantuzzi and Hamidreza Dehghani and Razie Izadi and Halliru Ibrahim and Jakub Lengiewicz and Maël Belouettar-Mathis and Kouider Bendine and Ahmed Makradi and Martin Horsch and Peter Klein and Mohamed El Hachemi and Heinz A. Preisig and Yacine Rezgui and Natalia Konchakova and Ali Daouadji},
keywords = {Machine learning, Materials modeling, Materials design, Predictive modeling, Deep learning, Supervised learning, Unsupervised learning, Neural networks, Graph neural networks (GNNs), Convolutional neural networks (CNNs), Featurization, Property prediction, Materials discovery, Process optimization, Autonomous experimentation, Sustainability, Lifecycle assessment, Digital product passport, Data integration, Standardization},
abstract = {Artificial Intelligence is rapidly transforming materials science and engineering, offering powerful tools to navigate complexity, accelerate discovery, and optimize material design in ways previously unattainable. Driven by the accelerating pace of algorithmic advancements and increasing data availability, AI is becoming an essential competency for materials researchers. This review provides a comprehensive and structured overview of the current landscape, synthesizing recent advancements and methodologies for materials scientists seeking to effectively leverage these data-driven techniques. We survey the spectrum of machine learning approaches, from traditional algorithms to advanced deep learning architectures, including CNNs, GNNs, and Transformers, alongside emerging generative AI and probabilistic models such as Gaussian Processes for uncertainty quantification. The review also examines the pivotal role of data in this field, emphasizing how effective representation and featurization strategies, spanning compositional, structural, image-based, and language-inspired approaches, combined with appropriate preprocessing, fundamentally underpin the performance of machine learning models in materials research. Persistent challenges related to data quality, quantity, and standardization, which critically impact model development and application in materials science and engineering, are also addressed. Key applications are discussed across the materials lifecycle, including property prediction at multiple scales, high-throughput virtual screening, inverse design, process optimization, data extraction by large language models, and sustainability assessment. Critical challenges such as model interpretability, generalizability, and scalability are addressed, alongside promising future directions involving hybrid physics-ML models, autonomous experimentation, collaborative platforms, and human-AI synergy.}
}
@article{BEALE2025100553,
title = {Comparing physician and artificial intelligence chatbot responses to posthysterectomy questions posted to a public social media forum},
journal = {AJOG Global Reports},
volume = {5},
number = {3},
pages = {100553},
year = {2025},
issn = {2666-5778},
doi = {https://doi.org/10.1016/j.xagr.2025.100553},
url = {https://www.sciencedirect.com/science/article/pii/S2666577825001145},
author = {Shadae K. Beale and Natalie Cohen and Beatrice Secheli and Donald McIntire and Kimberly A. Kho},
keywords = {artificial intelligence, chatbot assistant, gynecologic surgery, hysterectomy, patient education, postoperative care},
abstract = {BACKGROUND
Within public online forums, patients often seek reassurance and guidance from the community regarding postoperative symptoms and expectations, and when to seek medical assistance. Others are using artificial intelligence in the form of online search engines or chatbots such as ChatGPT or Perplexity. Artificial intelligence chatbot assistants have been growing in popularity; however, clinicians may be hesitant to use them because of concerns about accuracy. The online networking service for medical professionals, Doximity, has expanded its resources to include a Health Insurance Portability and Accountability Act–compliant artificial intelligence writing assistant, Doximity GPT, designed to reduce the administrative burden on clinicians. Health professionals learn using a “medical model,” which greatly differs from the “health belief model” that laypeople learn through. This mismatch in learning perspectives likely contributes to a communication mismatch even during digital clinician–patient encounters, especially in patients with limited health literacy during the perioperative period when complications may arise.
OBJECTIVE
This study aimed to evaluate the ability of artificial intelligence chatbot assistants (Doximity GPT, Perplexity, and ChatGPT) to generate quality, accurate, and empathetic responses to postoperative patient queries that are also understandable and actionable.
STUDY DESIGN
Responses to 10 postoperative queries sourced from HysterSisters, a public forum for “woman-to-woman hysterectomy support,” were generated using 3 artificial intelligence chatbot assistants (Doximity GPT, Perplexity, and ChatGPT) and a minimally invasive gynecologic surgery fellowship–trained surgeon. Ten physician evaluators compared the blinded responses for quality, accuracy, and empathy. A separate pair of physician evaluators scored the responses for understandability and actionability using the Patient Education Materials Assessment Tool for Printable Materials (PEMAT-P). The final scores were the average of both reviewers’ scores. Analysis of variance was used for pairwise comparison of the evaluator scores between sources. Lastly, the Kruskal–Wallis test was used to analyze Flesch–Kincaid scoring for readability. The Pearson chi-square test was used to demonstrate the difference in reading level among the responses for each source.
RESULTS
Compared with a physician, Doximity GPT and ChatGPT were rated as more empathetic than a minimally invasive gynecologic surgeon, but quality and accuracy were similar across these sources. There was a significant difference between Perplexity and the other response sources, favoring the latter, for quality and accuracy (P<.001). Perplexity and the minimally invasive gynecologic surgeon ranked similarly for empathy. Reading ease was greater for the minimally invasive gynecologic surgeon responses (60.6 [53.5–68.4]; eighth and ninth grade) than for Perplexity (40.0 [28.6–47.2], college) and ChatGPT (35.5 [28.2–42.0], college) (P<.01). There was no significant difference in understandability and actionability, with all sources scored as having good understandability and average actionability.
CONCLUSION
As artificial intelligence chatbot assistants grow in popularity, including integration in the electronic health record, the output’s readability must reflect the general population’s health literacy to be impactful and effective. This analysis serves as a reminder for physicians to be mindful of this mismatch in readability and general health literacy when considering the integration of artificial intelligence chatbot assistants into patient care. The accuracy and consistency of these chatbots may also impact patient outcomes, making screening of utmost importance in this endeavor.}
}
@article{SULLIVAN2024298,
title = {Navigating the future: artificial intelligence's impact on transformational nurse leadership},
journal = {Teaching and Learning in Nursing},
volume = {19},
number = {3},
pages = {298-300},
year = {2024},
issn = {1557-3087},
doi = {https://doi.org/10.1016/j.teln.2024.04.017},
url = {https://www.sciencedirect.com/science/article/pii/S1557308724000933},
author = {Debra Sullivan and Vincent P. Hall and Jeanne Morrison},
keywords = {AI, Artificial intelligence, Generative AI, Nursing education, Transformational nurse leaders},
abstract = {Background
This article explores the historical development and recent surge of artificial intelligence (AI) technologies in healthcare, focusing on the role of the future nurse leader. The literature review emphasizes AI's potential in nursing education and patient care, including diagnosis, treatment planning, and personalized care, alongside the imperative of ethical considerations.
Innovation
Nurse leaders play a key role in shaping AI integration, emphasizing skill training and addressing legal and ethical challenges. They foster effective communication, trust, and creativity to enhance patient-focused care amidst AI adoption.
Implications
The implications highlight nurse leaders' pivotal role in navigating AI complexities and empowering teams to leverage technology while addressing concerns. This proactive approach ensures seamless AI integration, enhancing patient outcomes.
Conclusions
In conclusion, future nurse leaders are crucial in driving AI integration, fostering innovation, and ensuring ethical practice. Adaptable leadership is essential in addressing emerging challenges and advancing patient-centered care in the digital age.}
}
@article{MADADI2025e1,
title = {Artificial Intelligence-Driven Image and Data Analytics in Anesthesia},
journal = {Anesthesiology Clinics},
volume = {43},
number = {3, Supplement },
pages = {e1-e15},
year = {2025},
note = {Artificial Intelligence in Anesthesiology (Supplement)},
issn = {1932-2275},
doi = {https://doi.org/10.1016/j.anclin.2025.07.001},
url = {https://www.sciencedirect.com/science/article/pii/S1932227525000564},
author = {Firoozeh Madadi and Zeinab Kohzadi and Shahabedin Rahmatizadeh and A. Sassan Sabouri and Ali Dabbagh},
keywords = {Artificial intelligence (AI), Medical image analysis, Ultrasound-guided regional anesthesia (UGRA), Deep learning (DL), Clinical decision support}
}
@article{SALAZAR2025101882,
title = {Comparison of Qualitative Analyses Conducted by Artificial-Intelligence Versus Traditional Methods},
journal = {American Journal of Pharmaceutical Education},
pages = {101882},
year = {2025},
issn = {0002-9459},
doi = {https://doi.org/10.1016/j.ajpe.2025.101882},
url = {https://www.sciencedirect.com/science/article/pii/S0002945925005285},
author = {Marcela Salazar and May Chaw and Yvette Hellier and Stephanie Hsia and Katherine Gruenberg},
keywords = {artificial intelligence (AI), qualitative research, health professions education},
abstract = {Objective
Qualitative research remains underutilized in health professions education in part due to insufficient training and time-intensive analytic methods. Recent advances in generative artificial intelligence offer new opportunities to streamline the qualitative research process using large language models, such as GPT-4. However, the accuracy of GPT-4-generated codes and themes remains underexplored in health professions education research. This study characterizes qualitative analyses assisted by a general-purpose GPT-4 compared to traditional human-conducted analyses.
Methods
Two health professions datasets were previously analyzed using content or thematic analysis and then re-analyzed using a version of GPT-4. Researchers compared the accuracy, alignment, relevance, and appropriateness of codebooks and themes produced by GPT-4 with the prior findings. Dichotomous numerical ratings and explanations were assessed independently and then discussed collaboratively to identify strengths and weaknesses associated with GPT-4 qualitative analysis.
Results
Thirty-six survey responses and seven 1-hour interview transcripts were analyzed using GPT-4. The codebooks and themes generated by GPT-4 generally aligned with human-identified concepts. Challenges included failure to detect low frequency codes, difficulty constructing coherent code relationships, and a lack of nuance in theme descriptions and quote selection.
Conclusion
GPT-4 can support, though not replace, human-led qualitative analysis. A general understanding of qualitative research processes and the dataset is necessary for researchers to identify potential gaps, limitations, and redundancies in qualitative findings generated by GPT-4.}
}
@article{POHLMAN2025,
title = {The Use of Artificial Intelligence and Machine Learning in Thoracic Surgery},
journal = {Thoracic Surgery Clinics},
year = {2025},
issn = {1547-4127},
doi = {https://doi.org/10.1016/j.thorsurg.2025.07.006},
url = {https://www.sciencedirect.com/science/article/pii/S1547412725000489},
author = {Alexander Pohlman and Zaid M. Abdelsattar},
keywords = {Artificial intelligence, Machine learning, Thoracic surgery}
}
@article{OHAYA2025541,
title = {Artificial Intelligence and Deep Learning for Skin Image Analysis},
journal = {Dermatologic Clinics},
volume = {43},
number = {4},
pages = {541-552},
year = {2025},
note = {Artificial Intelligence in Dermatology},
issn = {0733-8635},
doi = {https://doi.org/10.1016/j.det.2025.05.004},
url = {https://www.sciencedirect.com/science/article/pii/S0733863525000439},
author = {Chikodi Ohaya and Ewoma Ogbaudu and Rachel Eunseo Choi and Justin Ko},
keywords = {Deep learning, Artificial intelligence, Neural networks, Melanoma}
}
@article{ARORA2025455,
title = {From data to decisions: Statistical tools and Artificial Intelligence in tuberculosis Operational Research},
journal = {Indian Journal of Tuberculosis},
volume = {72},
number = {4},
pages = {455-459},
year = {2025},
issn = {0019-5707},
doi = {https://doi.org/10.1016/j.ijtb.2025.09.001},
url = {https://www.sciencedirect.com/science/article/pii/S0019570725001921},
author = {V.K. Arora and Nishi Aggarwal and Sanjay Rajpal},
keywords = {Tuberculosis, Statistical tools, Operational research, Modeling, Artificial intelligence},
abstract = {Background
Tuberculosis (TB) remains a major public health challenge, especially in low- and middle-income countries. Operational Research (OR), supported by robust statistical methods, plays a critical role in optimizing TB control strategies.
Objective
This review highlights the statistical tools applied in TB Operational Research, their applications, and the emerging role of Artificial Intelligence (AI) in strengthening data-driven decision-making.
Methods
We examine classical statistical approaches alongside predictive modeling, cost-effectiveness analysis, and AI-based frameworks. Case examples from diverse settings illustrate their practical impact.
Findings
Statistical methods underpin surveillance, diagnosis, treatment evaluation, and policy modeling in TB programs. AI-driven techniques, such as machine learning and deep learning, are expanding the analytical landscape by enhancing prediction, identifying high-risk populations, and enabling real-time program monitoring.
Conclusion
Statistical tools from traditional inference to AI-modeling are essential for advancing TB control. Strengthening methodological rigor, reporting standards and interdisciplinary collaboration will be pivotal in harnessing data for effective TB elimination strategies.}
}
@article{REYESGIL2024109121,
title = {Venous thromboembolism in the era of machine learning and artificial intelligence in medicine},
journal = {Thrombosis Research},
volume = {242},
pages = {109121},
year = {2024},
issn = {0049-3848},
doi = {https://doi.org/10.1016/j.thromres.2024.109121},
url = {https://www.sciencedirect.com/science/article/pii/S0049384824002536},
author = {Morayma {Reyes Gil} and Joshua Pantanowitz and Hooman H. Rashidi},
keywords = {Venous thromboembolism, Artificial intelligence, Machine learning, Large language model (LLM), Deep vein thrombosis, Pulmonary embolism},
abstract = {In this review, we embark on a comprehensive exploration of venous thromboembolism (VTE) in the context of medical history and its current practice within medicine. We delve into the landscape of artificial intelligence (AI), exploring its present utility and envisioning its transformative roles within VTE management, from prevention to screening and beyond. Central to our discourse is a forward-looking perspective on the integration of AI within VTE in medicine, advocating for rigorous study design, robust validation processes, and meticulous statistical analysis to gauge the efficacy of AI applications. We further illuminate the potential of large language models and generative AI in revolutionizing VTE care, while acknowledging their inherent limitations and proposing innovative solutions to overcome challenges related to data availability and integrity, including the strategic use of synthetic data. The critical importance of navigating ethical, legal, and privacy concerns associated with AI is underscored, alongside the imperative for comprehensive governance and policy frameworks to regulate its deployment in VTE treatment. We conclude on a note of cautious optimism, where we highlight the significance of proactively addressing the myriad challenges that accompany the advent of AI in healthcare. Through diligent design, stringent validation, extensive education, and prudent regulation, we can harness AI's potential to significantly enhance our understanding and management of VTE. As we stand on the cusp of a new era, our commitment to these principles will be instrumental in ensuring that the promise of AI is fully realized within the realm of VTE care.}
}
@article{NUDELMAN2025,
title = {Artificial Intelligence to Detect Voice Disorders: An AI-Supported Systematic Review of Accuracy Outcomes},
journal = {Journal of Voice},
year = {2025},
issn = {0892-1997},
doi = {https://doi.org/10.1016/j.jvoice.2025.09.021},
url = {https://www.sciencedirect.com/science/article/pii/S0892199725003893},
author = {Charles J. Nudelman and Virginia Tardini and Pasquale Bottalico},
keywords = {Artificial intelligence, AI, Machine learning, Systematic review, Voice disorders},
abstract = {SUMMARY
Background
The objective of the present systematic review is to identify which artificial intelligence (AI) approaches have been used to successfully detect voice disorders. The review examines studies involving patients with non-neurological voice disorders and controls, where AI was applied to detect voice disorders. The primary outcome of interest is the accuracy of these AI models. Additionally, this review demonstrates how the procedures of conducting a systematic review can be supported by AI.
Methods
Studies were eligible for inclusion if they implemented an AI approach to detect non-neurological voice disorders from healthy voice samples. A comprehensive search was conducted using PubMed/MEDLINE, Science Direct, Web of Science, EBSCO, and Scopus databases. Risk of bias was assessed via the Quality Assessment Tool for Diagnostic Accuracy Studies. The occurrences of the most common AI techniques utilized in the literature are presented, and a summary of their abilities to accurately detect a voice disorder is reported.
Results
In total, 79 publications met the inclusion criteria. These studies included patient recordings from a variety of voice databases. The most common AI techniques implemented were Support Vector Machines (SVMs) (n = 28) and Convolutional Neural Networks (CNNs) (n = 22). The mean accuracy of the models in detecting voice disorders was 92% across all studies. Nine studies reported 100% accuracy, and 32 studies reported between 95% and 99%.
Discussion
Strengths of the evidence include high accuracies across diverse models and datasets. Limitations include a limited variety of datasets and a trend of hyperoptimization without sufficient external validation. Clinicians and researchers should recognize that while current AI models show promise, future studies should prioritize robust external validation and more representative datasets.}
}
@article{MOENS2025113559,
title = {Artificial intelligence as team member versus manual screening to conduct systematic reviews in medical sciences},
journal = {iScience},
volume = {28},
number = {10},
pages = {113559},
year = {2025},
issn = {2589-0042},
doi = {https://doi.org/10.1016/j.isci.2025.113559},
url = {https://www.sciencedirect.com/science/article/pii/S2589004225018206},
author = {Maarten Moens and Guy Nagels and Nicholas Wake and Lisa Goudman},
keywords = {Medical research, Artificial intelligence},
abstract = {Summary
Systematic reviews require substantial time and effort. This study compared the results of conducting reviews by human reviewers with those conducted with Artificial Intelligence (AI). We identified 11 AI tools that could assist in conducting a systematic review. None of the AI tools could retrieve all articles that were detected with a manual search strategy. We identified tools for deduplication but did not evaluate them. AI screening tools assist the human reviewer in presenting the most relevant article on top, which could reduce the number of articles that need to be screened on title and abstract, and on full text. There was a poor inter-rater reliability to evaluate the risk of bias between AI tools and the human reviewers. A summary table created by AI tools differs substantially from manually constructed summary tables. This study highlights the potential of AI tools to support systematic reviews, particularly during screening phases, but not to replace human reviews.}
}
@article{JAVAID202589,
title = {The impact of artificial intelligence on biomarker discovery},
journal = {Emerging Topics in Life Sciences},
volume = {8},
number = {2},
pages = {89-105},
year = {2025},
issn = {2397-8562},
doi = {https://doi.org/10.1042/ETLS20243003},
url = {https://www.sciencedirect.com/science/article/pii/S2397856225000047},
author = {Hira Javaid and Constantin Cezar Petrescu and Lisa J. Schmunk and Jack M. Monahan and Paul O'Reilly and Manik Garg and Leona McGirr and Mahmoud T. Khasawneh and Mustafa {Al Lail} and Deepak Ganta and Thomas M. Stubbs and Benjamin B. Sun and Dimitrios Vitsios and Daniel E. Martin-Herranz},
keywords = {biomarkers, diagnostics, biomarker discovery, artificial intelligence, multi-omics, electronic health records, multi-modal data},
abstract = {Artificial intelligence (AI) is transforming many fields, including healthcare and medicine. In biomarker discovery, AI algorithms have had a profound impact, thanks to their ability to derive insights from complex high-dimensional datasets and integrate multi-modal datatypes (such as omics, electronic health records, imaging or sensor and wearable data). However, despite the proliferation of AI-powered biomarkers, significant hurdles still remain in translating them to the clinic and driving adoption, including lack of population diversity, difficulties accessing harmonised data, costly and time-consuming clinical studies, evolving AI regulatory frameworks and absence of scalable diagnostic infrastructure. Here, we provide an overview of the AI toolkit available for biomarker discovery, and we discuss exciting examples of AI-powered biomarkers across therapeutic areas. Finally, we address the challenges ahead of us to ensure that these technologies reach patients and users globally and unlock a new era of fast innovation for precision medicine.}
}
@article{PENG2026103183,
title = {Foundations of Artificial Intelligence in Hepatology: What a Clinician Needs to Know},
journal = {Journal of Clinical and Experimental Hepatology},
volume = {16},
number = {1},
pages = {103183},
year = {2026},
issn = {0973-6883},
doi = {https://doi.org/10.1016/j.jceh.2025.103183},
url = {https://www.sciencedirect.com/science/article/pii/S0973688325006838},
author = {Nana Peng and Sherlot J. Song and Vicki Wing-Ki Hui and Jimmy Che-To Lai and Grace Lai-Hung Wong and Vincent Wai-Sun Wong and Terry Cheuk-Fung Yip},
keywords = {artificial intelligence, electronic health records, hepatocellular carcinoma, imaging, longitudinal data, TRIPOD+AI, PROBAST+AI, machine learning, deep learning},
abstract = {This review focuses on foundational knowledge about artificial intelligence (AI) in hepatology, exploring how AI, including machine learning and deep learning, leverages large-scale clinical data to transform the diagnosis, risk assessment, prognostication, and management of liver diseases. Online resources are described to offer fundamental AI knowledge and essential technical skills and to facilitate clinician participation across the entire AI lifecycle, ensuring they contribute not only as end users but also in development and deployment. Unlike traditional statistical approaches that prioritize interpretable parameters and clinical insight, AI focuses on maximizing predictive accuracy by identifying complex, often non-linear patterns using high-dimensional data, albeit often at the cost of model interpretability. AI is demonstrating clinical utility in liver histopathology and radiological imaging, significantly improving detection accuracy for cirrhosis, clinically significant portal hypertension, and hepatocellular carcinoma. Beyond diagnostics, AI-driven prediction models are emerging to provide personalized risk stratification for the development of liver-related complications and treatment guidance, based on complex data including longitudinal laboratory results, comorbidities, and co-medication use to monitor disease progression and therapy response. The field is rapidly expanding into novel areas such as analyzing patient-reported outcomes, genomic data, and real-time liver function monitoring, offering deeper mechanistic insights alongside clinical tools. Despite the potential to revolutionize hepatology practice and research, successful integration into routine care faces challenges. These include seamless workflow integration with existing electronic health records, establishing clear liability frameworks, and guaranteeing protection of patient privacy. Addressing these hurdles requires collaborative efforts from clinicians, researchers, and regulators to develop best practices and governance. Understanding the transformative capabilities, current applications, emerging frontiers, and essential implementation considerations is crucial for clinicians navigating the evolving AI landscape and responsibly utilizing its power for improved patient outcomes.}
}
@article{BENTZEN2025103798,
title = {Artificial Intelligence in Health Care: A Rallying Cry for Critical Clinical Research and Ethical Thinking},
journal = {Clinical Oncology},
volume = {41},
pages = {103798},
year = {2025},
issn = {0936-6555},
doi = {https://doi.org/10.1016/j.clon.2025.103798},
url = {https://www.sciencedirect.com/science/article/pii/S0936655525000536},
author = {S.M. Bentzen},
abstract = {Artificial intelligence (AI) will impact a large proportion of jobs in the short to medium term, especially in the developed countries. The consequences will be felt across many sectors including health care, a critical sector for implementation of AI tools because glitches in algorithms or biases in training datasets may lead to suboptimal treatment that may negatively affect the health of an individual. The stakes are obviously higher in case of potentially life-threatening diseases such as cancer and therapies with a potential for causing severe or even fatal adverse events. Over the last two decades, much of the research on AI in health care has focussed on diagnostic radiology and digital pathology, but a solid body of research is emerging on AI tools in the radiation oncology workflow. Many of these applications are relatively uncontroversial, although there is still a lack of evidence regarding effectiveness rather than efficiency, and—the ultimate bar—evidence of clinical utility. Proponents of AI will argue that these algorithms should be implemented with robust human supervision. One challenge here is the deskilling effect associated with new technologies. We will become increasingly dependent on the AI tools over time, and we will become less capable of assessing the quality of the AI output. Much of this research appears almost old-fashioned in view of the rapid advances in Generative artificial intelligence (GenAI). GenAI can draw from multiple types of data and produce output that is personalised and appears relevant in the given context. Especially the rapid progress in large language models (LLMs) has opened a wide field of potential applications that were out of bounds just a few years ago. One LLM, Generative Pre-trained Transformer 4 (GPT-4), has been made widely accessible to end-users as ChatGPT-4, which passed a rigorous Turing test in a recent study. In this viewpoint, I argue for the necessity of independent academic research to establish evidence-based applications of AI in medicine. Algorithmic medicine is an intervention similar to a new drug or a new medical device. We should be especially concerned about under-represented minorities and rare/atypical clinical cases that may drown in the petabyte-sized training sets. A huge educational push is needed to ensure that the end-users of AI in health care understand the strengths and weaknesses of algorithmic medicine. Finally, we need to address the ethical boundaries for where and when GenAI can replace humans in the relation between patients and healthcare providers.}
}
@article{NG2026214535,
title = {Advancing biomaterial research with artificial intelligence},
journal = {Biomaterials Advances},
volume = {180},
pages = {214535},
year = {2026},
issn = {2772-9508},
doi = {https://doi.org/10.1016/j.bioadv.2025.214535},
url = {https://www.sciencedirect.com/science/article/pii/S2772950825003620},
author = {Jun Chen Ng and Pauline Shan Qing Yeoh and Farina Muhamad and XiaoXu Zhao and ShuiLin Wu and Xiang Wu and Khin Wee Lai},
keywords = {Artificial intelligence, Ceramic biomaterial, Composite biomaterial, Explainable artificial intelligence, Machine learning, Metallic biomaterial, Polymer biomaterial},
abstract = {Biomaterials play a crucial role in the healthcare sector, particularly in applications involving implantation into the human body, where preventing adverse effects is of paramount importance. Artificial intelligence (AI) has become an essential tool in biomaterial research to accelerate the development and innovations of biomaterials across different applications while addressing challenges in fabrication and characterization processes that were traditionally time-consuming, labor-intensive, and costly. By leveraging AI, researchers can enhance the performance, efficiency, and scalability of biomaterial development. This review provides a detailed examination of the applications of Machine Learning and Deep Learning across various biomaterial categories, including polymeric, metallic, ceramic, and composite biomaterials. It also explores fundamental AI methodologies, including supervised, unsupervised, semi-supervised and reinforcement learning, highlighting their roles in tackling forward and inverse design problems. Beyond the benefits, the review discusses key limitations of AI, such as model interpretability, data quality, and overfitting, along with emerging solutions like Explainable Artificial Intelligence, integrating methods such as Sharpley Additive exPlanations (SHAP) and Local Interpretable Model-Agnostic Explanations (LIME) to address these challenges. Together, these insights underscore the potential and evolving landscape of AI in advancing biomaterial research.}
}
@article{HACHOUMI2025130,
title = {Enhancing teaching and learning in health sciences education through the integration of Bloom's taxonomy and artificial intelligence},
journal = {Informatics and Health},
volume = {2},
number = {2},
pages = {130-136},
year = {2025},
issn = {2949-9534},
doi = {https://doi.org/10.1016/j.infoh.2025.05.002},
url = {https://www.sciencedirect.com/science/article/pii/S2949953425000177},
author = {Nadia Hachoumi and Mohamed Eddabbah and Ahmed Rhassane {El adib}},
keywords = {Health sciences education, Bloom's taxonomy, Artificial Intelligence (AI), Teaching-learning process},
abstract = {The purpose of this research is to integrate artificial intelligence (AI) in Bloom's Taxonomy with the aim of improving critical thinking in health science education. Innovative teaching approaches will be employed for the broad spectrum of students; integrating AI across all levels of Bloom's processes-from production, comprehension, application, clinical case scenario harbingers, dynamic information delivery, and interactive teaching. Mixed-method design comprising both the quantitative (survey based analysis) and the qualitative (far-reaching theoretical framework and case studies review) methodologies was used in the current study. A structured survey was administered to collect data on the AI pattern, efficacy, and frequency of usage among 181 health sciences students. Case studies in practice were also used to serve as evidence of AI's role in medical training: from clinician-initiated simulations to AI-powered assessment tools. The data analysis approaches included descriptive statistics, correlation heat maps, and comparative analysis between AI-assisted teaching and standard teaching. It is concluded that such engagement of the use of AI makes for engagement and deep learning but requires strong institution-wide foundations and ethical frameworks, and measures of growth against institutional preparedness and of having a very rich ethical framework for risk management are still lacking. Hence, the study recommends that balancing technology with ethics would be needed in AI integration and proposes future studies to address gaps in teacher training, institution preparedness, and ethical consideration.}
}
@article{HOWARD2025,
title = {Artificial intelligence and infectious diseases: tackling antimicrobial resistance, from personalised care to antibiotic discovery},
journal = {The Lancet Infectious Diseases},
year = {2025},
issn = {1473-3099},
doi = {https://doi.org/10.1016/S1473-3099(25)00313-5},
url = {https://www.sciencedirect.com/science/article/pii/S1473309925003135},
author = {Alex Howard and Nada Reza and Peter L Green and Mo Yin and Erin Duffy and Henry C Mwandumba and Alessandro Gerada and William Hope},
abstract = {Summary
Antimicrobial resistance (AMR) is an intractable problem that has the potential to significantly limit advances in human health. Recently, the UN General Assembly (UNGA) High-Level Statement on AMR defined targets for addressing the impact of resistance on human, animal, and environmental health. For human health, the discovery and development of new antibiotics, antimicrobial stewardship programmes, antimicrobial surveillance, and infection control and prevention are all key areas. Artificial intelligence (AI) is ideally placed to help achieve the UNGA targets via its role in revealing patterns in data that are clinically indiscernible, and using that information to build clinical decision support systems. However, significant barriers remain in terms of necessary infrastructure, know-how, and the implementation of AI approaches. In this Series paper, we consider the potential applications of AI in combatting the AMR problem through drug discovery and development, antimicrobial stewardship, diagnostics, and surveillance, and their use in public health. We then discuss the technical, infrastructure, regulatory, ethical, and policy challenges that affect these domains.}
}
@article{FIGUEIREDO2025593,
title = {Applications of artificial intelligence in emotion recognition in pediatrics health care: Scoping review},
journal = {Journal of Pediatric Nursing},
volume = {85},
pages = {593-606},
year = {2025},
issn = {0882-5963},
doi = {https://doi.org/10.1016/j.pedn.2025.09.017},
url = {https://www.sciencedirect.com/science/article/pii/S0882596325003318},
author = {Ana Rita Figueiredo and António Pereira and Francisca Frias and Luíza Moura Dias Rodrigues and Paula Diogo},
keywords = {Artificial intelligence, Emotion recognition, Pediatrics, Health, Clinical applications},
abstract = {Background
The use of artificial intelligence in healthcare is growing rapidly. In pediatrics, artificial intelligence technologies have been applied to early diagnosis, treatment, increased precision in care, and recognition of emotions. This will provide new opportunities to overcome the difficulties that may have developed in children's ability to express emotions due to cognitive, physical, or emotional reasons.
Aim
To review the existing literature on the application of artificial intelligence to emotion recognition in children and adolescents, and to evaluate its applicability in clinical settings.
Methods
A scoping review was conducted using the Joanna Briggs Institute methodology. Searches were conducted in PubMed, Scopus, CINAHL Ultimate, MEDLINE Ultimate, IEEE Xplore and Wiley Online Library. A total of 136 records were initially identified, and 23 studies met the inclusion criteria. Data were analyzed and summarized narratively.
Results
The studies varied in methodology and scope, and included the use of artificial intelligence for facial, voice, and drawing-based emotion recognition, with applications in various domains. Artificial intelligence-based tools showed promising levels of accuracy, particularly in improving emotion identification, supporting early diagnosis, and informing clinical decision-making.
Conclusion
Artificial intelligence has the potential to transform pediatric healthcare by improving the identification and management of emotional states, particularly in vulnerable populations. Despite challenges, integrating technology into clinical practice is a promising strategy to promote personalized and emotional care.
Implications
By recognizing and responding to emotional needs, artificial intelligence in pediatric nursing practice can enhance the personalization of care and create therapeutic environments that are emotionally sensitive, promoting the humanization and effectiveness of interventions. Scoping review registration: doi:10.17605/OSF.IO/NXMH7.}
}
@article{TORTORA2025,
title = {Artificial Intelligence and Radiogenomics for Pediatric CNS Neoplasms},
journal = {Neuroimaging Clinics of North America},
year = {2025},
issn = {1052-5149},
doi = {https://doi.org/10.1016/j.nic.2025.09.003},
url = {https://www.sciencedirect.com/science/article/pii/S1052514925008354},
author = {Mario Tortora and Aline Ayres and Suely Fazio Ferraciolli},
keywords = {CNS5, Molecular alterations, Radiogenomics, Deep learning, Pediatric neuro-oncology}
}
@article{ZHANG2025100083,
title = {Material intelligence by the convergence of artificial intelligence and robotic platforms},
journal = {Nexus},
volume = {2},
number = {3},
pages = {100083},
year = {2025},
issn = {2950-1601},
doi = {https://doi.org/10.1016/j.ynexs.2025.100083},
url = {https://www.sciencedirect.com/science/article/pii/S2950160125000300},
author = {Xinyu Zhang and Zijian Chen and Feibei Chen and Billy Fanady and Boyuan Wang and Zongming Ni and Shumin Zhou and Junzhi Ye and Guanhua Chen and Jie Liu and Robert L.Z. Hoye and Xiaobo Li and Samantha Y. Chong and Wei Feng and Chi-yung Chung and Ching-chuen Chan and Linjiang Chen and Han Hao and Alán Aspuru-Guzik and Jun Jiang and Haitao Zhao},
keywords = {Material intelligence, artificial intelligence, robotic platforms, rational design, controllable synthesis},
abstract = {The emerging interdisciplinary research of material intelligence through the convergence of artificial intelligence, robotic platforms, and material informatics has revolutionized the field of chemistry and material science. This shift enables precision and intelligence in materials research to avoid the problems of trial-and-error synthesis and labor-intensive characterization. The aim of this review is to present a comprehensive methodology that unifies three interlinked domains: data-guided rational design (“reading”), automation-enabled controllable synthesis (“doing”), and autonomy-facilitated inverse design (“thinking”). We critically examine how the integration of materials common discipline (i.e., rational design, controllable synthesis, inverse design) with interdisciplinary research (i.e., data, automation, autonomy), with an emphasis on cutting-edge research of artificial intelligence and robotics, collectively shape a closed-loop next paradigm of material intelligence, revolutionizing experimental, theoretical, software-driven and data-driven paradigms. Ultimately, this paper discusses how these insights drive the new paradigm of materials research, which seamlessly combines database, robotics, artificial intelligence, and even embodied intelligence to empower the full potential of material intelligence.}
}
@article{FEWELLA2025103747,
title = {A developed framework for utilizing holograms and artificial intelligence in customized furniture design},
journal = {Ain Shams Engineering Journal},
volume = {16},
number = {12},
pages = {103747},
year = {2025},
issn = {2090-4479},
doi = {https://doi.org/10.1016/j.asej.2025.103747},
url = {https://www.sciencedirect.com/science/article/pii/S2090447925004885},
author = {Lina Nageb Fewella},
keywords = {Visual information design, Co-creative artificial intelligence, Midjourney, Virtual reality, Mixed reality, Industry 4.0},
abstract = {This study offers a framework integrating artificial intelligence, specifically the Midjourney text-to-image platform, with holographic display technologies to enhance and accelerate customized furniture design. The suggested approach facilitates the rapid creation of innovative ideas by designers utilizing AI, presenting them as realistic 3D visualizations via accessible hologram devices. This enables clients to interactively assess and refine designs before production. The experimental application of the framework produced a notable decrease in design development time, alongside enhanced client engagement and satisfaction. The research identifies limitations in the precision of AI-generated models compared to traditional 3D modeling, emphasizing the necessity for designer intervention before manufacturing. The study advocates for developing prompt engineering skills and a more profound integration of digital tools to enhance the co-creative process between designers and clients in the furniture industry.}
}
@article{RAHIMI2025100420,
title = {Developing and validating the scale of language teachers’ design thinking competency in artificial intelligence language teaching (LTDTAILT)},
journal = {Computers and Education: Artificial Intelligence},
volume = {8},
pages = {100420},
year = {2025},
issn = {2666-920X},
doi = {https://doi.org/10.1016/j.caeai.2025.100420},
url = {https://www.sciencedirect.com/science/article/pii/S2666920X25000608},
author = {Amir Reza Rahimi},
keywords = {21st-century digital skills, 21st-century digital competence, Design thinking skill, Artificial intelligence in education, Artificial intelligence in language teaching},
abstract = {Design thinking (DT) is one of the critical 21st-century digital skills that allows individuals to solve real-world problems by redesigning their problem procedure to achieve the desired outcome. Nowadays, cultivating DT within any educational program is becoming increasingly important for teachers since Artificial Intelligence (AI) and chatbots are available to all students. However, teachers themselves need to possess DT competency to effectively cultivate it in their students, particularly in humanistic fields like applied linguistics, Computer Assisted Language Learning (CALL), and Artificial Intelligence Language Teaching (AILT). For this reason, the researcher in the current study developed a new conceptual framework and a scale specifically designed for the field of AILT, known as Language Teachers’ Design Thinking Competence in Artificial Intelligence Language Teaching (LTDTAILT). The researcher generated the items both deductively and inductively, evaluating their face and content validity through the Delphi methodology and a cognitive review. Having piloted the scale, the researcher distributed it to 273 in-service English as a Foreign Language (EFL) teachers in Spain who had experience teaching languages using AI. The validation process, which included the Rasch-Andrich rating scale model (RSM), exploratory factor analysis (EFA), and confirmatory factor analysis (CFA), confirmed that the theoretical framework and its scale were well-aligned and validated to study context and the field, comprising five components: empathy, define, ideate, prototype, and test, with a total of 17 items. Consequently, the researcher established a new theoretical framework applicable to the fields of artificial intelligence in general and specifically to CALL and AILT. Furthermore, this framework provides a pathway for English teachers and researchers to stay current with developments in other fields that integrate 21st-century digital skills and competencies through the application of artificial intelligence.}
}
@article{ALAHWANY20251659,
title = {Leveraging artificial intelligence for risk stratification of inherited cardiomyopathies in under-resourced settings},
journal = {Heart Rhythm O2},
volume = {6},
number = {10},
pages = {1659-1667},
year = {2025},
issn = {2666-5018},
doi = {https://doi.org/10.1016/j.hroo.2025.07.020},
url = {https://www.sciencedirect.com/science/article/pii/S2666501825002855},
author = {Salah H. Alahwany and Omnia Kamel and Amir Abdelghany and Ahmed Ammar},
keywords = {Artificial intelligence, Deep learning, Machine learning, Inherited cardiomyopathy, Risk stratification, Sudden cardiac death, Ventricular arrhythmias, Under-resourced settings, Developing countries},
abstract = {Inherited cardiomyopathies are a significant global cause of sudden cardiac death, particularly among younger individuals and those in under-resourced regions. Despite progress in diagnostics and therapeutics, screening and risk stratification remain challenging due to genetic complexity, variable clinical presentation, and the interpretive limitations of current electrophysiological and imaging tools. Artificial intelligence (AI)—particularly machine learning, deep learning, and natural language processing offers transformative potential by enabling large-scale analysis of complex data and detecting subtle disease patterns which could potentially improve diagnostic accuracy and cost-effectiveness, particularly in low-resource environments. This review evaluates the limitations of existing risk models, synthesizes disease-specific AI applications within a unified framework, and explores the role of AI in advancing personalized care and risk prediction in underserved populations.}
}

@article{GROZA2025100057,
title = {Realising the potential impact of artificial intelligence for rare diseases – A framework},
journal = {Rare},
volume = {3},
pages = {100057},
year = {2025},
issn = {2950-0087},
doi = {https://doi.org/10.1016/j.rare.2024.100057},
url = {https://www.sciencedirect.com/science/article/pii/S2950008724000401},
author = {Tudor Groza and Chun-Hung Chan and David A. Pearce and Gareth Baynam},
keywords = {Rare diseases, Patient journey, Generative artificial intelligence, Diagnosis, Care coordination},
abstract = {Rare diseases (RD) are conditions affecting fewer than 1 in 2000 persons, with over 7000 largely genetic RDs affecting 3.5 %-5.9 % of the global population, or approximately 262.9–446.2 million people. The substantial healthcare burden and costs, such as the $1 trillion annual expense in the USA, highlight the urgent need for improved RD management. The International Rare Diseases Research Consortium (IRDiRC) addresses this need through global collaboration, aiming for timely and accurate diagnosis, development of 1000 new therapies, and methodologies to measure impact by 2027. IRDiRC's initiatives include biannual meetings and workshops, like the AI-focused workshop in October 2023. This identified AI as crucial for advancing RD research and proposed a Framework for AI to enhance the RD patient journey by addressing efficiency and quality of life through modular solutions mapped to critical stages. The Framework integrates diverse data sources to improve diagnosis, treatment, and impact assessment, reflecting a holistic, cross-sector approach. By guiding multi-stakeholder efforts, the Framework aims to harness AI’s potential to significantly improve rare disease care.}
}
@article{VERAAMARO2025107821,
title = {Towards accessible website design through artificial intelligence: A systematic literature review},
journal = {Information and Software Technology},
volume = {186},
pages = {107821},
year = {2025},
issn = {0950-5849},
doi = {https://doi.org/10.1016/j.infsof.2025.107821},
url = {https://www.sciencedirect.com/science/article/pii/S0950584925001600},
author = {Guillermo Vera-Amaro and José Rafael Rojano-Cáceres},
keywords = {Web accessibility, Systematic literature review, Artificial intelligence, Wcag, Machine learning, Large language models},
abstract = {Context:
Web accessibility ensures that individuals with disabilities can access, navigate, and interact with online content effectively. Despite the availability of the Web Content Accessibility Guidelines (WCAG), significant barriers persist, largely due to the complexity of their implementation. Artificial intelligence (AI), particularly machine learning models, has emerged as a promising avenue to address these challenges, offering solutions for evaluation, correction, and content generation.
Objective:
This study aims to systematically review the intersection of web accessibility and AI by evaluating how AI-based methods enhance compliance with accessibility standards over the period 2019–2025, assessing their efficacy and alignment with WCAG principles.
Methods:
A systematic literature review (SLR) was conducted in three phases: planning, execution, and reporting. Research questions were formulated guiding the selection of search terms and strategies. A systematic search process was implemented, complemented by a snowballing technique to ensure comprehensive coverage of relevant studies. The quality of selected studies was rigorously assessed using predefined criteria, and data extraction was carried out following established best practices. The analysis combined narrative synthesis for qualitative insights and bibliometric techniques for quantitative evaluation.
Results:
From 277 studies, 31 were identified as relevant, highlighting AI’s primary contributions to generating alternative text for images, automating compliance assessments, providing correction suggestions, and designing alternative interfaces to enhance accessibility. Advances in large language models (LLMs) further demonstrate their potential for facilitating the creation of accessible content.
Conclusions:
AI presents significant potential to improve web accessibility by streamlining evaluation processes and supporting the creation of accessible content. However, further research is needed to address limitations such as inconsistent compliance and the lack of focus on non-visual disabilities. These findings underline the importance of leveraging AI to facilitate inclusive web design practices while ensuring adherence to accessibility standards.}
}
@article{GENOVESE2025103519,
title = {The Current Landscape of Artificial Intelligence in Plastic Surgery Education and Training: A Systematic Review},
journal = {Journal of Surgical Education},
volume = {82},
number = {8},
pages = {103519},
year = {2025},
issn = {1931-7204},
doi = {https://doi.org/10.1016/j.jsurg.2025.103519},
url = {https://www.sciencedirect.com/science/article/pii/S1931720425000996},
author = {Ariana Genovese and Sahar Borna and Cesar A. Gomez-Cabello and Syed Ali Haider and Srinivasagam Prabha and Maissa Trabilsy and Antonio Jorge Forte},
keywords = {plastic surgery, AI (artificial intelligence), education, residency, Medical Knowledge (MK)},
abstract = {Objective
Artificial intelligence (AI) shows promise in surgery, but its role in plastic surgery education remains underexplored. This review evaluates the current landscape of AI in plastic surgery education.
Design
A systematic search was conducted on August 11, 2024, across PubMed, CINAHL, IEEE, Scopus, Web of Science, and Google Scholar using terms related to AI, plastic surgery, and education. Original research articles focusing on AI in plastic surgery education were included, excluding correspondence, reviews, book chapters, theses, corrections, and non–peer-reviewed or non-English articles. Two investigators independently screened studies and synthesized data. ROBINS-I was used to assess bias.
Results
Fifteen studies were included, with 13 evaluating large language models (LLMs) such as ChatGPT, Microsoft Bing, and Google Bard. ChatGPT-4 outperformed other models on In-Service Examinations (average score of 72.7%) and demonstrated potential as a teaching assistant in plastic surgery education. AI-generated personal statements were comparable to human-written ones. However, ChatGPT showed inaccuracies in generating surgical protocols. ChatGPT demonstrated its ability to provide qualitative predictions, forecasting survey results that indicated limited current use of AI in plastic surgery education but support for further AI research. a study combined ChatGPT with DALL-E 2, a generative model, to create acceptable educational images. Machine learning was used in 1 study for evaluating surgical skill and providing real-time feedback during liposuction. Nine studies had low risk of bias, while 6 had moderate risk.
Conclusions
AI demonstrates potential as an educational tool in plastic surgery. However, limitations of evidence, such as AI model uncertainties, introduce ambiguity. While AI cannot replicate the expertise of seasoned surgeons, it shows promise for foundational learning and skill assessment. Developing authenticity guidelines and enhancing AI capabilities are essential for its effective, ethical integration into plastic surgery education.}
}
@article{MEDEIROS2025491,
title = {Artificial Intelligence in Regional Anesthesia and Pain Management},
journal = {Anesthesiology Clinics},
volume = {43},
number = {3},
pages = {491-505},
year = {2025},
note = {Artificial Intelligence in Anesthesiology},
issn = {1932-2275},
doi = {https://doi.org/10.1016/j.anclin.2025.05.004},
url = {https://www.sciencedirect.com/science/article/pii/S1932227525000345},
author = {Heitor J.S. Medeiros and Ali Dabbagh and Kamen Vlassakov and A. Sassan Sabouri},
keywords = {Artificial intelligence, Regional anesthesia, Machine learning, Ultrasound, Pain management, Predictive analytics, Education, Automation}
}
@article{NALBANT2025179,
title = {A bibliometric approach to the evolution of artificial intelligence in digital marketing},
journal = {International Marketing Review},
volume = {42},
number = {2},
pages = {179-218},
year = {2025},
issn = {0265-1335},
doi = {https://doi.org/10.1108/IMR-04-2024-0132},
url = {https://www.sciencedirect.com/science/article/pii/S026513352500005X},
author = {Kemal Gokhan Nalbant and Sevgi Aydin},
keywords = {Artificial intelligence, Digital marketing, Bibliometric analysis, Web of science, VOSviewer},
abstract = {Purpose
This research aims to examine the dynamic relationship between digital marketing and AI. This study used bibliometric analysis to investigate the significance of artificial intelligence in digital marketing research. The study was conducted using the WOS database, which includes word cloud analysis, keyword analysis, citation analysis, and publication analysis.
Design/methodology/approach
The present inquiry utilized the Web of Science database to gather scholarly publications that were published between 2000 and 2023. A search was performed using the Boolean operator “AND” to retrieve pertinent publications that contain both the terms “artificial intelligence” and “digital marketing” in the first query. A total of 96 publications were found during the search. The search terms were expanded, and the content analysis was enhanced to include studies from 1993 to 2023, resulting in 521 studies for in-depth analysis in the second query. The acquired papers were subjected to bibliometric analysis using VOSviewer software (version 1.6.20).
Findings
The phrase “digital marketing” had the highest frequency, with a cumulative link strength of 94. This keyword exhibited a strong association with the phrase “artificial intelligence”. The WOS database shows a steady increase in publications on digital marketing and AI since 2017 for the first query. In 2017, there were about two publications, which grew to around 26 by 2021. For the second query, the number of publications on digital marketing and AI also increased steadily. In 1993, there was one publication, rising to about 102 by 2022.
Originality/value
The study conducts a comprehensive bibliometric analysis by examining publications that were released in the Web of Science database from 2000 to 2023 for the first query and from 1993 to 2023 for the second query. This research analyzes the progress and current status of corporate management and marketing techniques during the past twenty-four years. In addition, this approach enhances the originality of the second inquiry by providing a comprehensive analysis of studies spanning nearly 3 decades, offering unique insights into the evolution of the field. The research centers on the impact that AI has exerted on these sectors. Moreover, the results of this study emphasize the significance of the increasing number of scientific studies that intersect AI and digital marketing.}
}
@article{MCCARTHY2025100847,
title = {A Practical Guide to Evaluating Artificial Intelligence Imaging Models in Scientific Literature},
journal = {Ophthalmology Science},
volume = {5},
number = {6},
pages = {100847},
year = {2025},
issn = {2666-9145},
doi = {https://doi.org/10.1016/j.xops.2025.100847},
url = {https://www.sciencedirect.com/science/article/pii/S2666914525001459},
author = {Angela McCarthy and Ives Valenzuela and Royce W.S. Chen and Lora R. {Dagi Glass} and Kaveri Thakoor},
keywords = {Artificial intelligence, Glaucoma detection, Machine learning, Ophthalmology},
abstract = {Objective
Recent advances in artificial intelligence (AI) are revolutionizing ophthalmology by enhancing diagnostic accuracy, treatment planning, and patient management. However, a significant gap remains in practical guidance for ophthalmologists who lack AI expertise to effectively analyze these technologies and assess their readiness for integration into clinical practice. This paper aims to bridge this gap by demystifying AI model design and providing practical recommendations for evaluating AI imaging models in research publications.
Design
Educational review: synthesizing key considerations for evaluating AI papers in ophthalmology.
Participants
This paper draws on insights from an interdisciplinary team of ophthalmologists and AI experts with experience in developing and evaluating AI models for clinical applications.
Methods
A structured framework was developed based on expert discussions and a review of key methodological considerations in AI research.
Main Outcome Measures
A stepwise approach to evaluating AI models in ophthalmology, providing clinicians with practical strategies for assessing AI research.
Results
This guide offers broad recommendations applicable across ophthalmology and medicine.
Conclusions
As the landscape of health care continues to evolve, proactive engagement with AI will empower clinicians to lead the way in innovation while concurrently prioritizing patient safety and quality of care.
Financial Disclosure(s)
Proprietary or commercial disclosure may be found in the Footnotes and Disclosures at the end of this article.}
}
@incollection{ELANGO2025,
title = {Delineating artificial intelligence and its engrossing potentials for automated software developments},
series = {Advances in Computers},
publisher = {Elsevier},
year = {2025},
issn = {0065-2458},
doi = {https://doi.org/10.1016/bs.adcom.2025.06.015},
url = {https://www.sciencedirect.com/science/article/pii/S0065245825001068},
author = {Elakkiya Elango and Sundaravadivazhagan Balasubramanian and Gnanasankaran Natarajan},
keywords = {Artificial intelligence, Automated software development, Machine learning, Code generation, AI-driven debugging, Software test automation, Predictive analytics},
abstract = {Artificial Intelligence (AI) is revolutionizing software development, which optimizes the code production, increases productivity, and automatic complex operations. This study checks how AI can revolutionize software development by automatic by automatic AI code synthesis, debugging functions, testing, and signs. Software engineering machine is becoming more wisely automatic for AI-operated models such as learning and deep learning, which reduces human labor by increasing accurate and dependence. Predictive Analytics, Automatic Refactoring, and generative models are examples of the AI-powered tools that are changing traditional growth processes. AI’s ability to inspire innovation and effectiveness in the software sector has been exposed in this letter, which also underlines its abilities, difficulties and possibilities for automated software development.}
}
@article{MARABELLI2025101921,
title = {Artificial intelligence and the environment: ethical challenges and strategic opportunities for organizations},
journal = {The Journal of Strategic Information Systems},
volume = {34},
number = {3},
pages = {101921},
year = {2025},
issn = {0963-8687},
doi = {https://doi.org/10.1016/j.jsis.2025.101921},
url = {https://www.sciencedirect.com/science/article/pii/S0963868725000368},
author = {Marco Marabelli and Robert M. Davison},
keywords = {Artificial intelligence, GAI and AI strategizing, Global warming, Climate changes, Ethics, Global South, Social justice},
abstract = {In this viewpoint article, our goal is to raise awareness and spark debate in the Information Systems (IS) community regarding a prominent concern that has important strategic and ethical implications: the environmental impact of the increasing use of generative artificial intelligence (GAI). We examine several specific issues, beginning with GAI’s heavy consumption of natural resources and electricity. We then move to assessing how the rich and the Global North gain via GAI, while the poor and the Global South must deal with its adverse effects. We then move to assessing GAI’s impact on underrepresented communities and countries in the Global South; while GAI contributes to global warming, this affects people unevenly, because it is mostly rich people and the Global North that make intensive use of these technologies. After suggesting that more local and global laws are needed to regulate the sustainable use of AI, we report on how organizations can perform AI strategizing, for instance to control emissions in smart cities and improve weather forecasting. We conclude with a research agenda that aims to encourage IS scholars to focus on the environmental impact of AI, its ethical implications for organizations, and how GAI can be used strategically to benefit all.}
}
@article{MURAD2025,
title = {The Current State of Artificial Intelligence for Benign Prostatic Hyperplasia},
journal = {European Urology Focus},
year = {2025},
issn = {2405-4569},
doi = {https://doi.org/10.1016/j.euf.2025.07.004},
url = {https://www.sciencedirect.com/science/article/pii/S2405456925002081},
author = {Liam Murad and Ethan Layne and Conner Ganjavi and Inderbir Gill and Mihir Desai and Kevin C. Zorn and Giovanni E. Cacciamani},
keywords = {Artificial intelligence, Benign prostatic hyperplasia, Lower urinary tract symptoms, Prostate cancer, Machine learning},
abstract = {We review recent literature on the use of artificial intelligence (AI) for benign prostate hyperplasia (BPH). Many researchers have explored application of AI-based technologies for diagnosis and management of disease, prediction of treatment responses, and optimization of surgery and workflows. The latest research in urology is replete with AI-focused studies. However, AI applications in BPH have not been well established. Although many researchers have started to touch on key areas of interest, further research is necessary to fully elucidate the potential benefits of AI for patients with BPH. The development and implementation of standardized guidelines for model reporting and external validation are essential prerequisites for widespread adoption of AI within urology and across medicine in general.
Patient summary
This mini review looks at how artificial intelligence AI) may help doctors in treating men with a large prostate gland. AI tools may help in picking treatments, improving surgery, and helping doctors to work faster, but not enough is known yet. More studies are needed before these tools can be routinely used to help patients.}
}
@article{ROSEN2025667,
title = {How Artificial Intelligence, Virtual Reality, and Other Digital Technologies Are Changing the Field of Pediatric Neurogastroenterology},
journal = {Gastroenterology Clinics of North America},
volume = {54},
number = {3},
pages = {667-679},
year = {2025},
note = {Present and Future of Pediatric Neurogastroenterology and Motility},
issn = {0889-8553},
doi = {https://doi.org/10.1016/j.gtc.2025.01.001},
url = {https://www.sciencedirect.com/science/article/pii/S0889855325000019},
author = {John M. Rosen},
keywords = {Artificial intelligence, Neurogastroenterology, Pediatric gastroenterology, Virtual reality}
}
@article{MISHRA202589,
title = {Leveraging Generative AI for Drug Safety and Pharmacovigilance},
journal = {Current Reviews in Clinical and Experimental Pharmacology},
volume = {20},
number = {2},
pages = {89-97},
year = {2025},
issn = {2772-4328},
doi = {https://doi.org/10.2174/0127724328311400240823062829},
url = {https://www.sciencedirect.com/science/article/pii/S2772432825000121},
author = {Hara Prasad Mishra and Rachna Gupta},
keywords = {Generative AI, Chat -GPT, pharmacovigilance, drug safety, patient safety, artificial intelligence, machine learning},
abstract = {Predictions are made by artificial intelligence, especially through machine learning, which uses algorithms and past knowledge. Notably, there has been an increase in interest in using artificial intelligence, particularly generative AI, in the pharmacovigilance of pharmaceuticals under development, as well as those already in the market. This review was conducted to understand how generative AI can play an important role in pharmacovigilance and improving drug safety monitoring. Data from previously published articles and news items were reviewed in order to obtain information. We used PubMed and Google Scholar as our search engines, and keywords (pharmacovigilance, artificial intelligence, machine learning, drug safety, and patient safety) were used. In toto, we reviewed 109 articles published till 31st January 2024, and the obtained information was interpreted, compiled, evaluated, and conclusions were reached. Generative AI has transformative potential in pharmacovigilance, showcasing benefits, such as enhanced adverse event detection, data-driven risk prediction, and optimized drug development. By making it easier to process and analyze big datasets, generative artificial intelligence has applications across a variety of disease states. Machine learning and automation in this field can streamline pharmacovigilance procedures and provide a more efficient way to assess safety-related data. Nevertheless, more investigation is required to determine how this optimization affects the caliber of safety analyses. In the near future, the increased utilization of artificial intelligence is anticipated, especially in predicting side effects and Adverse Drug Reactions (ADRs).}
}
@article{BONCI2025104929,
title = {Artificial intelligence in NSCLC management for revolutionizing diagnosis, prognosis, and treatment optimization: A systematic review},
journal = {Critical Reviews in Oncology/Hematology},
volume = {216},
pages = {104929},
year = {2025},
issn = {1040-8428},
doi = {https://doi.org/10.1016/j.critrevonc.2025.104929},
url = {https://www.sciencedirect.com/science/article/pii/S1040842825003178},
author = {Eduard-Alexandru Bonci and Artur Bandura and Andrew Dooley and Ayah Erjan and Hailemichael Welekidan Gebreslase and Mirela Hategan and Divetiya Khanduja and Eleonora Lai and Andreea Lescaie and Gabriela Viorela Nitescu and Sofia Ramalho and Aung Thiha and Luca Bertolaccini},
keywords = {Artificial intelligence, Artificial neural networks, Lung cancer, Machine learning, Non-small lung cancer, Overall survival, Patient-reported outcome measures},
abstract = {Background
Non-small cell lung cancer (NSCLC) accounts for approximately 85 % of all lung cancer cases and remains a leading cause of cancer-related mortality. The integration of artificial intelligence (AI), artificial neural networks (ANNs), and machine learning (ML) into NSCLC management has shown potential in improving diagnostic accuracy, treatment personalization, and patient outcomes. However, the impact of these technologies on patient-reported outcome measures (PROM), overall survival (OS), and cost-effectiveness remains underexplored. This systematic review aims to evaluate the impact of AI, ANNs, and ML models on PROM, OS, and cost-effectiveness in adult patients with histologically confirmed NSCLC compared to conventional research methodologies and standard-of-care approaches.
Methods
A systematic review was conducted following the PRISMA guidelines, with data synthesized using the Synthesis Without Meta-analysis (SWiM) approach. Data extraction focused on study design, patient characteristics, AI methodology, and outcomes of interest. Given the heterogeneity in study designs and statistical methods, a meta-analysis was deemed inappropriate.
Results
Ten studies were included after screening 509 articles. AI-based models demonstrated improvements in diagnostic precision, treatment optimization, and predictive accuracy for survival outcomes. AI-enhanced approaches outperformed conventional statistical models in prognosis prediction and resource allocation. However, data heterogeneity, model generalizability, and algorithmic transparency remain significant challenges.
Conclusion
Current evidence supports exploratory associations between AI models and prognostic stratification for OS; there is no evaluable evidence on PROM or cost‑effectiveness in NSCLC. Future prospective studies should incorporate validated PROM and formal economic evaluation alongside clinical endpoints. AI, ANNs, and ML have the potential to revolutionize NSCLC care by improving diagnostic accuracy and treatment outcomes. However, further research is needed to validate their real-world clinical applicability and address potential biases, ethical implications, and concerns regarding healthcare disparities.}
}
@article{HO2025102628,
title = {Ethics, Bias, and Governance in Artificial Intelligence for Hepatology: Toward Building a Safe and Fair Future},
journal = {Journal of Clinical and Experimental Hepatology},
volume = {15},
number = {6},
pages = {102628},
year = {2025},
issn = {0973-6883},
doi = {https://doi.org/10.1016/j.jceh.2025.102628},
url = {https://www.sciencedirect.com/science/article/pii/S0973688325001288},
author = {Chanda K. Ho and Sumeet K. Asrani},
keywords = {artificial intelligence, machine learning, hepatology, ethics, governance},
abstract = {Artificial intelligence (AI) is fundamentally changing how modern medicine is practiced with the intent of advancing and accelerating patient care and improving both patient experience and outcomes. AI, however, has been confronted by several challenges, including but not limited to ethics, regulation, and public trust. This paper explores an approach to AI governance in healthcare, specifically in hepatology. As AI continues to grow, it will be crucial for healthcare providers and our community as hepatologists to understand the implications and impact of this growth and what this means for our practice and patients. We draw from existing AI frameworks, principles of medical ethics, as well as quality healthcare principles to propose our framework for AI in hepatology. Our proposed framework includes patient-centered care, non-maleficence and safety, equity, transparency, accountability, and security and privacy. For each of these topics, we discuss examples relevant to hepatology. We also propose an action plan for hepatologists on how each of these principles can be upheld in our day-to-day practice. While many hepatology specific AI applications are currently being tested in research studies, they have not yet made it to “prime time.” As a result, the hepatology community has time to consider governance structures to put in place in preparation for the inherent challenges that come with AI implementation and integration into clinical care to ensure that care is responsible, ethical, safe, and secure. With careful and conscientious planning, the inclusion of relevant stakeholders, and laying the groundwork for governance, AI can improve quality of health care in hepatology with efficiency, improved safety, and equity.}
}
@article{YANG2025101372,
title = {Illuminating the universe of enzyme catalysis in the era of artificial intelligence},
journal = {Cell Systems},
pages = {101372},
year = {2025},
issn = {2405-4712},
doi = {https://doi.org/10.1016/j.cels.2025.101372},
url = {https://www.sciencedirect.com/science/article/pii/S2405471225002054},
author = {Jason Yang and Francesca-Zhoufan Li and Yueming Long and Frances H. Arnold},
keywords = {protein, enzyme, biocatalysis, artificial intelligence, machine learning, directed evolution},
abstract = {Summary
Scientific research has revealed only a minuscule fraction of the enzymes that evolution has generated to power life’s essential chemical reactions—and an even tinier fraction of the vast universe of possible enzymes. Beyond the enzymes already annotated lie an astronomical number of biocatalysts that could enable sustainable chemical production, degrade toxic pollutants, and advance disease diagnosis and treatment. For the past few decades, directed evolution has been a powerful strategy for reshaping enzymes to access new chemical transformations: by harnessing nature’s existing diversity as a starting point and taking inspiration from nature’s most powerful design process, evolution, to modify enzymes incrementally. Recently, artificial intelligence (AI) methods have started revolutionizing how we understand and compose the language of life. In this perspective, we discuss a vision for AI-driven enzyme discovery to unveil a world of enzymes that transcends biological evolution and perhaps offers a route to genetically encoding almost any chemistry.}
}
@article{WANG2025100993,
title = {Artificial intelligence in high-entropy materials},
journal = {Next Materials},
volume = {9},
pages = {100993},
year = {2025},
issn = {2949-8228},
doi = {https://doi.org/10.1016/j.nxmate.2025.100993},
url = {https://www.sciencedirect.com/science/article/pii/S2949822825005118},
author = {Jiasheng Wang and Yong Zhang},
keywords = {High-Entropy Materials, Artificial Intelligence, Machine Learning, High-Throughput Techniques, Multi-Objective Optimization},
abstract = {High-entropy materials (HEMs) are a transformative class of materials exhibiting remarkable properties, making them highly attractive for demanding applications. However, their vast compositional space and complex inter-element interactions pose significant challenges for traditional development methods. The integration of artificial intelligence (AI) and machine learning (ML) with high-throughput techniques has emerged as a powerful solution, revolutionizing the discovery and optimization of HEMs. This review highlights the synergistic paradigm of AI and high-throughput methods in HEMs research. High-throughput experimental approaches enable rapid screening of multiple compositions, while complementary computational methods provide theoretical insights and accelerate predictions of material properties. Machine learning models, ranging from supervised learning to unsupervised learning offer robust tools for predicting material properties, optimizing compositions, and discovering new materials. Generative models and inverse design approaches further enable the creation of novel HEMs with desired properties. The multi - objective optimization framework provides an effective means to find the best balance among multiple performance indicators. Large language models process and integrate massive amounts of data and extract key information, providing data-driven insights for the discovery of complex materials. The integration of these techniques into a closed-loop development system enables continuous feedback between experimental data, computational predictions, and machine learning models, thereby accelerating the discovery and optimization of HEMs, which not only streamlines the exploration of vast compositional spaces but also provides multi-scale insights into material behavior. As AI continues to evolve and integrate with emerging technologies, the future of HEM research holds great promise for sustainable development and accelerate their translation from the laboratory to practical applications.}
}
@article{KIM2025100214,
title = {Navigating the human-AI divide: Boundary work in the age of generative AI},
journal = {Computers in Human Behavior: Artificial Humans},
volume = {6},
pages = {100214},
year = {2025},
issn = {2949-8821},
doi = {https://doi.org/10.1016/j.chbah.2025.100214},
url = {https://www.sciencedirect.com/science/article/pii/S2949882125000982},
author = {Young Ji Kim and Ceciley Xinyi Zhang and Chengyu Fang},
keywords = {Generative AI, Human-machine communication, Boundary work, Human-computer interaction, Ontological boundaries},
abstract = {Generative artificial intelligence (GenAI), such as ChatGPT, has recently attracted vast public attention for its remarkable ability to produce sophisticated, human-like content. As these technologies increasingly blur the boundaries between artificial and human intelligence, understanding how users perceive and manage this boundary becomes essential. Drawing on the concept of boundary work, this paper examines how GenAI users discursively and practically navigate the ontological boundaries between human intelligence and GenAI. Through a qualitative analysis of nine focus groups involving 45 college students from diverse academic backgrounds, this study identifies three types of human-GenAI boundaries: complementary, competitive, and co-evolving. Complementary boundaries highlight GenAI's supportive and instrumental role and competitive boundaries emphasize human superiority and concerns over GenAI's threats, while co-evolving boundaries acknowledge dynamic interplay and reflective collaboration between humans and GenAI. The paper contributes theoretically by demonstrating that human-machine boundaries are dynamic, multifaceted, and actively negotiated. Practically, it offers insights into user strategies and implications for responsible adoption of GenAI technologies in educational and organizational contexts.}
}
@article{CONNOR2025100259,
title = {Byline or Botline? The Dilemma of Artificial Intelligence in Medical Scholarship},
journal = {Mayo Clinic Proceedings: Digital Health},
volume = {3},
number = {4},
pages = {100259},
year = {2025},
issn = {2949-7612},
doi = {https://doi.org/10.1016/j.mcpdig.2025.100259},
url = {https://www.sciencedirect.com/science/article/pii/S2949761225000665},
author = {James Connor}
}
@article{CLORION2025107,
title = {AI-Powered Professionals and Digital Natives: A Correlational Analysis of the Use and Benefits of Artificial Intelligence for the Employability Skills of Postgraduate Education Students},
journal = {Procedia Computer Science},
volume = {263},
pages = {107-114},
year = {2025},
note = {International Conference on Industry Sciences and Computer Science Innovation (iSCSi’24)},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2025.07.014},
url = {https://www.sciencedirect.com/science/article/pii/S1877050925020642},
author = {Frenz Djaxxas D. Clorion and Justine O. Fuentes and Dinnesse Joi B. Suicano and Edison B. Estigoy and Abee M. Eijansantos and Richard M. Rillo and Cimon E. Pantaleon and Christopher Iris Francisco and Marianet R. {Delos Santos} and Ericson O. Alieto},
keywords = {Artificial intelligence, AI tools, AI software, Employability skills, Postgraduate},
abstract = {This investigation provides crucial insights and results on the most utilized AI tools/platforms for postgraduate education students. The study also focuses on examining the uses, benefits, and challenges of using artificial intelligence (AI) in the context of skills and professional enhancement in the 21st century. The significance of this study lies in the constant demand for technological skills and competence toward prospective professionals, where artificial intelligence provides support toward academic and professional excellence. The survey included responses from a total of 1107 postgraduate education students, 72.4% of whom were females enrolled in various education courses. With 394 (35.4%) respondents previously enrolled in Bachelor of Secondary Education (BSED), 295 (26.6%) in Bachelor of Elementary Education (BEED), 61 (5.5%) in Bachelor of Early Childhood Education (BECED), 186 (16.8%) in Bachelor of Culture and Arts Education (BCAED), and a total of 120 (10.85%) of participants enrolled in Bachelor of Special Needs Education (BSNED). The Kolmogorov-Smirvov test was used to ensure the normal distribution of the data. Furthermore, the findings indicate that 49.6% of the respondents utilized AI for general learning and that 64.6% of postgraduates strongly agreed that AI provides support for learning. Moreover, the study revealed a significant correlation between the use and benefits of artificial intelligence in developing the skills of postgraduate students, which generally equate to improved employability skills.}
}
@article{PORTILLOJUAN2025122077,
title = {Advancing artificial intelligence in ocean and maritime engineering: Trends, progress, and future directions},
journal = {Ocean Engineering},
volume = {339},
pages = {122077},
year = {2025},
issn = {0029-8018},
doi = {https://doi.org/10.1016/j.oceaneng.2025.122077},
url = {https://www.sciencedirect.com/science/article/pii/S0029801825017615},
author = {Nerea {Portillo Juan} and Vicente {Negro Valdecantos} and Peter Troch},
keywords = {Machine learning, Structural applications, Hybrid AI models, Ethics, Reinforcement learning, Maritime engineering},
abstract = {This review article presents an analysis of Artificial intelligence (AI) applications in ocean and maritime engineering, examining the evolution, current trends, and future directions of AI in the field. A key finding is the transformative impact of Reinforcement Learning (RL), which enables real-time adaptation in dynamic and uncertain marine environments, essential for applications such as autonomous navigation, vessel control, and route optimization. Additionally, the study identifies the promising potential of hybrid AI models, which combine optimization algorithms, fuzzy logic, and deep learning to address the complex, nonlinear challenges inherent in maritime structures and fluid-structure interactions. Looking ahead, the review highlights several promising directions: the expansion of RL into new domains such as coastal erosion modelling and flood prediction; the adoption of transformer architectures for time-series forecasting; and the growing importance of Explainable AI (XAI) and digital twins for transparent and trustworthy deployment in safety-critical systems. As the industry moves towards Artificial General Intelligence (AGI), the article stresses the need for robust regulatory frameworks, ethical safeguards, and the preservation of human oversight to ensure responsible and effective integration of AI technologies in maritime applications.}
}
@article{VOIGT2025104154,
title = {Let it go and embrace something new: How goal reengagement capacities moderate the effect of interacting with artificial intelligence on career optimism},
journal = {Journal of Vocational Behavior},
volume = {161},
pages = {104154},
year = {2025},
issn = {0001-8791},
doi = {https://doi.org/10.1016/j.jvb.2025.104154},
url = {https://www.sciencedirect.com/science/article/pii/S0001879125000739},
author = {Julian Voigt and Karoline Strauss},
keywords = {Artificial intelligence, Goal reengagement capacities, Career optimism},
abstract = {Artificial Intelligence (AI) is rapidly entering the workplace, changing the way people work and affecting their careers. This integration raises critical questions about the capabilities employees need to maintain a positive outlook on the rise of AI and the future of their career. We explore how goal reengagement capacities shape the impact of human-AI interaction. In two experimental studies, we develop a moderated mediation model in which goal reengagement capacities moderate the path from AI interaction (vs. a control group) through perceived threat of AI to career-related optimism. Using two experimental studies with students (N = 355) and full-time employees (N = 186), we show that individuals' goal reengagement capacities moderate the indirect relationship between AI interaction and career-related optimism via perceived threat of AI, such that this indirect effect is negative for those with low goal reengagement capacities and positive for those with high goal reengagement capacities. Our findings underscore the value of letting go of previously held goals and embracing new ones as AI reshapes the world of work, and highlight goal reengagement capacities as critical for maintaining career optimism in an AI-transformed workplace.}
}
@article{FUREY2025300,
title = {Can Artificial Intelligence Coach Faculty to Utilize Growth Mindset Language? A Qualitative Analysis of Feedback Statements},
journal = {Journal of Surgical Research},
volume = {308},
pages = {300-306},
year = {2025},
issn = {0022-4804},
doi = {https://doi.org/10.1016/j.jss.2025.01.029},
url = {https://www.sciencedirect.com/science/article/pii/S0022480425000964},
author = {Michael J. Furey and Raymond Stemrich and Jamaica Westfall-Snyder and Tanvi Gupta and Megan Rapp and Rebecca L. Hoffman},
keywords = {Artificial intelligence, Coach, Faculty, Feedback, Growth mindset language, Medical students, Mindset theory, Residents},
abstract = {Introduction
Feedback is at the core of competency-based medical education. Learner perceptions of the evaluation process influence how feedback is utilized. Systems emphasize a fixed mindset, prioritizing evaluation over growth. Embracing growth mindset culture, the belief that ability is acquired through effort and human capabilities can be developed over time, will allow learners to gain greater benefits from feedback. Transitioning from fixed mindset language (FML) to growth mindset language (GML) will require faculty training. Artificial intelligence (AI) can assist faculty with incorporating GML concepts in written feedback. The aim of this study was to assess the ability of AI to assist in changing FML feedback statements into statements with GML.
Methods
A qualitative study was performed utilizing a sample of 83 summative and formative feedback statements provided to students (37) and residents (46) from surgery clerkship and national SIMPL-inguinal hernia evaluations. Of these 83 statements, a reviewer coded 41 statements as using GML and 42 using FML. Original statements identified as using FML were entered into the Google Chrome "Help me write" tool, a writing aid using Generative AI. The AI tool was prompted with the statement "rewrite using growth mindset language:," followed by an original FML statement. A dataset containing a combination of AI-altered and original statements, 99 statements in all, was provided to two additional blinded reviewers trained in GML concepts. Reviewers evaluated statements as predominantly GML or FML and commented on their perception of AI use in statements. Reviewer agreement was adjudicated by the original coder.
Results
Of the 41 original GML statements, coders correctly identified 37 (90.2%) as using GML. Of the 26 original FML statements, coders correctly identified all 26 (100%) as using FML. Of the AI-modified FML to GML statements, coders correctly identified 17 of 18 (94.4%) as using GML. They correctly identified 56.3% as AI-modified and 44.8% as not AI-modified statements. They disagreed on AI use in 39.4% of statements. AI-assistance was unrecognized in 16 (8.1%) statements and mistaken for use in 47 (23.7%) statements.
Conclusions
AI was successful at modifying FML statements into feedback containing GML, and in a way that was not obviously AI-generated. This proof-of-concept study demonstrates that AI can be a helpful tool for faculty to increase the use of GML in written feedback. While AI cannot perfectly create GML feedback without initial input and understanding from faculty, it does serve as a promising educational aid. As the body of work on using GML in surgical education grows, the better AI can assist in the generation of quality feedback.}
}
@article{GORYANIN2025104448,
title = {Revolutionizing drug discovery: Integrating artificial intelligence with quantitative systems pharmacology},
journal = {Drug Discovery Today},
volume = {30},
number = {9},
pages = {104448},
year = {2025},
issn = {1359-6446},
doi = {https://doi.org/10.1016/j.drudis.2025.104448},
url = {https://www.sciencedirect.com/science/article/pii/S1359644625001618},
author = {Igor Goryanin and Irina Goryanin and Oleg Demin},
keywords = {quantitative systems pharmacology (QSP), artificial intelligence (AI), machine learning (ML), large language models (LLMs), drug discovery, digital twins, regulatory acceptance},
abstract = {Quantitative systems pharmacology (QSP) provides a mechanistic framework for integrating diverse biological, physiological, and pharmacological data to predict drug interactions and clinical outcomes. Recent advances in artificial intelligence (AI) might transform QSP by enhancing model generation, parameter estimation, and predictive capabilities. AI-driven databases and cloud-based platforms might support QSP model development and facilitate QSP as a service (QSPaaS). However, challenges such as computational complexity, high dimensionality, explainability, data integration, and regulatory acceptance persist. This review critically evaluates the integration of AI within QSP, highlighting novel methodologies like surrogate modeling, virtual patient generation, and digital twin technologies. It also discusses current limitations and outlines strategies for future integration to enhance precision medicine, regulatory acceptability, and mechanistic interpretability in drug discovery and development.}
}
@article{SANG2025111318,
title = {Discovery of α-mangostin derivatives as novel PDE4 inhibitors for the treatment of Alzheimer's disease: An artificial intelligence-driven synergized strategy},
journal = {Chinese Chemical Letters},
pages = {111318},
year = {2025},
issn = {1001-8417},
doi = {https://doi.org/10.1016/j.cclet.2025.111318},
url = {https://www.sciencedirect.com/science/article/pii/S1001841725005030},
author = {Zhi-Pei Sang and Teng Xue and Qian-Ru Xing and Qi-Yao Zhang and Hong-Song Chen and Xue Wang and Fu-Rong Zhang and Wen-Ling Fu and Wu Dong and Shu-Heng Huang and Yi-You Huang and Hai-Bin Luo},
keywords = {Alzheimer’s disease, Generative recurrent neural network, -Mangostin, PDE4 inhibitor,  study},
abstract = {Alzheimer's disease (AD) is a chronic, progressive neurodegenerative disorder with no effective therapeutic agents currently available. Inhibiting phosphodiesterase 4 (PDE4) has emerged as a promising strategy for AD treatment. In this study, we employed a synergistic approach combining generative recurrent neural network (RNN)-driven combinatorial compound design, virtual screening, and structure-activity relationship (SAR) analysis to discover novel PDE4 inhibitors. Utilizing α-mangostin as a hit compound (half maximal inhibitory concentration (IC50) = 1.31 μmol/L), we identified a novel PDE4 inhibitor, 13d (IC50 = 72.8 nmol/L) with moderate liver microsomal stability (rat liver microsomes (RLM), t1/2 = 32.4 min). In vitro activity results indicated that 13d exhibited favorable anti-inflammatory effects and promising neuroprotective activity. In vivo experiments demonstrated that 13d significantly improved AlCl3-induced zebrafish AD model by inhibiting PDE4 and reducing inflammatory cytokine. Further, 13d significantly alleviated AlCl3/D-galactose-induced AD mouse model. These findings highlight the potent PDE4 inhibitor 13d with promising anti-AD activity, underscoring the potential of artificial intelligence-driven drug discovery for novel therapeutic agents for AD.}
}
@article{ARSHAD2025105776,
title = {Artificial intelligence and companion animals: Perspectives on digital healthcare for dogs, cats, and pet ownership},
journal = {Research in Veterinary Science},
volume = {193},
pages = {105776},
year = {2025},
issn = {0034-5288},
doi = {https://doi.org/10.1016/j.rvsc.2025.105776},
url = {https://www.sciencedirect.com/science/article/pii/S0034528825002504},
author = {Muhammad Furqan Arshad and Fahad Ahmed and Francesca Nonnis and Claudia Tamponi and Antonio Scala and Antonio Varcasia},
keywords = {Artificial intelligence (AI), Machine learning (ML), Pets, Monitoring, Welfare},
abstract = {The exponential increase in global pet ownership has been creating an urgent demand for novel solutions to upgrade care for companion animals, particularly dogs and cats. Similar to its impact on other domains, artificial intelligence (AI) delivers an alternative solution to this pressing requirement. Profound transformation in pet care management is underway with the application of cutting-edge AI technologies incorporating various machine learning (ML) algorithms. This thorough review highlights the expanding potential of AI in reshaping the pet industry and will embark on a two-fold exploration. The first section offers a brief explanation of AI paradigms, outlining essential concepts and presenting examples of their use in the management of companion animals. A more extensive second section provides a meticulous exploration of the diverse applications of AI for pets including health monitoring, behaviour monitoring, feed and feeding systems, parasite detection, artificial, virtual, and robotic pets, and veterinary care and support. It can be easily predicted from the ongoing research that the continuous integration of AI-driven innovations in the pet care sector will result in a balanced blend of compassion and technology offering optimized pet care. Currently, this integration still faces inherent challenges, and it is imperative to navigate them in order to leverage full potential of AI for companion animals.}
}
@article{LI2025,
title = {Artificial intelligence empowering evidence-based medicine: an L0-L5 evolutionary framework towards personalized precision medicine},
journal = {Intelligent Medicine},
year = {2025},
issn = {2667-1026},
doi = {https://doi.org/10.1016/j.imed.2025.07.002},
url = {https://www.sciencedirect.com/science/article/pii/S2667102625000889},
author = {Nan Li and Yanyan Shi and Yiming Zhao and Siyan Zhan},
keywords = {Artificial intelligence, Evidence-based medicine, Clinical decision support, Personalized medicine, Real-world data, Evolutionary framework},
abstract = {Evidence-based medicine (EBM) faces inherent challenges in bridging population-based evidence with personalized medical needs. The rapid advancement of artificial intelligence (AI) offers unprecedented opportunities to transform this paradigm. However, applications without theoretical guidance pose risks to the application, regulation and orderly development of AI technologies such as large language models (LLMs). This paper proposes a novel L0-L5 evolutionary framework to systematically guide the integration of LLMs into evidence-based clinical decision-making. The framework delineates a progressive path from current EBM practices (L0) through AI-assisted evidence retrieval (L1), accelerated evidence synthesis (L2), real-world data analysis (L3), digital twin-based personalized evidence (L4), to generative model-driven virtual evidence creation (L5). Each level represents increasing capabilities in addressing the core tensions between evidence timeliness, personalization resolution, and decision transparency. This framework offers a structured approach to harness the transformative potential of LLMs while preserving the fundamental principles of EBM, ultimately enabling truly personalized precision medicine grounded in robust evidence.}
}
@article{XUE2025100086,
title = {Advancements and future directions of artificial intelligence in tumor imaging: A comprehensive review of techniques and applications},
journal = {EngMedicine},
volume = {2},
number = {3},
pages = {100086},
year = {2025},
issn = {2950-4899},
doi = {https://doi.org/10.1016/j.engmed.2025.100086},
url = {https://www.sciencedirect.com/science/article/pii/S2950489925000326},
author = {Jinglei Xue and Jing Yu and Qianqian Mao and Xiaochun Gu},
keywords = {Imaging, Pathology, Genetics, Cancer, Artificial intelligence, Deep learning, Large models},
abstract = {Medical images captured using various imaging technologies can reveal the internal structures and functions of the human body. Tumor images depict the location, size, shape, and biological characteristics of tumors, which are crucial for diagnosis, staging, treatment planning, and outcome assessment. These images are obtained through modalities such as radiography, computed tomography, magnetic resonance imaging, ultrasound, positron emission tomography, single-photon emission computed tomography, digital mammography, digital breast tomosynthesis, histological imaging, and molecular imaging. The application of artificial intelligence (AI) in healthcare, particularly in tumor image recognition, is vital for early diagnosis, treatment planning, and prognostic assessment. Techniques such as AI, machine learning (ML), neural networks (NNs), and deep learning (DL) enhance the accuracy and efficiency of tumor recognition. This review introduces the fundamental principles and interrelationships among AI, ML, NNs, and DL, explores their applications and characteristics in tumor imaging, discusses their limitations in clinical settings and future research directions, and provides a comprehensive overview of technological advancements in this field and their potential for future medical applications.}
}
@article{BRUNO2025,
title = {Artificial Intelligence and Its Impact on Radiology: Summary of the 2024 Intersociety Summer Conference},
journal = {Journal of the American College of Radiology},
year = {2025},
issn = {1546-1440},
doi = {https://doi.org/10.1016/j.jacr.2025.07.025},
url = {https://www.sciencedirect.com/science/article/pii/S1546144025004442},
author = {Michael A. Bruno and Lars Grimm and Laeton J. Pang and Amy Bezold and Brandon K.K. Fields and Grayson L. Baird and Dana Smetherman and Laura Coombs and James V. Rawson and Christoph Wald and Ronald V. Hublall and Erin S. Schwartz and Paul J. Chang and Frank J. Lexa},
keywords = {Artificial intelligence, AI, health policy, patient safety},
abstract = {The 2024 ACR Intersociety Summer Conference was convened August 9 to 11, 2024, at the Seaport Hotel in Boston, with representation from 27 societies. This year’s agenda focused on the anticipated future impacts of artificial intelligence on the practice of radiology. Participants highlighted the need for transparent performance metrics, adaptive regulation, and fundamental changes to enterprise-wide IT infrastructure to support safe and scalable adoption of artificial intelligence in radiology, as well as the need to address potential legal and economic impacts proactively.}
}
@article{OZDEMIRAYDIN2025104429,
title = {The relationship between first-year nursing students' innovation skills and attitudes toward artificial intelligence: A multicentre study},
journal = {Nurse Education in Practice},
volume = {86},
pages = {104429},
year = {2025},
issn = {1471-5953},
doi = {https://doi.org/10.1016/j.nepr.2025.104429},
url = {https://www.sciencedirect.com/science/article/pii/S1471595325001854},
author = {Gülsün {Özdemir Aydın} and Semiha Küçükaydınoğlu and Aylin Palloş and Ela Yılmaz Coşkun and Nuray Turan},
keywords = {Nursing, Innovation skills, Artificial intelligence, Attitude, Students},
abstract = {Aim
To assess innovation skills and attitudes toward artificial intelligence
Background
The rapid advancement of modern healthcare technologies necessitates the transformation of traditionally structured nursing education. Attitudes toward innovation and artificial intelligence technologies will be crucial in determining their future impact on patient care. Therefore, assessing these attitudes early will be a significant step in shaping the future of nursing education.
Design
A cross-sectional multicenter study and adhering to STROBE guidelines.
Method
The study was performed at nursing schools of three universities, surveying a total of 269 first-year nursing students enrolled in 2024. A validated instrument, Innovation Skills Measurement Tool for Youth and the General Attitudes towards Artificial Intelligence Scale. Descriptive statistics, Student's t-test and One-Way ANOVA tests were used in the analyses.
Results
Students demonstrated high innovation skills (121.51 (SD 23.42) and positive attitudes towards artificial intelligence (65.83 (SD 8.99). Innovation skills were significantly higher among those knowledgeable about healthcare innovation (125.63 (SD 23.20) and those following innovation-related applications (129.16 (SD 24.66). Positive AI attitudes were higher in those familiar with AI (67.31 (SD 8.83), those using AI-based applications (67.39 (SD 8.95) and those interested in developing innovative products (68.13 (SD 9.66) (p < 0.05). A moderate correlation was found between positive AI attitudes and innovation skills (r = .314).
Conclusions
First-year nursing students generally have a positive attitude towards artificial intelligence; however, concerns remain regarding its use in daily practice. This suggests that specialized training programs focusing on both artificial intelligence applications and innovation skills could be beneficial for nursing students.}
}
@article{UTTI2025573,
title = {Artificial Intelligence in Dermatology Research and Drug Discovery},
journal = {Dermatologic Clinics},
volume = {43},
number = {4},
pages = {573-583},
year = {2025},
note = {Artificial Intelligence in Dermatology},
issn = {0733-8635},
doi = {https://doi.org/10.1016/j.det.2025.05.008},
url = {https://www.sciencedirect.com/science/article/pii/S0733863525000476},
author = {Vivian Utti and Thomas Bikias and Ank A. Agarwal and Vasiliki Bikia and Anson Y. Zhou and Mihir M. Shah and Roxana Daneshjou},
keywords = {Dermatology, Drug discovery, Artificial intelligence}
}
@article{LIAO2025106334,
title = {Artificial intelligence for spatial analysis in cities},
journal = {Cities},
volume = {167},
pages = {106334},
year = {2025},
issn = {0264-2751},
doi = {https://doi.org/10.1016/j.cities.2025.106334},
url = {https://www.sciencedirect.com/science/article/pii/S0264275125006353},
author = {Chuangchang Liao and Yaxing Li and Renzhong Guo and Xiaoming Li},
keywords = {Artificial intelligence, Urban studies, Spatial analysis, Interdisciplinary research, Technical review},
abstract = {Spatial analysis, a cornerstone of urban research, has been widely recognized for its contributions to urban governance, environmental protection, and spatial planning. The advent of artificial intelligence is revitalizing urban spatial research. Research on the integration of AI technology and urban spatial research is emerging, and research reviews have been conducted in many application areas; there is still a need to provide a comprehensive knowledge and identify trends from a technological perspective. This paper addressed this gap by constructing a methodological framework that integrates bibliometrics and qualitative technical review. It systematically mapped the existing knowledge, reviewed current research themes, and analyzed patterns in AI-driven spatial analysis. Then, we further identified the development potential of various research themes and suggested future research directions. This study provides insights into the intersection of AI and urban spatial analysis, aiming to inform the development of related theories, methodological models, and applications.}
}
@article{VYAS2025110178,
title = {Advancing the frontier of artificial intelligence on emerging technologies to redefine cancer diagnosis and care},
journal = {Computers in Biology and Medicine},
volume = {191},
pages = {110178},
year = {2025},
issn = {0010-4825},
doi = {https://doi.org/10.1016/j.compbiomed.2025.110178},
url = {https://www.sciencedirect.com/science/article/pii/S0010482525005293},
author = {Akanksha Vyas and Krishan Kumar and Ayushi Sharma and Damini Verma and Dhiraj Bhatia and Nitin Wahi and Amit K. Yadav},
keywords = {Artificial intelligence, Blood cancer diagnosis, Prognosis markers, Hematology, Metastasis},
abstract = {Background
Artificial Intelligence (AI) is capable of revolutionizing cancer therapy and advancing precision oncology via integrating genomics data and digitized health information. AI applications show promise in cancer prediction, prognosis, and treatment planning, particularly in radiomics, deep learning, and machine learning for early cancer diagnosis. However, widespread adoption requires comprehensive data and clinical validation. While AI has demonstrated advantages in treating common malignancies like lung and breast cancers, challenges remain in managing rare tumors due to limited datasets. AI's role in processing multi-omics data and supporting precision oncology decision-making is critical as genetic and health data become increasingly digitized.
Method
This review article presents current knowledge on AI and associated technologies, which are being utilized in the diagnosis and therapy of cancer. The applications of AI in radiomics, deep learning, and machine learning for cancer screening and treatment planning are examined. The study also explores the capabilities and limitations of predictive AI in diagnosis and prognosis, as well as generative AI, such as advanced chatbots, in patient and provider interactions.
Results
AI can improve the early diagnosis and treatment of high-incidence cancers like breast and lung cancer. However, its application in rare cancers is limited by insufficient data for training and validation. AI can effectively process large-scale multi-omics data from DNA and RNA sequencing, enhancing precision oncology. Predictive AI aids in risk assessment and prognosis, while generative AI tools improve patient-provider communication. Despite these advancements, further research and technological progress are needed to overcome existing challenges.
Conclusions
AI holds transformative potential for cancer therapy, particularly in precision oncology, early detection, and personalized treatment planning. However, challenges such as data limitations in rare cancers, the need for clinical validation, and regulatory considerations must be addressed. Future advancements in AI could significantly improve decision-support systems in oncology, ultimately enhancing patient care and quality of life. The review highlights both the opportunities and obstacles in integrating AI into cancer diagnostics and therapeutics, calling for continued research and regulatory oversight.}
}
@article{ABDULAZEEM2025107620,
title = {Challenging the status quo: Why artificial intelligence models must go beyond accuracy in cervical cancer diagnosis},
journal = {Biomedical Signal Processing and Control},
volume = {105},
pages = {107620},
year = {2025},
issn = {1746-8094},
doi = {https://doi.org/10.1016/j.bspc.2025.107620},
url = {https://www.sciencedirect.com/science/article/pii/S1746809425001314},
author = {Yousry AbdulAzeem and Hossam Magdy Balaha and Hanaa ZainEldin and Waleed AbdelKarim Abuain and Mahmoud Badawy and Mostafa A. Elhosseini},
keywords = {Cervical cancer, Computer-aided diagnosis (CAD), Deep learning (DL), Machine learning (ML)},
abstract = {Cervical cancer is a significant health issue affecting women globally, with a high number of new cases and deaths reported each year. The disease is linked to HPV infection, but early detection through Pap smear tests can significantly increase performance. Deep learning techniques, particularly convolutional neural networks, transfer learning, generative adversarial networks, and attention mechanisms, are employed to identify cervical cancer. These innovative methods can increase the effectiveness and efficiency of cervical cancer screening and diagnosis. Although these technologies provide advantages for diagnosing cervical cancer, issues related to the availability and integrity of data, interpretability of models, and integration into clinical workflows exist. A computer-aided diagnostic system that uses vision transformers, a majority fusion mechanism, and explainable artificial intelligence is presented to address these challenges. This framework aims to increase cervical cancer detection accuracy and efficiency. Two cutting-edge datasets, DTU/Herlev and SIPaKMeD, are used to evaluate the system, yielding overall accuracy results of 99.22% and 99.8%, respectively. A comparison of the suggested framework with state-of-the-art methods revealed equivalent or even better results.}
}
@article{TIAN2025100728,
title = {The impact of artificial intelligence on students’ 4C skills: A meta-analysis},
journal = {Educational Research Review},
volume = {49},
pages = {100728},
year = {2025},
issn = {1747-938X},
doi = {https://doi.org/10.1016/j.edurev.2025.100728},
url = {https://www.sciencedirect.com/science/article/pii/S1747938X2500065X},
author = {Qian Tian and Xudong Zheng},
keywords = {Artificial intelligence, Artificial intelligence in education, 4C skills, Meta-analysis},
abstract = {The widespread integration of artificial intelligence (AI) in education has highlighted its potential to enhance students' higher-order competencies, particularly the 4C skills (critical thinking, communication, collaboration, and creativity). However, the effectiveness of AI in fostering these skills remains debated, primarily due to inconsistent findings across studies. To address this research gap, this study employs the meta-analysis method, analyzing 39 experimental and quasi-experimental studies published in international journals between January 2010 and July 2024. The results reveal that: (1) AI has a moderately positive impact on students' 4C skills (the combined effect size = 0.624), while there is no significant difference in creativity, critical thinking, communication, and collaboration; (2) AI-based learning tools are most effective in enhancing the 4C skills of primary school students compared to other educational levels; (3) a mix of different technology types is more conducive to developing students' 4C skills than any single technology; (4) AI is most effective in fostering 4C skills when applied in adaptive systems and personalization; (5) smartphones, as AI learning devices, show significant potential in promoting 4C skills. These findings provide valuable insights for future research and practice aimed at leveraging AI tools to enhance students’ 4C skills, particularly by identifying key factors that maximize the effectiveness of AI in education.}
}
@article{SHEN2025108050,
title = {Artificial intelligence and corporate investment efficiency},
journal = {Finance Research Letters},
volume = {85},
pages = {108050},
year = {2025},
issn = {1544-6123},
doi = {https://doi.org/10.1016/j.frl.2025.108050},
url = {https://www.sciencedirect.com/science/article/pii/S154461232501308X},
author = {Ling Shen and Yifei Jin and Qinyuan Xue},
keywords = {Artificial Intelligence, Investment Efficiency, Internal Information Processing Efficiency},
abstract = {This study examines how a firm's artificial intelligence (AI) level influences its corporate investment efficiency. Using panel data from Chinese A-share listed companies covering the period 2010–2023 and a firm-level AI indicator derived from patent information, we empirically examine this relationship and explore the underlying mechanisms. Our findings indicate the following: (1) A firm's AI level significantly enhances its investment efficiency. This conclusion remains robust across a series of robustness checks. (2) Mechanism analysis indicates that AI primarily enhances investment efficiency by improving internal information processing efficiency. (3) Heterogeneity analysis reveals that the positive effect of AI on investment efficiency is more pronounced in firms with longer listing histories (more mature firms) and in non-state-owned enterprises. This research contributes micro-level evidence regarding the economic consequences of AI from a corporate investment perspective.}
}
@article{JIANG20255099,
title = {New insights into translational research in Alzheimer's disease guided by artificial intelligence, computational and systems biology},
journal = {Acta Pharmaceutica Sinica B},
volume = {15},
number = {10},
pages = {5099-5126},
year = {2025},
issn = {2211-3835},
doi = {https://doi.org/10.1016/j.apsb.2025.08.015},
url = {https://www.sciencedirect.com/science/article/pii/S2211383525005647},
author = {Shulan Jiang and Zixi Tian and Yuchen Yang and Xiang Li and Feiyan Zhou and Jianhua Cheng and Jihui Lyu and Tingting Gao and Ping Zhang and Hongbin Han and Zhiqian Tong},
keywords = {Alzheimer's disease, Artificial intelligence, Computational biology, Systems biology, Big biomedical data mining, Drug development, Machine learning, Deep learning},
abstract = {Alzheimer's disease (AD) is characterized by cognitive and functional deterioration, with pathological features such as amyloid-beta (Aβ) aggregates in the extracellular spaces of parenchymal neurons and intracellular neurofibrillary tangles formed by the hyperphosphorylation of tau protein. Despite a thorough investigation, current treatments targeting the reduction of Aβ production, promotion of its clearance, and inhibition of tau protein phosphorylation and aggregation have not met clinical expectations, posing a substantial obstacle in the development of drugs for AD. Recently, artificial intelligence (AI), computational biology (CB), and systems biology (SB) have emerged as promising methodologies in AD research. Their capacity to analyze extensive and varied datasets facilitates the identification of intricate patterns, thereby enriching our comprehension of AD pathology. This paper provides a comprehensive examination of the utilization of AI, CB, and SB in the diagnosis of AD, including the use of imaging omics for early detection, drug discovery methods such as lecanemab, and complementary therapies like phototherapy. This review offers novel perspectives and potential avenues for further research in the realm of translational AD studies.}
}
@article{LI2024e40037,
title = {The application and impact of artificial intelligence technology in graphic design: A critical interpretive synthesis},
journal = {Heliyon},
volume = {10},
number = {21},
pages = {e40037},
year = {2024},
issn = {2405-8440},
doi = {https://doi.org/10.1016/j.heliyon.2024.e40037},
url = {https://www.sciencedirect.com/science/article/pii/S2405844024160689},
author = {Hong Li and Tao Xue and Aijia Zhang and Xuexing Luo and Lingqi Kong and Guanghui Huang},
keywords = {Atificial intelligence, Graphic design, Machine learning, Computer vision, Visual communication design, Systematic review},
abstract = {In the field of graphic design, the application of Artificial Intelligence (AI) is reshaping the design process. This study employs the Critical Interpretive Synthesis (CIS) approach to explore the impacts and challenges of AI on graphic design. Through a comprehensive review of 33 papers, this research reveals four research paradigms of AI in graphic design: Artificial Intelligence Driven Design Automation and Generation (AIDAG), Artificial Intelligence Assisted Graphic Design and Image Processing (AGDIP), Artificial Intelligence in Art and Creative Design Processes (AACDP), and Artificial Intelligence Enhanced Visual Attention and Emotional Response Modeling (AVERM). These paradigms demonstrate the multidimensional role of AI in design, ranging from automation to emotional interaction. The findings suggest that AI serves a dual role as both a design tool and a medium for innovation. AI not only enhances the automation and efficiency of the design process but also fosters designers' creative thinking and understanding of users' emotional needs. This study also proposes a path for the application of the four paradigms in the graphic design process, providing effective design ideas for future design workflows.}
}
@article{KELLY2025102105,
title = {Artificial Intelligence (AI) and academic publishing in psychiatry},
journal = {International Journal of Law and Psychiatry},
volume = {101},
pages = {102105},
year = {2025},
issn = {0160-2527},
doi = {https://doi.org/10.1016/j.ijlp.2025.102105},
url = {https://www.sciencedirect.com/science/article/pii/S016025272500038X},
author = {Brendan D. Kelly},
keywords = {Technology, Artificial intelligence, Psychiatry, Publishing, Ethics},
abstract = {The current and potential impact of various applications of artificial intelligence (AI) to the field of academic publishing in psychiatry is the subject of increasing attention. At present, AI algorithms assist in data analysis, allowing researchers to process large datasets quickly and uncover complex patterns that would be challenging to detect manually. In psychiatry, this capability can potentially help integrate data from genetics, neuroimaging, and clinical assessments. AI-driven natural language processing (NLP) tools might also facilitate systematic reviews and meta-analyses by automating the extraction and synthesis of information from vast bodies of published literature. In publishing, AI can potentially help to streamline the publication process in certain ways. Automated systems might screen manuscripts for methodological rigor, ethical compliance, and potential conflicts of interest, thereby reducing the burden on editors by prompting them to consider certain matters, and possibly accelerating the publication timeline. AI-powered tools are already used to help with dissemination of research findings by generating summaries and identifying key insights, making information more accessible to a broader audience. In the future, AI has the potential to enhance psychiatric publishing in various other ways. Predictive analytics might identify emerging trends and research gaps in the literature, guiding future studies and funding priorities, although this remains speculative for now. AI could also facilitate more robust collaborations by connecting researchers with complementary expertise and interests. Additionally, the integration of AI in digital platforms could democratise access to cutting-edge research, promote global knowledge sharing, and accelerate advancements in clinical care. As AI continues to evolve, its applications in research and publishing hold the potential to drive significant progress in understanding and treating mental disorders. It is essential that these developments are accompanied by openness about the use of AI in publishing, with clear declarations by authors and publishers about the use of specific applications in published work.}
}
@article{FENG2024102269,
title = {Automated de novo design of architectured materials: Leveraging eXplainable Artificial Intelligence (XAI) for inspiration from stochastic microstructure outliers},
journal = {Extreme Mechanics Letters},
volume = {73},
pages = {102269},
year = {2024},
issn = {2352-4316},
doi = {https://doi.org/10.1016/j.eml.2024.102269},
url = {https://www.sciencedirect.com/science/article/pii/S2352431624001494},
author = {Zhengkun Feng and Weijun Lei and Leidong Xu and Shikui Chen and Hongyi Xu},
keywords = {Architectured materials, XAI, Stochastic microstructures, Periodic microstructures, Generative design, Design inspiration},
abstract = {Engineered architectured Materials, such as metamaterials with periodic patterns, achieve superior properties compared with their stochastic counterparts, such as the random microstructures found in natural materials. The primary research question focuses on the feasibility of learning advantageous microstructural features from stochastic microstructure samples to facilitate the generative design of periodic microstructures, resulting in unprecedented properties. Instead of relying on brainstorming-based, ad hoc design inspiration approaches, we propose an eXplainable Artificial Intelligence (XAI)-based framework to automatically learn critical features from the exceptional outliers (with respect to properties) in stochastic microstructure samples, enabling the generation of novel periodic microstructure patterns with superior properties. This framework is demonstrated on three benchmark cases: designing 2D cellular metamaterials to maximize stiffness in all directions, to maximize the Poisson’s ratio in all directions, and to minimize the thermal expansion ratio. The effectiveness of the design framework is validated by comparing its novel microstructure designs with known stochastic and periodic microstructure designs in terms of the properties of interest.}
}
@article{LEHMANN20253903,
title = {Deep mutual learning: incentives and trust through collaborative integration of artificial intelligence into sustainability science},
journal = {RSC Sustainability},
volume = {3},
number = {9},
pages = {3903-3909},
year = {2025},
issn = {2753-8125},
doi = {https://doi.org/10.1039/d5su00572h},
url = {https://www.sciencedirect.com/science/article/pii/S2753812525002022},
author = {Johannes Lehmann and Carla Gomes and Matthias C. Rillig and Shashi Shekhar},
abstract = {Sustainability science increasingly requires computationally intensive predictive and decision-making tasks across varied temporal and spatial scales. We argue that these needs in sustainability science offer opportunities to develop trusted and transparent artificial intelligence (AI) based on principles that we define here as relevance, abundance, complexity, transferability, and specificity. Collaborations between AI and sustainability scientists should adopt the proposed “deep mutual learning” that integrates engagement with practitioners to build a shared incentive structure, and innovate question creation and an environment of co-creation with co-location. We emphasize a shared incentive structure that rests on fully integrating practitioners in the collaboration, including industry, municipalities, and the public. This approach will guide us towards sustainable policies with far-reaching societal benefits.}
}
@article{PARLAK2025114402,
title = {Blockchain-assisted explainable decision traces (BAXDT): An approach for transparency and accountability in artificial intelligence systems},
journal = {Knowledge-Based Systems},
volume = {329},
pages = {114402},
year = {2025},
issn = {0950-7051},
doi = {https://doi.org/10.1016/j.knosys.2025.114402},
url = {https://www.sciencedirect.com/science/article/pii/S0950705125014418},
author = {İsmail Enes Parlak},
keywords = {Explainable artificial intelligence (XAI), Blockchain, Decision traceability, Artificial intelligence accountability, Auditability},
abstract = {The increasing opacity and lack of verifiable audit trails in AI decision-making systems pose significant challenges to establishing trust and accountability, particularly in high-impact domains. This paper introduces Blockchain-Assisted Explainable Decision Traces (BAXDT), a novel architecture designed to enhance the transparency and auditability of AI systems. BAXDT creates comprehensive, immutable records for each AI decision by integrating model outputs, SHAP-based XAI summaries, a novel Explanation Density Metric, and detailed model/data context into a unified JSON trace. The 0.80 threshold for the Explanation Density Metric was empirically supported by Kneedle-based automatic threshold detection. The BAXDT architecture leverages blockchain by recording a cryptographic hash of each decision trace on-chain, while the full trace is stored off-chain. The system's effectiveness was demonstrated through a multi-faceted evaluation: simulations across three diverse public datasets (medical, financial, educational) confirmed its domain-agnostic applicability; a scalability analysis of up to 20,000 traces demonstrated its efficient and linear performance; and a successful deployment on the Ethereum Sepolia public testnet verified its real-world viability. A case study on text data further underscored the framework's flexibility. BAXDT provides a robust framework for documenting AI decisions - what, why, based on what, and when - thereby fostering trustworthy AI and supporting regulatory compliance.}
}
@article{WANG2025100676,
title = {Improving Artificial Intelligence–based Microbial Keratitis Screening Tools Constrained by Limited Data Using Synthetic Generation of Slit-Lamp Photos},
journal = {Ophthalmology Science},
volume = {5},
number = {3},
pages = {100676},
year = {2025},
issn = {2666-9145},
doi = {https://doi.org/10.1016/j.xops.2024.100676},
url = {https://www.sciencedirect.com/science/article/pii/S2666914524002124},
author = {Daniel Wang and Bonnie Sklar and James Tian and Rami Gabriel and Matthew Engelhard and Ryan P. McNabb and Anthony N. Kuo},
keywords = {Artificial intelligence, Microbial keratitis, Generative adversarial network, Slit-lamp photography, Cornea},
abstract = {Objective
We developed a novel slit-lamp photography (SLP) generative adversarial network (GAN) model using limited data to supplement and improve the performance of an artificial intelligence (AI)–based microbial keratitis (MK) screening model.
Design
Cross-sectional study.
Subjects
Slit-lamp photographs of 67 healthy and 36 MK eyes were prospectively and retrospectively collected at a tertiary care ophthalmology clinic at a large academic institution.
Methods
We trained the GAN model StyleGAN2-ADA on healthy and MK SLPs to generate synthetic images. To assess synthetic image quality, we performed a visual Turing test. Three cornea fellows tested their ability to identify 20 images each of (1) real healthy, (2) real diseased, (3) synthetic healthy, and (4) synthetic diseased. We also used Kernel Inception Distance (KID) to quantitatively measure realism and variation of synthetic images. Using the same dataset used to train the GAN model, we trained 2 DenseNet121 AI models to grade SLP images as healthy or MK with (1) only real images and (2) real supplemented with GAN-generated images.
Main Outcome Measures
Classification performance of MK screening models trained with only real images compared to a model trained with both limited real and supplemented synthetic GAN images.
Results
For the visual Turing test, the fellows on average rated synthetic images as good quality (83.3% ± 12.0% of images), and synthetic and real images were found to depict pertinent anatomy and pathology for accurate classification (96.3% ± 2.19% of images). These experts could distinguish between real and synthetic images (accuracy: 92.5% ± 9.01%). Analysis of KID score for synthetic images indicated realism and variation. The MK screening model trained on both limited real and supplemented synthetic data (area under the receiver–operator characteristic curve: 0.93, bootstrapping 95% CI: 0.77–1.0) outperformed the model trained with only real data (area under the receiver–operator characteristic curve: 0.76, 95% CI: 0.50–1.0), with an improvement of 0.17 (95% CI: 0–0.4; 2-tailed t test P = 0.076).
Conclusions
Artificial intelligence–based MK classification may be improved by supplementation of limited real training data with synthetic data generated by GANs.
Financial Disclosure(s)
Proprietary or commercial disclosure may be found in the Footnotes and Disclosures at the end of this article.}
}
@article{MATLIN2025101421,
title = {Artificial Intelligence in migrant health: a critical perspective on opportunities and risks},
journal = {The Lancet Regional Health - Europe},
volume = {57},
pages = {101421},
year = {2025},
issn = {2666-7762},
doi = {https://doi.org/10.1016/j.lanepe.2025.101421},
url = {https://www.sciencedirect.com/science/article/pii/S2666776225002133},
author = {Stephen A. Matlin and Iona M.M. Claron and Jessica Merone and Gina Netto and Amirhossein Takian and Muhammad Hamid Zaman and Luciano Saso},
abstract = {Summary
Rapid advances in Artificial Intelligence (AI) are leading to the proliferation of health applications. AI presents both opportunities and risks for migrants, including refugees, and asylum-seekers. This Personal View provides a critical perspective on opportunities and risks of using AI in migrant health. It synthesises literature insights to highlight the potential health benefits of AI, for both the general population and migrants, in areas including information retrieval, translation, education, empowerment, disease prevention and diagnosis, and personalised treatments. It addresses risks posed by AI, including the potential for tracking and monitoring individuals, which could threaten the anonymity and freedom of those using digital services, as well as the perpetuation or exacerbation of biases in the algorithms used. Current deficiencies in AI, including issues of quality and tendencies to sometimes invent data, as well as to reinforce existing biases and discriminatory processes, may also adversely impact on various groups of migrants coming from different parts of the world, compounding existing ethical challenges. Given the high level of digital infrastructure and opportunities for coherent policy-making and regulatory control within the region, Europe can provide leadership in developing guidelines, policies and agreements ensuring that AI serves migrants' health needs while not compromising their rights.}
}
@article{DELRE2025104488,
title = {Artificial intelligence in the development of small nucleic acid therapeutics: toward smarter and safer medicines},
journal = {Drug Discovery Today},
volume = {30},
number = {11},
pages = {104488},
year = {2025},
issn = {1359-6446},
doi = {https://doi.org/10.1016/j.drudis.2025.104488},
url = {https://www.sciencedirect.com/science/article/pii/S1359644625002016},
author = {Pietro Delre and Carmen Cerchia and Antonio Lavecchia},
keywords = {antisense oligonucleotides (ASOs), miRNA, siRNA, RNA interference, artificial intelligence (AI)},
abstract = {Small nucleic acid therapeutics, including antisense oligonucleotides (ASOs), small interfering (si)RNAs, miRNAs, and aptamers, modulate gene expression through complementary sequence recognition. Unlike traditional drugs, they can target previously inaccessible pathways and are showing promise for treating genetic, infectious, and degenerative diseases. Yet, their clinical translation is often constrained by poor stability and unpredictable pharmacokinetics. In this review, we focus on the main classes of small nucleic acid drugs, their mechanisms of action, and the chemical modifications that enhance their pharmacological properties. Importantly, we provide a critical comparison of different artificial intelligence (AI)-based methodologies for the design and optimization of oligonucleotide therapeutics, discuss their limitations (including data scarcity, off-target predictions, and clinical translation barriers), and outline concrete directions for future improvements.}
}
@article{WANG20251238,
title = {Application of Artificial Intelligence Large Models on Smart Culture and Tourism},
journal = {Procedia Computer Science},
volume = {261},
pages = {1238-1245},
year = {2025},
note = {The 5th International Conference on Machine Learning and Big Data Analytics for IoT Security and Privacy (SPIoT2024)},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2025.04.710},
url = {https://www.sciencedirect.com/science/article/pii/S1877050925018149},
author = {Bing Wang},
keywords = {Large-Scale, Artificial Intelligence, Model Smart, Cultural, tourism field},
abstract = {With the rapid development of information technology, artificial intelligence models are gradually becoming a key force driving innovation and change in various industries. In the field of smart tourism, artificial intelligence models have shown great potential for application. This article analyzes the connotation and development status of smart cultural tourism, introduces the advantages and application scenarios of artificial intelligence big models in smart cultural tourism, elaborates on the key links and special factors that need to be considered in building artificial intelligence models, and analyzes the challenges and countermeasures faced by the application of artificial intelligence big models in smart cultural tourism. Through in-depth exploration of the application of artificial intelligence models in the field of smart tourism, necessary references are provided for the intelligent upgrading of the tourism industry.}
}
@article{SMITH2025,
title = {From Automation to Innovation: How Artificial Intelligence Is Reshaping Global Industries},
journal = {Journal of the American College of Radiology},
year = {2025},
issn = {1546-1440},
doi = {https://doi.org/10.1016/j.jacr.2025.06.030},
url = {https://www.sciencedirect.com/science/article/pii/S1546144025003400},
author = {Jack Smith and Elliot K. Fishman and Linda C. Chu and Steven P. Rowe and Charles K. Crawford}
}
@article{KIM2025100803,
title = {“Demanding perfection, losing innovation”: The sequential mediating roles of psychological contract breach and knowledge-hiding behavior and the buffering effect of artificial intelligence technology acceptance},
journal = {Journal of Innovation & Knowledge},
volume = {10},
number = {5},
pages = {100803},
year = {2025},
issn = {2444-569X},
doi = {https://doi.org/10.1016/j.jik.2025.100803},
url = {https://www.sciencedirect.com/science/article/pii/S2444569X25001489},
author = {BYUNG-JIK KIM and JULAK LEE},
keywords = {Organizationally prescribed perfectionism, Artificial intelligence technology acceptance, Psychological contract breach, Knowledge-hiding behavior, Innovation, Structural equation modeling, M12, M15, O33},
abstract = {This study investigates how organizationally prescribed perfectionism (OPP) influences organizational innovation through the sequential mediating roles of psychological contract breach (PCB) and knowledge-hiding behavior (KHB), with artificial intelligence technology acceptance (AITA) demonstrating a moderating impact. Adopting a four-wave, time-lagged research design, data were gathered from 849 employed adults in South Korea, yielding 363 usable responses. The measurement model was evaluated using confirmatory factor analysis, which demonstrated the distinctiveness of the core constructs. Structural equation modeling assessed the hypothesized relationships and revealed that OPP had no direct effect on innovation; rather, its impact was mediated by PCB, which occurs when employees perceive the unyielding demands of an organization as violating mutual obligations, and subsequently by KHB, which refers to individuals withholding work-related information. This chain of unfavorable perceptions and behaviors ultimately diminishes organization-level innovation capacity. Furthermore, AITA functioned as a crucial buffer in the link between OPP and PCB, signifying that employees who were more receptive to AI tools were less likely to interpret perfectionistic standards as unfair. This study’s findings enhance the current theoretical discourse by highlighting a multi-level explanatory process that elucidates how externally imposed performance pressure erodes innovation potential. The results also demonstrate technological acceptance’s pivotal role in mitigating such challenges.}
}
@article{BORUGADDA2025,
title = {A Comprehensive Analysis of Artificial Intelligence, Machine Learning, Deep Learning and Computer Vision in Food Science},
journal = {Journal of Future Foods},
year = {2025},
issn = {2772-5669},
doi = {https://doi.org/10.1016/j.jfutfo.2025.07.002},
url = {https://www.sciencedirect.com/science/article/pii/S2772566925001235},
author = {Premkumar Borugadda and Hemantha Kumar Kalluri},
keywords = {artificial intelligence, computer vision, deep learning, food quality, food recognition, machine learning},
abstract = {ABSTRACT
Providing safe and quality food is crucial for every household and is of extreme significance in the growth of any society. It is a complex procedure that deals with all issues focusing on the development of food processing from seed to harvest, storage, preparation, and consumption. This current paper seeks to demystify the importance of Artificial Intelligence (AI), Machine Learning (ML), Deep Learning (DL), and Computer Vision (CV) in ensuring food safety and quality. By stressing the importance of these technologies, the audience will feel reassured and confident in their potential. These are very handy for such problems, giving assurance over food safety. CV is incredibly noble in today’s generation because it improves food processing quality and positively impacts firms and researchers. Thus, at the present production stage, rich in image processing and computer visioning is incorporated into all facets of food production. In this field, DL and ML are implemented to identify the type of food in addition to quality. Concerning data and result-oriented perceptions, one has found similarities regarding various approaches. As a result, the findings of this study will be helpful for scholars looking for a proper approach to identify the quality of food offered. It helps to indicate which food products have been discussed by other scholars and lets the reader know papers by other scholars inclined to research further. Also, deep learning is accurately integrated with identifying the quality and safety of foods in the market. This paper describes the current practices and concerns of ML, DL, and probable trends for its future development.}
}
@article{MULLAN2025104579,
title = {Use of artificial intelligence image generation to promote self-reflection and recognition of unconscious bias: A cross-sectional study of nursing students},
journal = {Nurse Education in Practice},
volume = {88},
pages = {104579},
year = {2025},
issn = {1471-5953},
doi = {https://doi.org/10.1016/j.nepr.2025.104579},
url = {https://www.sciencedirect.com/science/article/pii/S1471595325003361},
author = {Leanne Mullan and Bethany Arbuckle and Wendy Luck},
keywords = {Artificial Intelligence, AI, Nursing, Higher education, University, Self-reflection, Technology-enabled learning},
abstract = {Aim
To determine the value of an artificial intelligence (AI)-image generation learning sequence on higher-education nursing student self-reflection and recognition of unconscious bias in the context of disability.
Background
Self-reflection and recognition of bias amongst undergraduate nursing students enhances reasoning skills and self-awareness in clinical situations. Teaching self-reflection to a diverse cohort can be challenging, making it essential to develop and assess innovative technological tools that support engagement in reflective practice.
Design
A multi-methods approach was adopted, obtaining both quantitative and qualitative data for analysis through a survey.
Methods
Twenty-nine nursing students from the Australian Catholic University were surveyed. Qualitative data underwent both content and inductive thematic analysis. Quantitative data were summarised using descriptive statistics. The study is reported according to the Strengthening the Reporting of Observational Studies in Epidemiology (STROBE) cross-sectional study guideline.
Results
AI-image generation aided self-reflection on personal views about disability and recognition of potential personal and society biases towards disability amongst 90 % (n = 26) and 70 % of participants respectively. Visualisation of thoughts supported self-reflection and identification of generalisations held about disability. Eighty percent of respondents felt AI-image generation prompted them to consider how views and biases about disability may influence nursing practice. AI-image generation was identified to be an interesting and novel tool for self-reflection.
Conclusion
Findings suggest AI-image generation may be a useful tool in supporting students to practice self-reflection and identify unconscious biases. AI-image generation may assist students to consider how personal views can impact on clinical practice.}
}
@article{NIGAR2025100607,
title = {Artificial intelligence and technological unemployment: Understanding trends, technology's adverse roles, and current mitigation guidelines},
journal = {Journal of Open Innovation: Technology, Market, and Complexity},
volume = {11},
number = {3},
pages = {100607},
year = {2025},
issn = {2199-8531},
doi = {https://doi.org/10.1016/j.joitmc.2025.100607},
url = {https://www.sciencedirect.com/science/article/pii/S2199853125001428},
author = {Meher Nigar and Jannatul Ferdous Juli and Uttam Golder and Mohammad Jahangir Alam and Mohammad Kamal Hossain},
keywords = {Artificial intelligence, Technological unemployment, Open innovation in employment, Open innovation complexity},
abstract = {As artificial intelligence (AI) and automation continue to reshape industries, concerns about technological unemployment are intensifying. This study employs a Systematic Literature Review (SLR) guided by the PRISMA framework to examine peer-reviewed literature from the Scopus database (2015–July 09, 2025). It identifies three core themes: (1) trends in AI-induced labor displacement, including task automation, skill polarization, and industry-specific disruptions in sectors such as healthcare, education, and creative industries; (2) the adverse roles of AI technologies, particularly in affecting white-collar professionals, gig workers, and freelancers by increasing precarity and skill mismatches; and (3) existing mitigation strategies, including responsible AI guidelines proposed by governments, institutions, and firms aimed at balancing technological advancement with employment protection. While a growing body of policy responses encourages human-AI complementarity, current measures remain fragmented and insufficient to address the structural risks of workforce displacement. This study presents a comprehensive synthesis of the evolving relationship between AI and employment, highlighting key areas for further inquiry and policy development.}
}
@article{PINOTARRAGO2025100307,
title = {Artificial intelligence and soft skills in civil engineering education: A Latin American curriculum gap with global implications},
journal = {Research in Globalization},
volume = {11},
pages = {100307},
year = {2025},
issn = {2590-051X},
doi = {https://doi.org/10.1016/j.resglo.2025.100307},
url = {https://www.sciencedirect.com/science/article/pii/S2590051X25000401},
author = {Julio César {Pino Tarragó} and Dunia Lisbet {Domínguez Gálvez} and Julio Johnny {Regalado Jalca} and Erik Gabriel {Villavicencio Cedeño}},
keywords = {Curriculum development, Artificial intelligence, Soft skills, Engineering education, Industry 4.0, Higher education innovation, Latin America},
abstract = {This study analyzes the integration of Artificial Intelligence (AI) and the development of soft skills within the Civil Engineering program at the Universidad Estatal del Sur de Manabí (UNESUM) in Ecuador. Using a qualitative documentary analysis, the research examined 20 course syllabi and institutional curricular frameworks to assess the presence of socio-emotional competencies and emerging technologies. The findings reveal a fragmented and insufficient incorporation of soft skills, mainly restricted to transversal courses, and a complete absence of AI-related pedagogical content—even in technology-relevant subjects. These gaps indicate a structural misalignment between the graduate profile and the implemented curriculum. The study argues for a comprehensive curricular redesign that combines technical instruction with transversal competencies and leverages AI as a pedagogical resource. While based on a single Latin American institution, the results highlight broader systemic challenges in engineering education across developing regions, offering insights relevant to similar contexts. This paper contributes to the global discussion on curriculum innovation in the era of Industry 4.0.}
}
@article{KANG2025,
title = {Nurse Researchers’ Experiences and Perceptions of Generative AI: Qualitative Semistructured Interview Study},
journal = {Journal of Medical Internet Research},
volume = {27},
year = {2025},
issn = {1438-8871},
doi = {https://doi.org/10.2196/65523},
url = {https://www.sciencedirect.com/science/article/pii/S1438887125011495},
author = {Ruifu Kang and Zehui Xuan and Ling Tong and Yanling Wang and Shuai Jin and Qian Xiao},
keywords = {generative artificial intelligence, large language model, nurse researcher, nursing research, qualitative study},
abstract = {Background
With the rapid development and iteration of generative artificial intelligence, the growing popularity of such groundbreaking tools among nurse researchers, represented by ChatGPT (OpenAI), is receiving passionate debate and intrigue. Although there has been qualitative research on generative artificial intelligence in other fields, little is known about the experiences and perceptions of nurse researchers; this study seeks to report on the topic.
Objective
This study aimed to describe the experiences and perceptions of generative artificial intelligence among Chinese nurse researchers, as well as provide a reference for the application of generative artificial intelligence in nursing research in the future.
Methods
Semistructured interviews were used to collect data in this qualitative study. Researchers mainly conducted interviews on the cognition, experience, and future expectations of nurse researchers regarding the use of generative artificial intelligence. Twenty-seven nurse researchers were included in the study. Through purposive sampling and snowball sampling, there were 7 nursing faculty researchers, 10 nursing graduate students, and 10 clinical nurse researchers. Data were analyzed using inductive content analysis.
Results
Five themes and 12 subthemes were categorized from 27 original interview documents as follows: (1) diverse reflections on human-machine symbiosis, which includes the interplay between substitution and assistance, researchers shaping the potential of generative artificial intelligence, and acceptance of generative artificial intelligence with alacrity; (2) multiple factors of the usage experience, including individual characteristics and various usage scenarios; (3) research paradigm reshaping in the infancy stage, which involves full-process groundbreaking assistive tools and emergence of new research paths; (4) application risks of generative artificial intelligence, including intrinsic limitations of generative artificial intelligence and academic integrity and medical ethics; and (5) the co-improvement of technology and literacy, which concerns reinforcement needs for generative artificial intelligence literacy, development of nursing research generative artificial intelligence and urgent need for artificial intelligence–generated content detection tools. In this context, the first 4 themes form the rocket of the human-machine symbiosis journey. Only when humans fully leverage the advantages of machines (generative artificial intelligence) and overcome their shortcomings can this human-machine symbiosis journey reach the correct future direction (fifth theme).
Conclusions
This study explored the experiences and perceptions of nurse researchers interacting with generative artificial intelligence, which was a “symbiotic journey” full of twists and turns, and provides a reference and basis for achieving harmonious coexistence between nurse researchers and generative artificial intelligence in the future. Nurse researchers, policy makers, and application developers can use the conclusions of this study to further promote the application of generative artificial intelligence in nursing research, policy making, and product development.}
}
@article{YAN2025100903,
title = {Human-centric artificial intelligence towards Industry 5.0: retrospect and prospect},
journal = {Journal of Industrial Information Integration},
volume = {47},
pages = {100903},
year = {2025},
issn = {2452-414X},
doi = {https://doi.org/10.1016/j.jii.2025.100903},
url = {https://www.sciencedirect.com/science/article/pii/S2452414X25001268},
author = {Jiahe Yan and Zean Liu and Jiewu Leng and J.Leon Zhao and Chong Chen and Ding Zhang and Yong Tao and Yiwei Wang and Tingyu Liu and Chao Zhang and Yifei Tong and Dimitris Mourtzis and Lihui Wang},
keywords = {Human-centric AI, Human-AI collaboration, Human-centric, Industry 5.0, Embodied AI},
abstract = {The technology-driven Industry 4.0 paradigm is in a prosperous stage. Meanwhile, the industry is shifting towards a more human-centric, sustainable, and resilient paradigm, which is envisioned as a value-oriented Industry 5.0. Embodied Artificial Intelligence (AI) has shown promising benefits, but challenges persist in the proper orchestration between AI and human beings. Human-Centric Artificial Intelligence (HCAI) emphasizes that AI systems should enhance and complement human abilities rather than replace humans. It focuses on the interaction between humans and AI, aims to improve human well-being, and ensures that AI technologies are consistent with human values and needs. HCAI prioritizes user experience and ethical considerations by following three principles: being inspired by human intelligence, guided by human impact, and augmenting human capabilities. This paper examines the growing trend of deep integration between AI and human intelligence in industries, emphasizing that AI development necessitates the interdependence of technology, people, and ethics to create reliable, safe, and trustworthy systems. This paper conducts a detailed analysis of the evolution stages and modes of human-AI collaboration in industry. Based on an in-depth examination of enablers of HCAI models in industry, this paper examines HCAI applications for the product lifecycle management. Social barriers, technology challenges, and future research directions of HCAI are underscored, respectively. We believe that our effort lays a foundation for unlocking the power of HCAI during the transition from Industry 4.0 to Industry 5.0.}
}
@article{DIRKS2025813,
title = {The Future of the Future: Artificial Intelligence in Transforming Primary and Health Care},
journal = {Primary Care: Clinics in Office Practice},
volume = {52},
number = {4},
pages = {813-830},
year = {2025},
note = {AI in Primary Care},
issn = {0095-4543},
doi = {https://doi.org/10.1016/j.pop.2025.07.012},
url = {https://www.sciencedirect.com/science/article/pii/S0095454325000739},
author = {Radhika Dirks},
keywords = {AI, Primary care, Precision medicine, Ambient intelligence, Future of medicine}
}
@article{PARVAR20251173,
title = {Preserving humanity in health care advancement: How artificial intelligence in dermatologic care erodes and creates trust in patients},
journal = {Journal of the American Academy of Dermatology},
volume = {93},
number = {4},
pages = {1173-1175},
year = {2025},
issn = {0190-9622},
doi = {https://doi.org/10.1016/j.jaad.2025.05.1433},
url = {https://www.sciencedirect.com/science/article/pii/S0190962225022224},
author = {S. Yasamin Parvar and Vinod E. Nambudiri and Peter Lio and Travis W. Blalock},
keywords = {artificial intelligence, dermatology, humanities, teledermatology, trust, trustworthiness}
}
@article{RIVIERE2025878,
title = {Current perspectives and challenges of using artificial intelligence in immunodeficiencies},
journal = {Journal of Allergy and Clinical Immunology},
volume = {156},
number = {4},
pages = {878-888},
year = {2025},
issn = {0091-6749},
doi = {https://doi.org/10.1016/j.jaci.2025.06.015},
url = {https://www.sciencedirect.com/science/article/pii/S0091674925006918},
author = {Jacques G. Rivière and Roser Cantenys-Saba and Gerard Carot-Sans and Jordi Piera-Jiménez and Manish J. Butte and Pere Soler-Palacín and Xiao P. Peng},
keywords = {Artificial intelligence, machine learning, inborn errors of immunity, primary immunodeficiency, secondary immunodeficiency, predictive modeling, genomics, electronic health records, clinical decision support, implementation science, screening algorithm},
abstract = {The rapid growth of artificial intelligence (AI) in health care is promising for screening and early diagnosis in settings that heavily rely on professional expertise, such as rare diseases like inborn errors of immunity (IEI). However, the development of AI algorithms for IEI and other rare diseases faces important challenges such as dataset sizes, availability and harmonization. Similarly, the implementation of AI-based strategies for screening and diagnosis of IEI in real-world scenarios is hampered by multiple factors including stakeholders’ acceptance, ethical and legal constraints, and technologic barriers. Consequently, while the body of literature on AI-based solutions for early diagnosis of IEI continues to expand, clinical utility and widespread implementation remain limited. In this review, we provide an up-to-date comprehensive review of current applications and challenges facing AI use for IEI diagnosis and care.}
}
@article{WAKEFIELD2025104694,
title = {Artificial intelligence in prediction of postpartum hemorrhage: a primer and review},
journal = {International Journal of Obstetric Anesthesia},
volume = {63},
pages = {104694},
year = {2025},
issn = {0959-289X},
doi = {https://doi.org/10.1016/j.ijoa.2025.104694},
url = {https://www.sciencedirect.com/science/article/pii/S0959289X25002869},
author = {B.M. Wakefield and M.A. Zapf and H.B. Ende},
keywords = {Artificial Intelligence, Postpartum hemorrhage, Electronic Health Record, Risk Assessment, Machine Learning},
abstract = {Postpartum hemorrhage (PPH) is a leading cause of maternal mortality worldwide, and the ability to predict PPH may help address preventable causes of morbidity and mortality such as delays in care. Understanding the importance of standardized approaches to PPH, the National Partnership for Maternal Safety Consensus Bundle on Obstetric Hemorrhage outlines four critical domains for safe and effective PPH care: 1) Readiness; 2) Recognition and Prevention; 3) Response; and 4) Reporting and System Learning. The Recognition and Prevention domain includes recommendations for standardized methods of PPH risk prediction, and The Joint Commission now requires use of an evidence-based PPH prediction tool. Postpartum hemorrhage risk predictions can be accomplished via checklist tools completed manually by healthcare providers or via machine-assisted calculations in the form of logistic regression or machine learning populated by automated electronic health record data. The latter examples of machine-assisted calculations of PPH risk are a form of artificial intelligence. The purpose of this review is to describe the current state of AI-based PPH risk assessment, including the application of logistic regression and machine learning. A primer on interpretation of such models is provided, along with identification of research gaps and future directions.}
}
@article{NGUYEN2025,
title = {Artificial intelligence applications in the diagnosis and management of cleft lip and palate: An updated review},
journal = {Journal of Dental Sciences},
year = {2025},
issn = {1991-7902},
doi = {https://doi.org/10.1016/j.jds.2025.09.014},
url = {https://www.sciencedirect.com/science/article/pii/S1991790225003538},
author = {Tu Manh Nguyen and Uyen Ngoc Thao Huynh and Thi Thuy Tien Vo and Yang-Che Wu and Chien-Fu Tseng and I-Ta Lee},
keywords = {Artificial intelligence, Cleft lip and/or palate, Machine learning, Deep learning, Craniofacial anomalies},
abstract = {According to the U.S. National Institutes of Health, cleft lip and/or palate (CL/P) is one of the most common congenital anomalies, significantly affecting both function and aesthetics while placing a considerable burden on healthcare systems worldwide. With the rapid advancement of artificial intelligence (AI) in various medical fields, a thorough evaluation of its role in CL/P management has become essential. Therefore, this review was undertaken to summarize recent clinical applications of AI in the diagnosis, treatment, and care of CL/P. A comprehensive search of PubMed and IEEE Xplore was conducted from January 1, 2015, to May 31, 2025, using combined keywords related to AI and CL/P. Of the 134 records initially identified, 51 full-text articles met the eligibility criteria and were included in the final analysis. In conclusion, AI is driving innovation in CL/P management across multiple domains; however, further evidence from diverse populations and the establishment of clear ethical frameworks are required to ensure its long-term clinical applicability.}
}
@article{CASALO2025104130,
title = {Intelligence and humanness as key drivers of service value in Generative AI chatbots},
journal = {International Journal of Hospitality Management},
volume = {128},
pages = {104130},
year = {2025},
issn = {0278-4319},
doi = {https://doi.org/10.1016/j.ijhm.2025.104130},
url = {https://www.sciencedirect.com/science/article/pii/S0278431925000532},
author = {Luis V. Casaló and Paola Millastre-Valencia and Daniel Belanche and Carlos Flavián},
keywords = {Warmth, Competence, Automated social presence, Perceived value, Generative AI, Artificial intelligence levels},
abstract = {Automated service agents with different levels of artificial intelligence (AI) - mechanical, analytical, and emotional - are gradually replacing employees in their interactions with customers. Previous research suggests that these agents (e.g., chatbots) should embed human behavioral traits such as warmth, competence, and even automated social presence (i.e., perceiving that one is interacting with someone else). However, it is unknown whether different levels of AI are perceived by customers as features increasing humanness and, subsequently, leading to higher functional, monetary, social, or emotional value. Through an experimental design based on tourism chatbots, the results from structural equation analysis reveal that whereas mechanical AI decreases automated social presence, analytical AI increases perceptions of competence and warmth, and emotional AI improves all humanness cues. The article merges the research streams of service agent design and customers’ perceptions of humanness to guide tourism managers in implementing generative AI agents to increase service value.}
}
@article{LEE2025102089,
title = {Artificial Intelligence–Enabled ECG Screening for LVSD in LBBB: Evaluating Model Development and Transfer Learning Approaches},
journal = {JACC: Advances},
volume = {4},
number = {9},
pages = {102089},
year = {2025},
issn = {2772-963X},
doi = {https://doi.org/10.1016/j.jacadv.2025.102089},
url = {https://www.sciencedirect.com/science/article/pii/S2772963X25005149},
author = {Hak Seung Lee and Sooyeon Lee and Sora Kang and Ga In Han and Ah-Hyun Yoo and Jong-Hwan Jang and Yong-Yeon Jo and Jeong Min Son and Min Sung Lee and Joon-myoung Kwon and Kyung-Hee Kim},
keywords = {artificial intelligence, electrocardiogram, left bundle branch block, left ventricular systolic dysfunction},
abstract = {Background
Left bundle branch block (LBBB) is a common electrocardiogram (ECG) abnormality associated with left ventricular systolic dysfunction (LVSD). Although artificial intelligence (AI)–driven ECG analysis shows promise for LVSD screening, it remains unclear if a general AI-ECG model or one tailored for LBBB patients yields better performance.
Objectives
This study evaluates 4 AI-ECG models for detecting LVSD in LBBB patients and examines the impact of training cohort definitions.
Methods
We developed 4 models using 364,845 ECGs from 4 hospitals: 1) a general AI-ECG model; 2) a model trained on automatically extracted LBBB cases; 3) a model trained on a well-curated single-center LBBB data set with expert review; and 4) a hybrid model employing transfer learning by fine-tuning the general model with single-center LBBB data. LVSD was defined as an ejection fraction ≤40%. All models were externally validated on 1,334 ECGs from another hospital, with performance assessed by area under the receiver operating characteristic curve (AUROC), sensitivity, specificity, and predictive values.
Results
In external validation, the transfer learning model achieved the highest AUROC (0.903; 95% CI: 0.887-0.918), closely followed by the general model (0.899; 95% CI: 0.883-0.915); the difference was not significant. Models using automated or expert-based LBBB extraction had lower AUROCs (0.879 and 0.841, respectively). The general model demonstrated high sensitivity, whereas the transfer learning model exhibited superior specificity.
Conclusions
Our findings indicate that a broad AI-ECG model reliably detects LVSD in LBBB patients, and transfer learning offers modest improvements without requiring curated LBBB data sets. Evaluating algorithms in representative clinical populations is essential.}
}
@article{MCSWEENEY202583,
title = {Artificial Intelligence in the Business of Urology},
journal = {Urology},
volume = {203},
pages = {83-85},
year = {2025},
note = {The business of urology: A changing landscape},
issn = {0090-4295},
doi = {https://doi.org/10.1016/j.urology.2025.04.059},
url = {https://www.sciencedirect.com/science/article/pii/S0090429525004248},
author = {Sean T. McSweeney and Glenn T. Werneburg and Sandip P. Vasavada},
abstract = {Our invited review discusses the current and expanding role that artificial intelligence plays in the business of urology. Specifically, it highlights how artificial intelligence can not only provide cost-saving capabilities but also improve patient care and streamline urologist productivity.}
}
@article{ALABDOULI2025107636,
title = {Artificial intelligence and its performance impacts in the oil and gas industry: Challenges, insights, and evaluation approaches},
journal = {Results in Engineering},
volume = {28},
pages = {107636},
year = {2025},
issn = {2590-1230},
doi = {https://doi.org/10.1016/j.rineng.2025.107636},
url = {https://www.sciencedirect.com/science/article/pii/S2590123025036898},
author = {Mohamed Abdalla AlAbdouli and Sameh Al-Shihabi},
keywords = {Artificial intelligence, Thematic literature review, AI realization, Performance measurement, Oil and gas industry, Digital transformation},
abstract = {Oil and gas (O&G) companies are experimenting with artificial intelligence (AI) tools in exploration, production, and trading, but few are able to provide long-term benefits. This thematic review distinguishes basic AI adoption from AI realization—the sustainable ability to embed, scale, and profit from AI through coherent data, skills, and routines. Three research strands are synthesised. First, the literature consistently identifies three driver groups—people, technical, and managerial—that accelerate or hinder realization. Second, progress is usually gauged with three measurement families: text mining of corporate filings, proxy indicators such as AI-related patents or robot density, and survey-based capability indices. Third, realised AI affects three performance domains: operational, financial, and environmental. Within O&G, value chain stage (upstream, midstream, downstream) and ownership model (state-owned and privately owned) modulate both measurement validity and outcome strength. These strands are integrated into a conceptual synthesis that links drivers to gauges and gauges to results, stressing triangulation across indicators to limit bias. Triangulated dashboards linking capability scores to these outcomes expose trade-offs, such as efficiency gains that raise energy use. Recommended actions for practitioners include: connecting operational, financial, and sustainability databases; deploying an annual “AI readiness” survey covering data, talent, and governance; and adopting shared reporting rules that enable cross-company learning. For scholars, the paper highlights measurement gaps, suggests triangulated research designs, and maps boundary conditions needing further study. Together, the insights give executives a firmer basis for allocating AI budgets and give researchers a clearer roadmap toward comparative, evidence-based evaluation of AI value in complex, asset-intensive settings.}
}
@article{KUSZTOS2025102579,
title = {Challenges and Future Perspectives for Artificial Intelligence in Hepatology: Breaking Barriers for Better Care},
journal = {Journal of Clinical and Experimental Hepatology},
volume = {15},
number = {5},
pages = {102579},
year = {2025},
issn = {0973-6883},
doi = {https://doi.org/10.1016/j.jceh.2025.102579},
url = {https://www.sciencedirect.com/science/article/pii/S0973688325000799},
author = {Victoria E. Kusztos and Douglas A. Simonetto},
keywords = {artificial intelligence, machine learning, digital health},
abstract = {Artificial intelligence (AI) presents a compelling opportunity to revolutionize the practice of hepatology through a myriad of novel approaches ranging from predictive modeling to patient-specific clinical decision support systems. While AI will undoubtedly transform clinical practice in the coming years, there remains an evolving set of challenges to the implementation of AI. In this review article, we address technical and stakeholder barriers to the adoption of AI and potential repercussions if they remain unaddressed. We highlight strategies to mitigate these potential pitfalls and the need for prospective research to confirm model validity. Lastly, we look to the future of what AI in clinical practice will mean for patients and clinicians.}
}
@article{GREUTMANN2025105562,
title = {ESCMID workshop: Artificial intelligence and machine learning in medical microbiology diagnostics},
journal = {Microbes and Infection},
pages = {105562},
year = {2025},
issn = {1286-4579},
doi = {https://doi.org/10.1016/j.micinf.2025.105562},
url = {https://www.sciencedirect.com/science/article/pii/S1286457925000942},
author = {Mariella Greutmann and Karsten Borgwardt and Sarah Brüningk and Fabian Franzeck and Christian G. Giske and Anna G. Green and Alejandro Guerrero-López and Margaret Ip and Catherine Jutzeler and Andre Kahles and Michael Krauthammer and Nenad Macesic and Benjamin McFadden and Eline Meijer and Nathan Moore and Jacob Moran-Gilad and Imane Lboukili and Oliver Nolte and Robin Patel and Gerold Schneider and Markus A. Seeger and Tavpritesh Sethi and Robert L. Skov and Chang Ho Yoon and Belén Rodríguez-Sánchez and Adrian Egli},
keywords = {Conference report, Meeting report, Artificial intelligence, Machine learning, Diagnostics, Medical microbiology},
abstract = {Rapid advancements in artificial intelligence (AI) and machine learning (ML) offer significant potential to transform medical microbiology diagnostics, improving pathogen identification, antimicrobial susceptibility prediction and outbreak detection. To address these opportunities and challenges, the ESCMID workshop, “Artificial Intelligence and Machine Learning in Medical Microbiology Diagnostics”, was held in Zurich, Switzerland, from June 2–5, 2025. The course featured expert lectures, practical sessions and panel discussions covering foundational ML concepts and deep learning architectures, data interoperability, quality control processes, model development and validation strategies. Key applications discussed included whole-genome sequencing for antimicrobial resistance detection, AI-enhanced digital microscopy automation and MALDI-TOF mass spectrometry-based diagnostics. Participants gained hands-on experience with essential AI tools and platforms. Special emphasis was placed on standardised laboratory protocols, regulatory compliance and ethical considerations, including data governance and patient privacy. Panel sessions further highlighted critical issues of equity, global disparities in AI access, sustainability and environmental impacts related to AI infrastructure. The workshop concluded by underscoring a necessity for ongoing interdisciplinary collaboration, continued education, and substantial investment in equitable AI infrastructure to realise the full potential of AI in clinical diagnostics.}
}
@article{POWELL2025,
title = {Agentic Artificial Intelligence: The Power to Change Medicine and Our World},
journal = {Journal of the American College of Radiology},
year = {2025},
issn = {1546-1440},
doi = {https://doi.org/10.1016/j.jacr.2025.06.032},
url = {https://www.sciencedirect.com/science/article/pii/S1546144025003424},
author = {Kimberly Powell and Elliot K. Fishman and Linda C. Chu and Steven P. Rowe and Charles K. Crawford}
}
@article{SAHEB2024100146,
title = {Convergence of artificial intelligence with social media: A bibliometric & qualitative analysis},
journal = {Telematics and Informatics Reports},
volume = {14},
pages = {100146},
year = {2024},
issn = {2772-5030},
doi = {https://doi.org/10.1016/j.teler.2024.100146},
url = {https://www.sciencedirect.com/science/article/pii/S277250302400032X},
author = {Tahereh Saheb and Mouwafac Sidaoui and Bill Schmarzo},
keywords = {Social media, Artificial intelligence, Bibliometric analysis, Qualitative research},
abstract = {The integration of artificial intelligence (AI) and social media has provided numerous benefits to businesses, including improved audience analysis and content optimization. However, AI has facilitated the spread of misinformation, emphasizing the importance of taking a balanced approach that considers both the technology's positive applications and its ethical risks. This paper looks at the intersection of AI and social media. The researchers use a mixed-method approach to analyze 1540 scholarly documents, combining bibliometric and systematic literature review techniques. The goal of this research is to identify the most important topics and trends, as well as potential business values and implications, in the AI Social Media domain. The first stage of the research involved a quantitative keyword co-occurrence analysis, which resulted in the identification of ten dominant themes. These include Conversational Agents & User Experience, Human Emotion and Content Recommendation & Moderation, Collective Intelligence in Emergency Management, Algorithmic Activism on social media, Deep Fakes and Fake News, Generative Artificial Intelligence, Algorithmic Bias in Content Moderation Systems, Deep Sentiment Analysis, Metaverse Technologies, and NLP & Mental Health Detection. Each identified theme is then subjected to a qualitative thematic literature review, which provides a more in-depth, context-specific understanding of the associated findings. Because of this comprehensive approach, the study provides a broad overview of the current state of AI social media, shedding light on the potential applications and far-reaching implications of this interdisciplinary nexus. The study's findings have the potential to shape strategic decision-making, policy development, and future research directions in this rapidly changing field.}
}
@article{CHENG20252724,
title = {Inter-organizational knowledge sharing in the age of artificial intelligence: the mediating role of knowledge digitization and cross-language collaboration},
journal = {Journal of Knowledge Management},
volume = {29},
number = {8},
pages = {2724-2744},
year = {2025},
issn = {1367-3270},
doi = {https://doi.org/10.1108/JKM-12-2024-1423},
url = {https://www.sciencedirect.com/science/article/pii/S1367327025000560},
author = {Qiang Cheng and Shuangyang Zhang and Lili Wang and Ya Lu},
keywords = {Inter-organizational knowledge sharing, Artificial intelligence generated content, Knowledge digitization, Cross-language collaboration},
abstract = {Purpose
The mode of inter-organizational knowledge sharing (IKS) in the age of artificial intelligence (AI) has undergone new changes, and AI technology provides new tools for improving the efficiency of inter-organizational knowledge sharing. This paper aims to investigate the impact of artificial intelligence generated content (AIGC) on inter-organizational knowledge sharing. Specifically, this paper seeks to uncover how AI technology can be leveraged to facilitate knowledge flow and innovation, and ultimately enhance the efficiency and competitiveness of inter-organizational collaborations.
Design/methodology/approach
The data comes from 323 members of digital groups with AI technology foundation and participating in inter-organizational cooperation or collaborative innovation activities across China. Using structural equation modeling, the chain-mediated relationship between AIGC, knowledge digitization (KD), cross-language collaboration (CLC) and inter-organizational knowledge sharing is examined.
Findings
The study findings indicate that AIGC has a significant positive impact on inter-organizational knowledge sharing, with knowledge digitization and cross-language collaboration playing a chain-mediated role.
Originality/value
This study bridges the gap in the literature regarding AIGC’s role in enhancing knowledge generation and flow among organizations. It introduces two mediating variables: knowledge digitization and cross-language collaboration. In addition, it develops a measurement scale for cross-language collaboration, addressing a quantitative research gap in this area.}
}
@article{BINGOL2025101380,
title = {Integrating smart technologies and artificial intelligence to build smart tourism destination ecosystems: A model for smart destination management},
journal = {Tourism Management Perspectives},
volume = {58},
pages = {101380},
year = {2025},
issn = {2211-9736},
doi = {https://doi.org/10.1016/j.tmp.2025.101380},
url = {https://www.sciencedirect.com/science/article/pii/S2211973625000455},
author = {Serhat Bingöl and Yang Yang},
keywords = {Smart tourism, Smart destination management, Smart destination ecosystem, Smart technologies, Artificial intelligence, United States},
abstract = {This study explores how smart technologies and artificial intelligence transform destination management into smart destination management in urban destinations in the United States. Hence, primary and secondary data were collected in ten cities in the United States through qualitative research to provide multiple perspectives. The secondary data consisted of smart technologies and artificial intelligence initiatives published by Destination Management/Marketing Organizations, Departments of Transportation, and Technology Offices across these cities. The authors also interviewed professionals from these organizations, including initiative leaders, project managers, marketing specialists, and data analysts. The study revealed that these destinations have created smart technologies and artificial intelligence initiatives to transform destination management into smart destination management by developing destination ecosystems. The study proposes a smart destination model that guides destinations in adopting smart technologies and artificial intelligence initiatives to build smart destination ecosystems. The results offer conceptual, theoretical, and practical applications for enhancing destination management.}
}
@article{ARSEVEN2025101850,
title = {Critical literacy in artificial intelligence assisted writing instruction: A systematic review},
journal = {Thinking Skills and Creativity},
volume = {57},
pages = {101850},
year = {2025},
issn = {1871-1871},
doi = {https://doi.org/10.1016/j.tsc.2025.101850},
url = {https://www.sciencedirect.com/science/article/pii/S1871187125000999},
author = {Tülin Arseven and Mazhar Bal},
keywords = {Writing skills, Artificial intelligence, Artificial intelligence-assisted writing, Critical literacy, K-12 education, Systematic review},
abstract = {This systematic review aims to examine the relationship between artificial intelligence (AI)- assisted writing instruction and critical literacy skills of K-12 students. As a result of searching Web of Science (WoS), Scopus, Education Resources Information Center (ERIC), and EBSCO databases in accordance with the criteria determined, 15 studies were included in the analysis. As a result of the descriptive analysis, five main themes were identified: critical content production and evaluation, metacognitive skills and self-regulation, ethical thinking and evaluation, analytical thinking and problem solving, motivation and self-efficacy for the AI-assisted writing process and critical literacy skills. Our findings show that students use AI tools not as a simple copy-paste tool, but as a supportive element to develop their thinking. Students question AI outputs, synthesize them with their own ideas and manage their writing processes more consciously. The findings of our study reveal that AI-assisted writing experiences increase students' ethical awareness of originality, academic honesty and creativity, improve their systematic thinking skills in complex writing tasks, and increase their motivation to write. However, the lack of any study at preschool level, the limited number of studies at primary school level, and the scarcity of qualitative studies indicate that more research is needed in this field.}
}
@article{RODGER2025104461,
title = {Generative AI in healthcare education: How AI literacy gaps could compromise learning and patient safety},
journal = {Nurse Education in Practice},
volume = {87},
pages = {104461},
year = {2025},
issn = {1471-5953},
doi = {https://doi.org/10.1016/j.nepr.2025.104461},
url = {https://www.sciencedirect.com/science/article/pii/S1471595325002173},
author = {Daniel Rodger and Sebastian Porsdam Mann and Brian Earp and Julian Savulescu and Christopher Bobier and Bruce P. Blackshaw},
keywords = {Artificial intelligence, Nursing, Chatbot, ChatGPT, Generative artificial intelligence, Machine learning, Patient safety, Workforce, Literacy, Universities, AI},
abstract = {Aim
To examine the challenges and opportunities presented by generative artificial intelligence in healthcare education and explore how it can be used ethically to enhance rather than compromise future healthcare workforce competence.
Background
Generative artificial intelligence is fundamentally changing healthcare education, yet many universities and healthcare educators have failed to keep pace with its rapid development.
Design
A discussion paper.
Methods
Discussion and analysis of the challenges and opportunities presented by students' increasing use of generative artificial intelligence in healthcare education, with particular focus on assessment approaches, critical thinking development and artificial intelligence literacy.
Results
Students' widespread use of generative artificial intelligence threatens assessment integrity and may inhibit critical thinking, problem-solving skills and knowledge acquisition. Without adequate artificial intelligence literacy there is a risk of eroding future healthcare workforce competence and compromising patient safety and professional integrity.
Conclusion
While generative artificial intelligence presents significant challenges to healthcare education, it offers great promise if used carefully with awareness of its limitations. The development of artificial intelligence literacy is crucial for maintaining professional standards and ensuring patient safety and mitigating its potentially negative impact on the formation of critical thinking skills.}
}
@article{ARZA2025529,
title = {Applications of Artificial Intelligence in Dermatology: Ethical Considerations},
journal = {Dermatologic Clinics},
volume = {43},
number = {4},
pages = {529-540},
year = {2025},
note = {Artificial Intelligence in Dermatology},
issn = {0733-8635},
doi = {https://doi.org/10.1016/j.det.2025.05.003},
url = {https://www.sciencedirect.com/science/article/pii/S0733863525000427},
author = {Alexis Arza and Jamie Lebhar and Jules B. Lipoff},
keywords = {Artificial intelligence, Deep learning, Machine learning, Dermatology, Ethics, Teledermatology}
}
@article{OZMEN202470,
title = {Future of artificial intelligence in plastic surgery: Toward the development of specialty-specific large language models},
journal = {Journal of Plastic, Reconstructive & Aesthetic Surgery},
volume = {93},
pages = {70-71},
year = {2024},
issn = {1748-6815},
doi = {https://doi.org/10.1016/j.bjps.2024.04.054},
url = {https://www.sciencedirect.com/science/article/pii/S1748681524002353},
author = {Berk B. Ozmen and Graham S. Schwarz},
keywords = {Artificial intelligence, Large language models, Generative AI, Clinical decision support, Surgical education, Evidence-based medicine}
}
@incollection{MUNSHI2025,
title = {Artificial intelligence for cell-free systems},
series = {Progress in Molecular Biology and Translational Science},
publisher = {Academic Press},
year = {2025},
issn = {1877-1173},
doi = {https://doi.org/10.1016/bs.pmbts.2025.08.009},
url = {https://www.sciencedirect.com/science/article/pii/S1877117325001681},
author = {Ingita Dey Munshi and Indra Mani},
keywords = {Artificial intelligence, Cell-free systems, Synthetic biology, Machine learning, Deep learning},
abstract = {Cell-free systems let researchers carry out biological processes like protein synthesis and metabolism without using living cells. This approach has become increasingly important in synthetic biology because it allows for quick testing of ideas, running many experiments simultaneously, and maintaining tight control over reaction conditions. The main challenge has been figuring out how to optimize these systems, since there are so many variables that interact in unpredictable ways. Artificial intelligence (AI), including machine learning, deep learning, and generative models, has begun to tackle this problem by helping predict experimental outcomes, design new proteins, and find better reaction conditions. The discovery of antimicrobial peptides through deep learning and cell-free protein synthesis, along with a 34-fold increase in protein yield through buffer optimization guided by active learning, are some of the major advancements made possible. The use of Bayesian optimization and neural networks has helped to streamline metabolic pathway designing, enzyme engineering as well as yield prediction, which in turn has diversified the use of AI-driven approaches in biomanufacturing, pharmaceuticals, and diagnostics. In spite of hurdles like data requirements, model transferability, and scalability, the compatibility of AI and cell-free systems gives adequate probabilities of innovations like digital twins and self-driven biomanufacturing units. This chapter explores the integration of AI with cell-free systems, focusing on recent advances, industrial applications, and ending with future directions for synthetic biology.}
}
@article{ZHU2025108640,
title = {Artificial intelligence, digital financial development, and corporate innovation performance},
journal = {Finance Research Letters},
volume = {86},
pages = {108640},
year = {2025},
issn = {1544-6123},
doi = {https://doi.org/10.1016/j.frl.2025.108640},
url = {https://www.sciencedirect.com/science/article/pii/S154461232501894X},
author = {Yufei Zhu and Xiaoxu Zhao and Yaqi Liu},
keywords = {Artificial intelligence use, Corporate innovation performance, Digital finance, A-share listed companies},
abstract = {This study analyzes Chinese A-share listed companies from 2014 to 2023 to explore the impact of corporate AI adoption on innovation performance and the moderating role of digital finance. Findings show that AI adoption significantly boosts innovation performance, with regional digital finance, particularly its coverage, usage, and digitalization—further enhancing this effect. Heterogeneity analysis indicates stronger effects in non-state-owned firms and high-tech industries. Additionally, AI exerts a greater influence on green innovation than on non-green innovation. The results offer theoretical insights and practical guidance for enterprises implementing AI and for policymakers designing innovation-supporting strategies.}
}
@article{PANCHPURI2025882,
title = {Artificial intelligence in smart drug delivery systems: a step toward personalized medicine},
journal = {RSC Pharmaceutics},
volume = {2},
number = {5},
pages = {882-914},
year = {2025},
issn = {2976-8713},
doi = {https://doi.org/10.1039/d5pm00089k},
url = {https://www.sciencedirect.com/science/article/pii/S2976871325000481},
author = {Mitali Panchpuri and Ritu Painuli and Chetan Kumar},
abstract = {One of the most interesting applications of artificial intelligence is in the design of drug delivery systems. Smart drug delivery systems can transfer drugs to specific tissues and cells, enhancing therapeutic effects while reducing undesirable side effects. Attention is focused on the main concepts and techniques of AI such as machine learning, deep learning, and genetic algorithms. In addition to this, genetic algorithms can be used for the selection of the best numerical models, which are able to predict biological processes or optimize the activity of new drugs. Besides the powerful impact of AI on drug design, its combination with new biotechnologies for personalized medicine, sometimes called theragnostics, brings novel diagnostic tools together with targeted therapy, which could ensure quality and effectiveness during clinical research on new drugs. Artificial intelligence (AI) techniques are finding their application in almost all disciplines, with particular success in healthcare. AI-based algorithms can solve complex problems related to diagnosis, prediction, control, and prevention of diseases that are beyond the scope of human abilities. At the same time, the Internet of Things (IoT) revolution has added value to the healthcare sector. The resulting combination of IoT and AI platforms presents a promising fusion to provide healthcare delivery innovations like digital drug delivery, online healthcare consultancy platforms, and virtual healthcare assistants. Personalized medicine is well-suited, regardless of potential disadvantages, to creating drug delivery systems that can respond to the exact needs and other special requirements of patients. The development of smart drug delivery systems is a potential response to the unimodal properties of drugs and the discordance between patient requirements and patient outcomes achieved by currently prescribed medications. The potential and actual positive economic and health-related impacts of advanced drug delivery technologies have created strong demand for new advanced delivery forms.}
}
@article{LAAMANEN2025102561,
title = {Artificial intelligence in adaptive strategy creation and implementation: Toward enhanced attentional control in strategy processes},
journal = {Long Range Planning},
volume = {58},
number = {4},
pages = {102561},
year = {2025},
issn = {0024-6301},
doi = {https://doi.org/10.1016/j.lrp.2025.102561},
url = {https://www.sciencedirect.com/science/article/pii/S0024630125000640},
author = {Tomi Laamanen and Ann-Kristin Weiser and Georg {von Krogh} and William Ocasio},
keywords = {Artificial intelligence, Attention-Based View, Attentional Control, Strategy process, Adaptive Strategy Creation and Implementation},
abstract = {This article focuses on the deployment of proprietary artificial intelligence (AI) systems in strategy creation and implementation processes, with a specific focus on their role in enhancing organizational attentional control. By employing the attention-based view (ABV) as an overarching theoretical framework, we examine how company-specific AI systems trained on proprietary data can support strategy processes. We identify three key contributions of AI in strategy creation and implementation processes: (1) broadening organizational attention to external and internal developments, (2) democratizing strategic processes through improved transparency and inclusivity, and (3) accelerating feedback loops with real-time monitoring of strategy implementation progress. Potential challenges associated with the deployment of AI systems for attentional control are also addressed. The paper concludes by putting forward potential directions for future research.}
}
@article{ARORA2025152100,
title = {Preserving medical ethics in the era of artificial intelligence: Challenges and opportunities in neonatology},
journal = {Seminars in Perinatology},
volume = {49},
number = {6},
pages = {152100},
year = {2025},
note = {Neonatal Ethics},
issn = {0146-0005},
doi = {https://doi.org/10.1016/j.semperi.2025.152100},
url = {https://www.sciencedirect.com/science/article/pii/S0146000525000771},
author = {Tanima Arora and Habeebah Muhammad-Kamal and Kristyn Beam},
keywords = {Artificial intelligence, Bias, Clinical decision support, Neonatology},
abstract = {The integration of artificial intelligence (AI) into neonatology offers improved patient care while raising ethical challenges across four principles: beneficence, non-maleficence, justice, and autonomy. AI enhances prediction and early detection capabilities, but introduces concerns including the “black box” nature of many algorithms, which compromises transparency and may propagate existing biases. Justice considerations arise from potential inequities in AI development and deployment. Autonomy is challenged when clinicians cannot fully explain algorithmic decision-making, affecting shared decision-making with families. These ethical tensions are particularly acute in neonatology, where decisions impact vulnerable patients who cannot advocate for themselves. Mitigating these challenges requires developing transparent AI systems, ensuring diverse training data, maintaining human oversight of clinical decisions, and conducting rigorous validation across diverse healthcare settings. Responsible implementation requires balancing technological benefits with ethical principles.}
}
@article{HADIDABARZILAI2025102152,
title = {Randomized Controlled Trials Evaluating Artificial Intelligence in Cardiovascular Care: A Systematic Review},
journal = {JACC: Advances},
volume = {4},
number = {11, Part 1},
pages = {102152},
year = {2025},
issn = {2772-963X},
doi = {https://doi.org/10.1016/j.jacadv.2025.102152},
url = {https://www.sciencedirect.com/science/article/pii/S2772963X25005770},
author = {Dor {Hadida Barzilai} and Karin Sudri and Gal Goshen and Eyal Klang and Eyal Zimlichman and Israel Barbash and Michal {Cohen Shelly}},
keywords = {artificial intelligence, cardiovascular care, clinical outcome, machine learning, randomized controlled trial, systematic review},
abstract = {Background
Artificial intelligence (AI) has shown promise in transforming health care, particularly in cardiology. However, there is a lack of high-quality evidence demonstrating its impact on crucial clinical outcomes.
Objectives
The purpose of this study was to synthesize existing evidence from randomized controlled trials (RCTs) on the application of AI in cardiology, evaluating its impact on key clinical outcomes.
Methods
We conducted a systematic review following Preferred Reporting Items for Systematic Reviews and Meta-Analyses (PRISMA) guidelines, searching MEDLINE, Web of Science, and the Cochrane Library from inception to November 2024. We included RCTs evaluating machine learning models compared to traditional methods in cardiovascular care. Primary outcomes focused on patient-important metrics, while secondary outcomes covered time and resource savings.
Results
Eleven RCTs met the inclusion criteria. Studies were conducted between 2021 and 2024, with 81.2% being multicenter trials. Five studies (45.5%) reported improvements in clinical events, 6 (54.5%) showed enhanced diagnostic accuracy and early detection, and 3 (27.3%) demonstrated improved resource utilization.
Conclusions
This review highlights AI's potential to enhance cardiovascular care through improved early detection, diagnostic accuracy, and resource efficiency. However, the limited number of RCTs indicates a need for more high-quality studies to validate AI’s effectiveness across various clinical domains.}
}
@article{HOELSCHER2025102466,
title = {N.U.R.S.E.S. embracing artificial intelligence: A guide to artificial intelligence literacy for the nursing profession},
journal = {Nursing Outlook},
volume = {73},
number = {4},
pages = {102466},
year = {2025},
issn = {0029-6554},
doi = {https://doi.org/10.1016/j.outlook.2025.102466},
url = {https://www.sciencedirect.com/science/article/pii/S0029655425001198},
author = {Stephanie H. Hoelscher and Ashley Pugh},
keywords = {Nursing education, Digital health literacy, AI literacy, Healthcare technology, Informatics, Workforce development},
abstract = {Artificial intelligence (AI) is reshaping health care, making AI literacy vital for nursing professionals. The Navigate AI basics, Utilize AI strategically, Recognize AI pitfalls, Skills support, Ethics in action, and Shape the future framework provides a structured approach to AI integration into nursing. Nurses need to understand AI’s fundamentals and its impact on clinical practice and patient care, both in the classroom and at the bedside. Nurses can use AI effectively and responsibly by recognizing benefits, such as enhanced decision-making, and challenges, like biased data. Ethical considerations should guide AI usage in health care, with a commitment to frequent skill development. Nurses play a pivotal role in shaping the future by ensuring AI is applied to benefit their organizations and, more importantly, healthcare workers and patients. This AI literacy guide is designed to empower nurses to navigate and help build the future of health care and AI with confidence and competence.}
}
@article{REGMI2025103240,
title = {Artificial intelligence in severe rigid Scoliosis: Opportunities, challenges, and the road ahead},
journal = {Journal of Clinical Orthopaedics and Trauma},
volume = {71},
pages = {103240},
year = {2025},
issn = {0976-5662},
doi = {https://doi.org/10.1016/j.jcot.2025.103240},
url = {https://www.sciencedirect.com/science/article/pii/S0976566225003388},
author = {Anil Regmi and Bishwa Bandhu Niraula},
keywords = {Artificial intelligence, Severe rigid scoliosis, Surgical navigation, Cobb angle measurement, Explainable AI},
abstract = {Severe rigid scoliosis remains one of the most complex challenges in spine surgery, characterized by three-dimensional deformity, progressive rigidity, and high perioperative risks. Traditional surgical planning and correction strategies are limited by variability in anatomical presentations, difficulty in predicting outcomes, and the need for meticulous intraoperative decision-making. In recent years, artificial intelligence (AI) has emerged as a promising tool to address these challenges, offering applications in imaging analysis, deformity classification, surgical planning, navigation, and outcome prediction. This review explores the current opportunities of AI in the management of severe rigid scoliosis, critically examines its limitations, and outlines the future roadmap toward integration in precision spine surgery.}
}
@article{SPAETHCOOK2025,
title = {JACR Expert Panel: Artificial Intelligence in Radiology Residency Training},
journal = {Journal of the American College of Radiology},
year = {2025},
issn = {1546-1440},
doi = {https://doi.org/10.1016/j.jacr.2025.08.003},
url = {https://www.sciencedirect.com/science/article/pii/S1546144025004521},
author = {Douglas Spaeth-Cook and Morgan P. McBee and Margaret C. Lin and Peter D. Chang and Elias G. Kikano}
}
@article{LANICCA2025102971,
title = {Readability of Orthopaedic Patient Educational Material: An artificial intelligence application},
journal = {Journal of Clinical Orthopaedics and Trauma},
volume = {64},
pages = {102971},
year = {2025},
issn = {0976-5662},
doi = {https://doi.org/10.1016/j.jcot.2025.102971},
url = {https://www.sciencedirect.com/science/article/pii/S0976566225000670},
author = {Miles LaNicca and Ellis Wright and Ellen Lutnick},
keywords = {Patient education, Patient education material, Readability, Reading, Artificial intelligence, Artificial intelligence software, Orthopedic surgery},
abstract = {Background
This study aims to determine the efficacy of the use of artificial intelligence (AI) in rewriting orthopaedic trauma hospital patient educational materials to a patient-appropriate reading level.
Materials and methods
35 orthopaedic patient educational articles were identified from three hospital networks with Level 1 Trauma Centers, categorized based on average reading level. They were run through a formatting Python code, and then a secondary code to determine readability metrics outlined in Table 1. The articles were then rewritten via four iterations of Generative Pre-Trained Transformer (GPT) AI language models. Each model was given the same prompt, outlined in Fig. 1, to rewrite the articles to a 6th grade reading level per AMA recommendations. The rewritten articles were checked for accuracy and formatted and scored to determine mean reading level. Additional analysis was run comparing 9 different AI models from 3 different companies, using the same prompt, comparing cost and percent token reduction.
Results
All GPT AI models lowered the mean combined grade level (Table 2). Fig. 2 compares each GPT model's output to the original articles reading grade level. The oldest model (GPT-3.5-Turbo) was the least consistent and least effective. GPT-4o-Mini and GPT-4o were the most effective and consistent regardless of original article difficulty. Table 3 outlines the cost of running all 35 articles through each GPT model. The most accurate model (GPT-4o) was only $0.61; however, there was only a 0.421 % increase in effectiveness comparing GPT-4o vs. GPT-4o-Mini, at a 175.38 % increase in cost. All GPT rewritten articles were screened for accuracy and determined to have no falsified information or medical inaccuracies. Expanded analysis across 9 AI models is demonstrated in Fig. 4. Fig. 5 compares cost and percent token reduction.
Conclusion
AI is a viable option for reducing the reading difficulty of patient educational materials while maintaining accuracy. Of the models included for analysis, GPT-4o-Mini appears to be the most efficient language model when considering effectiveness, cost, and maintenance of the information included in the original articles.}
}
@article{CAI2025111577,
title = {Medical artificial intelligence for early detection of lung cancer: A survey},
journal = {Engineering Applications of Artificial Intelligence},
volume = {159},
pages = {111577},
year = {2025},
issn = {0952-1976},
doi = {https://doi.org/10.1016/j.engappai.2025.111577},
url = {https://www.sciencedirect.com/science/article/pii/S0952197625015799},
author = {Guohui Cai and Ying Cai and Zeyu Zhang and Yuanzhouhan Cao and Lin Wu and Daji Ergu and Zhibin Liao and Yang Zhao},
keywords = {Lung cancer detection, Deep learning, Artificial intelligence, Pulmonary nodule detection, Computer-aided diagnosis, Pulmonary nodule segmentation and classification},
abstract = {Lung cancer remains one of the leading causes of morbidity and mortality worldwide, making early diagnosis critical for improving therapeutic outcomes and patient prognosis. Computer-aided diagnosis systems, which analyze computed tomography images, have proven effective in detecting and classifying pulmonary nodules, significantly enhancing the detection rate of early-stage lung cancer. Although traditional machine learning algorithms have been valuable, they exhibit limitations in handling complex sample data. The recent emergence of deep learning has revolutionized medical image analysis, driving substantial advancements in this field. This review focuses on recent progress in deep learning for pulmonary nodule detection, segmentation, and classification. Traditional machine learning methods, such as support vector machines and k-nearest neighbors, have shown limitations, paving the way for advanced approaches like Convolutional Neural Networks, Recurrent Neural Networks, and Generative Adversarial Networks. The integration of ensemble models and novel techniques is also discussed, emphasizing the latest developments in lung cancer diagnosis. Deep learning algorithms, combined with various analytical techniques, have markedly improved the accuracy and efficiency of pulmonary nodule analysis, surpassing traditional methods, particularly in nodule classification. Although challenges remain, continuous technological advancements are expected to further strengthen the role of deep learning in medical diagnostics, especially for early lung cancer detection and diagnosis. A comprehensive list of lung cancer detection models reviewed in this work is available at https://github.com/CaiGuoHui123/Awesome-Lung-Cancer-Detection.}
}
@article{SOURIAL2025101455,
title = {A Pilot Study Using Artificial Intelligence to Enhance Efficiency, Accuracy, and Objectivity in Grading Pharmacy Objective Structured Clinical Examinations},
journal = {American Journal of Pharmaceutical Education},
volume = {89},
number = {8},
pages = {101455},
year = {2025},
issn = {0002-9459},
doi = {https://doi.org/10.1016/j.ajpe.2025.101455},
url = {https://www.sciencedirect.com/science/article/pii/S0002945925001007},
author = {Mariette Sourial and Jeremy C. Hagler},
keywords = {Performance-based assessment (PBA), Objective structured clinical examination (OSCE), Artificial intelligence (AI), Large language model (LLM)},
abstract = {Objective
The goal of this project was to evaluate the feasibility of using artificial intelligence (AI) in grading pharmacy Objective Structured Clinical Examination (OSCE) analytical checklists in terms of accuracy, objectivity and consistency, and efficiency compared to faculty evaluators.
Methods
Third-year pharmacy students (n = 39) enrolled in a private Christian university completed a 5-station OSCE as part of the Advanced Pharmacy Practice Experience-readiness plan. Audio recordings from 2 of the interactive stations were de-identified and fed into 2 customized language learning models: a speech-to-text and a tailored transformer model trained on the analytical checklist. A validation set using the analytical checklist was completed by the study investigator. Comparison of AI scoring of the analytical checklist against the validation set and faculty evaluators' scoring was retrospectively reviewed for analysis.
Results
The customized AI model demonstrated >96% and 94% accuracy for stations A and B, respectively. There was an observed statistically significant inter-rater variability among the faculty evaluators, with one evaluator scoring on average 4 points higher in one station and another evaluator scoring on average one point higher in the second station. For efficiency, the AI model graded 39 students in <5 min, saving time for faculty grading, along with timely feedback to assist in improving future student performance.
Conclusion
Customized AI model outperformed faculty scoring on the pharmacy OSCE analytical checklists of 2 stations in accuracy, objectivity and consistency, and efficiency.}
}
@article{DIETRICH2025,
title = {Adversarial artificial intelligence in radiology: Attacks, defenses, and future considerations},
journal = {Diagnostic and Interventional Imaging},
year = {2025},
issn = {2211-5684},
doi = {https://doi.org/10.1016/j.diii.2025.05.006},
url = {https://www.sciencedirect.com/science/article/pii/S2211568425001044},
author = {Nicholas Dietrich and Bo Gong and Michael N. Patlas},
keywords = {Adversarial attacks, Artificial intelligence, Cybersecurity, Machine learning, Medical imaging},
abstract = {Artificial intelligence (AI) is rapidly transforming radiology, with applications spanning disease detection, lesion segmentation, workflow optimization, and report generation. As these tools become more integrated into clinical practice, new concerns have emerged regarding their vulnerability to adversarial attacks. This review provides an in-depth overview of adversarial AI in radiology, a topic of growing relevance in both research and clinical domains. It begins by outlining the foundational concepts and model characteristics that make machine learning systems particularly susceptible to adversarial manipulation. A structured taxonomy of attack types is presented, including distinctions based on attacker knowledge, goals, timing, and computational frequency. The clinical implications of these attacks are then examined across key radiology tasks, with literature highlighting risks to disease classification, image segmentation and reconstruction, and report generation. Potential downstream consequences such as patient harm, operational disruption, and loss of trust are discussed. Current mitigation strategies are reviewed, spanning input-level defenses, model training modifications, and certified robustness approaches. In parallel, the role of broader lifecycle and safeguard strategies are considered. By consolidating current knowledge across technical and clinical domains, this review helps identify gaps, inform future research priorities, and guide the development of robust, trustworthy AI systems in radiology.}
}
@article{SMITH2025100051,
title = {Artificial Intelligence in Emergency Medicine: A Primer for the Nonexpert},
journal = {JACEP Open},
volume = {6},
number = {2},
pages = {100051},
year = {2025},
issn = {2688-1152},
doi = {https://doi.org/10.1016/j.acepjo.2025.100051},
url = {https://www.sciencedirect.com/science/article/pii/S2688115225000098},
author = {Moira E. Smith and C. Christopher Zalesky and Sangil Lee and Michael Gottlieb and Srikar Adhikari and Mat Goebel and Martin Wegman and Nidhi Garg and Samuel H.F. Lam},
keywords = {artificial intelligence, machine learning, neural networks, natural language processing, informatics, education},
abstract = {Artificial intelligence (AI) is increasingly being utilized to augment the practice of emergency medicine due to rapid technological advances and breakthroughs. AI applications have been used to enhance triage systems, predict disease-specific risk, estimate staffing needs, forecast patient decompensation, and interpret imaging findings in the emergency department setting. This article aims to help readers without formal training become informed end-users of AI in emergency medicine. The authors will briefly discuss the principles and key terminology of AI, the reasons for its rising popularity, its potential applications in the emergency department setting, and its limitations. Additionally, resources for further self-studying will also be provided.}
}
@article{LEE2025553,
title = {Artificial Intelligence in Teledermatology},
journal = {Dermatologic Clinics},
volume = {43},
number = {4},
pages = {553-561},
year = {2025},
note = {Artificial Intelligence in Dermatology},
issn = {0733-8635},
doi = {https://doi.org/10.1016/j.det.2025.05.005},
url = {https://www.sciencedirect.com/science/article/pii/S0733863525000440},
author = {Ivy Lee},
keywords = {Teledermatology, Telehealth, Telemedicine, Artificial intelligence, Augmented intelligence}
}
@article{PINEDA202626,
title = {Integrating artificial intelligence and quantum computing: A systematic literature review of features and applications},
journal = {International Journal of Cognitive Computing in Engineering},
volume = {7},
pages = {26-39},
year = {2026},
issn = {2666-3074},
doi = {https://doi.org/10.1016/j.ijcce.2025.08.002},
url = {https://www.sciencedirect.com/science/article/pii/S266630742500035X},
author = {Vanessa García Pineda and Alejandro Valencia-Arias and Francisco Eugenio López Giraldo and Edison Andrés Zapata-Ochoa},
keywords = {System architecture, Quantum computing, Artificial intelligence, Machine learning, Quantum optimization},
abstract = {Quantum Computing (QC) and Artificial Intelligence (AI) have emerged as key technologies in the evolution of Industry 6.0, driving advancements in automation and advanced analytics, and process optimization. Their integration holds the potential to revolutionize sectors such as data science, healthcare, finance, and cybersecurity by enabling faster and more efficient computations through qubits, superposition, and quantum entanglement. However, the lack of structured knowledge regarding specific QC methodologies and applications in AI hinders its optimal implementation and development. Consequently, this study aims to identify the applications and variables associated with QC-AI integration. To this end, a systematic literature review was conducted following the PRISMA 2020 methodology, drawing on studies from Scopus and Web of Science databases. This enabled the analysis of trends, limitations, and opportunities in this technological convergence. This study aims to systematically examine the intersection of quantum computing and artificial intelligence by identifying the key technological features, integration requirements, and sectoral applications that define the current state of the field. The review contributes by mapping existing research, highlighting methodological approaches, and revealing gaps that may guide targeted advancements in hybrid quantum AI systems. The insights generated have the potential to accelerate innovation in high-impact domains such as healthcare, finance, energy, and cybersecurity. The findings indicate that the main advances in QC applied to AI focus on quantum optimization, Quantum Machine Learning (QML), and post-quantum cryptography. Notably, sectors such as energy, healthcare, and finance have shown significant progress in adopting these technologies. For example, in healthcare, QML has been applied to simulate molecular interactions to accelerate drug discovery, and in finance, it enhances predictive models for market behavior. The study concludes that although QC demonstrates substantial potential to enhance AI, its broader adoption remains constrained by reliance on NISQ hardware, the need for effective error correction, and the limited scalability of hybrid quantum classical algorithms. Addressing these challenges will be essential to establishing QML as a cornerstone of technological innovation and digital transformation. Additionally, this review introduces an integrative framework that categorizes key AI QC convergence dimensions and proposes a classification of application areas based on technical requirements and algorithmic capabilities. These contributions aim to guide future experimental validations and hybrid model development.}
}
@incollection{OBRIEN2025323,
title = {Artificial Intelligence and Machine Learning in Bioinformatics},
editor = {Shoba Ranganathan and Mario Cannataro and Asif M. Khan},
booktitle = {Encyclopedia of Bioinformatics and Computational Biology (Second Edition)},
publisher = {Elsevier},
edition = {Second Edition},
address = {Oxford},
pages = {323-341},
year = {2025},
isbn = {978-0-323-95503-4},
doi = {https://doi.org/10.1016/B978-0-323-95502-7.00108-1},
url = {https://www.sciencedirect.com/science/article/pii/B9780323955027001081},
author = {Mitchell J. O’Brien and Letitia M.F. Sng and Priya Ramarao-Milne and Kieran Didi and Denis C. Bauer},
keywords = {Artificial intelligence (AI), Bioinformatics, Data integration, Deep Learning, Feature selection, Genomics, Health, Machine learning (ML), Multi-omics, Neural Networks, Precision medicine, Supervised Learning, Unsupervised Learning},
abstract = {In this comprehensive chapter, we will provide an overview of machine learning (ML) techniques available to bioinformaticians and discuss their applications in bioinformatics. The chapter will cover algorithms used to analyze and make predictions in complex biological data, with a focus on genetics, health, and multi-omic data. The chapter will introduce key topics in ML such as datasets, performance measures, and a range of algorithms, including supervised, unsupervised, and generative methods, as well as deep learning approaches. While exploring ML models, the chapter will also survey how these techniques and developments are being applied in this field. The chapter considers the challenges and limitations of using ML in bioinformatics and will serve as an introductory guide for researchers.}
}
@article{EMERY2025,
title = {Machine learning, deep learning, and artificial intelligence as applied to the field of cytopathology: a comprehensive review},
journal = {Journal of the American Society of Cytopathology},
year = {2025},
issn = {2213-2945},
doi = {https://doi.org/10.1016/j.jasc.2025.07.004},
url = {https://www.sciencedirect.com/science/article/pii/S2213294525000833},
author = {John F. Emery and Minh-Khang Le and Joshua Levy and Louis Vaickus and Xiaoying Liu},
keywords = {Artificial intelligence, Machine learning, GYN cytology, Head and Neck cytology, Thyroid cytology, Pancreaticobilary cytology},
abstract = {Imaging informatics approaches have played a significant role in gynecologic cytology since the introduction of BD FocalPoint and the ThinPrep Imaging System at the dawn of the new millennium. Although rudimentary compared to modern artificial intelligence and machine learning (AI/ML) techniques, the development of these systems nearly 20 years ago led to increased diagnostic performance, with potential to address issues relating to speed, throughput and reliability of cytologic assessment. However, rather than ushering in an age of increasing automation and quantitative analysis, algorithmic advances in cytology (and pathology in general), stagnated for approximately a decade after its introduction. In the 2010’s, the advent of AlexNet, coupled with plummeting storage and GPU costs, open-source development environments and the marketing of affordable, high throughput digital slide scanners accelerated progress and interest in digital pathology AI/ML applications. While the widespread adoption of large-scale consortium level datasets (e.g., The Cancer Genome Atlas) spurred the development of AI/ML methods for surgical pathology, large-scale collection, and algorithmic modeling of cytology specimens has lagged behind due to the varied nature of cytology preparations and assessment. However, increasing attention has been paid to cytopathology with a commensurate increase in publications and commercial applications in this area. Still, the applications of AI/ML to cytopathology and the herculean effort to implement fully digital pathology services remain in its nascent stages. This review explores the current state of research and commercial development in digital cytopathology, with a focus on AI/ML technologies.}
}
@article{YETER2025101261,
title = {Exploring the synergistic interactions between artificial intelligence and biomimicry for sustainable solutions},
journal = {Sustainable Futures},
volume = {10},
pages = {101261},
year = {2025},
issn = {2666-1888},
doi = {https://doi.org/10.1016/j.sftr.2025.101261},
url = {https://www.sciencedirect.com/science/article/pii/S2666188825008226},
author = {Ibrahim H. Yeter and Weixiang Peng and Hortense {Le Ferrand}},
keywords = {Sustainable computing, Artificial intelligence, Biomimicry or bioinspiration, Sustainable development goals (SDGs), Engineering education},
abstract = {The environmental and climate crisis calls for the sustainable solutions. As a potential approach, this paper reviews the latest developments in the fields of artificial intelligence (AI) and biomimicry, and reveals that: (1) biomimicry can supplement digital methods to induce sustainable computing; (2) machine learning and AI offer opportunities to develop sustainable biomimetic systems; (3) AI and biomimicry can synergistically work together to find sustainable solutions. The remaining areas of improvement and actions are also discussed to list concrete actions that support the 17 sustainable development goals. This paper is aimed at researchers, developers and policymakers.}
}
@incollection{RIZAL2026381,
title = {Artificial Intelligence in Finance},
editor = {Vanessa Ratten},
booktitle = {International Encyclopedia of Business Management (First Edition)},
publisher = {Academic Press},
edition = {First Edition},
address = {Oxford},
pages = {381-385},
year = {2026},
isbn = {978-0-443-13702-0},
doi = {https://doi.org/10.1016/B978-0-443-13701-3.00030-X},
url = {https://www.sciencedirect.com/science/article/pii/B978044313701300030X},
author = {Nora A. Rizal},
keywords = {Artificial intelligence (AI), Bank, Finance, Financial market, GenAI, Insurance, XAI},
abstract = {Artificial intelligence (AI) is a branch of computer science that aims to mimic and simulate human intelligence into machines and search for human-like answers. AI is the most recent technology of the early 21st century which becoming a technology that dominates all lines of process, penetrates various fields and business processes, finance is no exception. The implementation of AI in finance has surpassed many things such as efficiency cost reduction, improved customer experience, data analysis, fraud detection, personalised advice, and many more. To date the development of AI in the financial sector is still being developed}
}
@article{MUEHLEMANN2025107206,
title = {Artificial intelligence adoption and workplace training},
journal = {Journal of Economic Behavior & Organization},
volume = {238},
pages = {107206},
year = {2025},
issn = {0167-2681},
doi = {https://doi.org/10.1016/j.jebo.2025.107206},
url = {https://www.sciencedirect.com/science/article/pii/S0167268125003257},
author = {Samuel Muehlemann},
keywords = {Artificial intelligence, Technological change, Automation, Apprenticeship training, Human capital},
abstract = {As artificial intelligence (AI) reshapes business processes, firms must adapt their training strategies to cultivate a skilled workforce. Using German establishment-level panel data from 2019 to 2023, this study analyzes how firms adjust their training strategies following AI adoption. Staggered difference-in-differences analysis shows that sustained AI adoption is associated with a 14% increase in new apprenticeships among training firms (intensive margin), but is not linked to the training decision (extensive margin). AI adoption is also associated with a modest increase in continuing training, with resources shifting toward high-skilled employees. The results align with AI as an automation innovation that reduces demand for simple skills as well as an augmentation innovation that increases demand for more advanced skills. The German dual apprenticeship system appears critical for firms aiming to build a future-ready workforce in the age of AI.}
}
@article{VOIGTLAENDER2025100876,
title = {Value of artificial intelligence in neuro-oncology},
journal = {The Lancet Digital Health},
pages = {100876},
year = {2025},
issn = {2589-7500},
doi = {https://doi.org/10.1016/j.landig.2025.100876},
url = {https://www.sciencedirect.com/science/article/pii/S2589750025000585},
author = {Sebastian Voigtlaender and Thomas A Nelson and Philipp Karschnia and Eugene J Vaios and Michelle M Kim and Philipp Lohmann and Norbert Galldiks and Mariella G Filbin and Shekoofeh Azizi and Vivek Natarajan and Michelle Monje and Jorg Dietrich and Sebastian F Winter},
abstract = {Summary
CNS cancers are complex, difficult-to-treat malignancies that remain insufficiently understood and mostly incurable, despite decades of research efforts. Artificial intelligence (AI) is poised to reshape neuro-oncological practice and research, driving advances in medical image analysis, neuro–molecular–genetic characterisation, biomarker discovery, therapeutic target identification, tailored management strategies, and neurorehabilitation. This Review examines key opportunities and challenges associated with AI applications along the neuro-oncological care trajectory. We highlight emerging trends in foundation models, biophysical modelling, synthetic data, and drug development and discuss regulatory, operational, and ethical hurdles across data, translation, and implementation gaps. Near-term clinical translation depends on scaling validated AI solutions for well defined clinical tasks. In contrast, more experimental AI solutions offer broader potential but require technical refinement and resolution of data and regulatory challenges. Addressing both general and neuro-oncology-specific issues is essential to unlock the full potential of AI and ensure its responsible, effective, and needs-based integration into neuro-oncological practice.}
}
@article{KIM2025207,
title = {The Role of Artificial Intelligence in Obesity Medicine},
journal = {Endocrinology and Metabolism Clinics of North America},
volume = {54},
number = {1},
pages = {207-215},
year = {2025},
note = {Update on Obesity},
issn = {0889-8529},
doi = {https://doi.org/10.1016/j.ecl.2024.10.008},
url = {https://www.sciencedirect.com/science/article/pii/S0889852924000884},
author = {Dong Wook Kim and Cheol-Young Park and Jeong-Hun Shin and Hyunjoo Jenny Lee},
keywords = {Artificial intelligence, Obesity medicine, Personalized treatment, Machine learning, Deep learning, Large language model}
}
@article{POZZAR2025151901,
title = {Integrating Remote Symptom Monitoring, Person-Centered Analytics, and Artificial Intelligence to Advance Precision Health Symptom Science in Oncology},
journal = {Seminars in Oncology Nursing},
volume = {41},
number = {4},
pages = {151901},
year = {2025},
note = {Symptom Science},
issn = {0749-2081},
doi = {https://doi.org/10.1016/j.soncn.2025.151901},
url = {https://www.sciencedirect.com/science/article/pii/S0749208125000944},
author = {Rachel A. Pozzar},
keywords = {Signs and symptoms, Precision medicine, Digital health, Artificial intelligence, Neoplasms},
abstract = {Objectives
To summarize the relevance of remote symptom monitoring, person-centered statistical analyses, and artificial intelligence to precision health symptom science in oncology; and propose ways in which these three approaches can be integrated to further advance the field.
Methods
The following commentary was adapted from a talk delivered at the Symptom Science Experts Meeting in October 2023 at the University of Lausanne, Switzerland. The commentary and talk were informed by an informal review of recent literature in precision health oncology symptom science.
Results
Several remote symptom monitoring interventions have demonstrated potential to reduce disease- and treatment-related symptom burden and improve health outcomes in patients with cancer. Data collected passively by wearable and sensor technologies are also being used to characterize patients’ health status. Person-centered statistical analyses have identified interindividual variability in the symptom experiences of patients with cancer. Together with artificial intelligence-based approaches, these analyses have identified factors associated with relatively adverse symptom experiences. Future directions for the field include integrating these approaches to optimize clinical resource allocation, tailor symptom management in real-time, and advance scientific knowledge of the symptom experience.
Conclusions
Integrating remote symptom monitoring, person-centered statistical analyses and artificial intelligence may provide deeper insights into how patients with cancer experience symptoms.
Implications for Nursing Practice
Findings from research that uses remote symptom monitoring, person-centered statistical analyses, and artificial intelligence may enhance clinicians’ ability to deliver personalized symptom management interventions.}
}
@article{SEPULVEDAOVIEDO2025100558,
title = {Artificial intelligence in photovoltaic fault diagnosis: A Natural Language-Based Topic-tSNE Fusion analysis},
journal = {Energy and AI},
volume = {21},
pages = {100558},
year = {2025},
issn = {2666-5468},
doi = {https://doi.org/10.1016/j.egyai.2025.100558},
url = {https://www.sciencedirect.com/science/article/pii/S2666546825000904},
author = {Edgar Hernando Sepúlveda-Oviedo and Louise Travé-Massuyès and Audine Subias and Marko Pavlov and Corinne Alonso},
keywords = {Photovoltaic fault diagnosis, Machine learning, Topic modeling, t-SNE visualization, PV system reliability, Artificial intelligence},
abstract = {Timely fault detection in photovoltaic systems is critical for ensuring energy efficiency, reliability, and cost-effectiveness. However, the nonlinear and weather-dependent behavior of photovoltaic systems poses challenges for accurate diagnosis. This study presents a large-scale review of 983 scientific publications on artificial intelligence-based photovoltaic fault detection, using a novel methodology called Topic-tSNE Fusion. This approach integrates topic modeling, dimensionality reduction, and expert analysis to extract and visualize dominant research themes. Four key machine learning paradigms are identified: supervised, unsupervised, semi-supervised, and reinforcement learning. Among them, supervised methods, particularly neural networks and support vector machines, are the most frequently applied, showing accuracies above 95% in controlled conditions. The analysis also reveals growing use of semi-supervised and hybrid approaches to overcome data scarcity. Commonly monitored variables include irradiance, voltage, and current, while the most studied faults are shading, open-circuit, and degradation. Several open-access datasets supporting fault diagnosis research are catalogued. Overall, the proposed method enables a more objective and scalable review process and uncovers emerging trends, such as the shift toward lightweight artificial intelligence for edge deployment and frugal diagnostic architectures. The methodology is scalable and adaptable to other domains facing similar challenges in knowledge synthesis and system monitoring.}
}
@article{DENUCCI2025649,
title = {Summary of the Veterans Health Administration’s First International Symposium on Artificial Intelligence in Dentistry},
journal = {The Journal of the American Dental Association},
volume = {156},
number = {8},
pages = {649-657},
year = {2025},
issn = {0002-8177},
doi = {https://doi.org/10.1016/j.adaj.2025.05.018},
url = {https://www.sciencedirect.com/science/article/pii/S0002817725003587},
author = {Donald J. DeNucci and Elizabeth Nuñez and Owais A. Farooqi and Christopher Balaban and Ibrahim Sevki Bayrakdar and Michael M. Bornstein and Adam Foresman and Seth A. Gibree and Reinhilde Jacobs and Joshua Mueller and Falk Schwendicke and Philippe Salah and Dmitri Tuzoff},
keywords = {Artificial intelligence, dental diagnostics, clinical workflows, VA dentistry, innovation, ethical AI, remote monitoring, robotics, dental records},
abstract = {Background
The Veterans Health Administration’s First International Symposium on Artificial Intelligence in Dentistry, held virtually on October 11, 2024, marked a step toward improving oral health care for veterans through the adoption of cutting-edge artificial intelligence (AI) technologies. AI offers the potential to transform dental diagnostics, treatment planning, and care delivery; however, its clinical application in dentistry remains limited. The symposium addressed this gap by means of highlighting innovations and implementation strategies to help clinicians prepare for the technological changes reshaping oral health care.
Types of Studies Reviewed
The authors summarized presentations and panel discussions from the symposium, encompassing developments in AI-assisted cariology, maxillofacial radiology, diagnostic and presurgical planning, clinical workflows, remote monitoring, and the ethical and regulatory landscape. The review is based on content submitted by the symposium’s presenters, reflecting their research, operational experience, and emerging innovations.
Results
The presentations established that AI technologies can standardize diagnostics, reduce interoperator variability, and enhance clinical decision making through predictive analytics, digital simulations, and multimodal data integration. AI applications exhibited high specificity in detecting pathologies, improved early intervention capabilities, and optimized treatment planning. Key findings emphasized the value of responsible AI adoption within institutional settings, such as the US Department of Veterans Affairs, supported by means of clinician engagement, regulatory guidance, and ethical oversight.
Conclusions and Practical Implications
Integrating AI into dental practice can improve diagnostic accuracy, streamline administrative processes, and enhance access to care. These tools offer substantial benefits for large health care systems, such as the Veterans Health Administration, including greater efficiency, personalization of treatment, and improved outcomes, particularly in underserved or resource-limited environments.}
}
@article{MOHAMMED2025110933,
title = {Artificial intelligence approaches in predicting the mechanical properties of natural fiber-reinforced concrete: A comprehensive review},
journal = {Engineering Applications of Artificial Intelligence},
volume = {153},
pages = {110933},
year = {2025},
issn = {0952-1976},
doi = {https://doi.org/10.1016/j.engappai.2025.110933},
url = {https://www.sciencedirect.com/science/article/pii/S0952197625009339},
author = {Mohammed Mohammed and Jawad K. Oleiwi and Aeshah M. Mohammed and Azlin F. Osman and Tijjani Adam and Bashir O. Betar and Subash C.B. Gopinath},
keywords = {Implemented artificial intelligence, Natural fiber-reinforced concrete, Mechanical properties, Applications artificial intelligence, Sustainability},
abstract = {Implementing artificial intelligence (AI) techniques in predicting the mechanical properties of natural fiber-reinforced concrete (NFRC) has emerged as a transformative approach, offering significant advancements over traditional modeling methods. Construction materials science increasingly leverages advanced technologies to enhance composites like natural fiber-reinforced concrete (NFRC). However, the varied nature of natural fibers and their interactions within concrete matrices present significant challenges in accurately predicting the NFRC's mechanical properties. This comprehensive review highlights the innovative use of artificial intelligence (AI) techniques to address challenges in predicting material reliability. It explores the application of various AI methodologies, including machine learning (ML) techniques such as artificial neural networks (ANN) and support vector machines (SVM), along with pattern recognition (PR) and deep learning (DL). These approaches are utilized to tackle the challenges posed by the variability of natural fibers and their interactions within concrete matrices. These techniques have proven highly effective in accurately predicting the mechanical behavior of NFRC, marking significant advancements in the field. This review paper aims to summarize techniques for applying the AI methods mentioned in the NFRC. Firstly, we present a general introduction to AI and NFRC, highlighting the significance of AI in predicting the mechanical properties of NFRC. After that, a comparison between ML, PR, and DL in the field is discussed, and a review of recent applications of AI in the field is provided. Further, the advantages of employing such algorithmic methods are discussed in detail. Finally, future directions for employing ML, PR, and DL are presented, and their limitations are discussed.}
}
@article{YAO2025100366,
title = {Artificial intelligence in de novo protein design},
journal = {Medicine in Novel Technology and Devices},
volume = {26},
pages = {100366},
year = {2025},
issn = {2590-0935},
doi = {https://doi.org/10.1016/j.medntd.2025.100366},
url = {https://www.sciencedirect.com/science/article/pii/S2590093525000177},
author = {Jiawei Yao and Xiaogang Wang},
keywords = {Artificial intelligence, De novo protein design},
abstract = {The primary goal of protein engineering has always been to create molecules with optimal functions and characteristics. One of the most exciting avenues of research in this field is de novo protein design. This approach facilitates the synthesis of entirely new molecules without relying on existing protein, thereby offering a novel method for generating molecular entities that were previously unimaginable. The application of artificial intelligence in this field has been a significant advancement. By leveraging machine learning algorithms trained on extensive sequence and structure datasets, scientists have been able to make de novo protein design a practical reality. In this paper, we will delve into the key artificial intelligence innovations that have driven this progress and explore how they unlock groundbreaking opportunities. These advancements, we believe, have the potential to push beyond the current state of the art, enabling us to design proteins strategically and robustly. Moreover, they offer solutions to pressing societal challenges, such as developing new therapeutics, creating sustainable biomaterials, or engineering enzymes for environmental remediation.}
}
@article{ALVAREZICAZA2025101312,
title = {Driving complex thinking and technological entrepreneurship with artificial intelligence: a mixed methods study},
journal = {Sustainable Futures},
volume = {10},
pages = {101312},
year = {2025},
issn = {2666-1888},
doi = {https://doi.org/10.1016/j.sftr.2025.101312},
url = {https://www.sciencedirect.com/science/article/pii/S2666188825008731},
author = {Inés Alvarez-Icaza and J. Miranda and A. Martínez-Arboleda and P. Suárez-Brito and M.S. Ramírez-Montoya},
keywords = {Artificial intelligence, Educational platforms, Innovative thinking, Complex Thinking, Educational Innovation, Higher Education},
abstract = {AI technologies offer unique capabilities that enhance collaboration and creativity among students by providing novel insights, generating diverse perspectives, and triggering the development of innovative thinking as a sub-competency of the mega-competency of complex thinking. Regarding entrepreneurial skills development, applying AI-powered tools, such as natural language processing on digital educational platforms, allows students to engage in dynamic ideation processes for entrepreneurial projects with social, technological, and scientific approaches. This article explores the application of artificial intelligence (AI) as a valuable resource for fostering creative idea generation within co-creation strategies for university students. In a mixed-method analysis, we obtained valuable information regarding engagement through co-creation approaches. This paper describes the early implementation stages of the introductory course in technological entrepreneurship, applying the educational platform OpenEdR4C in a hybrid workshop with a group of 20 students in a public higher education institution in central Mexico, this being the first group of >900 people reached during 2024. The findings show that (a) the students are prone to use and explore AI tools in a natural and immediate manner, (b) interdisciplinary collaboration was effectively promoted through co-creation strategies, and (c) training the tool is crucial to keep engagement and ideas fluency. This is a contribution to the exploration to open new opportunities for interdisciplinary collaboration, experiential learning, and knowledge co-production, ultimately empowering students to develop innovative solutions to complex societal challenges.}
}

@article{CHEN20247510,
title = {Biological and bio-inspired materials: Multi-scale modeling, artificial intelligence approaches, and experiments},
journal = {Journal of Materials Research and Technology},
volume = {30},
pages = {7510-7511},
year = {2024},
issn = {2238-7854},
doi = {https://doi.org/10.1016/j.jmrt.2024.05.117},
url = {https://www.sciencedirect.com/science/article/pii/S2238785424011578},
author = {Po-Yu Chen and Iwona Jasiuk},
abstract = {Biological materials often possess remarkable properties and functionalities owing to their complex hierarchical and composite structures. Learning from nature can lead to revolutionary breakthroughs in materials science and innovative new technologies. This Special Issue titled “Biological and Bio-inspired Materials: Multi-scale Modeling and Artificial Intelligence Approaches” is a collection of research articles and comprehensive reviews utilizing multi-scale modeling, artificial intelligence approaches, and experiments to elucidate the characteristics of biological materials and design and optimize bio-inspired materials. The computational approaches of interest include but are not limited to molecular dynamics, lattice spring models, finite element analysis, genetic algorithms, neural networks, generative adversarial networks, and other modeling and artificial intelligence approaches for better understanding the structure-property relationships and underlying mechanisms of biological (natural) materials, and reproducing, designing, and optimizing bio-inspired materials. Novel experimental results, fabrication strategies, and applications of biological, bio-inspired and biomedical materials are also collected in this special issue.}
}
@article{RANJBAR2025101125,
title = {Overview of key power system state estimation methods with a focus on artificial intelligence-based approaches},
journal = {e-Prime - Advances in Electrical Engineering, Electronics and Energy},
volume = {14},
pages = {101125},
year = {2025},
issn = {2772-6711},
doi = {https://doi.org/10.1016/j.prime.2025.101125},
url = {https://www.sciencedirect.com/science/article/pii/S2772671125002311},
author = {Mohammad Amin Ranjbar and Sasan Azad and Morteza Nazari-Heris and Mostafa Mohammadpourfard},
keywords = {State estimation, Artificial intelligence, Machine learning, Deep learning, Transfer learning},
abstract = {State estimation (SE) is the most critical part of power systems management and control centers because correct data from the equipment in the network is needed before any operation. Power systems in the past were less complex than today's systems, so simple methods were sufficient to solve the SE problem. As power systems have developed and distribution systems have become more interconnected to enhance reliability and handle growing loads and uncertainties, the methods for solving the SE problem have evolved over time. Many methods have been employed so far to address the state estimate problem; each of these techniques has the potential to be helpful in particular situations; therefore, identifying the strategies and getting familiar with their features can be crucial. Based on this issue, SE methods are divided into two categories. In one category, their dynamic and static characteristics are specified, and another category is based on the application of methods. Most of the methods have been studied, and the advantages and disadvantages of each have been thoroughly investigated to identify their strengths and weaknesses. The methods based on artificial intelligence (AI) can have good potential in solving SE problems, so they have been specifically investigated. This category of SE methods can be beneficial in solving future problems. Based on this, the existing challenges for the future of SE have been discussed. As a case study, we demonstrate how AI techniques, such as transfer learning (TL), can address one of these challenges—specifically in handling network reconfiguration in a 118-bus system. This example can guide those interested in the field to tackle similar challenges and provide direction for future research.}
}
@article{SOTODIAZ2025101949,
title = {A review of artificial intelligence techniques for optimizing friction stir welding processes and predicting mechanical properties},
journal = {Engineering Science and Technology, an International Journal},
volume = {62},
pages = {101949},
year = {2025},
issn = {2215-0986},
doi = {https://doi.org/10.1016/j.jestch.2025.101949},
url = {https://www.sciencedirect.com/science/article/pii/S2215098625000047},
author = {Roosvel Soto-Diaz and Mauricio Vásquez-Carbonell and Jose Escorcia-Gutierrez},
keywords = {Artificial intelligence (AI), Friction stir-welding (FSW), Ultimate tensile strength (UTS), PRISMA},
abstract = {The implementation of artificial intelligence (AI) has been instrumental in the optimization of friction stir welding (FSW) parameters. Artificial intelligence (AI) techniques, including artificial neural networks (ANN) and adaptive neuro-fuzzy inference systems (ANFIS), were utilized to predict mechanical properties such as ultimate tensile strength (UTS) and optimize pivotal welding parameters, such as rotational speed, feed rate, axial force, and tilt angle. These methodologies enabled precise real-time control, thus improving the quality and consistency of the resulting welded joints. The objective of this study was to conduct a comprehensive review of the application of artificial intelligence (AI) techniques in friction stir welding (FSW). The objective of the study was to synthesize existing research using AI to predict mechanical properties and optimize welding parameters. Furthermore, the study aimed to illustrate how artificial intelligence has improved the caliber and dependability of FSW joints through real-time observation and defect identification. A systematic literature review was conducted according to the PRISMA guidelines to identify relevant studies on the utilization of AI in FSW. A search algorithm was applied to databases such as ScienceDirect and Web of Science, resulting in the identification of 27 relevant scientific papers. The selection criteria were designed to identify studies that employed AI techniques for the prediction and optimization of FSW parameters. The principal findings indicated the pervasive deployment of 34 distinct AI techniques, with ANN being the most prevalent. Hybrid models combining AI with optimization algorithms, such as particle swarm optimization (PSO) and genetic algorithms, were particularly effective. These models demonstrated high precision in predicting tensile strength and detecting internal defects, significantly improving joint quality. In conclusion, AI applications in FSW have proven essential for optimizing welding processes, with hybrid AI models showing superior performance. The continued integration of AI in FSW is expected to enhance the efficiency and reliability of welding operations, offering significant industrial advantages.}
}
@article{MEDEIROS2025491,
title = {Artificial Intelligence in Regional Anesthesia and Pain Management},
journal = {Anesthesiology Clinics},
volume = {43},
number = {3},
pages = {491-505},
year = {2025},
note = {Artificial Intelligence in Anesthesiology},
issn = {1932-2275},
doi = {https://doi.org/10.1016/j.anclin.2025.05.004},
url = {https://www.sciencedirect.com/science/article/pii/S1932227525000345},
author = {Heitor J.S. Medeiros and Ali Dabbagh and Kamen Vlassakov and A. Sassan Sabouri},
keywords = {Artificial intelligence, Regional anesthesia, Machine learning, Ultrasound, Pain management, Predictive analytics, Education, Automation}
}
@article{ZACK2025100246,
title = {Artificial Intelligence and Multi-Omics in Pharmacogenomics: A New Era of Precision Medicine},
journal = {Mayo Clinic Proceedings: Digital Health},
volume = {3},
number = {3},
pages = {100246},
year = {2025},
issn = {2949-7612},
doi = {https://doi.org/10.1016/j.mcpdig.2025.100246},
url = {https://www.sciencedirect.com/science/article/pii/S2949761225000537},
author = {Mike Zack and Danil N. Stupichev and Alex J. Moore and Ioan D. Slobodchikov and David G. Sokolov and Igor F. Trifonov and Allan Gobbs},
abstract = {Pharmacogenomics is entering a transformative phase as high-throughput “omics” techniques become increasingly integrated with state-of-the-art artificial intelligence (AI) methods. Although early successes in single-gene pharmacogenetics reported clear clinical benefits, many drug response phenotypes are governed by intricate networks of genomic variants, epigenetic modifications, and metabolic pathways. Multi-omics approaches address this complexity by capturing genomic, transcriptomic, proteomic, and metabolomic data layers, offering a comprehensive view of patient-specific biology. Advanced AI models, including deep neural networks, graph neural networks, and representation learning techniques, further enhance this landscape by detecting hidden patterns, filling gaps in incomplete data sets, and enabling in silico simulations of treatment responses. Such capabilities not only improve predictive accuracy but also deepen mechanistic insights, revealing how gene–gene and gene–environment interactions shape therapeutic outcomes. At the same time, real-world data from diverse patient populations is broadening the evidence base, underscoring the importance of inclusive datasets and population-specific algorithms to reduce health disparities. Despite challenges related to data harmonization, interpretability, and regulatory oversight, the synergy between multi-omics integration and AI-driven analytics holds relevant promise for revolutionizing clinical decision-making. In this review, we highlighted key technological advances, discussed current limitations, and outlined future directions for translating multi-omics plus AI innovations into routine personalized medicine.}
}
@incollection{WHEATLEY2025286,
title = {Artificial Intelligence and Libraries},
editor = {David Baker and Lucy Ellis},
booktitle = {Encyclopedia of Libraries, Librarianship, and Information Science (First Edition)},
publisher = {Academic Press},
edition = {First Edition},
address = {Oxford},
pages = {286-290},
year = {2025},
isbn = {978-0-323-95690-1},
doi = {https://doi.org/10.1016/B978-0-323-95689-5.00275-3},
url = {https://www.sciencedirect.com/science/article/pii/B9780323956895002753},
author = {Amanda Wheatley and Sandy Hervieux},
keywords = {AI literacy, Algorithmic bias, Artificial intelligence, Computer science, Deep learning, Generative AI, Information theory, Libraries, Library science, Machine learning},
abstract = {Artificial intelligence (AI) is broadly defined as the ability of computers to exhibit human-like behavior and thought processes. The significance of AI rests on the ability to automate both complex and simple tasks. Large data can be computed and analyzed at increasingly faster speeds, far outweighing the abilities of humans. Computers and libraries both store, organize, and make information accessible to users through a variety of means, making the practical applications of AI a natural fit for library science.}
}
@article{WANNASINGHA2025103650,
title = {Advances in artificial intelligence to model the impact of El Niño–Southern Oscillation on crop yield variability},
journal = {MethodsX},
volume = {15},
pages = {103650},
year = {2025},
issn = {2215-0161},
doi = {https://doi.org/10.1016/j.mex.2025.103650},
url = {https://www.sciencedirect.com/science/article/pii/S2215016125004947},
author = {Usa Humphries Wannasingha and Muhammad Waqas and Angkool Wangwongchai and Phyo Thandar Hlaing and Porntip Dechpichai and Shakeel Ahmad},
keywords = {El Niño-Southern oscillation, Artificial intelligence, Machine learning, Deep learning, Cereal crops, Crop yield},
abstract = {El Niño-Southern Oscillation (ENSO) has a significant impact on global agricultural systems in tropical regions, where rainfed rice production is highly vulnerable to climatic extremes, including droughts and floods. This systematic review synthesizes findings from two decades of research to examine the effects of ENSO phases—El Niño and La Niña—on cereal crop yields, with a focus on rainfed rice in Thailand. The study also evaluates the role of artificial intelligence (AI) in predicting ENSO-induced impacts on crop productivity. Findings indicate that El Niño events often reduce rainfall, increasing drought stress, while La Niña leads to excessive precipitation and flooding—both of which adversely affect rice productivity. AI-based studies have shown that models such as Random Forest (RF), Long Short-Term Memory (LSTM), and Convolutional Neural Networks (CNNs) demonstrate strong potential, although limitations remain in terms of scalability and local adaptation. • Hybrid modeling approaches that integrate physical and statistical methods are essential. • Future research must enhance data quality and integrate adaptive technologies to support climate-resilient agriculture.}
}
@article{POURHEJAZY20252479,
title = {Exploring the role of Artificial Intelligence in life-cycle-related studies},
journal = {IFAC-PapersOnLine},
volume = {59},
number = {10},
pages = {2479-2484},
year = {2025},
note = {11th IFAC Conference on Manufacturing Modelling, Management and Control MIM 2025},
issn = {2405-8963},
doi = {https://doi.org/10.1016/j.ifacol.2025.09.417},
url = {https://www.sciencedirect.com/science/article/pii/S2405896325011802},
author = {Pourya Pourhejazy and Wei Deng Solvang},
keywords = {Life cycle assessment, Artificial Intelligence, Cluster Analysis, Supply chain management},
abstract = {With the proliferation of data in the digital era, Artificial Intelligence (AI) plays an increasingly important role in reducing human involvement and extracting information effectively and efficiently. The use of AI in Life Cycle Assessment (LCA)-related studies is growing. Drawing a big picture of this development helps inspire new research ideas. This study identifies the major research themes based on Cluster Analysis, considering the literature at the intersection of AI and LCA. Decision support for maintenance; Data, knowledge management, and real-time/intelligent systems; Industry 4.0, the Internet of Things, and new technologies; Digital twins, automation, and decision-making; AI explainability, implementation issues, and LCA software; Carbon footprint, energy efficiency, and sustainability; and Machine learning methods and algorithms for LCA are identified as the major research themes. Suggestions for future research conclude the article.}
}
@article{MISHRA202589,
title = {Leveraging Generative AI for Drug Safety and Pharmacovigilance},
journal = {Current Reviews in Clinical and Experimental Pharmacology},
volume = {20},
number = {2},
pages = {89-97},
year = {2025},
issn = {2772-4328},
doi = {https://doi.org/10.2174/0127724328311400240823062829},
url = {https://www.sciencedirect.com/science/article/pii/S2772432825000121},
author = {Hara Prasad Mishra and Rachna Gupta},
keywords = {Generative AI, Chat -GPT, pharmacovigilance, drug safety, patient safety, artificial intelligence, machine learning},
abstract = {Predictions are made by artificial intelligence, especially through machine learning, which uses algorithms and past knowledge. Notably, there has been an increase in interest in using artificial intelligence, particularly generative AI, in the pharmacovigilance of pharmaceuticals under development, as well as those already in the market. This review was conducted to understand how generative AI can play an important role in pharmacovigilance and improving drug safety monitoring. Data from previously published articles and news items were reviewed in order to obtain information. We used PubMed and Google Scholar as our search engines, and keywords (pharmacovigilance, artificial intelligence, machine learning, drug safety, and patient safety) were used. In toto, we reviewed 109 articles published till 31st January 2024, and the obtained information was interpreted, compiled, evaluated, and conclusions were reached. Generative AI has transformative potential in pharmacovigilance, showcasing benefits, such as enhanced adverse event detection, data-driven risk prediction, and optimized drug development. By making it easier to process and analyze big datasets, generative artificial intelligence has applications across a variety of disease states. Machine learning and automation in this field can streamline pharmacovigilance procedures and provide a more efficient way to assess safety-related data. Nevertheless, more investigation is required to determine how this optimization affects the caliber of safety analyses. In the near future, the increased utilization of artificial intelligence is anticipated, especially in predicting side effects and Adverse Drug Reactions (ADRs).}
}
@article{PANTIC2025382,
title = {Artificial intelligence strategies based on random forests for detection of AI-generated content in public health},
journal = {Public Health},
volume = {242},
pages = {382-387},
year = {2025},
issn = {0033-3506},
doi = {https://doi.org/10.1016/j.puhe.2025.03.029},
url = {https://www.sciencedirect.com/science/article/pii/S0033350625001489},
author = {Igor V. Pantic and Snezana Mugosa},
keywords = {Public health policy, Machine learning, Decision tree, Linguistic patterns, Generative AI},
abstract = {Objectives
To train and test a Random Forest machine learning model with the ability to distinguish AI-generated from human-generated textual content in the domain of public health, and public health policy.
Study design
Supervised machine learning study.
Methods
A dataset comprising 1000 human-generated and 1000 AI-generated paragraphs was created. Textual features were extracted using TF-IDF vectorization which calculates term frequency (TF) and Inverse document frequency (IDF), and combines the two measures to produce a score for individual terms. The Random Forest model was trained and tested using the Scikit-Learn library and Jupyter Notebook service in the Google Colab cloud-based environment, with Google CPU hardware acceleration.
Results
The model achieved a classification accuracy of 81.8 % and an area under the ROC curve of 0.9. For human-generated content, precision, recall, and F1-score were 0.85, 0.78, and 0.81, respectively. For AI-generated content, these metrics were 0.79, 0.86, and 0.82. The MCC value of 0.64 indicated moderate to strong predictive power. The model demonstrated robust sensitivity (recall for AI-generated class) of 0.86 and specificity (recall for human-generated class) of 0.78.
Conclusions
The model exhibited acceptable performance, as measured by classification accuracy, area under the receiver operating characteristic curve, and other metrics. This approach can be further improved by incorporating additional supervised machine learning techniques and serves as a foundation for the future development of a sophisticated and innovative AI system. Such a system could play a crucial role in combating misinformation and enhancing public trust across various government platforms, media outlets, and social networks.}
}
@article{BONCI2025104929,
title = {Artificial intelligence in NSCLC management for revolutionizing diagnosis, prognosis, and treatment optimization: A systematic review},
journal = {Critical Reviews in Oncology/Hematology},
volume = {216},
pages = {104929},
year = {2025},
issn = {1040-8428},
doi = {https://doi.org/10.1016/j.critrevonc.2025.104929},
url = {https://www.sciencedirect.com/science/article/pii/S1040842825003178},
author = {Eduard-Alexandru Bonci and Artur Bandura and Andrew Dooley and Ayah Erjan and Hailemichael Welekidan Gebreslase and Mirela Hategan and Divetiya Khanduja and Eleonora Lai and Andreea Lescaie and Gabriela Viorela Nitescu and Sofia Ramalho and Aung Thiha and Luca Bertolaccini},
keywords = {Artificial intelligence, Artificial neural networks, Lung cancer, Machine learning, Non-small lung cancer, Overall survival, Patient-reported outcome measures},
abstract = {Background
Non-small cell lung cancer (NSCLC) accounts for approximately 85 % of all lung cancer cases and remains a leading cause of cancer-related mortality. The integration of artificial intelligence (AI), artificial neural networks (ANNs), and machine learning (ML) into NSCLC management has shown potential in improving diagnostic accuracy, treatment personalization, and patient outcomes. However, the impact of these technologies on patient-reported outcome measures (PROM), overall survival (OS), and cost-effectiveness remains underexplored. This systematic review aims to evaluate the impact of AI, ANNs, and ML models on PROM, OS, and cost-effectiveness in adult patients with histologically confirmed NSCLC compared to conventional research methodologies and standard-of-care approaches.
Methods
A systematic review was conducted following the PRISMA guidelines, with data synthesized using the Synthesis Without Meta-analysis (SWiM) approach. Data extraction focused on study design, patient characteristics, AI methodology, and outcomes of interest. Given the heterogeneity in study designs and statistical methods, a meta-analysis was deemed inappropriate.
Results
Ten studies were included after screening 509 articles. AI-based models demonstrated improvements in diagnostic precision, treatment optimization, and predictive accuracy for survival outcomes. AI-enhanced approaches outperformed conventional statistical models in prognosis prediction and resource allocation. However, data heterogeneity, model generalizability, and algorithmic transparency remain significant challenges.
Conclusion
Current evidence supports exploratory associations between AI models and prognostic stratification for OS; there is no evaluable evidence on PROM or cost‑effectiveness in NSCLC. Future prospective studies should incorporate validated PROM and formal economic evaluation alongside clinical endpoints. AI, ANNs, and ML have the potential to revolutionize NSCLC care by improving diagnostic accuracy and treatment outcomes. However, further research is needed to validate their real-world clinical applicability and address potential biases, ethical implications, and concerns regarding healthcare disparities.}
}
@article{LIU2025101271,
title = {Artificial intelligence guided Raman spectroscopy in biomedicine: Applications and prospects},
journal = {Journal of Pharmaceutical Analysis},
pages = {101271},
year = {2025},
issn = {2095-1779},
doi = {https://doi.org/10.1016/j.jpha.2025.101271},
url = {https://www.sciencedirect.com/science/article/pii/S2095177925000887},
author = {Yuan Liu and Sitong Chen and Xiaomin Xiong and Zhenguo Wen and Long Zhao and Bo Xu and Qianjin Guo and Jianye Xia and Jianfeng Pei},
keywords = {, , , , , },
abstract = {Abstract:
Due to its high sensitivity and non-destructive nature, Raman spectroscopy has become an essential analytical tool in biopharmaceutical analysis and drug development. Despite of the computational demands, data requirements, or ethical considerations, artificial intelligence (AI) and particularly deep learning algorithms has further advanced Raman spectroscopy by enhancing data processing, feature extraction, and model optimization, which not only improves the accuracy and efficiency of Raman spectroscopy detection, but also greatly expands its range of application. AI-guided Raman spectroscopy has numerous applications in biomedicine, including characterizing drug structures, analyzing drug forms, controlling drug quality, identifying components, and studying drug-biomolecule interactions. AI-guided Raman spectroscopy has also revolutionized biomedical research and clinical diagnostics, particularly in disease early diagnosis and treatment optimization. Therefore, AI methods are crucial to advancing Raman spectroscopy in biopharmaceutical research and clinical diagnostics, offering new perspectives and tools for disease treatment and pharmaceutical process control. In summary, integrating AI and Raman spectroscopy in biomedicine has significantly improved analytical capabilities, offering innovative approaches for research and clinical applications.}
}
@article{READINGTURCHIOE2025102484,
title = {Education, empowerment, and elevating nursing voices: Nursing informatics leaders’ perspectives on the path forward with artificial intelligence in nursing},
journal = {Nursing Outlook},
volume = {73},
number = {5},
pages = {102484},
year = {2025},
issn = {0029-6554},
doi = {https://doi.org/10.1016/j.outlook.2025.102484},
url = {https://www.sciencedirect.com/science/article/pii/S002965542500137X},
author = {Meghan {Reading Turchioe} and Christianna Pepingco and Charlene Ronquillo and Stephen A. Ferrara and Max Topaz and Robin Austin and Kay Lytle},
keywords = {Artificial intelligence, Nursing, Health information technology, Nursing informatics},
abstract = {Background
As artificial intelligence (AI) is rapidly transforming healthcare, there is a critical need to understand how AI can be thoughtfully integrated into nursing practice to support clinicians, reduce burden, and enhance patient care.
Purpose
We aimed to understand nursing informatics leaders’ perspectives on AI's current and future state in nursing.
Methods
We conducted a qualitative study with 20 national experts in nursing informatics. The Non-Adoption, Abandonment, Scale-up, Spread, Sustainability (NASSS) framework guided data collection and analysis using directed content analysis.
Findings
Participants highlighted the unclear value of AI to nurses and of nurses to technology vendors and AI developers. They identified nursing-specific (burnout, education, and attitudes) and organization-specific (leadership and culture) factors that influence AI’s integration in nursing. They highlighted how education, establishing ideal nurse–AI partnerships, and leveraging AI, may alleviate burnout.
Discussion
Education, empowerment, and elevating nursing voices (“three e’s”) can guide the nursing profession to thrive in the era of AI.}
}
@article{MA2025100005,
title = {Harnessing artificial intelligence to decode the rhizosphere microbiome},
journal = {aBIOTECH},
pages = {100005},
year = {2025},
issn = {2662-1738},
doi = {https://doi.org/10.1016/j.abiote.2025.100005},
url = {https://www.sciencedirect.com/science/article/pii/S2662173825002127},
author = {Juan Ma and Jiangfang Qiao and Yanyong Cao and Zeqiang Cheng},
keywords = {Artificial intelligence, Microbiome engineering, Rhizosphere microbiome, Microbiome-enabled genomic selection, Predictive modeling},
abstract = {The rhizosphere microbiome plays crucial roles in plant health by regulating nutrient cycling and enhancing stress resilience. However, due to its complexity, the rhizosphere microbiome is quite challenging to analyze using conventional approaches. Recent advances in artificial intelligence (AI) offer unprecedented opportunities to decipher intricate microbial interactions and leverage their potential for crop breeding. In this review, we assess AI methodologies derived from human microbiome studies that address foundational data challenges, including high dimensionality, compositionality, and sparsity. Next, we examine the uses of these methods for the functional prediction of microbial traits. We then shift our focus to the rhizosphere, exploring AI-driven approaches for predictive modeling of rhizosphere dynamics, integrating plant phenotypic and microbiome data, and designing synthetic microbial communities (SynComs). Finally, we discuss the major challenges and future prospects of using AI in rhizosphere microbiome research. Specifically, we propose an emerging AI paradigm that integrates complementary inside-out (hologenome-based genomic selection) and outside-in (SynCom design) strategies, powered by transformative technologies such as federated learning, large language models, digital twins, and autonomous AI agents. This review underscores the potential for AI to revolutionize microbiome science and crop improvement.}
}
@article{SINGH2025100231,
title = {United States Food and Drug Administration Regulation of Clinical Software in the Era of Artificial Intelligence and Machine Learning},
journal = {Mayo Clinic Proceedings: Digital Health},
volume = {3},
number = {3},
pages = {100231},
year = {2025},
issn = {2949-7612},
doi = {https://doi.org/10.1016/j.mcpdig.2025.100231},
url = {https://www.sciencedirect.com/science/article/pii/S2949761225000380},
author = {Vidhi Singh and Susan Cheng and Alan C. Kwan and Joseph Ebinger}
}
@article{GIRAUD2024475,
title = {Artificial intelligence in radiotherapy: Current applications and future trends},
journal = {Diagnostic and Interventional Imaging},
volume = {105},
number = {12},
pages = {475-480},
year = {2024},
issn = {2211-5684},
doi = {https://doi.org/10.1016/j.diii.2024.06.001},
url = {https://www.sciencedirect.com/science/article/pii/S2211568424001372},
author = {Paul Giraud and Jean-Emmanuel Bibault},
keywords = {Artificial intelligence, Automatic segmentation, Clinical decision-support, Radiation oncology, Synthetic imaging},
abstract = {Radiation therapy has dramatically changed with the advent of computed tomography and intensity modulation. This added complexity to the workflow but allowed for more precise and reproducible treatment. As a result, these advances required the accurate delineation of many more volumes, raising questions about how to delineate them, in a uniform manner across centers. Then, as computing power improved, reverse planning became possible and three-dimensional dose distributions could be generated. Artificial intelligence offers the opportunity to make such workflow more efficient while increasing practice homogeneity. Many artificial intelligence-based tools are being implemented in routine practice to increase efficiency, reduce workload and improve homogeneity of treatments. Data retrieved from this workflow could be combined with clinical data and omic data to develop predictive tools to support clinical decision-making process. Such predictive tools are at the stage of proof-of-concept and need to be explainatory, prospectively validated, and based on large and multicenter cohorts. Nevertheless, they could bridge the gap to personalized radiation oncology, by personalizing oncologic strategies, dose prescriptions to tumor volumes and dose constraints to organs at risk.}
}
@article{ELLERY2025101100,
title = {The state of hybrid artificial intelligence for interstellar missions},
journal = {Progress in Aerospace Sciences},
volume = {156},
pages = {101100},
year = {2025},
note = {Unidentified Aerospace Phenomena},
issn = {0376-0421},
doi = {https://doi.org/10.1016/j.paerosci.2025.101100},
url = {https://www.sciencedirect.com/science/article/pii/S0376042125000260},
author = {Alex Ellery},
keywords = {Interstellar missions, Spacecraft autonomy, Artificial intelligence (AI), Self-repair, Neural networks, Symbolic logic, Evolutionary algorithms},
abstract = {Interstellar missions will require a high degree of autonomy mediated through artificial intelligence (AI). All interstellar missions are characterised by 50-100-year transits to extrasolar systems. High system availability demands that interstellar spacecraft are self-repairable imposing significant demands on onboard intelligence. We review the current status of artificial intelligence to assess its capabilities in providing such autonomy. In particular, we focus on hybrid AI methods as these appear to offer the richest capabilities in offsetting weaknesses inherent in paradigmic approaches. Symbolic manipulation systems offer logical and comprehensible rationality with predictable behaviours but are brittle beyond their specific applications (a charge that may be levelled at neural networks unless the transfer learning problem can be resolved). More modern approaches to expert systems include Bayesian networks that incorporate probabilistic treatment to accommodate uncertainty. Artificial neural networks are fundamentally different. They are opaque to analysis but potentially offer greater adaptability in application by virtue of their ability to learn. Indeed, deep machine learning is a variation on neural networks with unsupervised neural front ends and supervised neural back ends. Reinforcement learning offers a promising approach for learning directly from the environment. There are inherent weaknesses in neural approaches regarding their hidden mechanisms rendering their distributed representations opaque to analysis. Hybridising symbolic processing techniques with artificial neural networks appears to offer the advantages of both. Human cognition appears to implement both neural learning and symbolic processing. There are several approaches to such hybridisation that we explore including knowledge-based artificial neural networks, fuzzy neural networks, Bayesian methods such as Markov logic networks and genetic methods such as learning classifier systems. Markov logic networks propose a natural correlation between Bayesian probability and neural weights but mapping representation of symbols into switching neurons is less clear (though vector symbolic architectures present an approach) while learning classifier systems are reinforcement learning methods that are promising for interacting with the physical world. We conclude that current AI may not yet be up to the task of interstellar transits and flybys let alone for physical interaction with unknown planetary environments. Certainly, AI is incapable of interactive encounters with extraterrestrial intelligence.}
}
@article{KANDHARE2025100375,
title = {Artificial intelligence in pharmaceutical sciences: A comprehensive review},
journal = {Medicine in Novel Technology and Devices},
volume = {27},
pages = {100375},
year = {2025},
issn = {2590-0935},
doi = {https://doi.org/10.1016/j.medntd.2025.100375},
url = {https://www.sciencedirect.com/science/article/pii/S2590093525000268},
author = {Priyanka Kandhare and Mrunal Kurlekar and Tanvi Deshpande and Atmaram Pawar},
keywords = {Artificial intelligence, Molecular modeling, Pharmacovigilance, Deep learning, Cheminformatics, Drug discovery},
abstract = {The integration of artificial intelligence (AI) and machine learning (ML) into pharmaceutical sciences has catalyzed transformative advancements across drug discovery, clinical development, manufacturing, and post-market surveillance. This review comprehensively examines AI's role in modern pharmacotherapy, beginning with its historical evolution in life sciences and progressing to cutting-edge applications such as AlphaFold-driven protein modeling, natural language processing (NLP) for biomedical literature mining, and AI-augmented pharmacovigilance. Methodologically, we synthesize interdisciplinary insights from peer-reviewed literature (2013–2023), highlighting innovations in cheminformatics (e.g., QSAR, RDKit), predictive toxicology, and personalized medicine. Case studies illustrate AI's capacity to compress drug development timelines, as seen in COVID-19 repurposing efforts and de novo kinase inhibitor design. However, challenges persist, including algorithmic bias, regulatory ambiguities, and the “black-box” nature of deep learning models. By critically evaluating successes and limitations, this review underscores AI's potential to redefine pharmaceutical innovation while advocating for robust frameworks to ensure ethical, transparent, and clinically translatable AI deployment.}
}
@article{XU2025267,
title = {Artificial intelligence in surgical oncology: A comprehensive review from preoperative planning to postoperative care},
journal = {Intelligent Oncology},
volume = {1},
number = {4},
pages = {267-276},
year = {2025},
issn = {2950-2616},
doi = {https://doi.org/10.1016/j.intonc.2025.09.001},
url = {https://www.sciencedirect.com/science/article/pii/S2950261625000470},
author = {Peijun Xu and Miao Liu and Maoyun Liu and Ai Shen},
keywords = {Artificial intelligence, Machine learning, Robotic surgery, Personalized medicine},
abstract = {While artificial intelligence (AI) has demonstrated significant potential across medical fields, its surgical applications, particularly in oncology remain largely exploratory. This review synthesizes recent advances in AI technologies and their clinical integration within surgery. Preoperatively, AI strengthens planning by increasing risk prediction accuracy, refining imaging analysis, and enabling virtual surgical training, thereby optimizing surgical preparation and safety. Intraoperatively, it facilitates real-time navigation, powers robotic assistance, enables 5G telesurgery, and provides decision support, contributing to enhanced precision and procedural efficiency. Postoperatively, AI-driven monitoring and remote care optimize recovery pathways and complication management, improving outcomes and resource utilization. Despite these advancements, key challenges persist, including data bias, the “black-box” problem, privacy concerns, model generalizability, and real-time processing constraints. Interdisciplinary collaboration, robust ethical frameworks, and sustained technical refinement are essential to fully realizing AI’s potential. Future progress, driven by technological evolution and deeper multidisciplinary cooperation, is poised to advance the practice of surgical oncology toward greater precision, intelligence, and accessibility, thereby fostering innovation in global healthcare systems.}
}
@article{LI20251012,
title = {Personalized recommendation of intelligent library resources based on artificial intelligence algorithm},
journal = {Procedia Computer Science},
volume = {261},
pages = {1012-1018},
year = {2025},
note = {The 5th International Conference on Machine Learning and Big Data Analytics for IoT Security and Privacy (SPIoT2024)},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2025.04.494},
url = {https://www.sciencedirect.com/science/article/pii/S1877050925015972},
author = {Siqi Li},
keywords = {Artificial intelligence, Personalized recommendation, Intelligent library;},
abstract = {This paper proposes a personalized recommendation method of intelligent library resources based on artificial intelligence algorithm, aiming at improving the utilization rate of library resources and user satisfaction. By analyzing the user’s borrowing history, browsing behavior, interests and other multidimensional information, the method constructs a user portrait, combines the characteristics of book resources, uses advanced artificial intelligence algorithms to accurately match, and recommends the book resources that meet the user’s needs. The experiment proves that through this method, the smart library can realize the accurate grasp of user needs and provide more personalized services, so as to improve the overall service quality and user experience of the library.}
}
@article{TRIGUERO2024102135,
title = {General Purpose Artificial Intelligence Systems (GPAIS): Properties, definition, taxonomy, societal implications and responsible governance},
journal = {Information Fusion},
volume = {103},
pages = {102135},
year = {2024},
issn = {1566-2535},
doi = {https://doi.org/10.1016/j.inffus.2023.102135},
url = {https://www.sciencedirect.com/science/article/pii/S1566253523004517},
author = {Isaac Triguero and Daniel Molina and Javier Poyatos and Javier {Del Ser} and Francisco Herrera},
keywords = {General-purpose AI, Meta-learning, Reinforcement learning, Neuroevolution, Few-shot learning, AutoML, Transfer learning, Generative AI, Large language models},
abstract = {Most applications of Artificial Intelligence (AI) are designed for a confined and specific task. However, there are many scenarios that call for a more general AI, capable of solving a wide array of tasks without being specifically designed for them. The term General Purpose Artificial Intelligence Systems (GPAIS) has been defined to refer to these AI systems. To date, the possibility of an Artificial General Intelligence, powerful enough to perform any intellectual task as if it were human, or even improve it, has remained an aspiration, fiction, and considered a risk for our society. Whilst we might still be far from achieving that, GPAIS is a reality and sitting at the forefront of AI research. This work discusses existing definitions for GPAIS and proposes a new definition that allows for a gradual differentiation among types of GPAIS according to their properties and limitations. We distinguish between closed-world and open-world GPAIS, characterising their degree of autonomy and ability based on several factors such as adaptation to new tasks, competence in domains not intentionally trained for, ability to learn from few data, or proactive acknowledgement of their own limitations. We then propose a taxonomy of approaches to realise GPAIS, describing research trends such as the use of AI techniques to improve another AI (commonly referred to as AI-powered AI) or (single) foundation models. As a prime example, we delve into generative AI (GenAI), aligning them with the terms and concepts presented in the taxonomy. Similarly, we explore the challenges and prospects of multi-modality, which involves fusing various types of data sources to expand the capabilities of GPAIS. Through the proposed definition and taxonomy, our aim is to facilitate research collaboration across different areas that are tackling general purpose tasks, as they share many common aspects. Finally, with the goal of providing a holistic view of GPAIS, we discuss the current state of GPAIS, its prospects, implications for our society, and the need for regulation and governance of GPAIS to ensure their responsible and trustworthy development.}
}
@article{CHEN2025151916,
title = {Systematic review: The integration of artificial intelligence-powered cognitive-behavioural therapy for autonomous mental health management},
journal = {Archives of Psychiatric Nursing},
volume = {57},
pages = {151916},
year = {2025},
issn = {0883-9417},
doi = {https://doi.org/10.1016/j.apnu.2025.151916},
url = {https://www.sciencedirect.com/science/article/pii/S0883941725000871},
author = {Li-Ting Chen and Li-Ching Yang and Fang-Yi Lin and Yueh-Hsiu Lin},
keywords = {Systematic review, Artificial intelligence, Depressive symptoms, College students, Young adults},
abstract = {Background
Depression is a widespread mental health disorder that affects quality of life, with traditional treatments often resource-intensive. Studies have demonstrated the effectiveness of CBT-based AI in alleviating depressive symptoms through autonomous mental health management.
Purpose
To evaluate the effect and the integration level of Cognitive-Behavioural Therapy-based artificial intelligence (AI) on autonomous health management in depressive symptoms care.
Methods
This systematic review used the PRISMA methodology and a mixed-methods appraisal tool. Studies included randomized controlled trials using artificial intelligence interventions for depression, analysing theoretical frameworks, intervention designs, and outcomes. Reviews and protocols were excluded. Data sources were searched in the Cochrane Library, CINAHL Plus with Full Text, and PubMed for articles published between October 2019 and October 2024.
Results
Five studies demonstrated that artificial intelligence designs incorporating the Cognitive-Behavioural Therapy guidance framework specifically indicated short-term intervention effectiveness. Of these AI interventions, only partial integration of 54 % implemented a theoretical framework in AI design. Nevertheless, findings revealed a significant 60 % decrease in depressive symptoms among participants who engaged with the AI-based autonomous mental health management, particularly those with moderate-to-severe depression, when grounded in a strong theoretical foundation.
Conclusion
Cognitive-Behavioural Therapy-based artificial intelligence interventions have demonstrated effectiveness in decrease depressive symptoms through patient self-management platforms. The theory-driven approach not only guides the development of AI applications but also facilitates the implementation of automated mental health interventions, thereby reducing the workload of nursing staff. This integration of CBT-guided AI technology empowers patients with self-management tools while optimizing nursing resources in mental health settings.}
}
@article{PARAB2025,
title = {Artificial Intelligence in Diabetes Care: Applications, Challenges, and Opportunities Ahead},
journal = {Endocrine Practice},
year = {2025},
issn = {1530-891X},
doi = {https://doi.org/10.1016/j.eprac.2025.07.008},
url = {https://www.sciencedirect.com/science/article/pii/S1530891X25009668},
author = {Rohit Parab and Jenna M. Feeley and Maria Valero and Laya Chadalawada and Gian-Gabriel P. Garcia and Sudeshna Sil Kar and Anant Madabhushi and Marc D. Breton and Jing Li and Hui Shao and Francisco J. Pasquel},
keywords = {artificial intelligence, machine learning, diabetes, technology, automated insulin, delivery, continuous glucose monitoring},
abstract = {Background. Artificial intelligence (AI) is rapidly transforming clinical medicine, and its impact on diabetes care is especially noteworthy. By enhancing diagnostic accuracy and optimizing treatment strategies, AI can reduce patient burden and improve quality of life. In this narrative review, we examine the latest AI applications in diabetes care, exploring their capabilities, limitations, and the future directions needed to fully translate these advances into routine practice.
Methods
A comprehensive search of PubMed, Google Scholar, and ScienceDirect identified relevant articles focused on the use of AI and machine learning (ML) in diabetes care. To enrich the evidence base, we also incorporated emerging approaches from the research programs of the contributing authors. Key findings from these studies were extracted and synthesized to highlight emerging trends, applications, and outcomes.
Findings
In recent years, both traditional ML approaches and deep learning algorithms have been applied to improve screening for complications of diabetes such as retinopathy, macular edema, and neuropathy, predict disease progression risk, and enhance clinical decision support systems for diagnosis, prognosis, and treatment optimization. AI-driven solutions are also emerging to identify noninvasive biomarkers for detecting diabetes and prediabetes, analyze the macronutrient content of meals using image-based deep learning methods, integrate novel risk prediction tools within electronic health records, and optimize automated insulin delivery systems.
Implications
AI advancements hold promise for streamlining patient care, personalizing treatment plans, and ultimately improving clinical outcomes for individuals living with diabetes.}
}
@article{TUROS2025100394,
title = {What percentage of secondary school students do their homework with the help of artificial intelligence? - A survey of attitudes towards artificial intelligence},
journal = {Computers and Education: Artificial Intelligence},
volume = {8},
pages = {100394},
year = {2025},
issn = {2666-920X},
doi = {https://doi.org/10.1016/j.caeai.2025.100394},
url = {https://www.sciencedirect.com/science/article/pii/S2666920X25000347},
author = {Mátyás Turós and Róbert Nagy and Zoltán Szűts},
keywords = {Education, Authorship, Student, Attitudes, Sentiment analysis, Educational technology},
abstract = {Based on practical experiences, news articles, and subjective reports, a significant proportion of high school students complete their writing assignments (essays) using ChatGPT or other text-generating software. However, to the best of our knowledge, there is a very limited amount of work on this topic. Therefore, our study has two objectives. First, through human coding, we determine whether student essays submitted as homework were created by humans or software, and second, we examine these essays' sentiment and authorship, as well as factors determining the use of artificial intelligence in learning. Data collection was conducted in April and May 2024 across thirty classes from twenty Hungarian high schools. Our results show that 16 % of high school students (N = 548) wrote their text-based homework assignments using artificial intelligence, though neither age nor parents' average educational level determined the use of AI in learning. Although women have more positive attitudes toward using AI for learning purposes, they are less likely to use it to complete their homework assignments. Finally, we found that fears related to artificial intelligence are general and lack specificity. Our findings have three practical implications: 1) they highlight the need for targeted educational programs to develop ethical AI use, 2) they assist teachers in identifying AI-generated texts, and 3) they draw attention to gender differences in AI usage.}
}
@article{LUKAC2025104564,
title = {Artificial intelligence as treatment support in breast cancer: current perspectives},
journal = {The Breast},
volume = {83},
pages = {104564},
year = {2025},
issn = {0960-9776},
doi = {https://doi.org/10.1016/j.breast.2025.104564},
url = {https://www.sciencedirect.com/science/article/pii/S0960977625005818},
author = {Stefan Lukac and Florian Putz and Giacomo {De Micheli} and Chiara Corti and Wolfgang Janni and Sara M. Tolaney and Giuseppe Curigliano and Sibylle Loibl and Paolo Tarantino and Jose Pablo Leone},
keywords = {Artificial intelligence, Breast cancer treatment, Surgery, Irradiation, Systemic treatment, Supportive care},
abstract = {With the increasing amount of information related to breast cancer (BC) management, artificial intelligence (AI) has emerged as a tool with the potential to enhance the quality of treatment through the efficient integration of large datasets; however, the specific areas for which AI may be ready for clinical implementation remain unclear. In this narrative review, we recapitulate the available data on AI utilization in BC treatment by focusing on surgical therapy, radiation therapy, systemic and supportive treatment, but including the diagnostics, too. While AI has been implemented successfully in mammography screening, preoperative consultation, and radiation oncology, its use intraoperatively, post-operatively, and in systemic and supportive treatment is still in development. AI has potential to improve care, but since the accuracy of AI varies, careful consideration of its benefits and limitations is necessary.}
}
@article{GORSKI2025102819,
title = {Parental, Patient, and Provider Perspectives on the Use of Artificial Intelligence in Pediatric Care},
journal = {Academic Pediatrics},
volume = {25},
number = {6},
pages = {102819},
year = {2025},
issn = {1876-2859},
doi = {https://doi.org/10.1016/j.acap.2025.102819},
url = {https://www.sciencedirect.com/science/article/pii/S1876285925000440},
author = {Jillian Gorski and James Rudloff and Sriram Ramgopal},
keywords = {artificial intelligence, clinical, decision support systems, parents, pediatrics}
}
@article{KHAMAJ2024e30866,
title = {Human factors engineering simulated analysis in administrative, operational and maintenance loops of nuclear reactor control unit using artificial intelligence and machine learning techniques},
journal = {Heliyon},
volume = {10},
number = {10},
pages = {e30866},
year = {2024},
issn = {2405-8440},
doi = {https://doi.org/10.1016/j.heliyon.2024.e30866},
url = {https://www.sciencedirect.com/science/article/pii/S240584402406897X},
author = {Abdulrahman Khamaj and Abdulelah M. Ali and Rajasekaran Saminathan and Shanmugasundaram M},
keywords = {Artificial intelligence, Machine learning, Human factor engineering, Nuclear reactor control unit, GAN, iForest},
abstract = {The nuclear reactor control unit employs human factor engineering to ensure efficient operations and prevent any catastrophic incidents. This sector is of utmost importance for public safety. This study focuses on simulated analysis of specific areas of nuclear reactor control, specifically administration, operation, and maintenance, using artificial intelligence software. The investigation yields effective artificial intelligence algorithms that capture the essential and non-essential components of numerous parameters to be monitored in nuclear reactor control. The investigation further examines the interdependencies between various parameters and validates the statistical outputs of the model through attribution analysis. Furthermore, a Multivariant ANOVA analysis is conducted to identify the interactive plots and mean plots of crucial parameters interactions. The artificial intelligence algorithms demonstrate the correlation between the number of vacant staff jobs and both the frequency of license event reports each year and the ratio of contract employees to regular employees in the administrative domain. An AI method uncovers the relationships between the operator failing rate (OFR), operator processed errors (OEE), and operations at limited time frames (OLC). The AI algorithm reveals the interdependence between equipment in the out of service (EOS), progressive maintenance schedule (PRMR), and preventive maintenance schedules (PMRC). Effective machine learning neural network models are derived from generative adversarial network (GAN) algorithms and proposed for administrative, operational and maintenance loops of nuclear reactor control unit.}
}
@article{WU2026100817,
title = {New paradigm of distributed artificial intelligence for LLM implementation and its key technologies},
journal = {Computer Science Review},
volume = {59},
pages = {100817},
year = {2026},
issn = {1574-0137},
doi = {https://doi.org/10.1016/j.cosrev.2025.100817},
url = {https://www.sciencedirect.com/science/article/pii/S1574013725000930},
author = {Yijin Wu and Zirun Li and Bingrui Guo and Shanshan He and Bijing Liu and Xiaojie Liu and Shan He and Donghui Guo},
keywords = {Distributed artificial intelligence, Cloud computing, Caching, Load-balancing, Reasoning, LLM},
abstract = {With the Internet’s development and information technology advancement, current network applications and services, such as e-commerce, industrial automation, and vehicular automation, have experienced substantial expansion. Foundation models, represented by large language models (LLMs), have emerged in response to growing demands. Their broad range of applications has brought significant advancements to various industries. While such developments have improved people’s economic lives and social activities, the challenges posed by the rapid growth of data volume and network traffic cannot be overlooked. Intelligent systems aimed at enhancing knowledge computation and learning capabilities are gradually gaining attention. Nevertheless, efficient and flexible intelligent systems are still in their early stages, leaving ample space for further optimization. This study provides an overview of Distributed Artificial Intelligence (DAI) with its related paradigm, briefly introduces the evolution of LLMs, and proposes a novel optimization framework named PCD Tri-Tuning for DAI workflows: leveraging caching-related technologies to enhance perceptual capabilities, adopting load-balancing techniques for computational optimization, and developing reasoning methodologies and cooperation techniques to improve decision-making. Subsequently, the study examines the pivotal role of the proposed optimization framework in practical domains such as e-commerce, smart manufacturing, and vehicular automation while also discussing the challenges and outlining strategies for further development.}
}
@article{KANTOR2025xi,
title = {Artificial Intelligence in Dermatology: Fundamentals and Advanced Applications},
journal = {Dermatologic Clinics},
volume = {43},
number = {4},
pages = {xi-xii},
year = {2025},
note = {Artificial Intelligence in Dermatology},
issn = {0733-8635},
doi = {https://doi.org/10.1016/j.det.2025.07.001},
url = {https://www.sciencedirect.com/science/article/pii/S0733863525000518},
author = {Jonathan Kantor}
}
@article{CLAMAN2024,
title = {Artificial Intelligence in Dental Education: Opportunities and Challenges of Large Language Models and Multimodal Foundation Models},
journal = {JMIR Medical Education},
volume = {10},
year = {2024},
issn = {2369-3762},
doi = {https://doi.org/10.2196/52346},
url = {https://www.sciencedirect.com/science/article/pii/S2369376224001119},
author = {Daniel Claman and Emre Sezgin},
keywords = {artificial intelligence, large language models, dental education, GPT, ChatGPT, periodontal health, AI, LLM, LLMs, chatbot, natural language, generative pretrained transformer, innovation, technology, large language model},
abstract = {Instructional and clinical technologies have been transforming dental education. With the emergence of artificial intelligence (AI), the opportunities of using AI in education has increased. With the recent advancement of generative AI, large language models (LLMs) and foundation models gained attention with their capabilities in natural language understanding and generation as well as combining multiple types of data, such as text, images, and audio. A common example has been ChatGPT, which is based on a powerful LLM—the GPT model. This paper discusses the potential benefits and challenges of incorporating LLMs in dental education, focusing on periodontal charting with a use case to outline capabilities of LLMs. LLMs can provide personalized feedback, generate case scenarios, and create educational content to contribute to the quality of dental education. However, challenges, limitations, and risks exist, including bias and inaccuracy in the content created, privacy and security concerns, and the risk of overreliance. With guidance and oversight, and by effectively and ethically integrating LLMs, dental education can incorporate engaging and personalized learning experiences for students toward readiness for real-life clinical practice.}
}
@article{VOLIN2025,
title = {Artificial Intelligence and Its Effect on Radiology Residency Education: Current Challenges, Opportunities, and Future Directions},
journal = {Journal of the American College of Radiology},
year = {2025},
issn = {1546-1440},
doi = {https://doi.org/10.1016/j.jacr.2025.07.004},
url = {https://www.sciencedirect.com/science/article/pii/S1546144025003990},
author = {Joshua Volin and Marly {van Assen} and Wasif Bala and Nabile Safdar and Patricia Balthazar},
keywords = {Artificial intelligence, bias, education, residency},
abstract = {Artificial intelligence has become an impressive force manifesting itself in the radiology field, improving workflows, and influencing clinical decision making. With this increasing presence, a closer look at how residents can be properly exposed to this technology is needed. Within this article, we aim to discuss the three pillars central to a trainee’s experience including education on AI, AI education tools, and clinical implementation of AI. An already overcrowded clinical residency curricula makes little room for a thorough AI education, the challenge of which may be overcome through longitudinal distinct educational tracks during residency or external courses offered through a variety of societies. In addition to teaching the fundamentals of AI, programs that offer education tools using AI will improve on antiquated clinical curricula. These education tools are a growing field in research and industry offering a variety of unique opportunities to promote active inquiry, improved comprehension, and overall clinical competence. The near 700 FDA-approved AI clinical tools almost guarantee that residents will be exposed to this technology, which may have mixed effects on education, although more research needs to be done to further elucidate this challenge. Ethical considerations, including algorithmic bias, liability, and postdeployment monitoring, highlight the need for structured instruction and mentorship. As AI continues to evolve, residency programs must prioritize evidence-based, adaptable curricula to prepare future radiologists to critically assess, use, and contribute to AI advancements, ensuring that these tools complement rather than undermine clinical expertise.}
}
@article{LAJOIE2025102810,
title = {Content marketing as a propaganda vehicle for a romantic-managerial conception of artificial intelligence},
journal = {Critical Perspectives on Accounting},
volume = {102},
pages = {102810},
year = {2025},
issn = {1045-2354},
doi = {https://doi.org/10.1016/j.cpa.2025.102810},
url = {https://www.sciencedirect.com/science/article/pii/S1045235425000231},
author = {Pier-Luc Lajoie},
keywords = {Artificial intelligence, Content marketing, Technical society, Technical propaganda, Professional service firms, Discourse analysis, Commercialization of social issues},
abstract = {Drawing on Deloitte’s content marketing between 2017 and 2022, this study examines how a conception of artificial intelligence (AI) is shaped and disseminated according to the precepts of technical propaganda outlined by Jacques Ellul. The firm promotes a romantic-managerial conception of AI that suggests business specialists can help organizations reap the benefits of the miraculous promises of a human-centered AI, without incurring any of the drawbacks, based on the assumption that it is possible to control AI. Three complementary discursive archetypes are mobilized by the firm to spur organizations into action: the prophet, arousing enthusiasm by spreading the “Good News” about AI; the demystifier, numbing concerns about the potential drifts of the technical society; and the bird of ill omen, stoking a fear of inertia. This study highlights the relevance of Jacques Ellul’s work to stimulate the ongoing debate within the critical accounting community about the perils of AI’s proliferation in organizations and society. Beyond its traditional function of legitimizing expertise, content marketing is mobilized as a propaganda vehicle for a conception of AI seemingly shaped in the mold of the firm’s own professional services offering. Finally, by showing how the precepts of propaganda are incorporated into content marketing, this study highlights the commercialization of contemporary social issues as a pivotal step in the colonization of professional accounting services by marketing expertise.}
}
@incollection{MONFORTLANZAS2024,
title = {Application of artificial intelligence in immuno-oncology},
booktitle = {Reference Module in Biomedical Sciences},
publisher = {Elsevier},
year = {2024},
isbn = {978-0-12-801238-3},
doi = {https://doi.org/10.1016/B978-0-443-14064-8.00017-5},
url = {https://www.sciencedirect.com/science/article/pii/B9780443140648000175},
author = {Pablo Monfort-Lanzas and Raphael Gronauer and Melanie Balaz and Gabriel Floriani and Hubert Hackl},
keywords = {Antigen prediction, Artificial intelligence, Deep learning, Explainable AI, Immuno-oncology, Immunotherapy, Large language model, Predictive biomarker, T cell activation, T cell receptor, Therapeutic vaccination, Tumor microenvironment},
abstract = {Artificial intelligence (AI) has significantly influenced biomedicine, particularly in the field of immuno-oncology. This work explores the current advancements and challenges in AI emphasizing their application in immuno-oncology. We discuss various AI principles and architectures, such as transformer technology, highlighting their predictive and generative capabilities. One of the main challenges in immuno-oncology is predicting responses to immunotherapy. We describe AI-driven methods for developing predictive biomarkers using digital pathology, radiomics, and transcriptomics data. Recent AI successes in this area include the activation of T cells by antigens and the analysis of the tumor immune microenvironment, especially in cell annotation.}
}
@article{TAO2025100696,
title = {Mapping the landscape of Artificial intelligence for serious games in Health: An enhanced meta review},
journal = {Computers in Human Behavior Reports},
volume = {18},
pages = {100696},
year = {2025},
issn = {2451-9588},
doi = {https://doi.org/10.1016/j.chbr.2025.100696},
url = {https://www.sciencedirect.com/science/article/pii/S2451958825001113},
author = {Xiya Tao and Nicolás Sáenz-Lechón and Martina Eckert},
keywords = {Serious games, Artificial intelligence, Machine learning, Exergames, Gamification, Gaming, Adaptation, Personalisation, Individualization, Health, Multimodal data},
abstract = {This paper presents an enhanced meta-review of artificial intelligence (AI) applications in serious games (SGs) for health, focusing on adaptation, personalisation, and real-time data processing to improve rehabilitation outcomes. A systematic review methodology, following PRISMA-ScR guidelines, was employed to analyse studies from 2017 to 2025, identifying the AI algorithms most frequently used to personalise gaming experiences, improve patient engagement, and increase treatment efficacy. Our proposal categorises the algorithms based on their role in the game environment, which can either be game control or user assessment. Game control algorithms adapt the game environment and difficulty, while user assessment algorithms gather information about the player's state, such as performance, mood, or physiological data, to evaluate the treatment progress. The review also examines the growing trend of using multimodal data as input for machine learning models. Results show that a few well-known algorithms, such as Decision Trees (DT), Artificial Neural Networks (ANN), Fuzzy Logic (FL), Naïve Bayes (NB), and Support Vector Machines (SVM), are frequently used. However, there is a clear distinction in their purposes: while FL is typically applied to game control tasks, SVMs are mainly used for user assessment. This review offers valuable insights for researchers in the field, providing a comprehensive overview of the suitability of different AI algorithms for various tasks in SGs, with a particular focus on personalisation and motivation.}
}
@article{YERRA2026110779,
title = {A study on challenges and solutions in artificial intelligence-driven demand side optimization and security enhancement for smart grids},
journal = {Computers and Electrical Engineering},
volume = {129},
pages = {110779},
year = {2026},
issn = {0045-7906},
doi = {https://doi.org/10.1016/j.compeleceng.2025.110779},
url = {https://www.sciencedirect.com/science/article/pii/S0045790625007220},
author = {Chittemma Yerra and Kiran Teeparthi and Srinu Naik Ramavathu and S.N. V. Bramareswara Rao and Y.V. Pavan Kumar and Rammohan Mallipeddi},
keywords = {Artificial intelligence, Blockchain, Decentralized systems, Demand-side management, Energy management, Optimization, Peer-to-peer trading, Smart grids},
abstract = {In modern smart grids, demand-side management (DSM) plays a vital role in enhancing energy efficiency, balancing supply and demand, and managing distributed energy resources. Conventional DSM approaches, however, often lack the flexibility, scalability, and security required for decentralized energy systems. The integration of Advanced Metering Infrastructure (AMI) and growing dependence on communication networks further introduce new challenges. Artificial Intelligence (AI)-driven solutions offer promising pathways by enabling intelligent demand response and enhanced security. This paper reviews the role of Machine Learning (ML), Deep Reinforcement Learning (DRL), and blockchain in reshaping DSM strategies. ML and DRL provide intelligent adaptability through real-time data processing, demand forecasting, and autonomous decision-making, while blockchain ensures decentralized data security, privacy, and trust. The study highlights their combined potential for efficient, secure, and resilient DSM in future smart grids.}
}
@article{MATHESON20256330,
title = {Disease Classification of Pulmonary Xenon Ventilation MRI Using Artificial Intelligence},
journal = {Academic Radiology},
volume = {32},
number = {10},
pages = {6330-6342},
year = {2025},
issn = {1076-6332},
doi = {https://doi.org/10.1016/j.acra.2025.06.024},
url = {https://www.sciencedirect.com/science/article/pii/S1076633225005732},
author = {Alexander M. Matheson and Abdullah S. Bdaiwi and Matthew M. Willmering and Erik B. Hysinger and Francis X. McCormack and Laura L. Walkup and Zackary I. Cleveland and Jason C. Woods},
keywords = {Deep learning, Artificial intelligence, Pulmonary imaging, Classification, Convolutional neural networks},
abstract = {Rationale and Objectives
Hyperpolarized 129Xenon magnetic resonance imaging (MRI) measures the extent of lung ventilation by ventilation defect percent (VDP), but VDP alone cannot distinguish between diseases. Prior studies have reported anecdotal evidence of disease-specific defect patterns such as wedge-shaped defects in asthma and polka-dot defects in lymphangioleiomyomatosis (LAM). Neural network artificial intelligence can evaluate image shapes and textures to classify images, but this has not been attempted in xenon MRI. We hypothesized that an artificial intelligence network trained on ventilation MRI could classify diseases based on spatial patterns in lung MR images alone.
Materials and Methods
Xenon MRI data in six pulmonary conditions (control, asthma, bronchiolitis obliterans syndrome, bronchopulmonary dysplasia, cystic fibrosis, LAM) were used to train convolutional neural networks. Network performance was assessed with top-1 and top-2 accuracy, recall, precision, and one-versus-all area under the curve (AUC). Gradient class-activation-mapping (Grad-CAM) was used to visualize what parts of the images were important for classification.
Results
Training/testing data were collected from 262 participants. The top performing network (VGG-16) had top-1 accuracy=56%, top-2 accuracy=78%, recall=.30, precision=.70, and AUC=.85. The network performed better on larger classes (top-1 accuracy: control=62% [n=57], CF=67% [n=85], LAM=69% [n=61]) and outperformed human observers (human top-1 accuracy=40%, network top-1 accuracy=61% on a single training fold).
Conclusion
We developed an artificial intelligence tool that could classify disease from xenon ventilation images alone that outperformed human observers. This suggests that xenon images have additional, disease-specific information that could be useful for cases that are clinically challenging or for disease phenotyping.}
}
@article{CHEN2025100075,
title = {Intelligent assisted reproduction: Innovative applications of artificial intelligence in embryo health assessment},
journal = {LabMed Discovery},
volume = {2},
number = {2},
pages = {100075},
year = {2025},
issn = {3050-4740},
doi = {https://doi.org/10.1016/j.lmd.2025.100075},
url = {https://www.sciencedirect.com/science/article/pii/S3050474025000242},
author = {Kuo Chen and Jing Zuo and Wei Han and Jin-hong Guo},
keywords = {Embryo health assessment,  fertilization (IVF), Artificial intelligence (AI), Reproductive technology, Automated evaluation system, Assisted reproductive technologies (ARTs)},
abstract = {Identifying embryos with the highest likelihood of successful implantation is a critical component of the in vitro fertilization (IVF) process. Visual assessments are limited by the subjectivity of embryologists, making consistent evaluation of embryo health challenging with traditional methods. Recent advances in artificial intelligence (AI)—particularly in computer vision and deep learning—have enabled the automated analysis of embryo morphology images, reducing subjectivity and improving evaluation efficiency. Through an extensive literature search using keywords such as “embryo health assessment” and “artificial intelligence,” the present review focuses on AI-driven approaches for automated embryo evaluation. It examines AI techniques applied to embryo assessment across the early development, blastocyst, and full developmental stages. This review indicated the promising potential of AI technologies in enhancing the precision, consistency, and speed of embryo selection. AI models have been reported to outperform manual evaluations across several parameters, offering promising opportunities to improve success rates and operational efficiency in reproductive medicine. Additionally, this review discusses the current limitations of AI implementation in clinical settings and explores future research directions. Overall, the review provides insight into AI’s growing role in advancing embryo selection and highlights the path toward fully automated evaluation systems in assisted reproductive technology.}
}
@article{SANTHOSHKUMAR2025,
title = {Patient trust in artificial intelligence for orthodontic advice: A systematic review},
journal = {The Journal of the American Dental Association},
year = {2025},
issn = {0002-8177},
doi = {https://doi.org/10.1016/j.adaj.2025.08.003},
url = {https://www.sciencedirect.com/science/article/pii/S0002817725004647},
author = {Sanjana {Santhosh Kumar} and Dimitrios Michelogiannakis and Xiuhui Xu and Rachel Chacko and Junad Khan},
keywords = {Artificial intelligence, health information–seeking behavior, orthodontic patient advice, orthodontics, ChatGPT, machine learning, systematic review},
abstract = {Background
Artificial intelligence (AI) large language models are being used increasingly for health care–related queries. This systematic review assessed the reliability of AI chatbot responses to patient questions related to orthodontics.
Types of Studies Reviewed
PubMed, Web of Science, Scopus, Ovid MEDLINE, and Embase were systematically searched for studies published from January 1, 2022, through February 28, 2025. Only cross-sectional studies were included. Data were screened and extracted, and the risk of bias was assessed.
Results
Of 105 identified studies, 13 met the inclusion criteria. ChatGPT (OpenAI) showed 68.7% and 92.6% accuracy rates, scoring well on Likert scales and DISCERN evaluations. However, some studies reported lower scores (2.2/4.0, 3.8/10.0) and mixed results for Bard (Google) and Gemini (Google), highlighting inconsistencies in chatbot performance.
Practical Implications
Whereas large language models, particularly ChatGPT, cannot replace professional consultations, they offer generally reliable orthodontic information and can be valuable tools for addressing routine patient questions. Based on evolving commentary, AI is likely to serve as a frontline support system in the future, helping manage common inquiries, reduce clinician workload, and improve cost-effectiveness while ensuring that final care decisions remain with qualified professionals. This review was registered in Open Science Factory (https://doi.org/10.17605/OSF.IO/X8HJT).}
}
@article{MAJSTOROVIC2025753,
title = {Development and application of artificial intelligence in manufacturing systems – one approach},
journal = {Procedia CIRP},
volume = {134},
pages = {753-758},
year = {2025},
note = {58th CIRP Conference on Manufacturing Systems 2025},
issn = {2212-8271},
doi = {https://doi.org/10.1016/j.procir.2025.02.186},
url = {https://www.sciencedirect.com/science/article/pii/S221282712500575X},
author = {Vidosav Majstorovic and Dragan Djurdjanovic and Slavenko Stojadinovic},
keywords = {Artificial Intelligence, Industry 4.0/5.0, Smart manufacturing, Case studies},
abstract = {Artificial intelligence (AI) that is applied in the entire chain of the new value creation and product life cycle has become the most important part of the Industry 4.0/5.0 model. The history of AI is a little more than eight decades long, and in research and development for manufacturing, it has been applied since the mid-1980s. Expert systems (ES) were the first AI tools implemented in this field. The aim of this paper is to perform a systemic analysis of the state of development and application of AI in manufacturing, which is originally used as support to the engineer, planner, designer and manager of various mechanical products. It is also used to manage processes and systems in manufacturing engineering. The paper is structured in such way that it provides answers to the following questions: how did AI models in manufacturing systems come about and develop, what are today’s models and the perspectives of applying AI in them, and some directions of future research in this area. As a special point of this paper, a review of some of our research results in this area obtained in the last few decades are presented.}
}
@article{ZHANG2025127330,
title = {The paradox of artificial intelligence and environmental performance: The critical role of energy transition and institutional quality},
journal = {Journal of Environmental Management},
volume = {394},
pages = {127330},
year = {2025},
issn = {0301-4797},
doi = {https://doi.org/10.1016/j.jenvman.2025.127330},
url = {https://www.sciencedirect.com/science/article/pii/S0301479725033067},
author = {Anbang Zhang and  Danish and Rui Chen},
keywords = {Sustainable development goals, Energy transition, Artificial intelligence, AAH panel data estimator},
abstract = {The energy transition is crucial to ensuring energy security and achieving net-zero carbon emissions by 2050. Nonetheless, the potential role of artificial intelligence (AI) and institutional quality in the energy transition-carbon dioxide (CO2) emissions relationship is rare and complex in the literature. To fill this critical research gap, this study performs empirical analyses of the relationship between AI and CO2 emissions in 35 Organisation for Economic Co-operation and Development (OECD) countries between 1990 and 2020, considering the critical role of institutions and energy transition in enhancing the environmental advantages of energy transition and promoting Sustainable Development Goal 13 (SDG-13). To pursue the study's objective, the newly introduced Augmented Anderson-Hsiao (AAH) estimator, an efficient technique for panel data analysis, was employed. The AHH estimator's results indicate that a 1% increase in the green quality index significantly reduces CO2 emissions by approximately 66.7%. Additionally, AI has a negative impact on the environment through its detrimental effects on carbon emissions. Finally, institutional quality has a positive and significant impact on reducing CO2 emissions, indicating a beneficial effect on improving environmental performance. These findings highlight the importance of investments in AI-enabled sustainable technologies, robust institutional frameworks, and strategic regulatory measures to expedite global decarbonization.}
}
@article{SAVASTANO2025101374,
title = {Artificial intelligence in ophthalmology: Progress, challenges, and ethical implications},
journal = {Progress in Retinal and Eye Research},
volume = {107},
pages = {101374},
year = {2025},
issn = {1350-9462},
doi = {https://doi.org/10.1016/j.preteyeres.2025.101374},
url = {https://www.sciencedirect.com/science/article/pii/S1350946225000473},
author = {Maria Cristina Savastano and Clara Rizzo and Claudia Fossataro and Daniela Bacherini and Fabrizio Giansanti and Alfonso Savastano and Giovanni Arcuri and Stanislao Rizzo and Francesco Faraldi},
keywords = {Artificial intelligence in ophthalmology, AI ethical considerations, Black-box problem, Patient safety, Data privacy, Liability, Trustworthy AI},
abstract = {The adoption of artificial intelligence (AI) in ophthalmology holds great promise for improving diagnostic accuracy, optimizing workflows, and enhancing patient care. However, regulatory, ethical, and technical challenges must be addressed to ensure its safe and effective implementation. Bias in AI can lead to disparities in healthcare delivery, while the “black-box problem” raises concerns about transparency and trust. Ethical principles must guide AI integration, particularly regarding patient safety, accountability, and liability. Privacy risks related to data collection and security are especially critical in ophthalmology, where large imaging datasets are essential. Additionally, AI-generated inaccuracies, or “hallucinations,” pose potential risks to clinical decision-making. Cybersecurity threats targeting AI-powered healthcare systems further emphasize the need for robust protections. Despite these challenges, AI has the potential to improve access to ophthalmic care, particularly in underserved regions, as seen in AI-assisted diabetic retinopathy screening. However, financial and infrastructural barriers remain significant obstacles to widespread adoption. Addressing these issues requires collaboration among stakeholders, including regulators, healthcare providers, AI developers, and policymakers, to establish clear guidelines and promote trustworthy AI systems. This review explores key regulatory and ethical concerns and highlights strategies to ensure the responsible integration of AI into ophthalmology.}
}
@article{SADOK20244194,
title = {The Effects of Artificial Intelligence on the Future of Employment: Looking for a Trend from a Literature Review},
journal = {Procedia Computer Science},
volume = {246},
pages = {4194-4203},
year = {2024},
note = {28th International Conference on Knowledge Based and Intelligent information and Engineering Systems (KES 2024)},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2024.09.259},
url = {https://www.sciencedirect.com/science/article/pii/S1877050924022786},
author = {Hicham Sadok and Hasna Chaibi and Abdellah Chehri and Rachid Saadane},
keywords = {Artificial intelligence, Employment, Labor Policy},
abstract = {Each new wave of technological progress sparks debates about the effects of automation on the future of employment. Current debates on artificial intelligence (AI) and employment are reminiscent of those raised by mechanization in the 19th century, the generalization of electricity, and the introduction of computers in the 20th century: some consider new technologies as a way to relieve workers of the most challenging tasks, and others are alarmed by the imminent threat to employment. This article aims to contribute to the ongoing debate on the potential changes that may arise from the recent emergence of Generative AI in job markets. It is based on a historical analysis of technological revolutions and a literature review of technology’s impact on employment. The purpose of this study is not to gather general statistics but rather to analyze potential changes and help design suitable policy responses. This analysis will also consider the possible impact on job quality. The study emphasizes the potential implications for various professional categories but does not predetermine the outcomes of technological transition. The decision to incorporate such technologies is driven by humans, and it is their responsibility to guide the transition process.}
}
@article{SHAW2025102495,
title = {Physical artificial intelligence in nursing: Robotics},
journal = {Nursing Outlook},
volume = {73},
number = {5},
pages = {102495},
year = {2025},
issn = {0029-6554},
doi = {https://doi.org/10.1016/j.outlook.2025.102495},
url = {https://www.sciencedirect.com/science/article/pii/S0029655425001484},
author = {Ryan J. Shaw and Boyuan Chen},
keywords = {Nursing, Robotics, Generative artificial intelligence},
abstract = {Background
Robotics, driven by advancements in physical artificial intelligence (AI), offers potential solutions–yet many challenges– to creating innovative care models to meet the needs of the future.
Purpose
To present an overview of robotics across various industries and explain how physical AI is aiding the development and integration of robots into skilled nursing. We discuss the opportunities and challenges of incorporating robots into nursing and offer recommendations for nurses on designing equitable, human-centered care models that include robotics.
Methods
This paper discusses robotics across industries, with a focus on healthcare and nursing. It examines technological capabilities, nursing education needs, and ethical, regulatory, and workforce implications.
Discussion
Robots are increasingly used for logistics, cleaning, and limited direct care tasks. Advancement in physical AI will enable robots to perceive, reason, and act in dynamic environments, supporting human-robot teaming and patient care. Challenges include technical limitations, ethical concerns, disparities in access, and regulatory gaps. Nursing education must evolve to prepare professionals for collaborative practice with robotic systems.
Conclusion
Robotics must be designed to augment care delivery, such as through virtual care models and remote operation. Nurses must lead in designing, implementing, and regulating robotic technologies to ensure they enhance patient outcomes and promote health equity.}
}
@article{YIN2025100419,
title = {Leveraging Artificial Intelligence Technology for Mapping Publications to Sustainable Development Goals},
journal = {Array},
volume = {27},
pages = {100419},
year = {2025},
issn = {2590-0056},
doi = {https://doi.org/10.1016/j.array.2025.100419},
url = {https://www.sciencedirect.com/science/article/pii/S2590005625000463},
author = {Hui Yin and Amir Aryani and Gavin Lambert and Zhuochen Wu and Nakul Nambiar and Marcus White and Luis Salvador-Carulla and Shazia Sadiq and Elvira Sojli and Jennifer Boddy and Greg Murray and Wing Wah Tham},
keywords = {Sustainable Development Goals (SDGs), Research impact assessment, Text classification, Large language model (LLM), Generative Pre-trained Transformer (GPT)},
abstract = {Research publications addressing the Sustainable Development Goals (SDGs) have grown exponentially, reflecting an increasing global focus on sustainability challenges. However, linking these publications to relevant SDGs remains a time-consuming and non-trivial task due to the broad scope and interconnected nature of the goals. This study aims to improve the efficiency and accuracy of mapping publications to SDGs using automated methods. Specifically, we investigate the performance of a domain-adapted similarity measure compared to OpenAI’s GPT-3.5 Turbo and GPT-4 models. Using a dataset of over 82,000 research publications from an Australian university, we apply the similarity measure to assign SDG tags and benchmark the results against outputs from the two GPT models. Our findings show that the similarity-based method achieves comparable performance, with successful classification rates of 82.89% (GPT-3.5) and 89.34% (GPT-4), respectively. The proposed approach provides a reliable, transparent, and cost-effective solution for large-scale SDG classification, particularly valuable for institutions handling sensitive data or lacking access to commercial AI tools. This work provides a practical and reliable approach to help institutions track how their research contributes to the United Nations Sustainable Development Goals.}
}
@article{ROSIC2024451,
title = {Legal implications of artificial intelligence in health care},
journal = {Clinics in Dermatology},
volume = {42},
number = {5},
pages = {451-459},
year = {2024},
note = {Artificial Intelligence II},
issn = {0738-081X},
doi = {https://doi.org/10.1016/j.clindermatol.2024.06.014},
url = {https://www.sciencedirect.com/science/article/pii/S0738081X24000981},
author = {Ana Rosic},
abstract = {The last few years have seen a boom in the popularity of artificial intelligence (AI) around the world, and the health care sector has not been immune from what has been perceived by some as a revolutionary technology. Although AI has been around for many years, including in the field of health care, the recent introduction of consumer-facing generative AI tools has put a spotlight on the technology that has drawn attention from governments, corporations, consumers and more. Health care systems, physician groups, health insurance companies, and others in the space have shown an eagerness to explore AI's potential to improve various aspects of health care, but new legal risks and challenges are unfolding every day. This contribution looks at the latest health care-related measures in the United States and international legal and regulatory landscapes, as well as data privacy implications and discrimination concerns coming out of AI-enabled solutions. It also discusses concerns that health care systems and physicians alike are monitoring, including the potential for medical errors resulting from AI, liability considerations, and malpractice insurance trends.}
}
@article{PEDERSEN2025103192,
title = {Toward responsible artificial intelligence in medicine: Reflections from the Australian epilepsy project},
journal = {Artificial Intelligence in Medicine},
volume = {167},
pages = {103192},
year = {2025},
issn = {0933-3657},
doi = {https://doi.org/10.1016/j.artmed.2025.103192},
url = {https://www.sciencedirect.com/science/article/pii/S0933365725001277},
author = {Mangor Pedersen and Heath R. Pardoe and Anton {de Weger} and Donna Hutchison and David F. Abbott and Karin Verspoor and Graeme D. Jackson},
keywords = {AI, Ethics, Artificial Intelligence, Epilepsy, Australian Epilepsy Project, AEP},
abstract = {Artificial intelligence (AI) is a multidisciplinary scientific field that uses machines to solve real-world problems and predict outcomes. Despite the current enthusiasm about AI's potential as a clinical support tool, there is also a growing awareness and concern about the potentially harmful effects of AI. Because AI will likely impact expert-based decision-making in medicine, it is critical to consider the issues that AI raises in medical research. This paper outlines the AI guidelines of the Australian Epilepsy Project. This large-scale platform aims to democratise specialist care in epilepsy and use AI for clinical decision support based on prospective multimodal datasets (MRI, genetic, clinical, and cognitive data) from thousands of people with epilepsy. As AI develops rapidly, we focus on key areas of medical AI identified in the literature, including Trust, Responsibility and Safety. We believe AI is changing medicine, and we believe it is imperative to advance and update our AI guidelines adaptably while preparing for an era of augmented-intelligence-based medicine.}
}
@article{XU2025104006,
title = {Standardization in artificial general intelligence model for education},
journal = {Computer Standards & Interfaces},
volume = {94},
pages = {104006},
year = {2025},
issn = {0920-5489},
doi = {https://doi.org/10.1016/j.csi.2025.104006},
url = {https://www.sciencedirect.com/science/article/pii/S0920548925000352},
author = {Qiuxuan Xu and Yonghe Wu and Hao Zheng and Huan Yan and Huina Wu and Yu Qian and You Wu and Bowen Liu},
keywords = {Artificial intelligence, Artificial general intelligence model for education, Standardization, Specifications, Use cases},
abstract = {The application of Artificial General Intelligence Models (AGIMs) in education has been identified as a promising emerging field. However, extensive research has revealed limitations in using AGIM in education, particularly in terms of controllability, trustworthiness, explainability, evaluation and feedback, security, and privacy. Therefore, standardization in AGIMs for Education (AGIME) is urgently required to provide normative guidance for developing artificial intelligence systems in education. This study first explores an AGIME standardization process with the methodology of use case collection and iterative research. We then propose the definition and attributes of AGIME and establish a standard system framework for the AGIME life cycle. This framework includes published specifications such as information model, data specification, evaluation specification, and application requirements on teaching and learning. We introduce standard application cases to validate the effectiveness of AGIME standard system framework. Finally, we present several specifications currently under development within this standard system, including interface, regulatory, operation and maintenance, and security, ethics, and privacy specifications. This study provides references for AGIME development and deployment, ensuring the technical stability, data credibility, evaluation accuracy, and pedagogical applicability of AGIME.}
}
@article{ABEO2025100269,
title = {Artificial Intelligence Techniques and Health Literacy: A Systematic Review},
journal = {Mayo Clinic Proceedings: Digital Health},
volume = {3},
number = {4},
pages = {100269},
year = {2025},
issn = {2949-7612},
doi = {https://doi.org/10.1016/j.mcpdig.2025.100269},
url = {https://www.sciencedirect.com/science/article/pii/S2949761225000768},
author = {Abigail Naa Amankwaa Abeo and Sophie Armstrong and Michael Scriney and Hannah Goss},
abstract = {Objective
To systematically review the utilization of artificial intelligence (AI) in health literacy, highlighting limitations and future developments.
Methods
A systematic review, following PRISMA guidelines, was conducted searching 6 databases for studies published from January 1, 2014, through April 10, 2024. Data extracted included population characteristics, health literacy definitions and measurement, study objectives, AI techniques, and metrics. Risk of bias was assessed using an adapted checklist.
Results
From 1296 studies, 18 (1.4%) met inclusion criteria. These studies primarily evaluated text-based materials, including online articles, and electronic health records, with most materials in English, but also incorporated other languages. Artificial intelligence played various roles, including evaluating complexity, text simplification/readability enhancement, translation, and question-answering. Only 5 studies involved participant engagement. Seven studies provided a health literacy definition, consistently describing it as an individual’s ability to obtain, understand, and use health information for informed decisions, often linking it to external factors. However, only 1 study incorporated an individual level health literacy measurement tool, whereas organizational level health literacy measurement remained largely overlooked. The AI techniques used included traditional machine learning, deep learning, and transformer-based models. Evaluation metrics were categorized into human evaluation, readability, and machine learning metrics.
Conclusion
The review highlights AI’s dynamic application in relation to health literacy; however, measurement of health literacy, at both an individual and organizational level, to evidence AI's effectiveness remains limited. In addition, future work should not only measure health literacy outcomes more rigorously but also pursue research on enhancing AI model performance, robust evaluation, and their practical implementation in real-world settings.}
}
@article{CHITYALA2025153882,
title = {Can artificial intelligence lower the global sudden cardiac death rate? A narrative review},
journal = {Journal of Electrocardiology},
volume = {89},
pages = {153882},
year = {2025},
issn = {0022-0736},
doi = {https://doi.org/10.1016/j.jelectrocard.2025.153882},
url = {https://www.sciencedirect.com/science/article/pii/S002207362500010X},
author = {Raja Savanth Reddy Chityala and Sandhya Bishwakarma and Kaival Malav Shah and Ashmita Pandey and Muhammad Saad},
keywords = {Sudden cardiac arrest, Artificial intelligence, Machine learning, Deep learning, Prediction, Prevention, Healthcare technology},
abstract = {Purpose of review
WHO defines SCD as sudden unexpected death either within 1 h of symptom onset (witnessed) or within 24 h of having been observed alive and symptom-free (unwitnessed). Sudden cardiac arrest is a major cause of mortality worldwide, with survival to hospital discharge for hospital cardiac arrest and in-hospital cardiac arrest being only 9.3 % and 21.2 %, respectively, despite treatment highlighting the importance of effectively predicting and preventing cardiac arrest. This literature review aims to explore the role and application of AI (Artificial Intelligence) in predicting and preventing sudden cardiac arrest.
Material and methods
Eligible studies were searched from PubMed and Web of Science. The inclusion criteria were fulfilled if sudden cardiac death prediction and prevention, artificial intelligence, machine learning, and deep learning were included.
Conclusions
Artificial intelligence, machine learning, and deep learning have shown remarkable prospects in SCA risk stratification, which can improve the survival rate from SCA. Nonetheless, they have not been adequately trained and tested, necessitating further studies with explainable techniques, larger sample sizes, external validation, more diverse patient samples, multimodal tools, ethics, and bias mitigation to unlock their full potential.}
}
@article{MENDIOLACONTRERAS2025183,
title = {Artificial intelligence as an enabler of financial inclusion and financial education in Indigenous people},
journal = {Journal of Enabling Technologies},
volume = {19},
number = {3},
pages = {183-200},
year = {2025},
issn = {2398-6263},
doi = {https://doi.org/10.1108/JET-01-2025-0007},
url = {https://www.sciencedirect.com/science/article/pii/S2398626325000067},
author = {Luis Mendiola-Contreras and César Jhonnatan Horna-Saldaña},
keywords = {Indigenous languages, Indigenous communities, Financial inclusion, Financial education, Enabling technologies, Artificial intelligence},
abstract = {Purpose
The purpose of this article is to demonstrate how artificial intelligence (AI) enables financial education and inclusion for Indigenous communities in Peru.
Design/methodology/approach
An analysis of the context of AI in the field of financial education and inclusion in Peru was conducted. Subsequently, the study highlighted the case of the digital tool Illariy, which uses AI to educate on savings habits and financial products in Indigenous languages (Quechua, Aymara and Shipibo-Konibo). Finally, the contributions of AI to financial inclusion for Peruvian Indigenous communities were reflected upon.
Findings
The study evidenced that AI can reduce linguistic and cultural barriers by promoting financial inclusion for Peru’s Indigenous communities. Illariy, an avatar developed in the Quechua language, enables the preservation and valorization of cultural traditions, fostering trust in the financial system. Additionally, the importance of integrating enabling tools to disseminate information in Indigenous languages and revitalize endangered languages is highlighted.
Practical implications
The use of AI allows for the preservation of Indigenous languages spoken by financially marginalized groups. It also facilitates the dissemination and communication of financial information in Indigenous languages.
Originality/value
This article addresses a scarcely explored context within Peruvian Indigenous communities, emphasizing the contributions that AI can make to financial education and inclusion.}
}
@article{DARA2025102314,
title = {The transformative role of Artificial Intelligence in genomics: Opportunities and challenges},
journal = {Gene Reports},
volume = {41},
pages = {102314},
year = {2025},
issn = {2452-0144},
doi = {https://doi.org/10.1016/j.genrep.2025.102314},
url = {https://www.sciencedirect.com/science/article/pii/S2452014425001876},
author = {Mahintaj Dara and Mehdi Dianatpour and Negar Azarpira and Nader Tanideh},
keywords = {Artificial Intelligence, Genomics, CRISPR, Personalized medicine, Ethical concerns, Data analysis},
abstract = {Artificial Intelligence (AI) is poised to revolutionize genomics, offering transformative opportunities while simultaneously presenting significant challenges. This review article explores the multifaceted integration of AI into genomic medicine, highlighting its potential to enhance genomic data analysis, improve disease diagnosis, and enable personalized treatment strategies. We discuss the advancements in machine learning and deep learning techniques that facilitate the identification of genetic variants, optimize genome sequencing, and predict disease outcomes by analyzing vast datasets. Despite these promising developments, the application of AI in genomics faces hurdles such as data quality issues, algorithmic bias, and ethical concerns regarding patient privacy and health disparities. Furthermore, the article addresses the need for robust regulatory frameworks to ensure the safe and effective implementation of AI technologies in clinical settings. By synthesizing current research and emerging applications, we aim to provide a comprehensive overview of the state of AI in genomics, emphasizing both the opportunities for innovation and the challenges that must be navigated to fully realize its potential in advancing genomic medicine.}
}
@article{SCHMIDT2025100274,
title = {Integrating artificial intelligence in higher education: perceptions, challenges, and strategies for academic innovation},
journal = {Computers and Education Open},
volume = {9},
pages = {100274},
year = {2025},
issn = {2666-5573},
doi = {https://doi.org/10.1016/j.caeo.2025.100274},
url = {https://www.sciencedirect.com/science/article/pii/S2666557325000333},
author = {Dusana Alshatti Schmidt and Bedour Alboloushi and Anisha Thomas and Rodrigo Magalhaes},
keywords = {Artificial intelligence, Higher education, Curriculum development, Qualitative research, Kuwait},
abstract = {In recent years artificial intelligence (AI) has emerged as a transformative force across various industries impacting the workforce dynamics. To ensure that graduates possess the necessary skills, higher education institutions are exploring new ways to align their approaches with labor market demands. This study examines how AI is being integrated in higher education institutions, aimed at gaining an understanding of how students and faculty perceive AI, how it is applied, its impact on performance, the challenges encountered, and the strategies used for its adoption. The study also aims to provide practical, evidence-based recommendations for effective integration of AI into curriculum. The research employs a qualitative approach, incorporating focus group interviews and open-ended questionnaires. Findings indicate that while both faculty and students recognize AI's transformative potential and benefits, they are also concerned about its impact on critical thinking and academic integrity. Faculty use AI tools for teaching and assessment, but face challenges with tool accuracy and integration. Students utilize AI for academic tasks but struggle with reliability and ethical issues. The study highlights the need for increased awareness, continuous professional development, and ethical guidelines to overcome these challenges. The findings of this study contribute to the successful adoption of AI in higher education in general, ensuring that both teaching and learning processes are enriched by the potential of AI.}
}
@article{HOLT2025291,
title = {The Role of Artificial Intelligence and Big Data for Gastrointestinal Disease},
journal = {Gastrointestinal Endoscopy Clinics of North America},
volume = {35},
number = {2},
pages = {291-308},
year = {2025},
note = {Artificial Intelligence in Endoscopy},
issn = {1052-5157},
doi = {https://doi.org/10.1016/j.giec.2024.09.004},
url = {https://www.sciencedirect.com/science/article/pii/S1052515724000862},
author = {Nicholas Mathew Holt and Michael Francis Byrne},
keywords = {Gastroenterology, Artificial intelligence, Big data}
}
@article{MAITRA202565,
title = {Applications of Artificial Intelligence in Pediatric Ophthalmology: Part 1: Retinopathy of Prematurity},
journal = {Advances in Ophthalmology and Optometry},
volume = {10},
number = {1},
pages = {65-76},
year = {2025},
note = {Advances in Ophthalmology and Optometry, Volume 10},
issn = {2452-1760},
doi = {https://doi.org/10.1016/j.yaoo.2025.03.005},
url = {https://www.sciencedirect.com/science/article/pii/S2452176025000162},
author = {Puja Maitra and Ashok Puri and Pukhraj Rishi},
keywords = {Artificial intelligence, Ophthalmology, Pediatric, Retina, Retinopathy of prematurity}
}
@incollection{VERDICCHIO2025,
title = {Language of Artificial Intelligence Discourses},
booktitle = {Reference Module in Social Sciences},
publisher = {Elsevier},
year = {2025},
isbn = {978-0-443-15785-1},
doi = {https://doi.org/10.1016/B978-0-323-95504-1.00392-6},
url = {https://www.sciencedirect.com/science/article/pii/B9780323955041003926},
author = {Mario Verdicchio},
keywords = {Artificial intelligence, Figures of speech, Machine learning, Philosophy of mind},
abstract = {Language has played a fundamental role in Artificial Intelligence discourses from the very beginning of the establishment of the field. An early assumption was that every aspect of intelligence could be described in a manner compatible with machine operation. This assumption is critical for comparing humans and machines, given that, on the one hand, our understanding of how human brains work is insufficient to define intelligence clearly, and on the other hand, a focus on computational artifacts may lead to a limited conceptualization that overlooks significant aspects of what it means to be conscious and conscientious humans. A mindful analysis of the metaphors used to describe AI systems is key to navigating the intricate entanglements between society and technology that contribute to this endeavor.}
}
@article{DOU2025108515,
title = {Towards energy transition: Accessing the significance of artificial intelligence in ESG performance},
journal = {Energy Economics},
volume = {146},
pages = {108515},
year = {2025},
issn = {0140-9883},
doi = {https://doi.org/10.1016/j.eneco.2025.108515},
url = {https://www.sciencedirect.com/science/article/pii/S0140988325003391},
author = {Jie Dou and Dongjing Chen and Yuchen Zhang},
keywords = {Artificial intelligence, ESG performance, Energy transition, Quantile on quantile regression, Wavelet analysis},
abstract = {Investigating the crucial role of artificial intelligence in enhancing ESG performance is of utmost importance, particularly for advancing the energy transition. In this study, we utilise the wavelet-based quantile on quantile regression (QQR) to capture the evolving impact of the Artificial Intelligence Enabler Index (AII) on the Global ESG Index (ESGI). Based on raw data, AII's impact on ESGI varies across different quantiles, indicating artificial intelligence doesn't always boost ESG performance. We use wavelet analysis to explore AII's effects on ESGI over various time horizons. AII has more negative impacts in the short term due to early technology stages, slow social adaptation, and limited ESG awareness. However, in the medium to long term, AII's positives may outweigh its negatives, fueled by technological progress, efficiency gains, wider ESG adoption, and artificial intelligence applications in ESG. Hence, our analysis reveals that artificial intelligence's inhibitory effect on ESG performance is more pronounced in the short run. Still, its enhancement effect becomes significant over the medium to long term. In the face of a new technological revolution and industrial transformation, we will offer practical advice to boost ESG progress using artificial intelligence while simultaneously fostering energy transition.}
}
@article{ITO2025106087,
title = {Artificial intelligence in nursing support for patients: A rapid review},
journal = {International Journal of Medical Informatics},
volume = {204},
pages = {106087},
year = {2025},
issn = {1386-5056},
doi = {https://doi.org/10.1016/j.ijmedinf.2025.106087},
url = {https://www.sciencedirect.com/science/article/pii/S1386505625003041},
author = {Yoshiyasu Ito and Kohei Kajiwara and Jun Kako and Masamitsu Kobayashi and Michihiro Tsubaki and Hideaki Sakuramoto and Makoto Yamanaka and Takahiro Kakeda},
keywords = {Artificial intelligence, Nursing, Randomized controlled trial, Rapid review},
abstract = {Objectives
This study aimed to gain insights into the potential of using evidence from artificial intelligence (AI) in nursing support for clinical practice and decision-making and its implications for future studies.
Methods
This was a rapid review of the literature. The PubMed, CINAHL, and CENTRAL in the Cochrane Library databases were searched for randomized controlled trials (RCTs) on nursing support using AI for patient care, published between 2010 and 2024. The included studies were assessed for quality appraisal using the mixed methods appraisal tool, version 2018, and data extracted from each study were synthesized narratively considering the review questions.
Results
After removing duplicates, 5,176 studies were identified, resulting in the inclusion of 20 studies. The 20 studies were published between 2012 and 2024, with five studies focusing on “providing information and advice to patients using AI,” seven studies on “clinical decision-making support for nurses using predictive algorithms,” and eight studies on “psychosocial support using AI-equipped social robots.” In the qualitative appraisal of these studies, the proportion of studies that met the quality criteria for each item ranged from 35% to 85%.
Conclusions and Implications
In this review, we identified 20 RCTs that have been published so far on AI in nursing support, and currently, research is shifting from the development and testing phase to the implementation and effectiveness verification phase. However, many studies were found to be at risk of bias, suggesting caution when applying the evidence to clinical practice. Moving forward, there is a pressing need for the accumulation of high-quality RCTs and evidence integration through meta-analyses.
Brief summary
This study explored the potential of AI in nursing support, highlighting 20 published RCTs. Research in this field is transitioning from development and testing to implementation and effectiveness verification.}
}
@article{MIAO2025,
title = {Revolutionizing Gastroenterology with Artificial Intelligence: Clinical Insights and Challenges},
journal = {Gastroenterology},
year = {2025},
issn = {0016-5085},
doi = {https://doi.org/10.1053/j.gastro.2025.03.075},
url = {https://www.sciencedirect.com/science/article/pii/S0016508525061372},
author = {Yongchang Miao and Yuanhao Wei and Anquan Shang}
}
@article{MILLER2025361,
title = {Artificial Intelligence in Nuclear Cardiology},
journal = {Heart Failure Clinics},
volume = {21},
number = {3},
pages = {361-371},
year = {2025},
note = {Nuclear Cardiology},
issn = {1551-7136},
doi = {https://doi.org/10.1016/j.hfc.2025.01.015},
url = {https://www.sciencedirect.com/science/article/pii/S1551713625000157},
author = {Robert J.H. Miller},
keywords = {Artificial intelligence, Machine learning, Deep learning, Nuclear cardiology}
}
@article{RODRIGUEZMARTINEZ202573,
title = {Artificial intelligence in precision medicine: transforming disease subtyping, medical imaging, and pharmacogenomics},
journal = {Emerging Topics in Life Sciences},
volume = {8},
number = {2},
pages = {73-82},
year = {2025},
issn = {2397-8562},
doi = {https://doi.org/10.1042/ETLS20240011},
url = {https://www.sciencedirect.com/science/article/pii/S2397856225000023},
author = {Andrea Rodriguez-Martinez and Dilini Kothalawala and Rodrigo M. Carrillo-Larco and Antonios Poulakakis-Daktylidis},
keywords = {artificial intelligence, computational biology, drug discovery, precision medicine},
abstract = {Precision medicine marks a transformative shift towards a patient-centric treatment approach, aiming to match ‘the right patients with the right drugs at the right time’. The exponential growth of data from diverse omics modalities, electronic health records, and medical imaging has created unprecedented opportunities for precision medicine. This explosion of data requires advanced processing and analytical tools. At the forefront of this revolution is artificial intelligence (AI), which excels at uncovering hidden patterns within these high-dimensional and complex datasets. AI facilitates the integration and analysis of diverse data types, unlocking unparalleled potential to characterise complex diseases, improve prognosis, and predict treatment response. Despite the enormous potential of AI, challenges related to interpretability, reliability, generalisability, and ethical considerations emerge when translating these tools from research settings into clinical practice.}
}
@article{FU2025200538,
title = {The impact of artificial intelligence on digital enterprise innovation},
journal = {Journal of Strategy & Innovation},
volume = {36},
number = {1},
pages = {200538},
year = {2025},
issn = {3050-7901},
doi = {https://doi.org/10.1016/j.jsinno.2025.200538},
url = {https://www.sciencedirect.com/science/article/pii/S3050790125000087},
author = {Yu Fu and Jiacheng Ni and Mengwen Fang},
keywords = {Artificial intelligence, Enterprise innovation, Digital enterprise, Text analysis},
abstract = {The digital economy is transitioning into a new phase characterized as the intelligent economy, propelled by advancements in artificial intelligence (AI). This shift is poised to inject renewed dynamism into the global economy. This paper develops a theoretical framework that elucidates the relationship between AI adoption and innovation within digital enterprises, drawing upon resource-based theory (RBT) and absorptive capacity theory (ACAP). Utilizing a sample of Chinese digital enterprises listed overseas from 2000 to 2023, this study employs Python to extract keywords associated with “artificial intelligence” from corporate annual reports, thereby constructing a proxy measure for AI adoption. We empirically investigate the impact of AI adoption on innovation within digital enterprises. Our findings demonstrate that AI adoption significantly enhances innovation in digital enterprises, a result that remains robust across a series of robustness tests. Additional analysis reveals that the absorptive capacity of enterprises mediates the relationship between AI adoption and innovation, while slack resources act as a moderating factor, attenuating the link between absorptive capacity and innovation. This paper extends our understanding of the implications of AI on broader innovation entities, elucidating the mechanisms and boundary conditions of AI application in digital enterprises. It also offers insights into how enterprises can effectively integrate AI technology, strategically configure and utilize slack resources, and ultimately enhance their innovation performance.}
}
@article{BALOGUN2024105641,
title = {Artificial intelligence for deconstruction: Current state, challenges, and opportunities},
journal = {Automation in Construction},
volume = {166},
pages = {105641},
year = {2024},
issn = {0926-5805},
doi = {https://doi.org/10.1016/j.autcon.2024.105641},
url = {https://www.sciencedirect.com/science/article/pii/S0926580524003777},
author = {Habeeb Balogun and Hafiz Alaka and Eren Demir and Christian Nnaemeka Egwim and Razak Olu-Ajayi and Ismail Sulaimon and Raphael Oseghale},
keywords = {Artificial intelligence, Deconstruction, Sustainability, Challenges, Opportunities},
abstract = {Artificial intelligence and its subfields, such as machine learning, robotics, optimisation, knowledge-based systems, reality capture and extended reality, have brought remarkable advancements and transformative changes to various industries, including the building deconstruction industry. Acknowledging AI's benefits for deconstruction, this paper aims to investigate AI applications within this domain. A systematic review of existing literature focused on AI applications for planning, implementation and post-implementation activities within the context of deconstruction was carried out. Furthermore, the challenges and opportunities of AI for deconstruction activities were identified and presented in this paper. By offering insights into AI's application for key deconstruction activities, this paper paves the way for realising AI's potential benefits for this sector.}
}
@article{DAS2025110571,
title = {The evolving role of multimodal imaging, artificial intelligence and radiomics in the radiologic assessment of immune related adverse events},
journal = {Clinical Imaging},
volume = {125},
pages = {110571},
year = {2025},
issn = {0899-7071},
doi = {https://doi.org/10.1016/j.clinimag.2025.110571},
url = {https://www.sciencedirect.com/science/article/pii/S0899707125001718},
author = {Jeeban P. Das and Hong Y. Ma and Dorine {de Jong} and Conor Prendergast and Alireza Baniasadi and Brian Braumuller and Anna Giarratana and Mohammad Saeid Khonji and Jacienta Paily and Parnian Shobeiri and Randy Yeh and Laurent Dercle and Kathleen M. Capaccione},
keywords = {Multimodal imaging, PET/CT, Immunotherapy, Immune related adverse events, Artificial intelligence, Radiomics},
abstract = {Immunotherapy, in particular checkpoint blockade, has revolutionized the treatment of many advanced cancers. Imaging plays a critical role in assessing both treatment response and the development of immune toxicities. Both conventional imaging and molecular imaging techniques can be used to evaluate multisystemic immune related adverse events (irAEs), including thoracic, abdominal and neurologic irAEs. As artificial intelligence (AI) proliferates in medical imaging, radiologic assessment of irAEs will become more efficient, improving the diagnosis, prognosis, and management of patients affected by immune-related toxicities. This review addresses some of the advancements in medical imaging including the potential future role of radiomics in evaluating irAEs, which may facilitate clinical decision-making and improvements in patient care.}
}
@article{AKRAM2025100157,
title = {Artificial Intelligence in Dentistry: Advancements in Periodontology and Other Specialties, Diagnosis, Treatment Planning, and Ethical Considerations"},
journal = {Dentistry Review},
volume = {5},
number = {2},
pages = {100157},
year = {2025},
issn = {2772-5596},
doi = {https://doi.org/10.1016/j.dentre.2025.100157},
url = {https://www.sciencedirect.com/science/article/pii/S2772559625000069},
author = {Hadeel Mazin Akram},
keywords = {Artificial intelligence, Periodontology, Diagnosis, Treatment planning, Ethical Considerations, Convolutional Neural Networks (CNNs)},
abstract = {This narrative review aims to highlight how periodontology is transformed by applying artificial intelligence (AI). AI impacts periodontology in diagnosis, treatment planning, and ethical considerations. AI uses deep learning, genetic algorithms, and different logic systems to offer improved solutions for dental practices, such as in dental restoration, plaque detection, endodontic therapy, dental radiography, detection of malignant tumors, and diagnosis of periodontal diseases. In periodontology, AI has improved diagnoses and treatment plans. This discussion focuses on the advancements of using AI in healthcare and dentistry to identify and manage issues by utilizing different technologies such as convolutional neural networks (CNNs) segmentation models such as U Net and Mask R CNN and classification systems, such as VGG 16. This research discusses how AI is utilized to analyze radiography images and salivary biomarkers and classify diseases. It explores the influence of AI on treatment planning and outcome prediction. The ethical implications of AI in periodontology are also discussed, underscoring the significance of data confidentiality and protection. Periodontology can be revolutionized as AI may improve the diagnostic capability and facilintate highly individualized treatment methods to enhance the general quality of the treatment process.}
}
@article{NGUYEN2025,
title = {Artificial intelligence applications in the diagnosis and management of cleft lip and palate: An updated review},
journal = {Journal of Dental Sciences},
year = {2025},
issn = {1991-7902},
doi = {https://doi.org/10.1016/j.jds.2025.09.014},
url = {https://www.sciencedirect.com/science/article/pii/S1991790225003538},
author = {Tu Manh Nguyen and Uyen Ngoc Thao Huynh and Thi Thuy Tien Vo and Yang-Che Wu and Chien-Fu Tseng and I-Ta Lee},
keywords = {Artificial intelligence, Cleft lip and/or palate, Machine learning, Deep learning, Craniofacial anomalies},
abstract = {According to the U.S. National Institutes of Health, cleft lip and/or palate (CL/P) is one of the most common congenital anomalies, significantly affecting both function and aesthetics while placing a considerable burden on healthcare systems worldwide. With the rapid advancement of artificial intelligence (AI) in various medical fields, a thorough evaluation of its role in CL/P management has become essential. Therefore, this review was undertaken to summarize recent clinical applications of AI in the diagnosis, treatment, and care of CL/P. A comprehensive search of PubMed and IEEE Xplore was conducted from January 1, 2015, to May 31, 2025, using combined keywords related to AI and CL/P. Of the 134 records initially identified, 51 full-text articles met the eligibility criteria and were included in the final analysis. In conclusion, AI is driving innovation in CL/P management across multiple domains; however, further evidence from diverse populations and the establishment of clear ethical frameworks are required to ensure its long-term clinical applicability.}
}
@article{SHI2025100035,
title = {Artificial intelligence unlocks the future of oral organoid research},
journal = {Translational Dental Research},
volume = {1},
number = {3},
pages = {100035},
year = {2025},
issn = {2950-3485},
doi = {https://doi.org/10.1016/j.tdr.2025.100035},
url = {https://www.sciencedirect.com/science/article/pii/S2950348525000264},
author = {Yinghui Shi and Lin Wang and Heng Ji and Kin Liao and Vincent Chan and Weitao Li and Nicolae Goga and Winfred O. Larkotey and Wenya Shu and Tian Jian Lu and Yulong Han},
keywords = {Oral organoids, Artificial intelligence, Data analysis, Construction strategy, Image analysis},
abstract = {Oral organoids, emerging as a powerful method for modeling oral development and diseases, show potential in fundamental research and clinical applications. However, their translational application in clinics is limited by low construction efficiency, labor-intensive data processing, and the complexity of integrating multi-omics data. Artificial intelligence (AI) offers promising solutions to overcome these limitations. AI-based robots can optimize culture conditions to enhance construction efficiency. Furthermore, AI enables the efficient analysis of organoid images and multi-omics data to elucidate underlying molecular mechanisms. The integration of oral organoids and AI could potentially overcome the limitations in organoid research and accelerate clinical translation. In this review, we first summarize the main types of oral organoids in the field and their construction strategies. Then, we introduce their application in regenerative medicine and the modeling of oral disease. We also examine the current limitations and discuss AI-based approaches to address these challenges, highlighting the critical role of AI in benefiting basic and translational oral research.}
}
@article{TSAO2024101865,
title = {Beyond the author: Artificial intelligence, creative writing and intellectual emancipation},
journal = {Poetics},
volume = {102},
pages = {101865},
year = {2024},
issn = {0304-422X},
doi = {https://doi.org/10.1016/j.poetic.2024.101865},
url = {https://www.sciencedirect.com/science/article/pii/S0304422X24000044},
author = {Jack Tsao and Collier Nogues},
keywords = {Generative AI (GenAI), Artificial Intelligence (AI) literacies, Creativity, Intellectual emancipation, Creative writing, Jacques Rancière},
abstract = {This study explores university students’ engagement with Generative Artificial Intelligence (GenAI) tools for creative writing and graphic storytelling, drawing on Jacques Rancière's philosophy of intellectual equality and emancipation. Qualitative data analysis from a co-curricular creative writing programme, including reflections, surveys, and focus-group interviews, reveals emerging artificial intelligence literacies and students’ improvisational aptitudes for interpreting, subverting, and transforming notions of authorship. Students decentred authorial attribution through the pragmatic adoption of the technology as a creative catalyst, negotiated creative conventions by adopting non-conventional communication strategies, and reconceptualised creativity as distributed across human and non-human agents. Our approach of student-driven learning for autonomous exploration, sense-making, and criticality with GenAI indicates the potential for promoting conditions for students to exercise intellectual equality and emancipation. The findings contribute to the understanding of authorship and creativity; begin to contour emerging GenAI literacies and competencies; and suggest that creative collaborations with GenAI may be a promising way to foster emancipatory practices in the classroom, while nurturing creative and critical skills.}
}
@article{MEHTA2025101259,
title = {Artificial intelligence in integrative medicine: Transforming education for a digital future},
journal = {Integrative Medicine Research},
volume = {14},
number = {4},
pages = {101259},
year = {2025},
issn = {2213-4220},
doi = {https://doi.org/10.1016/j.imr.2025.101259},
url = {https://www.sciencedirect.com/science/article/pii/S2213422025001398},
author = {Darshan H. Mehta and Melinda Ring},
keywords = {Artificial intelligence, education, digital, integrative medicine}
}
@article{TEFERI2025100901,
title = {Artificial intelligence in clinical toxicology in Africa: Emerging applications and barriers},
journal = {African Journal of Emergency Medicine},
volume = {15},
number = {4},
pages = {100901},
year = {2025},
issn = {2211-419X},
doi = {https://doi.org/10.1016/j.afjem.2025.100901},
url = {https://www.sciencedirect.com/science/article/pii/S2211419X25000412},
author = {Mikiyas G. Teferi and Biruk T. Mengistie and Helina K. Teklehaimanot and Chernet T. Mengistie and Fitsum A. Gemechu and Michael A. Negussie and Tilahun J. Jufara and Getaw W. Hassen},
keywords = {Artificial intelligence, Clinical toxicology, Treatment, Africa, Machine learning, Emergency medicine},
abstract = {Artificial intelligence (AI) has a supplementary role in clinical toxicology in Africa, addressing key challenges such as delayed diagnoses, limited expertise, and inadequate healthcare infrastructure. This method has the potential to increase diagnostic accuracy, optimize treatment strategies, and advance research on toxic substance exposure and poisoning cases. AI-driven tools, including machine learning algorithms and decision-support systems, enhance the early detection and risk assessment of toxicities. AI-powered predictive models facilitate precision medicine by designing treatment plans for individual patient profiles. Integrating this in telemedicine expands access to toxicology expertise, particularly in resource-limited settings. Additionally, AI accelerates research by analyzing large datasets, identifying trends, and predicting toxicological risks, thus contributing to public health interventions. Despite these advancements, challenges such as data poverty, ethical issues, and restrictive policies hinder its full potential in African healthcare. These gaps can be bridged through policy reforms, capacity-building initiatives, and robust AI frameworks, which will be crucial in maximizing AI benefits for clinical toxicology. This narrative review highlights the emerging applications of AI in Africa, emphasizing the need for collaborative efforts to ensure equitable and effective implementation. However, its adoption is limited by financial constraints, scarce datasets, weak infrastructure, and ethical concerns.}
}
@article{ABRAHAMS2025171,
title = {The Basics of Artificial Intelligence with Applications in Healthcare and Neurosurgery},
journal = {World Neurosurgery},
volume = {193},
pages = {171-175},
year = {2025},
issn = {1878-8750},
doi = {https://doi.org/10.1016/j.wneu.2024.10.105},
url = {https://www.sciencedirect.com/science/article/pii/S1878875024018060},
author = {John M. Abrahams},
keywords = {Artificial intelligence, Machine learning, Neural networks, Healthcare Information}
}
@article{KLEINOVA202560,
title = {Artificial Intelligence in Transportation: The Potential of ChatGPT},
journal = {Transportation Research Procedia},
volume = {87},
pages = {60-65},
year = {2025},
note = {VSI: TRPRO_LOGI 2024},
issn = {2352-1465},
doi = {https://doi.org/10.1016/j.trpro.2025.04.108},
url = {https://www.sciencedirect.com/science/article/pii/S2352146525003552},
author = {Kristína Kleinová and Peter Kačmáry and Vieroslav Molnár and Blanka Kalupová},
keywords = {Artificial intelligence, ChatGPT, transportation, logistics},
abstract = {This article addresses the potential use of the artificial intelligence model to optimize processes in the field of transportation and logistics. Currently, the logistics sector faces numerous challenges, including the need to streamline logistics processes. This article aims to initiate a discussion about the possibilities of utilizing ChatGPT in areas such as transportation. The emphasis is placed on the advantages this advanced technology can bring, such as faster calculations, flexible adaptation to changing market conditions, and the ability to analyze large volumes of data in real-time. The article’s primary objective is to demonstrate that the integration of ChatGPT into logistics systems can significantly improve efficiency and sustainability in transportation. On the other hand, it is essential to consider that ChatGPT may exhibit errors and provide inaccurate information. Therefore, subsequent verification and validation of the outputs generated by this model are crucial. The results suggest that implementing the ChatGPT model can offer comprehensive solutions to the complexities of logistics operations, opening new perspectives for transformation and innovation in transportation and logistics. This approach offers a pathway to enhance performance and economic efficiency in the sector.}
}
@article{LI2025,
title = {Medical Artificial Intelligence in Scholarly and Public Perspective: BERTopic-Based Analysis of Topic-Sentiment Collaborative Mining},
journal = {Data Science and Informetrics},
year = {2025},
issn = {2694-6106},
doi = {https://doi.org/10.1016/j.dsim.2025.05.001},
url = {https://www.sciencedirect.com/science/article/pii/S2694610625000360},
author = {Chenchen Li and Xiaojun Hu},
keywords = {Artificial Intelligence, Medicine, BERTopic, SnowNLP, Topic-Sentiment Collaborative Mining},
abstract = {In order to deeply study the development trend of AI application in the medical field and the responses of different groups of people, based on the literature data of scholars and public opinion data in the field of medical artificial intelligence, this study combines the BERTopic model with SnowNLP for theme-sentiment collaborative mining analysis. Firstly, the topic model is used to analyze the features and differences of the topics in depth, and get the topic modelling results, so as to reveal the overall research structure of the field. Then, the sentiment analysis of each theme was conducted to obtain the sentiment classification under the corresponding theme text, in order to explore the emotional responses of different perspectives on this domain. This study not only considers the theme distribution and sentiment tendency at the same time, but also explores the trend of sentiment evolution and influencing factors through the exploration, with a view to providing useful references for future research. The results of the study show that academics and the public are interested in different topics. Scholars have more positive affective tendencies towards most topics, while the public has relatively lower positive affective tendencies. The public had a large percentage of negative emotions for the same topics compared to academics.}
}
@article{FERREIRA2025100117,
title = {Piloting a maturity model for responsible artificial intelligence: A portuguese case study},
journal = {Journal of Responsible Technology},
volume = {22},
pages = {100117},
year = {2025},
issn = {2666-6596},
doi = {https://doi.org/10.1016/j.jrt.2025.100117},
url = {https://www.sciencedirect.com/science/article/pii/S2666659625000137},
author = {Rui Miguel Frazão Dias Ferreira and António GRILO and Maria MAIA},
keywords = {Responsible artificial intelligence, Artificial intelligence regulation, Maturity model, Ethical, Legal and social issues, Responsible research and innovation},
abstract = {Recently, frameworks and guidelines aiming to assist trustworthiness in organizations and assess ethical issues related to the development and use of Artificial Intelligence (AI) have been translated into self-assessment checklists and other instruments. However, such tools can be very time consuming to apply. Aiming to develop a more practical tool, an Industry-Wide Maturity Model for Responsible AI was piloted in 3 companies and 2 research centres, in Portugal. Results show that organizations are aware of requirements (44 %) to deploy a responsible AI approach and have a reactive response to its implementation, as they are willing to integrate other requirements (33 %) into their business processes. The proposed Model was welcomed and showed openness from companies to consistently use it, since it helped to identify gaps and needs when it comes to foster a more trustworthy approach to the development and deployment of AI.}
}
@article{CHENG2025105203,
title = {Artificial intelligence-enhanced bioavailability studies: Advancing the quality of food},
journal = {Trends in Food Science & Technology},
volume = {163},
pages = {105203},
year = {2025},
issn = {0924-2244},
doi = {https://doi.org/10.1016/j.tifs.2025.105203},
url = {https://www.sciencedirect.com/science/article/pii/S0924224425003395},
author = {Huiyuan Cheng and Li Liu and Hongyan Zhang and Yang Yu and Yu Bai and Shang Wang and Mingliu Yang and Wenxu Lu and Jie Cheng and Yan Jin},
keywords = {Artificial intelligence, Bioavailability, Food quality, Quality control, Food analysis},
abstract = {Background
Bioavailability, defined as the extent to which active components in food are absorbed and utilized by the body, is a critical factor in determining the health benefits of food. The intricate interactions of various critical aspects, particularly those concerning extensive, complicated datasets of host conditions and ingredient matrix effects, are obstacles to bioavailability research. These difficulties influence research on intestinal absorption efficiency, solubility, and chemical stability.
Scope and approach
One effective tool for overcoming these challenges is artificial intelligence (AI). AI models can be used to analyse and forecast the bioavailability of food ingredients under various processing conditions and food matrix compositions by analyzing sizable datasets, as well as reveal the effects of these parameters. The aims of this review are to provide a theoretical foundation for AI-based bioavailability research, describe applicable methods, outline prospective research directions for AI-based innovation in food science and nutrition, and address existing difficulties.
Key findings and conclusions
The use of AI in bioavailability research on proteins, peptides, carbohydrates, and micronutrients has transformative potential. AI-based models can be used to simultaneously deduce structures, optimize excipient ingredients, devise distribution systems, offer research guidance and minimize experimental trials. However, the application of these models is hampered by the following factors: (1) the absence of high-quality standardized datasets that accurately represent biological complexity, which may result in model overfitting and bias; (2) the restricted mechanistic interpretability of "black box" algorithms, which impedes regulatory approval and scientific validation; and (3) interdisciplinary validation challenges between computational predictions and in vitro and in vivo experimental outcomes.}
}
@article{ZHANG2025234,
title = {Consensus on the research and application of artificial intelligence in coronary computed tomography angiography},
journal = {Intelligent Medicine},
volume = {5},
number = {3},
pages = {234-242},
year = {2025},
issn = {2667-1026},
doi = {https://doi.org/10.1016/j.imed.2024.11.006},
url = {https://www.sciencedirect.com/science/article/pii/S2667102625000609},
author = {Longjiang Zhang and Qian Chen and Chun Xiang Tang and Zhao Shi and Tongyuan Liu and Chunhong Hu and Bin Lu and Zhengyu Jin and Guangming Lu and Dianbo Cao and Xiangying Du and Xiaomin Duan and Xiangming Fang and Yinghui Ge and Xuechun Guan and Gulina Azati and Yingkun Guo and Yi He and Yang Hou and Zhihui Hou and Chunhong Hu and Hongjie Hu and Bin Hu and Zhengyu Jin and Cheng Li and Dong Li and Tao Li and Xiaohu Li and Guangming Lu and Hui Liu and Min Liu and Ting Liu and Tongyuan Liu and Bin Lu and Fajin Lu and Dan Mu and Pei Nie and Liqing Peng and Jianxing Qiu and Heshui Shi and Zhao Shi and Chunxiang Tang and Gang Wang and Gang Wang and Rongpin Wang and Ximing Wang and Yining Wang and Liming Xia and Bolin Wu and Jiang Wu and Yi Xiao and Xigang Xiao and Lei Xu and Yi Xu and Benqiang Yang and Qi Yang and Li Yuan and Xuchun Yuan and Wenjie Yang and Wei Yu and Lei Yin and Jiayin Zhang and Longjiang Zhang and Tong Zhang and Yonggao Zhang and Min Zhang and Qing Zhang and Yan Zhang and Lei Zhao and Minwen Zheng and Yumin Zhong and Hui Zhou and Fan Zhou and Li Zhu},
keywords = {Artificial intelligence, Coronary artery disease, Coronary computed tomography angiography},
abstract = {Coronary computed tomography angiography (CCTA), which enables noninvasive assessment of luminal stenosis and atherosclerotic plaque components, has become the first-line technique for evaluating coronary artery disease. Artificial intelligence (AI) has the potential to revolutionize the CCTA workflow. However, it is crucial to evaluate the effectiveness and feasibility of AI algorithms before their clinical deployment. This expert consensus proposes three fundamental elements of research designs of AI in CCTA and offers corresponding recommendations. The consensus also reviews the existing evidence on AI applications in CCTA and provides recommendations on the current clinical applications of AI, including image acquisition and reconstruction, postprocessing, diagnosis, prognostic prediction, guiding prevention and treatment, and cardiovascular disease prevention.}
}
@article{LEVKOVICH2025104970,
title = {Attributional patterns toward students with and without learning disabilities: Artificial intelligence models vs. trainee teachers},
journal = {Research in Developmental Disabilities},
volume = {160},
pages = {104970},
year = {2025},
issn = {0891-4222},
doi = {https://doi.org/10.1016/j.ridd.2025.104970},
url = {https://www.sciencedirect.com/science/article/pii/S089142222500054X},
author = {Inbar Levkovich and Eyal Rabin and Rania Hussein Farraj and Zohar Elyoseph},
keywords = {Generative artificial intelligence, Trainee teachers, Attribution, Learning disabilities, Expectations, Cultural differences},
abstract = {This study explored differences in the attributional patterns of four advanced artificial intelligence (AI) Large Language Models (LLMs): ChatGPT3.5, ChatGPT4, Claude, and Gemini) by focusing on feedback, frustration, sympathy, and expectations of future failure among students with and without learning disabilities (LD). These findings were compared with responses from a sample of Australian and Chinese trainee teachers, comprising individuals nearing qualification with varied demographic and educational backgrounds. Eight vignettes depicting students with varying abilities and efforts were evaluated by the LLMs ten times each, resulting in 320 evaluations, with trainee teachers providing comparable ratings. For LD students, the LLMs exhibited lower frustration and higher sympathy than trainee teachers, while for non-LD students, LLMs similarly showed lower frustration, with ChatGPT3.5 aligning closely with Chinese teachers and ChatGPT4 demonstrating more sympathy than both teacher groups. Notably, LLMs expressed lower expectations of future academic failure for both LD and non-LD students compared to trainee teachers. Regarding feedback, the findings reflect ratings of the qualitative nature of feedback LLMs and teachers would provide, rather than actual feedback text. The LLMs, particularly ChatGPT3.5 and Gemini, were rated as providing more negative feedback than trainee teachers, while ChatGPT4 provided more positive ratings for both LD and non-LD students, aligning with Chinese teachers in some cases. These findings suggest that LLMs may promote a positive and inclusive outlook for LD students by exhibiting lower judgmental tendencies and higher optimism. However, their tendency to rate feedback more negatively than trainee teachers highlights the need to recalibrate AI tools to better align with cultural and emotional nuances.}
}
@article{HUGHES2025100772,
title = {Impact of artificial intelligence on project management (PM): Multi-expert perspectives on advancing knowledge and driving innovation toward PM2030},
journal = {Journal of Innovation & Knowledge},
volume = {10},
number = {5},
pages = {100772},
year = {2025},
issn = {2444-569X},
doi = {https://doi.org/10.1016/j.jik.2025.100772},
url = {https://www.sciencedirect.com/science/article/pii/S2444569X25001179},
author = {Laurie Hughes and Reza Kiani Mavi and Masoud Aghajani and Keith Fitzpatrick and Senali Madugoda Gunaratnege and Seyed Ashkan Hosseini Shekarabi and Richard Hughes and Ahmad Khanfar and Ahdieh Khatavakhotan and Neda Kiani Mavi and Keyao Li and Moataz Mahmoud and Tegwen Malik and Sashah Mutasa and Farzaneh Nafar and Ross Yates and Rasha Alahmad and Il Jeon and Yogesh K. Dwivedi},
keywords = {Project management, Artificial intelligence, Sustainability, Resilience, Ethics},
abstract = {The project management profession is undergoing transformative change with the integration of Artificial Intelligence (AI), redefining core methodologies and decision-making processes. As societal expectations rise and technological complexity intensifies, project managers face unprecedented challenges. By 2030, AI-driven predictive insights and modelling capabilities are expected to significantly enhance efficiency, raising critical questions about the evolving role of human project managers. Will AI take the lead in key decisions, or will human attributes such as creativity, ethical judgment, and emotional intelligence remain essential? Framed as PM2030, this study explores future scenarios through expert insights from academia and industry. Using an opinion-based approach, we introduce two conceptual models: the AI-Augmented Ethics-Centric Model and the Predictive Model for AI Adoption and Human Trust. These models offer a forward-looking vision of project management shaped by automation, ethics, and human-AI collaboration. This study contributes to the growing discourse on the human-centric evolution of AI-enabled project management.}
}
@article{WALDOCK2024,
title = {The Accuracy and Capability of Artificial Intelligence Solutions in Health Care Examinations and Certificates: Systematic Review and Meta-Analysis},
journal = {Journal of Medical Internet Research},
volume = {26},
year = {2024},
issn = {1438-8871},
doi = {https://doi.org/10.2196/56532},
url = {https://www.sciencedirect.com/science/article/pii/S1438887124007520},
author = {William J Waldock and Joe Zhang and Ahmad Guni and Ahmad Nabeel and Ara Darzi and Hutan Ashrafian},
keywords = {large language model, LLM, artificial intelligence, AI, health care exam, narrative medical response, health care examination, clinical commissioning, health services, safety},
abstract = {Background
Large language models (LLMs) have dominated public interest due to their apparent capability to accurately replicate learned knowledge in narrative text. However, there is a lack of clarity about the accuracy and capability standards of LLMs in health care examinations.
Objective
We conducted a systematic review of LLM accuracy, as tested under health care examination conditions, as compared to known human performance standards.
Methods
We quantified the accuracy of LLMs in responding to health care examination questions and evaluated the consistency and quality of study reporting. The search included all papers up until September 10, 2023, with all LLMs published in English journals that report clear LLM accuracy standards. The exclusion criteria were as follows: the assessment was not a health care exam, there was no LLM, there was no evaluation of comparable success accuracy, and the literature was not original research.The literature search included the following Medical Subject Headings (MeSH) terms used in all possible combinations: “artificial intelligence,” “ChatGPT,” “GPT,” “LLM,” “large language model,” “machine learning,” “neural network,” “Generative Pre-trained Transformer,” “Generative Transformer,” “Generative Language Model,” “Generative Model,” “medical exam,” “healthcare exam,” and “clinical exam.” Sensitivity, accuracy, and precision data were extracted, including relevant CIs.
Results
The search identified 1673 relevant citations. After removing duplicate results, 1268 (75.8%) papers were screened for titles and abstracts, and 32 (2.5%) studies were included for full-text review. Our meta-analysis suggested that LLMs are able to perform with an overall medical examination accuracy of 0.61 (CI 0.58-0.64) and a United States Medical Licensing Examination (USMLE) accuracy of 0.51 (CI 0.46-0.56), while Chat Generative Pretrained Transformer (ChatGPT) can perform with an overall medical examination accuracy of 0.64 (CI 0.6-0.67).
Conclusions
LLMs offer promise to remediate health care demand and staffing challenges by providing accurate and efficient context-specific information to critical decision makers. For policy and deployment decisions about LLMs to advance health care, we proposed a new framework called RUBRICC (Regulatory, Usability, Bias, Reliability [Evidence and Safety], Interoperability, Cost, and Codesign–Patient and Public Involvement and Engagement [PPIE]). This presents a valuable opportunity to direct the clinical commissioning of new LLM capabilities into health services, while respecting patient safety considerations.
Trial Registration
OSF Registries osf.io/xqzkw; https://osf.io/xqzkw}
}
@article{BYRGE2025100105,
title = {Artificial Intelligence and the creative process: Does AI-creativity extend beyond divergent thinking?},
journal = {Journal of Creativity},
volume = {35},
number = {2},
pages = {100105},
year = {2025},
issn = {2713-3745},
doi = {https://doi.org/10.1016/j.yjoc.2025.100105},
url = {https://www.sciencedirect.com/science/article/pii/S2713374525000123},
author = {Christian Byrge and Erik E. Guzik and Christian Gilde},
keywords = {Creative problem solving, Future problem solving, Artificial intelligence, Ai, AGI, convergent thinking, divergent thinking, creative process},
abstract = {While several recent studies have demonstrated the impressive creative performance of Artificial Intelligence (AI) on divergent thinking tasks, there is currently insufficient research and understanding of how AI performs on convergent thinking and discernment activities, essential components of the human creative process. Creative problem-solving methods, in particular, present an intriguing means of researching AI’s capacity to identify problems within ambiguous situations, while also generating relevant, useful solutions that respond to authentic, real-world issues in a meaningful way. This paper examined the performance of three separate AI entries generated by GPT-4o as compared with 68 human team entries from students in grades 7–9 within the competitive World Solutions Challenge offered by the Future Problem Solving Program International (FPSPI). The three entries were blind-scored by trained human evaluators for measures of effectiveness, impact, humaneness, creative strength, and development of action plan. Though all three AI entries scored in the top 15 % for all measures, including achieving the top scores for effectiveness, impact, humaneness, development of action plan, and overall performance, the AI entries were not found to be significantly different than the student control group on the measure of creative strength. The results suggest that AI models like GPT-4 may approach human-like abilities on certain aspects of creative performance during a more comprehensive creative process than divergent thinking alone, providing new insight into the current creative strengths—and limitations—of existing AI models.}
}
@article{MA2025104345,
title = {The role of artificial intelligence in shaping nursing education: A comprehensive systematic review},
journal = {Nurse Education in Practice},
volume = {84},
pages = {104345},
year = {2025},
issn = {1471-5953},
doi = {https://doi.org/10.1016/j.nepr.2025.104345},
url = {https://www.sciencedirect.com/science/article/pii/S1471595325001015},
author = {Jiatian Ma and Jiamin Wen and Ying Qiu and Yuling Wang and Qiao Xiao and Tingting Liu and Dong Zhang and Yangyang Zhao and Zebang Lu and Zhiling Sun},
keywords = {Artificial Intelligence, Nursing education, Systematic review},
abstract = {Aim
This systematic review assesses AI's application, effectiveness and impact on nursing education, while identifying research limitations.
Background
AI integration in nursing education is transforming traditional teaching and learning paradigms.
Design
A systematic review.
Methods
Following PRISMA 2020 guidelines, a search was conducted in PubMed, Web of Science, Embase, Cochrane Library and CINAHL from the inception of the databases to November 1, 2024, focusing on "Artificial Intelligence" and "nursing education." Two reviewers independently screened and assessed the literature. The quality was assessed using the Cochrane Risk of Bias 2.0 (RoB-2) tool for randomized controlled trials (RCTs), the Agency for Healthcare Research and Quality (AHRQ) tools evaluation for observational studies and the JBI Critical Appraisal Checklist for quasi-experimental studies.
Results
Fifteen studies involving 1464 nursing students and professionals were included. The application scenarios of AI technology in nursing education are diverse and varied and it has shown significant potential in many areas of nursing education, but conflicting results have also been observed. Evaluation of literature quality showed that there were seven high-quality studies and eight medium-quality studies. Artificial intelligence was found to have a positive impact on students at three levels: learning attitude and psychological effects, learning effectiveness and comprehensive clinical nursing competencies. Key research gaps were identified, including the lack of longitudinal studies, uneven study populations and the lack of measurement instrument validity and objectivity.
Conclusion
AI positively impacts nursing education but requires further research to address gaps and ensure long-term effectiveness and privacy protection.
Registration
PROSPERO ID: CRD42024562849}
}
@article{QORICH2025128405,
title = {Detection of artificial intelligence-generated essays for academic assessment integrity using large language models},
journal = {Expert Systems with Applications},
volume = {291},
pages = {128405},
year = {2025},
issn = {0957-4174},
doi = {https://doi.org/10.1016/j.eswa.2025.128405},
url = {https://www.sciencedirect.com/science/article/pii/S095741742502024X},
author = {Mohammed Qorich and Rajae {El Ouazzani}},
keywords = {Artificial intelligence (AI), AI-Generated essays detection, Automatic optimization, ChatGPT, Education, Large language models (LLMs), Plagiarism detection},
abstract = {Across various fields of human life, the lightning adoption of generative artificial intelligence (AI) tools is driven by their ease of use and ability to produce high-quality outputs, transforming communication and productivity. However, the growing popularity and influence of models such as ChatGPT have raised concerns in education regarding academic integrity, as AI-generated content challenges the authenticity of student work and complicates traditional assessment practices. Existing plagiarism detection tools, such as Turnitin and GPTZero, attempt to identify AI-generated content; however, their reliability remains limited, as most struggle to accurately differentiate between human and AI essays. To address existing tools limitations, we propose a novel detection model leveraging three large language models (LLMs): Generative Pre-trained Transformer 2 (GPT-2), Robustly Optimized BERT Pretraining Approach (RoBERTa), and Bidirectional and Auto-Regressive Transformers (BART). We first fine-tuned each model on two large-scale datasets to evaluate their effectiveness in distinguishing between human and AI-generated essays. To further enhance the performance, we applied both manual and automated hyperparameter optimization techniques, including Random Search, Grid Search, and Bayesian Optimization. Building on these experiments, we developed our BART-CNN model, which incorporates the best-performing BART configuration with an additional convolutional head classifier. Our BART-CNN model achieved impressive Macro F1-scores of 99.78 % and 98.10 % on the Kaggle and Hugging Face datasets, respectively, and demonstrated significant performance gains over baseline methods in cross-domain validation. Our study offers a critical advancement in AI plagiarism detection, helping to uphold academic standards and the assessment quality in an evolving AI landscape.}
}
@article{CAI2025145,
title = {Evaluating the appropriateness of skin cancer prevention recommendations obtained from an online chat-based artificial intelligence model},
journal = {JAAD International},
volume = {18},
pages = {145-147},
year = {2025},
issn = {2666-3287},
doi = {https://doi.org/10.1016/j.jdin.2024.07.028},
url = {https://www.sciencedirect.com/science/article/pii/S2666328724001457},
author = {Elise M. Cai and Pirunthan Pathmarajah and Roxana Daneshjou and Justin M. Ko and Albert S. Chiou},
keywords = {artificial intelligence, Bing, ChatGPT, generative AI, information resource, large language model, LLM, medical dermatology, patient queries, skin cancer}
}
@article{WALI2025715,
title = {Advancing Bionic Solution through Artificial Intelligence in Healthcare IoT Environment},
journal = {Procedia Computer Science},
volume = {252},
pages = {715-727},
year = {2025},
note = {4th International Conference on Evolutionary Computing and Mobile Sustainable Networks},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2025.01.032},
url = {https://www.sciencedirect.com/science/article/pii/S1877050925000328},
author = {Girish Wali and Chetan Bulla},
keywords = {Artificial Intelligence, Deep learning, Health-IoT, Diabetic prediction, Fog computing},
abstract = {The convergence of human and artificial intelligence (AI) holds great potential for revolutionary changes in healthcare. This study investigates the possibility of a mutually beneficial relationship between artificial intelligence algorithms and human knowledge in creating bionic healthcare solutions. This paper emphasizes the revolutionary effect of this multidisciplinary strategy on healthcare delivery, patient outcomes, and quality of services by reviewing extensively recent developments and case examples. The Deep learning model is designed to predict diabetics using a standard dataset. The Convolution LSTM model is used to predict diabetics to improve accura-cy and reduce the latency. The proposed model is simulated in the Google Colab framework with Python programming language. The simulation results show that the proposed model is more accurate and lesser communication delay as compared to existing works.}
}
@article{AGATE2025100135,
title = {Artificial intelligence methods and approaches to improve data quality in healthcare data},
journal = {Artificial Intelligence in the Life Sciences},
volume = {8},
pages = {100135},
year = {2025},
issn = {2667-3185},
doi = {https://doi.org/10.1016/j.ailsci.2025.100135},
url = {https://www.sciencedirect.com/science/article/pii/S266731852500011X},
author = {Jarmakoviča Agate},
keywords = {Data quality, Artificial intelligence, Healthcare data, Deep learning, Federated learning, Ontology-based governance, Data completeness, Consistency, Systematic review, PRISMA},
abstract = {This study explores artificial intelligence (AI) methods and approaches used to improve data quality, with a particular focus on healthcare data. Applying a systematic literature review based on the PRISMA framework, the research examines publications from 2020 to 2025 that analyze AI applications across key data quality dimensions—accuracy, completeness, consistency, timeliness, uniqueness, and validity. The study aims to identify which AI methods are most commonly employed and how they align with these quality attributes. A conceptual map was developed to visualize the relationships between dimensions and AI techniques such as deep learning, federated learning, data-centric AI, and ontology-based data governance. Findings reveal that accuracy and consistency are the most emphasized dimensions in the literature, with methods like supervised learning, NLP, and isolation forest frequently applied. In contrast, dimensions like timeliness and validity receive comparatively limited attention. The study concludes that certain AI methods—particularly data-centric and cross-cutting approaches—are effective in addressing multiple data quality challenges simultaneously. These insights offer practical guidance for selecting AI strategies in healthcare data quality improvement and highlight areas for future research.}
}
@article{LIU2025,
title = {Generative AI for clinical reasoning: A scoping review},
journal = {Teaching and Learning in Nursing},
year = {2025},
issn = {1557-3087},
doi = {https://doi.org/10.1016/j.teln.2025.08.008},
url = {https://www.sciencedirect.com/science/article/pii/S1557308725002410},
author = {Ying-Mei Liu and Chang-Chuan Chou and Tang-Her Jaing and Chizimuzo T.C. Okoli},
keywords = {clinical reasoning, education, generative artificial intelligence, health, simulation},
abstract = {Objectives
To explore how generative artificial intelligence (AI) supports clinical reasoning development through simulation-based teaching in undergraduate health professions education.
Design
Scoping review.
Data Sources
CINAHL, ERIC, PubMed, ScienceDirect, and Web of Science databases.
Review Methods
A systematic search was conducted to identify studies exploring the integration of generative AI in simulation-based learning. Inclusion criteria focused on undergraduate health professions education and clinical reasoning outcomes.
Results
Six studies with a total of 492 participants met the inclusion criteria. Generative AI was used to create simulation scenarios, virtual patients, provide feedback, analyze student performance, and support inquiry-based learning. Four studies reported significantly improved clinical reasoning outcomes with AI-assisted teaching. One study reported the comparability between AI-generated feedback and expert feedback, though expert input remained superior in complex cases.
Conclusions
The integration of generative AI into simulation-based education is in its early stages. Most studies lacked theoretical frameworks and used diverse outcome measures, limiting comparability and generalizability. Future research should adopt theory-driven designs and standardized assessment tools to better evaluate the impact of generative AI on clinical reasoning development.}
}
@article{QU2025103949,
title = {Is new technology always good? Artificial intelligence and corporate tax avoidance: Evidence from China},
journal = {International Review of Economics & Finance},
volume = {98},
pages = {103949},
year = {2025},
issn = {1059-0560},
doi = {https://doi.org/10.1016/j.iref.2025.103949},
url = {https://www.sciencedirect.com/science/article/pii/S1059056025001121},
author = {Guimin Qu and Hao Jing},
keywords = {Artificial intelligence, Tax avoidance, Labor cost, Text analysis},
abstract = {Corporate tax avoidance is an enduring topic. With the advent of the intelligent era, how artificial intelligence affects corporate tax avoidance has become an important topic of existing researches. We take Chinese A-share enterprises from 2008 to 2023 as the research samples, and empirically test the impact and mechanisms of artificial intelligence on corporate tax avoidance. Based on the perspective of corporate governance costs, we discuss the influence and function mechanism of artificial intelligence on corporate tax avoidance. The results show that artificial intelligence can promote tax avoidance for enterprises by increasing high-skilled labor cost and intelligent input cost. Heterogeneity analysis reveals that artificial intelligence exerts a more influence on corporate tax avoidance in circumstances where tax regulatory intensity is diminished, and the tax burden is escalated. This study enriches the research on the development of enterprise intelligence in the new era, opens the "black box" between artificial intelligence and tax avoidance, and provides evidence for the logic between them.}
}
@article{FLOOD2025102488,
title = {The Digital Mentor: Artificial Intelligence Coaching for Transformative Nursing Leadership},
journal = {Nurse Leader},
volume = {23},
number = {5},
pages = {102488},
year = {2025},
note = {October 2025},
issn = {1541-4612},
doi = {https://doi.org/10.1016/j.mnl.2025.102488},
url = {https://www.sciencedirect.com/science/article/pii/S1541461225001429},
author = {Tessi Flood},
abstract = {Today nurse managers are navigating unprecedented complexity, balancing rising expectations with limited experience and minimal real-time support. Traditional leadership development approaches, while valuable, are episodic and disconnected from daily operational demands. This article introduces a novel approach: an artificial intelligence (AI)-powered digital mentor that delivers in-the-moment coaching, reinforces standard leadership practices, and supports clinical leaders where they work Figure 1. Drawing from early implementation findings across hospital units, the article highlights how an AI tool, reduces administrative burden, increases leader rounding and enhances role clarity.It explores how AI can scale leader mentorship, build equity in development access, and provide measurable returns for health systems. Far from replacing leaders, AI augments their presence and performance, positioning digital mentorship as a critical strategy for sustainable, high-impact transformational nursing leadership.}
}
@article{GENOVESE2025103622,
title = {The Evolving Role of Artificial Intelligence in Plastic Surgery Education: Insights From Program Directors and Residents},
journal = {Journal of Surgical Education},
volume = {82},
number = {9},
pages = {103622},
year = {2025},
issn = {1931-7204},
doi = {https://doi.org/10.1016/j.jsurg.2025.103622},
url = {https://www.sciencedirect.com/science/article/pii/S193172042500203X},
author = {Ariana Genovese and Srinivasagam Prabha and Cesar A. Gomez-Cabello and Syed Ali Haider and Sahar Borna and Maissa Trabilsy and Antonio Jorge Forte},
keywords = {AI, artificial intelligence, plastic surgery, residency, survey},
abstract = {Objective
To assess the current state of artificial intelligence (AI) policies, educational resources, and perceptions within U.S. plastic surgery residency programs from the perspectives of program directors (PDs) and residents.
Design
Cross-sectional study using 2 anonymized surveys to evaluate AI-related policies, current use, educational tools, perceived barriers, and attitudes toward AI use in surgical education and residency applications.
Setting
Plastic surgery residency programs across the United States
Participants
Program directors (n = 77) were invited via email, with 24 (31%) responding. Residents (n = 89) were recruited via social media; 1 resident per program was randomly selected to ensure institutional diversity, with 23 (26%) completing the survey.
Results
Institutional adoption of AI was limited. Only 8% of PDs reported screening residency applications for AI-generated content, and 88% indicated their programs had no formal policies on AI use. AI-based educational tools were available in 13% of programs, 21% offered AI ethics training, and 8% reported using AI to assess surgical skill. Barriers included lack of expertise (65%), data privacy concerns (52%), cost (48%), and limited evidence of efficacy (48%). In contrast, residents reported substantial independent AI use (50%). Residents used platforms such as ChatGPT (50%), Google Gemini, Microsoft Copilot, and Claude (each 9%)—often to generate clinical explanations (43%), procedural guides (17%), and differential diagnoses (13%). One resident also reported undergoing AI-based surgical skill assessment. Despite this engagement, 74% stated their programs lacked AI-related educational resources. Residents expressed moderate trust in AI (mean 5.26/10), stating it “probably” or “definitely” has a place in their education (86%).
Conclusions
A marked discrepancy exists between institutional policies and resident usage of AI in plastic surgery education. As residents adopt these tools independently, there is an urgent need for evidence-based guidelines, validated resources, and structured implementation to ensure safe, effective integration into surgical training.}
}
@article{OWUSU2025100377,
title = {Achieving operational excellence through artificial intelligence: The case of Ghanaian banks},
journal = {International Journal of Information Management Data Insights},
volume = {5},
number = {2},
pages = {100377},
year = {2025},
issn = {2667-0968},
doi = {https://doi.org/10.1016/j.jjimei.2025.100377},
url = {https://www.sciencedirect.com/science/article/pii/S2667096825000588},
author = {Acheampong Owusu},
keywords = {Operational excellence, Artificial intelligence, Resource base theory, Banks, Ghana},
abstract = {Using the resource-based theory as the lens, this research proposes a conceptual model to explore the determinants of AI in the Ghanaian banking sector and also examine its impact on the OpEx of the banks. The study adopted a quantitative research approach with a survey method to collect data from 331 CIOs/IS/IT Managers/Data Scientists/Business Analysts and other knowledgeable managers in the Ghanaian banks who were sampled via stratified and purposive sampling techniques. The data analysis was done via partial least squares structural equation modelling (PLS-SEM). The findings revealed the determinants of AI adoption in the Ghanaian banks are Absorptive Capacity, Agility and Capabilities of the banks. Also, it was established from the empirical results that the adoption of AI enhances OpEX of the banks. The determinants obtained in this study would lay a foundation for future research which could be incorporated into a new theoretical model of AI adoption.}
}
@article{NANDA2025102563,
title = {Evaluating the Ability of Artificial Intelligence to Address Nuanced Cardiology Subspecialty Questions: ChatGPT and CathSAP},
journal = {Journal of the Society for Cardiovascular Angiography & Interventions},
volume = {4},
number = {3, Part B},
pages = {102563},
year = {2025},
note = {The Role of Artificial Intelligence in Cardiovascular Interventions},
issn = {2772-9303},
doi = {https://doi.org/10.1016/j.jscai.2025.102563},
url = {https://www.sciencedirect.com/science/article/pii/S2772930325000043},
author = {Saumya Nanda and Khaled Abaza and Pyae Hein Kyaw and Robert Frankel and Partha Sardar and Sahil A. Parikh and Tharun Shyam and Saurav Chatterjee},
keywords = {artificial intelligence, Cath Self Assessment Program, ChatGPT, medical education},
abstract = {Background
Recent developments in artificial intelligence (AI), particularly in large language models, have shown promise in various fields, including health care. However, their performance on specialized medical board examinations, such as interventional cardiology assessments, remains relatively unexplored.
Methods
A cross-sectional study was conducted using a data set comprising 360 questions from the Cath Self Assessment Program (CathSAP) question bank. This study aimed to assess the overall performance of Chat Generative Pre-trained Transformer (ChatGPT) and compare it to that of average test takers. Additionally, the study evaluated the impact of pertinent educational materials on ChatGPT’s responses, both before and after exposure. The primary outcome measures included ChatGPT’s overall percentage score on the CathSAP examination and its performance across various subsections. Statistical significance was determined using the Kruskal-Wallis equality-of-populations rank test.
Results
Initially, ChatGPT achieved an overall score of 54.44% on the CathSAP exam, which improved significantly to 79.16% after exposure to relevant textual content. The improvement was statistically significant (P = .0003). Notably, the improved score was comparable with the average score achieved by typical test takers (as reported by CathSAP). ChatGPT demonstrated proficiency in sections covering basic science, pharmacology, and miscellaneous topics, although it struggled with anatomy, anatomic variants, and anatomic pathology questions.
Conclusions
The study demonstrates ChatGPT’s potential for learning and adapting to medical examination scenarios, with a notable enhancement in performance after exposure to educational materials. However, limitations such as the model’s inability to process certain visual materials and potential biases in AI models warrant further consideration. These findings underscore the need for continued research to optimize the use of AI in medical education and assessment.}
}
@article{HANYCZ2025153903,
title = {A practical review of generative AI in cardiac electrophysiology medical education},
journal = {Journal of Electrocardiology},
volume = {90},
pages = {153903},
year = {2025},
issn = {0022-0736},
doi = {https://doi.org/10.1016/j.jelectrocard.2025.153903},
url = {https://www.sciencedirect.com/science/article/pii/S0022073625000317},
author = {Shaun A. Hanycz and Pavel Antiperovitch},
keywords = {Artificial intelligence (AI), Generative adversarial networks (GANs), Surface electrocardiogram (ECG), Medical education},
abstract = {Generative artificial intelligence (AI) is a component of artificial intelligence that creates synthetic multi-modal output in the form of text, images, and audio. Multiple approaches have been implemented into teaching surface ECG interpretation. However, learner performance remains poor. Generative AI in the form of Generative Adversarial Networks (GANs) is a novel AI model that has the potential to augment trainee ECG interpretation via creation of synthetic ECGs and anatomical depiction of conduction defects. Generative AI may be implemented in medical education to customize trainee surface ECG interpretation to improve learning and retention.}
}
@article{TSOUPLAKI2025101752,
title = {Enhancing IoT privacy with artificial intelligence: Recent advances and future directions},
journal = {Internet of Things},
volume = {34},
pages = {101752},
year = {2025},
issn = {2542-6605},
doi = {https://doi.org/10.1016/j.iot.2025.101752},
url = {https://www.sciencedirect.com/science/article/pii/S2542660525002653},
author = {Asimina Tsouplaki and Carol Fung and Christos Kalloniatis},
keywords = {IoT, Artificial intelligence, Privacy, Ethics, AI solutions},
abstract = {The proliferation of Internet of Things (IoT) devices has brought tremendous convenience in our daily lives but has also brought significant privacy concerns. In recent years, many solutions have been found in the literature to address these challenges through advanced technologies such as Artificial Intelligence (AI). This paper aims to provide a comprehensive survey of the current landscape of IoT privacy, focusing on the role of AI in enhancing privacy measures. We categorize critical privacy challenges, outline AI strategies to address these challenges, and present AI-driven solutions that have shown real and substantial results in major sectors. We examine various AI techniques, assess their effectiveness, and highlight existing research gaps to inform future researchers. Our main contributions include a taxonomy of AI applications for IoT privacy, an analysis of AI-driven privacy solutions, and a discussion on the ethical implications and compliance requirements. This paper is recommended to researchers, practitioners, and policymakers seeking to develop secure and privacy-aware IoT systems. Unlike previous surveys that analyze thoroughly individual privacy-preserving methods, this study provides a multi layer synthesis of AI techniques tailored to IoT architectures and deployment realities, presenting a taxonomy grounded in both theoretical robustness and implementation feasibility.}
}
@article{BHAGAT2025100295,
title = {Cheminformatics in advancing dengue antiviral research: From conventional molecular modeling (MM) to current artificial intelligence (AI) approaches},
journal = {European Journal of Medicinal Chemistry Reports},
volume = {15},
pages = {100295},
year = {2025},
issn = {2772-4174},
doi = {https://doi.org/10.1016/j.ejmcr.2025.100295},
url = {https://www.sciencedirect.com/science/article/pii/S2772417425000512},
author = {Rinki Prasad Bhagat and Sk Abdul Amin and Lucia Sessa and Simona Concilio and Stefano Piotto and Shovanlal Gayen},
keywords = {Dengue virus, Cheminformatics, Molecular modeling, Artificial intelligence, QSAR, Molecular docking},
abstract = {Cheminformatics has rapidly evolved and garnered widespread attention due to its potential to accelerate the process and reduce the cost of drug design and development. These technologies play a crucial role in drug design against dengue virus (DENV), a neglected tropical disease that remains a significant global health burden, with millions of cases reported annually. Recent advancements in cheminformatics and artificial intelligence (AI)-driven approaches offer promising strategies for designing inhibitors targeting key viral proteins. This study explores the applications of various cheminformatics methods, including conventional molecular modeling (pharmacophore mapping, molecular docking, molecular dynamics (MD) simulations, virtual screening), and artificial intelligence (AI)/machine learning (ML)-based strategies reported to identify compounds with high affinity and specificity for critical DENV protein targets. Additionally, it highlights the synergy between experimental validation, and in silico predictions to prioritize candidate molecules for further development.}
}
@article{HANKENDI2025113705,
title = {Why Transparency Matters for Sustainable Data Centers and Carbon-Neutral Artificial Intelligence (AI)},
journal = {iScience},
pages = {113705},
year = {2025},
issn = {2589-0042},
doi = {https://doi.org/10.1016/j.isci.2025.113705},
url = {https://www.sciencedirect.com/science/article/pii/S2589004225019662},
author = {Can Hankendi and Ayse K. Coskun and Benjamin K. Sovacool},
abstract = {Summary
As artificial intelligence (AI) applications demand substantial computational power, their energy consumption and the attendant carbon footprint of data centers are accelerating at an alarming rate. Due to increasing demand, data centers could consume 9% of global electricity demand by 2030. However, the path toward more sustainable AI and carbon-neutral data centers is hindered by the lack of transparency in data sharing. Without access to operational data from data centers, researchers face limitations in developing effective solutions to minimize carbon emissions. Transparency is urgently needed to foster innovation, advance sustainability goals, and create practical strategies for reducing the environmental impact of AI and data centers. Transparency will help us to innovate around sustainability problems that are expected to become even harder to solve with the booming of the AI industry. Taking necessary actions discussed in this article is essential to ensure a more sustainable future of the data center industry.}
}
@article{FAN2025104661,
title = {Artificial intelligence and enterprise total factor productivity: A human capital requirement perspective},
journal = {International Review of Economics & Finance},
volume = {104},
pages = {104661},
year = {2025},
issn = {1059-0560},
doi = {https://doi.org/10.1016/j.iref.2025.104661},
url = {https://www.sciencedirect.com/science/article/pii/S105905602500824X},
author = {Chen Fan and Xuehui Liao and Xin Yang},
keywords = {Artificial intelligence, Human capital investment, Total factor productivity, Product competitiveness, Human capital structure},
abstract = {In the context of the new technological revolution, artificial intelligence (AI) has emerged as a critical driver of economic growth. This study constructs a novel AI indicator using Chinese internet recruitment data and examines the effects of AI on enterprise total factor productivity (TFP) from a human capital requirement perspective. The results indicate that AI can significantly enhance enterprise TFP. This improvement is primarily attributed to improved product competitiveness and optimized human capital structure. Moreover, this positive effect is more pronounced in the enterprises with greater intellectual capital, higher investment intensity in experienced AI-related human capital, and stronger government support. Further analysis reveals that widespread AI adoption induces resource reallocation within the industry. These findings deepen the understanding of the role of AI in enterprise production practices.}
}
@article{GAO2025105193,
title = {Artificial intelligence-enabled cellular Agriculture: Multiscale modeling, process optimization, and future directions},
journal = {Trends in Food Science & Technology},
volume = {163},
pages = {105193},
year = {2025},
issn = {0924-2244},
doi = {https://doi.org/10.1016/j.tifs.2025.105193},
url = {https://www.sciencedirect.com/science/article/pii/S0924224425003292},
author = {Wenli Gao and Runnan Bai and Shengjie Ling},
keywords = {Cellular agriculture, Artificial intelligence, Machine learning, Digital twin, Sensory optimization, Bioreactor control},
abstract = {Background
Cellular agriculture offers a transformative solution to global food production challenges, particularly in reducing environmental impact, improving animal welfare, and ensuring food security. However, the scalability of cellular agriculture is hindered by inherent complexities in biological systems, including multiscale interactions, data heterogeneity, and process optimization inefficiencies. Artificial intelligence (AI) is increasingly recognized as a vital tool in overcoming these challenges by enabling adaptive, cross-scale modeling and optimization across the entire cellular agriculture pipeline.
Scope and approach
This review synthesizes the application of AI across cellular agriculture, from molecular engineering and culture media optimization to real-time bioreactor monitoring and sensory prediction. We highlight how AI-driven technologies, including machine learning models, reinforcement learning, and digital twin systems, provide solutions to scalability issues, improve product quality, and enhance production efficiency. We also explore the integration of multimodal data streams to address cross-scale challenges, providing a novel framework for AI in cellular agriculture systems.
Key findings and significance
AI applications in cellular agriculture are revolutionizing the field by shifting it from empirical, trial-and-error approaches to intelligent, data-driven systems. AI is not only enabling precision in the optimization of growth conditions, tissue formation, and sensory properties but also fostering predictive, scalable, and customizable food production solutions. We discuss the challenges of data standardization, model interpretability, and cross-modal integration and propose future strategies to establish robust, explainable AI systems for next-generation food production.}
}
@article{GONG2025101248,
title = {Integrating artificial intelligence in entrepreneurship education: Dynamic capabilities and marketing performance among student entrepreneurs},
journal = {The International Journal of Management Education},
volume = {23},
number = {3},
pages = {101248},
year = {2025},
issn = {1472-8117},
doi = {https://doi.org/10.1016/j.ijme.2025.101248},
url = {https://www.sciencedirect.com/science/article/pii/S1472811725001181},
author = {Yi Gong and Shaofeng Wang and Yazhao Dong},
keywords = {Entrepreneurship education, Artificial intelligence, Student entrepreneurs, Dynamic capabilities, Marketing performance, Management education},
abstract = {The rapid integration of artificial intelligence (AI) technologies in business education presents both opportunities and challenges for developing entrepreneurial competencies among students. This study examines how AI adoption influences marketing performance through dynamic capabilities and organizational flexibility in the context of student entrepreneurship education. Drawing on a longitudinal survey of 434 student entrepreneurs across universities in Eastern China, we employ a dual-stage analytical framework combining PLS-SEM and fsQCA to investigate the multifaceted relationships between AI drivers, dynamic capabilities, and marketing outcomes. Our findings reveal that technology-driven, organization-driven, environment-driven, and human-driven factors of AI positively influence students' dynamic capabilities—sensing, seizing, and reconfiguring—which subsequently enhance their AI-enabled marketing performance. Organizational flexibility emerges as a significant positive moderator in this relationship. The fsQCA analysis identifies six configurations leading to optimal marketing performance, providing nuanced insights for curriculum design. These findings contribute to management education literature by demonstrating how AI integration can enhance entrepreneurial learning outcomes and inform pedagogical approaches. The study offers practical implications for educators seeking to prepare students for AI-driven business environments while advancing responsible management education aligned with sustainable development goals.}
}
@article{STEFAN2025100850,
title = {A new framework for the artificial intelligence entrepreneurship ecosystem},
journal = {Journal of Innovation & Knowledge},
volume = {10},
number = {6},
pages = {100850},
year = {2025},
issn = {2444-569X},
doi = {https://doi.org/10.1016/j.jik.2025.100850},
url = {https://www.sciencedirect.com/science/article/pii/S2444569X25001957},
author = {Simona Cătălina Ștefan and Ion Popa and Andreea Breazu},
keywords = {Artificial intelligence, AI, Entrepreneurship ecosystem, Market changes, Openness, Performance expectancy, Social influence, cIPMA},
abstract = {Artificial intelligence (AI) has revolutionized the way modern organizations operate, defining the transition from traditional industries to digital industries in which production systems can communicate, self-monitor, and collaborate autonomously. This study proposes a new framework for the AI entrepreneurship ecosystem that emphasizes the relationships, significance, and necessity of the factors shaping this field. Adopting a multifaceted approach that integrates several analyses—partial least squares structural equation modeling, importance-performance analysis, necessary conditions analysis, and artificial neural networks—this study identifies five predictors of AI entrepreneurship intention: entrepreneurial ecosystem, social influence, openness, performance expectancy, and market changes. Using 765 responses collected through a questionnaire from potential AI entrepreneurs, the findings show that the entrepreneurial ecosystem and social influence directly influence AI entrepreneurial intention, while the other factors act as mediators or moderators. The results indicate that managerial interventions should prioritize the entrepreneurial ecosystem and social influence, which are highly important but relatively underperforming. Moreover, although openness and performance expectancy are not primary drivers of AI entrepreneurial intention, they represent necessary conditions. This study makes an original contribution by examining the entrepreneurial ecosystem in the context of AI, as well as entrepreneurial intentions to adopt AI when starting a business.}
}
@article{LATA2025102517,
title = {Governing the Unbound: SCAI’s Role in the Future of Artificial Intelligence},
journal = {Journal of the Society for Cardiovascular Angiography & Interventions},
volume = {4},
number = {3, Part B},
pages = {102517},
year = {2025},
note = {The Role of Artificial Intelligence in Cardiovascular Interventions},
issn = {2772-9303},
doi = {https://doi.org/10.1016/j.jscai.2024.102517},
url = {https://www.sciencedirect.com/science/article/pii/S2772930324022063},
author = {Kusum Lata and Curtis Rooney and Deepali Tukaye and Raghava Velagaleti and Afnan Tariq},
keywords = {artificial intelligence, equity, machine learning, policy}
}
@article{LIAN2025108645,
title = {Using a two-stage method to understand the critical factors influencing customers’ intention to switch from traditional to artificial intelligence based banking services: A perspective based on the push–pull–mooring model},
journal = {Computers in Human Behavior},
volume = {168},
pages = {108645},
year = {2025},
issn = {0747-5632},
doi = {https://doi.org/10.1016/j.chb.2025.108645},
url = {https://www.sciencedirect.com/science/article/pii/S0747563225000925},
author = {Jiunn-Woei Lian and Cai-Wei Li},
keywords = {Generative artificial intelligence (GenAI), Customer service, Push–pull–mooring (PPM) model, Switching intention, Banking},
abstract = {Purpose
Generative artificial intelligence (GenAI) enables banks to enhance customer service experiences. However, limited research has been conducted on factors influencing customers’ intention to switch from traditional to artificial intelligence (AI) based banking services. Therefore, the present study explored the key antecedents of the aforementioned intention.
Methods
This two-stage study was based on the push–pull–mooring model. In Stage 1, in-depth semistructured interviews were conducted with stakeholders related to AI-based banking services to identify critical factors influencing customers’ intention to switch from traditional to AI-based customer services. In Stage 2, the results obtained in Stage 1 were combined with results from the literature to create a second-order model and direct-effect model (Models 1 and 2, respectively). Quantitative survey data were then collected to validate these models.
Results
Model 1 indicated that among pull, push, and mooring factors, pull factors had the strongest effect on the aforementioned intention, followed by mooring factors and then push factors. The explanatory power (R2) of this model was 70 %. Furthermore, Model 2 indicated that the attractiveness of the alternative (a pull factor) and the need for interpersonal interaction and inertia (mooring factors) were the key factors influencing switching intention. The explanatory power (R2) of this model was 76 %.
Conclusion
In summary, this study identified and validated critical factors affecting customers’ intention to switch to AI-based banking services. The findings enrich the understanding the social interaction and user behavior of AI, offering valuable insights for promoting AI-driven services and applications.}
}

@article{MIHALACHE2025100154,
title = {Fundus photograph interpretation of common retinal disorders by artificial intelligence chatbots},
journal = {AJO International},
volume = {2},
number = {3},
pages = {100154},
year = {2025},
issn = {2950-2535},
doi = {https://doi.org/10.1016/j.ajoint.2025.100154},
url = {https://www.sciencedirect.com/science/article/pii/S2950253525000577},
author = {Andrew Mihalache and Ryan S. Huang and Marko M. Popovic and Peng Yan and Rajeev H. Muni and Suber S. Huang and David T. Wong},
keywords = {Artificial intelligence, Natural language processing, Image processing, Fundus photography},
abstract = {Purpose
While previous studies have examined the ability of artificial intelligence (AI) chatbots to interpret optical coherence tomography scans, their performance in interpreting fundus photographs of retinal disorders without text-based context remains unexplored. This study aims to evaluate the ability of three widely used AI chatbots to accurately diagnose common retinal disorders from fundus photographs in the absence of text-based context.
Design
Cross-sectional study.
Methods
We prompted ChatGPT-4, Gemini, and Copilot, with a set of 50 fundus photographs from the American Society of Retina Specialists Retina Image Bank® in March 2024, comprising age-related macular degeneration, diabetic retinopathy, epiretinal membrane, retinal vein occlusion, and retinal detachment. Chatbots were re-prompted four times using the same images throughout June 2024. The primary endpoint was the proportion of each chatbot’s correct diagnoses. No text-based guidance was provided.
Results
In March 2024, Gemini provided a correct diagnosis for 17 (34 %, 95 % CI: 21–49 %) fundus images, ChatGPT-4 for 16 (32 %, 95 % CI: 20–47 %), and Copilot for 9 (18 %, 95 % CI: 9–31 %) (p > 0.05). In June 2024, Gemini provided a correct diagnosis for 122 (61 %, 95 % CI: 53–67 %) images, ChatGPT-4 for 101 (51 %, 95 % CI: 43–58 %), and Copilot for 57 (29 %, 95 % CI: 22–35 %).
Conclusion
No AI chatbot use in this study was sufficiently accurate for the diagnosis of common retinal disorders from fundus photographs. AI chatbots should not currently be utilized in any clinical setting involving fundus images, given concerns for accuracy and bioethical considerations.}
}
@article{ASAD2025366,
title = {Influence of artificial intelligence on students’ career competencies and career resources: a global perspective},
journal = {International Journal of Information and Learning Technology},
volume = {42},
number = {4},
pages = {366-391},
year = {2025},
issn = {2056-4880},
doi = {https://doi.org/10.1108/IJILT-05-2024-0091},
url = {https://www.sciencedirect.com/science/article/pii/S2056488025000071},
author = {Muhammad Mujtaba Asad and Khola Anwar},
keywords = {Artificial intelligence, Society 5.0, Cyber-physical learning, Students ‘career competencies, Students’ career resources},
abstract = {Purpose
The primary purpose of this study is to explore the influence of artificial intelligence on students’ career competencies and career resources. Artificial intellegence (AI) plays a pivotal role in the education system, so it is necessary to understand how it shapes students’ skills, expertise, attitudes and beliefs in the modern technological era. This research shows the influence of AI on students’ career competencies, i.e. critical thinking, problem-solving skills and digital literacy. Moreover, it helps students choose their future career paths based on their interests and potential. This research paper highlights some challenges in implementing advanced technology in modern classrooms. It gives recommendations to mitigate those potential challenges through proper reforms and strategies to maximize the use of AI in education for students’ career competencies and resources.
Design/methodology/approach
A narrative literature review has been conducted for this research. Seven themes emerged from the literature review: Technological advancements for Society 5.0 and Education 5.0, Influence of digital technologies in Education 5.0, digital literacy and students’ competencies for modern classrooms, technological developments for students’ career resources, impact of digital literacy on students’ career selection, challenges to integrate technology in modern classrooms and mitigating strategies to overcome potential challenges.
Findings
Based on the findings of the literature review, it is revealed that AI plays a significant role in students’ career competencies and career resources in the advanced era of technology. In Society 5.0, technologies help students gain better knowledge and skills and make connections globally. Students can find their career resources and enhance their competencies in the desired field by using AI in the cyber-physical environment. Moreover, some potential challenges nationally and internationally are highlighted in the literature review.
Practical implications
This narrative literature review helps stakeholders design curricula for higher education institutions and consider the potential challenges of implementing advanced technology in the classroom. Go through the ground realities of all contexts of a country and make an inclusive curriculum for marginalized communities. Educators and curriculum designers use their findings to use AI effectively in the classrooms; students benefit from AI to make their learning personalized and prepare for a better future, which directs them to choose their career paths. Moreover, educational institutions integrate AI in their education to meet the needs of Society 5.0, prepare students for the upcoming era of advanced technology and prepare their infrastructure accordingly. Policymakers can get insights from the findings of this research to make policies accordingly to train teachers for the implementation of AI in the education system and provide equitable access to technology to all students. The findings of this literature review also guide teachers and parents in analyzing the positive outcomes of technology for a conducive teaching-learning process.
Originality/value
This narrative literature review is unique in Pakistan because it draws the attention of all stakeholders to the significance of integrating artificial intelligence in modern classrooms and highlights its importance in Society 5.0. Students learn crucial skills in the 21st century and prepare for the future. Few research studies have been conducted in our context on implementing AI in modern classrooms in Society 5.0.}
}
@article{ALZOUBI2024143090,
title = {Green artificial intelligence initiatives: Potentials and challenges},
journal = {Journal of Cleaner Production},
volume = {468},
pages = {143090},
year = {2024},
issn = {0959-6526},
doi = {https://doi.org/10.1016/j.jclepro.2024.143090},
url = {https://www.sciencedirect.com/science/article/pii/S0959652624025393},
author = {Yehia Ibrahim Alzoubi and Alok Mishra},
keywords = {Artificial intelligence, Carbon footprint, Cloud, Green AI, Green AI tools, Sustainability},
abstract = {Recently, the widespread adoption of artificial intelligence, particularly generative AI technology, has surged across various industries. However, a notable drawback of this technology is its significant energy consumption during model training and operation, which poses challenges to sustainability goals and the environment. Consequently, various initiatives have emerged to promote what is termed "green artificial intelligence," aiming to mitigate these environmental impacts. Nevertheless, research discussing these initiatives remains scarce. Hence, this study aims to identify green artificial intelligence initiatives that contribute to environmental friendliness. This paper has comprehensively reviewed the existing literature, professional websites, and expert blogs to identify and analyze available green AI initiatives. This paper has identified 55 such initiatives, broadly categorized into six themes: cloud optimization, model efficiency, carbon footprinting, sustainability-focused AI development, open-source initiatives, and green AI research and community. This study discusses the strengths and limitations of each initiative to offer a comprehensive overview. The findings provide valuable insights, particularly for industries interested in green artificial intelligence and green technology in general. While some tools have been recognized and studied, comprehensive research and analysis are still required to empirically evaluate the majority of other tools due to their early stages of development in this field.}
}
@article{CHOW20241800,
title = {The Accuracy of Artificial Intelligence ChatGPT in Oncology Examination Questions},
journal = {Journal of the American College of Radiology},
volume = {21},
number = {11},
pages = {1800-1804},
year = {2024},
issn = {1546-1440},
doi = {https://doi.org/10.1016/j.jacr.2024.07.011},
url = {https://www.sciencedirect.com/science/article/pii/S1546144024006756},
author = {Ronald Chow and Shaakir Hasan and Ajay Zheng and Chenxi Gao and Gilmer Valdes and Francis Yu and Arpit Chhabra and Srinivas Raman and J. Isabelle Choi and Haibo Lin and Charles B. Simone},
keywords = {Artificial intelligence, ChatGPT, examination questions, one-shot learning},
abstract = {The aim of this study is to assess the accuracy of Chat Generative Pretrained Transformer (ChatGPT) in response to oncology examination questions in the setting of one-shot learning. Consecutive national radiation oncology in-service multiple-choice examinations were collected and inputted into ChatGPT 4o and ChatGPT 3.5 to determine ChatGPT’s answers. ChatGPT’s answers were then compared with the answer keys to determine whether ChatGPT correctly or incorrectly answered each question and to determine if improvements in responses were seen with the newer ChatGPT version. A total of 600 consecutive questions were inputted into ChatGPT. ChatGPT 4o answered 72.2% questions correctly, whereas 3.5 answered 53.8% questions correctly. There was a significant difference in performance by question category (P < .01). ChatGPT performed poorer with respect to knowledge of landmark studies and treatment recommendations and planning. ChatGPT is a promising technology, with the latest version showing marked improvement. Although it still has limitations, with further evolution, it may be considered a reliable resource for medical training and decision making in the oncology space.}
}
@article{CHIANG2025485,
title = {The Role of Industry to Grow Clinical Artificial Intelligence Applications in Gastroenterology and Endoscopy},
journal = {Gastrointestinal Endoscopy Clinics of North America},
volume = {35},
number = {2},
pages = {485-501},
year = {2025},
note = {Artificial Intelligence in Endoscopy},
issn = {1052-5157},
doi = {https://doi.org/10.1016/j.giec.2024.12.002},
url = {https://www.sciencedirect.com/science/article/pii/S1052515724001107},
author = {Austin L. Chiang and Ha Hong},
keywords = {Artificial intelligence, Responsible artificial intelligence, Medical device, Computer-aided detection, Clinical validation}
}
@article{NIEDBAL20233059,
title = {Students' Use of the Artificial Intelligence Language Model in their Learning Process},
journal = {Procedia Computer Science},
volume = {225},
pages = {3059-3066},
year = {2023},
note = {27th International Conference on Knowledge Based and Intelligent Information and Engineering Sytems (KES 2023)},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2023.10.299},
url = {https://www.sciencedirect.com/science/article/pii/S1877050923014576},
author = {Rafał Niedbał and Adam Sokołowski and Artur Wrzalik},
keywords = {ChatGPT, Generative Artificial Intelligence, chatbot, Large Language Models, modern IT in education, innovative education},
abstract = {Generative Artificial Intelligence (GAI), of which ChatGPT is an exemplary tool, is beginning to revolutionize the way people search for information and use the information they acquire in their personal and professional lives. ChatGPT is showing a strong track record in a variety of tasks, such as generating text, summarizing text and answering questions during a conversation. It has the potential to revolutionize a wide range of fields - including education. The purpose of this article is to evaluate the extent to which the ChatGPT language model can be applied in the learning process for two types of students: full-time and part-time. Additionally, this article assesses the level of students' familiarity with intelligent chat functionality and their ability to construct queries directed to it. The study found that the use of an advanced language model based on artificial intelligence is more beneficial for full-time students in the learning process. However, there was no statistically significant difference in the knowledge of intelligent chat functionality and the ability to construct queries directed to it between full-time and part-time students.}
}
@article{AJMERA2025,
title = {FDA-approved artificial intelligence products in abdominal imaging: A comprehensive review},
journal = {Current Problems in Diagnostic Radiology},
year = {2025},
issn = {0363-0188},
doi = {https://doi.org/10.1067/j.cpradiol.2025.04.011},
url = {https://www.sciencedirect.com/science/article/pii/S0363018825000829},
author = {Pranav Ajmera and Ryan Dillard and Timothy Kline and Andrew Missert and Panagiotis Korfiatis and Ashish Khandelwal},
keywords = {Abdominal Imaging, Artificial Intelligence, Deep Learning, Diagnostic Imaging, FDA Clearance},
abstract = {Purpose
This review aims to provide a comprehensive overview of the transformative impact of FDA-approved artificial intelligence (AI) products in abdominal imaging. It explores the evolution of AI in radiology, its rigorous FDA clearance process, and its role in revolutionizing diagnostic and non-diagnostic tasks across various abdominal organs.
Methods
Through a review of literature, this study categorizes AI products based on their applications in liver, prostate, bladder, kidney, and overall abdominal imaging. It analyzes the diagnostic and non-diagnostic functionalities of these AI solutions, elucidating their capabilities in enhancing disease detection, image quality, workflow efficiency, and longitudinal comparison standardization.
Results
The review identifies numerous FDA-approved AI products tailored for abdominal imaging, showcasing their diverse applications, from lesion detection and characterization to volume estimation and quantification of organ health parameters. These AI solutions have demonstrated their efficacy in improving diagnostic accuracy, streamlining radiological workflows, and ultimately optimizing patient care across various abdominal pathologies.
Conclusion
In conclusion, the integration of AI into abdominal imaging represents a paradigm shift in modern radiology. By empowering radiologists with advanced tools for timely diagnosis, precise treatment planning, and improved patient outcomes, FDA-approved AI products herald a new era of innovation in abdominal imaging. Collaboration between developers, regulatory bodies, and the medical community will be paramount in harnessing the full potential of AI to reshape the future of abdominal radiology.}
}
@article{AKUTAY2024104142,
title = {The effect of artificial intelligence supported case analysis on nursing students' case management performance and satisfaction: A randomized controlled trial},
journal = {Nurse Education in Practice},
volume = {80},
pages = {104142},
year = {2024},
issn = {1471-5953},
doi = {https://doi.org/10.1016/j.nepr.2024.104142},
url = {https://www.sciencedirect.com/science/article/pii/S1471595324002713},
author = {Seda Akutay and Hatice {Yüceler Kaçmaz} and Hilal Kahraman},
keywords = {Artificial intelligence, Nursing education, Nursing students, Satisfaction},
abstract = {Background
Rapid developments in artificial intelligence have begun to necessitate changes and transformations in nursing education.
Objective
This study aimed to evaluate the impact of an artificial intelligence-supported case created in the in-class case analysis lecture for nursing students on students' case management performance and satisfaction.
Design
This study was a randomized controlled trial.
Method
The study involved 188 third-year nursing students randomly assigned to the AI group (n=94) or the control group (n=94). An information form, case evaluation form, knowledge test and Mentimeter application were used to assess the students' case management performance and nursing diagnoses. The level of satisfaction with the case analysis lecture was evaluated using the VAS scale.
Results
The case management performance scores of the students in the artificial intelligence group were significantly higher than those of the control group (p<0.05). There was no statistically significant difference in satisfaction levels between the artificial intelligence (AI) group and the control group (p>0.05).
Conclusions
The study's results indicated that AI-supported cases improved students' case management performance and were as effective as instructor-led cases regarding satisfaction with the case analysis lecture, focus and interest in the case. The integration of artificial intelligence into traditional nursing education curricula is recommended.
Clinical trials registration number
https://register.clinicaltrials.gov; (NCT06443983).}
}
@article{ELOY2025156007,
title = {Clinical advantages in providing artificial intelligence-assisted prostate cancer diagnosis: A pilot study},
journal = {Pathology - Research and Practice},
volume = {271},
pages = {156007},
year = {2025},
issn = {0344-0338},
doi = {https://doi.org/10.1016/j.prp.2025.156007},
url = {https://www.sciencedirect.com/science/article/pii/S0344033825001992},
author = {C. Eloy and A. Asaturova and J. Pinto and I. Rienda and A. Syrnioti and R. Prisco and A. Polónia},
keywords = {Prostate cancer, Prostate biopsy, Artificial intelligence, Pathology, Whole slide image},
abstract = {Prostate cancer is a prevalent male malignancy, with increasing incidence rates placing significant diagnostic burdens on pathology services worldwide. Artificial intelligence (AI) is emerging as a promising aid in enhancing diagnostic efficiency and accuracy. This study evaluates the clinical benefits of AI-assisted prostate biopsy (PB) diagnosis, with Paige Prostate tool, compared to non-AI-assisted PB diagnosis, focusing on its predictive accuracy for features in radical prostatectomy (RP) specimens. A retrospective analysis included 55 patients divided into two cohorts: one with non-AI-assisted PB diagnosis (n = 25) and another with AI-assisted PB diagnosis (n = 30). Pathological assessments recorded tumor size, Gleason score, Grade Group, and perineural invasion. The correlation between PB and RP results was analyzed, with statistical significance set at p < 0.05. AI-assisted PB diagnosis showed faster reporting times by 24 hours, enhancing workflow efficiency. AI assistance improved the correlation of tumor size between PB and RP, showing a substantial agreement (R=0.646, p < 0.001) compared to non-AI (R=0.479, p = 0.015). Gleason Score concordance increased by 13 % in the AI-assisted group, achieving 73.3 % versus 60 % in the non-AI-assisted group. This small pilot study suggests that AI-assisted PB diagnosis appears to enhance efficiency and accuracy in the diagnosis of prostate cancer, a finding to be confirmed with further studies.}
}
@incollection{MA2025,
title = {Artificial intelligence in the development of antiviral drugs: Progress and applications},
series = {Annual Reports in Medicinal Chemistry},
publisher = {Academic Press},
year = {2025},
issn = {0065-7743},
doi = {https://doi.org/10.1016/bs.armc.2025.09.002},
url = {https://www.sciencedirect.com/science/article/pii/S0065774325000053},
author = {Feiyue Ma and Shuo Wang and Brijesh Rathi and Peng Zhan},
keywords = {Artificial intelligence, Machine learning, Deep learning, Antiviral agents, Drug discovery},
abstract = {Viral infections represent a persistent and significant threat to global public health, underscoring the critical importance of developing effective antiviral therapeutics. The integration of artificial intelligence (AI) is revolutionizing the landscape of antiviral drug discovery, offering unprecedented speed and efficiency. This chapter explores the transformative applications of AI across the development pipeline, from initial lead compound identification and de novo molecular design to lead compound optimization. We delve into how AI algorithms, through sophisticated virtual screening, drug repurposing, and bioactivity prediction strategies, are accelerating the identification of promising lead compounds. Furthermore, we examine the power of AI generative models in the de novo design of novel chemotypes possessing tailored engagement with specific viral targets. For the crucial stage of lead compound optimization, we discuss how AI models are employed to navigate the complex multi-parameter landscape, intelligently designing molecules that balance high potency against evolving viral threats with optimized pharmacokinetic properties. Collectively, these AI-driven strategies have demonstrably compressed discovery timelines and are establishing robust, adaptable frameworks to proactively address future and emerging viral threats.}
}
@article{TERRENCEJOSEJEROME2025100339,
title = {Is AI an advanced intelligence, artificial intelligence, or annoying intelligence in hand and microsurgery?},
journal = {Journal of Hand and Microsurgery},
volume = {17},
number = {5},
pages = {100339},
year = {2025},
issn = {0974-3227},
doi = {https://doi.org/10.1016/j.jham.2025.100339},
url = {https://www.sciencedirect.com/science/article/pii/S0974322725004971},
author = {J. {Terrence Jose Jerome}}
}
@article{AHMADZADEH2025174,
title = {Artificial Intelligence Solutions to Improve Emergency Department Wait Times: Living Systematic Review},
journal = {The Journal of Emergency Medicine},
volume = {75},
pages = {174-187},
year = {2025},
issn = {0736-4679},
doi = {https://doi.org/10.1016/j.jemermed.2025.05.031},
url = {https://www.sciencedirect.com/science/article/pii/S0736467925002318},
author = {Bahareh Ahmadzadeh and Christopher Patey and Paul Norman and Alison Farrell and John Knight and Stephen Czarnuch and Shabnam Asghari},
keywords = {emergency department, wait time, artificial intelligence, living systematic review},
abstract = {Background
Overcrowding and long wait times in emergency departments (EDs) remain global challenges that negatively affect patient outcomes and staff satisfaction. As an emerging technology, artificial intelligence (AI) offers the potential to optimize ED operations and reduce wait times.
Objective
Establish a strategy to evaluate AI modeling as it relates to utilizing AI based strategies for ED flow.
Methods
We searched Embase, MEDLINE, CINAHL, and Scopus for English-language studies published from January 1, 1946, to August 17, 2023, and we will update our search to ensure currency. The ROBINS-I tool assessed study quality, while PROBAST examined the risk of bias and applicability.
Results
Out of 17,569 screened studies, 65 full-text articles were evaluated for eligibility, with 16 quantitative observational studies meeting inclusion criteria. The best-performing algorithms included regression-based methods (n = 2), traditional single-model machine learning (n = 8), neural networks/deep learning (n = 3), natural language processing (n = 1), and ensemble methods (n = 2). None of the studies examined AI’s impact in a real ED setting, though four simulations reported wait-time reductions ranging from 7 to 43.2 minutes.
Conclusions
AI integration in ED is still in its infancy. Our review found no real-world ED implementation studies, and most of the existing research lacked involvement from ED experts. This gap highlights the lack of insight into AI’s practical impact. Future reviews and research must clarify these dimensions, guiding AI's effective, collaborative adoption in ED workflows.}
}
@article{ALZBOON2025105113,
title = {Beliefs of teachers who are blind related to the use of artificial intelligence (AI) in Jordan},
journal = {Research in Developmental Disabilities},
volume = {166},
pages = {105113},
year = {2025},
issn = {0891-4222},
doi = {https://doi.org/10.1016/j.ridd.2025.105113},
url = {https://www.sciencedirect.com/science/article/pii/S0891422225001970},
author = {Eman Al-Zboon},
keywords = {Beliefs, Teachers, Blind persons, Artificial intelligence, Assistive technology},
abstract = {This qualitative study employed Interpretative Phenomenological Analysis (IPA) to explore the beliefs and lived experiences of teachers who are blind (TWB) in Jordan regarding the use of artificial intelligence (AI) in education. Data were collected through semi-structured interviews with 14 TWB and a focus group with 8 additional teachers, recruited via snowball and purposive sampling. Findings reveal that TWB actively use various AI applications, including Siri, ChatGPT, currency and image readers, screen readers, and AI-powered search engines like Google and YouTube. Key domains of AI use include daily life, environmental recognition, education, and communication, while mobility, entertainment, and teaching were less common. The study identifies multiple factors shaping AI use, such as personal characteristics, environmental and technological contexts, and socio-cultural influences. Participants reported significant barriers, including limited training, financial constraints, accessibility challenges, and misconceptions about AI. TWB offered practical suggestions to enhance AI adoption in their professional and personal lives. The study concludes with recommendations for policy, practice, and future research to better support AI integration for TWB.}
}
@article{DULLINJA2025101720,
title = {Examining the knowledge level and opinions of architecture students about artificial intelligence},
journal = {Social Sciences & Humanities Open},
volume = {12},
pages = {101720},
year = {2025},
issn = {2590-2911},
doi = {https://doi.org/10.1016/j.ssaho.2025.101720},
url = {https://www.sciencedirect.com/science/article/pii/S2590291125004486},
author = {Ejup Dullinja and Kaltrina Jashanica},
keywords = {Architectural education, Artificial intelligence, Artificial intelligence in architecture},
abstract = {This study examines the knowledge and perspectives of architecture students in Kosovo and North Macedonia regarding artificial intelligence (AI) in architecture. An online survey comprising 28 questions was distributed to 482 students across five universities, with 228 valid responses (47.3 %) analyzed. The survey explored AI awareness, usage patterns, and attitudes towards AI integration in architectural education and practice. Findings show that 99.6 % of students are aware of AI, with social media as the main information source (59.7 %). Although 71.1 % use AI in their work, only 1.3 % have received formal training, indicating a clear educational gap. A positive correlation was found between duration of AI use and its perceived career relevance. Chi-square and logistic regression analyses revealed that year of study and university affiliation significantly predict AI usage, explaining 11.2 % of the variance. Students generally held favorable views towards AI integration in architectural education, recognizing its potential benefits while expressing some concerns about job market impacts. The findings suggest a need for formal AI education in architecture curricula to address the current knowledge gap and prepare students for future technological advancements in the field.}
}
@article{KERSIC2025486,
title = {A review on building blocks of decentralized artificial intelligence},
journal = {ICT Express},
volume = {11},
number = {3},
pages = {486-506},
year = {2025},
issn = {2405-9595},
doi = {https://doi.org/10.1016/j.icte.2025.04.001},
url = {https://www.sciencedirect.com/science/article/pii/S2405959525000463},
author = {Vid Keršič and Muhamed Turkanović},
keywords = {AI, Artificial intelligence, Blockchain, Cryptography, DEAI, Decentralization, Decentralized artificial intelligence},
abstract = {Artificial intelligence (AI) is one of the key technologies transforming our lives, while the transfer of knowledge and competencies from the academic sphere to the industry and real-world use cases are accelerating yearly. However, during that transition, several significant problems and questions need to be addressed for the field to develop ethically, such as digital privacy, ownership, and control. These are some of the reasons why the currently most popular approaches of artificial intelligence, i.e., centralized artificial intelligence (CEAI), are questionable, with other directions also being explored widely, such as decentralized artificial intelligence (DEAI), which aim to solve some of the most far-reaching problems. This paper aims to review and organize the knowledge in the field of DEAI, focusing solely on studies that fall within this category. A systematic literature review (SLR) was conducted using six scientific databases and additional gray literature to analyze and present the findings of 71 identified studies. The paper’s primary focus is identifying the building blocks of DEAI solutions and networks, tackling the DEAI analysis from a bottom-up approach. Future research directions and open problems are presented and proposed at the end.}
}
@article{SAKAOKA2025102381,
title = {Quantitative insights on artificial intelligence in the pharmaceutical industry: A patent-basis analysis of technological trends and key players},
journal = {World Patent Information},
volume = {82},
pages = {102381},
year = {2025},
issn = {0172-2190},
doi = {https://doi.org/10.1016/j.wpi.2025.102381},
url = {https://www.sciencedirect.com/science/article/pii/S0172219025000481},
author = {Shunsuke Sakaoka and Shingo Kano},
keywords = {Artificial intelligence, Pharmaceutical industry, Drug discovery, Drug development, Patent metric analysis, Correspondence analysis},
abstract = {The application of artificial intelligence (AI) in the pharmaceutical industry has rapidly expanded in recent years. To quantitatively assess this emerging trend, previous studies have conducted bibliometric analyses using publication databases to elucidate leading affiliations, research themes, and the contributions and research focuses of key players, including mega pharma, big IT firms, AI startups, and academic institutions. However, quantitative analyses that leverage patent databases to capture these significant shifts and assess the contributions of the key players are scarce. This study investigated technological trends in AI applications within the pharmaceutical industry and clarify the roles and strategic focuses of key players through patent analysis. A total of 1365 AI-related pharmaceutical patent applications in the United States between 2000 and 2023 were identified. Through a detailed analysis of patents, we revealed that AI is strategically employed across critical business domains, including drug discovery, drug development, diagnosis, manufacturing, marketing, and healthcare. Moreover, the study unveiled the specific business areas where each key player has focused their AI-driven initiatives and historical contributions to AI applications in the pharmaceutical industry. The findings underscore both patent and literature analyses are essential to comprehensively assess AI applications and contributions of key players in the pharmaceutical industry.}
}
@article{MONTAG2024103855,
title = {On artificial intelligence and global mental health},
journal = {Asian Journal of Psychiatry},
volume = {91},
pages = {103855},
year = {2024},
issn = {1876-2018},
doi = {https://doi.org/10.1016/j.ajp.2023.103855},
url = {https://www.sciencedirect.com/science/article/pii/S1876201823004124},
author = {Christian Montag and Raian Ali and Dena Al-Thani and Brian J. Hall},
keywords = {Artificial intelligence, Society, Mental health, Psychiatry, Psychology, Therapy},
abstract = {Artificial intelligence (AI) is affecting global societies and reshaping the status quo. AI technologies possess great potential to tackle some of mankind’s most pressing problems, although much of what can be achieved is still a matter of imagination and critical discussion (e.g., AI might also be a source of harm). In the present short communication, we outline AI’s potential for addressing several core issues in global mental health including its application in psychotherapeutic settings.}
}
@article{VANQUAQUEBEKE2025101895,
title = {Beyond efficiency: How artificial intelligence (AI) will reshape scientific inquiry and the publication process},
journal = {The Leadership Quarterly},
volume = {36},
number = {4},
pages = {101895},
year = {2025},
issn = {1048-9843},
doi = {https://doi.org/10.1016/j.leaqua.2025.101895},
url = {https://www.sciencedirect.com/science/article/pii/S1048984325000347},
author = {Niels {Van Quaquebeke} and Scott Tonidandel and George C. Banks},
keywords = {Artificial intelligence, AI, Authorship, Philosophy of science, Scholarship, Publishing},
abstract = {Artificial intelligence is rapidly transforming how research is conceived, executed, published, and shared. This editorial examines the “elephant in the room”: the integration of AI across every stage of the research life cycle and publication pipeline. We trace AI’s expanding footprint on the author side, from sparking novel research ideas, mapping literature, and designing studies, to simulating data, analyzing results, and drafting manuscripts. We also consider AI’s growing role on the journal side, including automated manuscript triage, AI-assisted peer review, decision synthesis, and revision checks. And we discuss AI’s impact on research dissemination. Throughout, we highlight not only the unprecedented opportunities for creativity, efficiency, and accessibility, but also the ethical risks, such as epistemic homogenization, challenges to accountability, and the loss of scholarly craft. We urge researchers, editors, and institutions not to fall into the false binary of blind optimism or blanket skepticism. Instead, we call for deliberate engagement: a principled, transparent, and reflexive partnership between human scholars and machine collaborators. The question is no longer whether we want AI to shape the future of scholarship—it already is. The challenge now is to ensure that what it amplifies is not only our productivity, but our judgment, imagination, and collective responsibility in knowledge creation and dissemination.}
}
@article{HOU2025,
title = {Artificial Intelligence in Medicinal Herb Breeding},
journal = {Engineering},
year = {2025},
issn = {2095-8099},
doi = {https://doi.org/10.1016/j.eng.2025.08.021},
url = {https://www.sciencedirect.com/science/article/pii/S2095809925004886},
author = {Biyu Hou and Caiyan Liang and Xiao Sheng and YongGuo Liu and JianDong Ren and Qiang Ma and Tengjiao Wang and Lei Zhang},
keywords = {Medicinal plants, Precision breeding, Artificial intelligence, Multi-omics integration, Genotype–phenotype prediction},
abstract = {Medicinal plant-derived bioactive compounds serve as a crucial foundation for natural pharmaceutical development. Contemporary breeding methodologies can boost both the quality and yield of these medicinally valuable compounds, thereby advancing the development of the pharmaceutical sector. However, conventional breeding encounters substantial challenges when addressing the intricate genetic architectures and polygenic regulatory networks characteristic of medicinal species. These traditional modalities are especially ineffective in optimizing multiple pharmacologically relevant traits while maintaining robust environmental adaptability across diverse cultivation conditions concurrently. Advanced computational tools are emerging for biological research with parallel development of artificial intelligence (AI), which have also been explored for their applications in medicinal plant breeding. In the current comprehensive review, we carried out a systematic examination of the state-of-the-art AI applications across different aspects of the breeding pipeline, encompassing multi-omics data integration, synthetic biology, precision gene editing, trait optimization, and intelligent monitoring systems. Meanwhile, this review elucidated current obstacles of data integration, model generalization, and environmental adaptation when applying AI in medicinal plants, and proposed a concept of constructing a genotype–environment–management (G × E × M) interactive intelligent breeding platform. The integration of AI with biotechnology emphasizes data-driven precision, computational analysis, and potential for trait customization, contributing to shaping new approaches in medicinal plant breeding gradually. Collectively, these developments may facilitate profound improvements in breeding efficiency, compound yield, and environmental sustainability.}
}
@article{YATES2025708,
title = {New horizons at the interface of artificial intelligence and translational cancer research},
journal = {Cancer Cell},
volume = {43},
number = {4},
pages = {708-727},
year = {2025},
issn = {1535-6108},
doi = {https://doi.org/10.1016/j.ccell.2025.03.018},
url = {https://www.sciencedirect.com/science/article/pii/S1535610825001199},
author = {Josephine Yates and Eliezer M. {Van Allen}},
keywords = {translational oncology, artificial intelligence, multiomics, cancer, machine learning, AI-aided diagnostics},
abstract = {Summary
Artificial intelligence (AI) is increasingly being utilized in cancer research as a computational strategy for analyzing multiomics datasets. Advances in single-cell and spatial profiling technologies have contributed significantly to our understanding of tumor biology, and AI methodologies are now being applied to accelerate translational efforts, including target discovery, biomarker identification, patient stratification, and therapeutic response prediction. Despite these advancements, the integration of AI into clinical workflows remains limited, presenting both challenges and opportunities. This review discusses AI applications in multiomics analysis and translational oncology, emphasizing their role in advancing biological discoveries and informing clinical decision-making. Key areas of focus include cellular heterogeneity, tumor microenvironment interactions, and AI-aided diagnostics. Challenges such as reproducibility, interpretability of AI models, and clinical integration are explored, with attention to strategies for addressing these hurdles. Together, these developments underscore the potential of AI and multiomics to enhance precision oncology and contribute to advancements in cancer care.}
}
@article{KUAN2025102984,
title = {Artificial intelligence in clinical thrombosis and hemostasis: A review},
journal = {Research and Practice in Thrombosis and Haemostasis},
volume = {9},
number = {5},
pages = {102984},
year = {2025},
issn = {2475-0379},
doi = {https://doi.org/10.1016/j.rpth.2025.102984},
url = {https://www.sciencedirect.com/science/article/pii/S2475037925003085},
author = {Yi Kiat Isaac Kuan and Yixin Jamie Kok and Nigel Sheng Hui Liu and Brandon Jin An Ong and Ying Jie Chee and Chuanhui Xu and Minyang Chow and Kollengode Ramanathan and Rinkoo Dalan and Prahlad Ho and Bingwen Eugene Fan},
keywords = {artificial intelligence, machine learning, thrombosis, hemostasis, hemorrhage},
abstract = {Background
Artificial Intelligence (AI) and machine learning (ML) are transforming hemostasis and thrombosis care, with applications spanning disease detection, risk assessment, laboratory testing, patient education, personalized medicine, and drug development. This narrative review explores AI’s clinical utility and limitations across these 6 domains.
Methods
A comprehensive search of PubMed, Embase, and Scopus (up to February 2025) was conducted using terms related to AI, thrombosis, and hemostasis. Peer-reviewed, English-language studies were included, supplemented by manual and reference screening. Of 84 studies included, 38 focused on risk assessment, 16 on diagnostics, and others on personalized medicine, drug development, and patient engagement.
Results
AI demonstrated high accuracy in diagnosing thrombotic events via imaging and electronic health record analysis, although sensitivity gaps persisted for complex cases. In laboratory settings, AI outperformed manual review in detecting errors (eg, sample mislabeling and clotted specimens). Risk stratification models surpassed traditional scores (eg, CHA2DS2-VASc) in predicting thromboembolism, yet inconsistently performed in cancer-associated thrombosis. Personalized anticoagulation dosing and genetic severity prediction in hemophilia highlighted AI’s precision. Chatbots and adherence tools have enhanced patient education while AI-driven drug discovery identified novel anticoagulants and repurposed existing therapies. Limitations included variable external validation, “black box” interpretability issues, and dataset biases.
Conclusion
AI offers significant promise for improving diagnostics, risk prediction, and individualized therapy in thrombosis and haemostasis. Future integration depends on transparent, validated, and equitable AI systems embedded within clinical workflows.}
}
@article{HO2025100715,
title = {Potential and pitfalls of romantic Artificial Intelligence (AI) companions: A systematic review},
journal = {Computers in Human Behavior Reports},
volume = {19},
pages = {100715},
year = {2025},
issn = {2451-9588},
doi = {https://doi.org/10.1016/j.chbr.2025.100715},
url = {https://www.sciencedirect.com/science/article/pii/S2451958825001307},
author = {Jerlyn Q.H. Ho and Meilan Hu and Tracy X. Chen and Andree Hartanto},
keywords = {Artificial intelligence, Chatbot, Romantic, Relationship, Companion, Potentials, Pitfalls},
abstract = {As Artificial Intelligence (AI) becomes more integrated into daily life, individuals have increasingly turned to AI-driven systems for emotional support, companionship, and even romantic relationships. These relationships can be both beneficial and detrimental. Given the need for a comprehensive understanding of this phenomenon, this systematic review uses Sternberg's Triangular Theory of Love to provide a holistic summary of its key potentials and pitfalls. A total of 23 articles were identified from the following databases: EBSCOhost ERIC, EBSCOhost PsycInfo, PubMed, Scopus, and Web of Science. Results highlighted the key potentials of being in a romantic relationship with AI companions as: the facilitation of personal growth and well-being, provision of emotional connection and perceived social support, availability of customisation options, ability to form a sexual connection, as well as a possible outlet for users to seek entertainment and stress-relieving companionship. However, the phenomenon also raises concerns, as it may lead to users' over-reliance and susceptibility to manipulation from the chatbot, perceived shame from stigma surrounding romantic-AI companions, risk of personal data misuse, erosion of human relationships, perpetuation of biases, erosion of emotional connection from abrupt system updates and technical glitches, discomfort from uncanny valley effects, or concerns surrounding coercion to respond and early exposure to sexual content. This systematic review synthesises the dual-edged nature of romantic relationships with AI companions, and outlines critical avenues for future research.}
}
@article{MOTA2025100910,
title = {Review of manufacturing integration between production, maintenance and quality artificial intelligence systems},
journal = {Journal of Industrial Information Integration},
volume = {47},
pages = {100910},
year = {2025},
issn = {2452-414X},
doi = {https://doi.org/10.1016/j.jii.2025.100910},
url = {https://www.sciencedirect.com/science/article/pii/S2452414X25001335},
author = {Bruno Mota and Pedro Faria and Carlos Ramos and Zita Vale},
keywords = {Artificial intelligence, Cost optimisation, Maintenance planning, Predictive maintenance, Production scheduling, Quality control},
abstract = {High inflation is causing major manufacturing cost increases, making optimizing production lines a priority in Industry 5.0 manufacturing. As a result, there has been a rising interest in reducing these costs by more efficiently optimizing production, maintenance, and quality costs. This can be accomplished in manufacturing systems by integrating production task and maintenance activity scheduling, predictive maintenance, and quality control, with the application of artificial intelligence, information integration, and interoperability techniques. Accordingly, the present paper’s premise is to perform a literature review regarding production, maintenance, and quality integration in manufacturing environments. It aims to answer the main research question: “What are the current state-of-the-art artificial intelligence techniques applied in production/maintenance scheduling, predictive maintenance, and quality control integration?”. To investigate this, a Preferred Reporting Items for Systematic Reviews and Meta-Analyses (PRISMA)-like methodology is followed to find the most efficient, reliable, and robust artificial intelligence techniques for production, maintenance, and quality optimization in production lines. Results show that Genetic Algorithms, Reinforcement Learning, Artificial Neural Networks, and Random Forests are among the most often used algorithms in the literature. Furthermore, integration between production/maintenance scheduling and predictive maintenance is done primarily through the rescheduling of production plans when a machine failure is detected. In addition, the same system employed for predictive maintenance is often integrated into also predicting product quality. However, while there have been some accomplishments in this field, research that considers full production, maintenance, and quality integration is still lacking, even if there is an increasing trend of research on this topic.}
}
@article{ELMESSAOUDI2025108457,
title = {The role of artificial intelligence in optimizing photocatalytic degradation technologies of dyes in textile wastewater: Recent advances, challenges, and prospects},
journal = {Journal of Water Process Engineering},
volume = {77},
pages = {108457},
year = {2025},
issn = {2214-7144},
doi = {https://doi.org/10.1016/j.jwpe.2025.108457},
url = {https://www.sciencedirect.com/science/article/pii/S2214714425015302},
author = {Noureddine {El Messaoudi} and Youssef Miyah and Mohammed Benjelloun and Jordana Georgin and Dison S.P. Franco and Parminder Kaur and Vuanghao Lim and Salah Knani},
keywords = {Artificial intelligence, Dye photocatalytic degradation, Machine learning, Textile wastewater treatment},
abstract = {Use of machine learning (ML) and deep learning (DL) techniques with the help of artificial intelligence (AI) has significantly enhanced photocatalyst decolorization of dyes in wastewater treatment generated in the process of textiles through specifically predicting, modeling, and optimizing. Here, the authors describe how models of machine learning like random forests, support vector machines (SVM), and artificial neural networks (ANN) can be used to predict degradation efficiency under pH, light intensity, and catalyst loading conditions in particular. Methods like transfer learning improve model generalizability to systems. AI also enables the identification of new photocatalysts and reduces the necessity for large-scale experimental screening. Hybridization of kinetic models like Langmuir-Hinshelwood with ML enables more stringent predictions at realistic, complex conditions. Additional explainability methods like SHAP and Grad-CAM enable a window into model decision-making, which can inform experimental design. Scripting sensors and reinforcement learning can enable AI to dynamically control and monitor photocatalytic reactors in real time and optimize in real time catalyst concentration, flow rate, and light intensity. AI-efficient reactors are energy-saving and cost-effective, and are capable of degrading up to 99 %. Scaling down the system is not feasible because of the complexity of real effluents and limited information. The article ends by suggesting research avenues for future studies to include the application of AI in digital twins, federated learning, and molecular simulations towards designing smart, scalable, and sustainable water treatment plants.}
}
@article{KASEREKA2025676,
title = {Leveraging Artificial Intelligence for Advancements in Mental Disorders: A Short Review},
journal = {Procedia Computer Science},
volume = {257},
pages = {676-683},
year = {2025},
note = {The 16th International Conference on Ambient Systems, Networks and Technologies Networks (ANT)/ the 8th International Conference on Emerging Data and Industry 4.0 (EDI40)},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2025.03.087},
url = {https://www.sciencedirect.com/science/article/pii/S1877050925008245},
author = {Selain K. Kasereka and Kenny N. Tshibangu and Myriam M. Nyembo and Lionel K. Tshitenge and Marina K. Muzindusi and Godwill W.K. Ilunga and Soufian Ben Amor and Christian D. Bope and Tasho Tashev and Kyandoghere Kyamakya},
keywords = {Mental Health, Predictive Analytics, Mental Health Interventions, Machine Learning, AI in Healthcare},
abstract = {This study explores the expanding influence of artificial intelligence (AI) on the comprehension and management of mental disorders conditions. By analyzing recent advancements, this article highlights how AI technologies are being applied to diagnose, model, predict, and treat conditions, such as depression, anxiety, and bipolar disorder. It examines innovative approaches, including AI-powered mental wellness apps, that enable users to monitor their symptoms and access personalized support. Additionally, it discusses research on advanced algorithms designed to analyze online social interactions to identify early signs of psychological distress and to facilitate timely interventions. The paper also addresses the challenges involved in integrating AI into mental healthcare and highlights ethical and legal concerns that should be addressed when developing AI mental health models.}
}
@article{HUANG2025113691,
title = {Artificial intelligence artificial muscle of dielectric elastomers},
journal = {Materials & Design},
volume = {251},
pages = {113691},
year = {2025},
issn = {0264-1275},
doi = {https://doi.org/10.1016/j.matdes.2025.113691},
url = {https://www.sciencedirect.com/science/article/pii/S026412752500111X},
author = {Dongyang Huang and Jiaxuan Ma and Yubing Han and Chang Xue and Mengying Zhang and Weijia Wen and Sheng Sun and Jinbo Wu},
keywords = {Artificial muscle, Artificial intelligence, Dielectric elastomer, Material database, Data mining, Natural language processing},
abstract = {Artificial muscles (AMs), which encompass materials or devices capable of replicating the functions of natural muscles, have garnered significant attention in recent years, driven by the advent of various materials (advanced hydrogels, pneumatic AMs, dielectric elastomers, etc.) that exhibit exceptional properties and devices that demonstrate remarkable performance. The immense potential of AMs spans numerous industries and aspects of daily life, necessitating accelerated research efforts to meet the increasing demand. This article focuses on dielectric responsive elastomers, which are key materials within the field of AMs, highlighting advancements in theory, materials, and devices. To expedite the research and development of dielectric elastomer AM materials and beyond, we propose leveraging artificial intelligence tools to transform the artificial intelligence muscle research paradigm. Establishing an AM material database is highly valuable, as seemingly minor material data can be correlated with descriptors and target values via machine learning. Through material data mining integrating materials science and data science, we can predict potential breakthroughs in AM materials. A data-driven experimental research approach significantly reduces the number of experiments required for AM development, leading to cost savings and increased research efficiency.}
}
@article{GONG202513137,
title = {ChemReactSeek: an artificial intelligence-guided chemical reaction protocol design using retrieval-augmented large language models},
journal = {Chemical Communications},
volume = {61},
number = {70},
pages = {13137-13140},
year = {2025},
issn = {1359-7345},
doi = {https://doi.org/10.1039/d5cc03155a},
url = {https://www.sciencedirect.com/science/article/pii/S135973452501688X},
author = {Ziyang Gong and Chengwei Zhang and Danyang Song and Weida Xia and Bin Shen and Weike Su and Hongliang Duan and An Su},
abstract = {We introduce ChemReactSeek, an advanced artificial intelligence platform that integrates retrieval-augmented generation using large language models (LLMs) to automate the design of chemical reaction protocols. The system employs DeepSeek-v3 to extract and structure data from scientific literature, enabling the construction of a specialized knowledge base focused on hydrogenation reactions. By combining FAISS-based semantic search with LLM-driven reasoning, ChemReactSeek generates executable reaction conditions, which we further validate through experiments on heterogeneous hydrogenation.}
}
@article{DURAN2025112310,
title = {A review on artificial intelligence applications for facades},
journal = {Building and Environment},
volume = {269},
pages = {112310},
year = {2025},
issn = {0360-1323},
doi = {https://doi.org/10.1016/j.buildenv.2024.112310},
url = {https://www.sciencedirect.com/science/article/pii/S0360132324011521},
author = {Ayca Duran and Christoph Waibel and Valeria Piccioni and Bernd Bickel and Arno Schlueter},
keywords = {Literature review, Building facades, Computer vision, Machine learning, Deep learning},
abstract = {This review applies a transformer-based topic model to reveal trends and relationships in Artificial Intelligence (AI)-driven facade research, with a focus on architectural, environmental, and structural aspects. AI methods reviewed include Machine Learning (ML), Deep Learning (DL), and Computer Vision (CV). Overall, a significantly growing interest in applying AI methods can be observed across all research areas. However, noticeable differences exist between the three topics. While CV and DL techniques are applied to image data in research on the architectural design of facades, research on environmental aspects of facades often uses numerical data with relatively small datasets and classical ML models. Research on facade structure also tends to use image data but also incorporates numerical performance prediction. A major limitation remains a lack of generalizability, which could be addressed by more comprehensive datasets and novel DL techniques. These include concepts such as Physics-Informed Neural Networks, where domain knowledge is integrated into hybrid data-driven models, and multi-modal diffusion models, which offer generative modeling capabilities to support inverse and forward design tasks. The trends and directions outlined in this review suggest that AI will continue to advance facade research and, in line with other domains, has the potential to achieve a level of maturity suitable for adoption beyond academia and into practice.}
}
@article{QUEIROZ2025105923,
title = {Editorial policies for use and acknowledgment of artificial intelligence in dental journals},
journal = {Journal of Dentistry},
volume = {161},
pages = {105923},
year = {2025},
issn = {0300-5712},
doi = {https://doi.org/10.1016/j.jdent.2025.105923},
url = {https://www.sciencedirect.com/science/article/pii/S0300571225003677},
author = {Ana Beatriz L. Queiroz and Letícia Regina Morello Sartori and Giana da Silveira Lima and Rafael R. Moraes},
keywords = {Artificial intelligence, Editorial policies, Ethics, Dental research},
abstract = {Objectives
This study mapped the editorial policies regarding the use and acknowledgment of artificial intelligence (AI) in dental journals.
Methods
Dental journals indexed in Web of Science were analyzed. Editorial guidelines and instructions for authors and reviewers were assessed. The outcome of interest was whether a journal reported an AI policy. Exposures of interest were Journal Impact Factor (JIF), Journal Citation Indicator (JCI), total number of citations, and percentage of open access content. Associations between journal metrics and the presence of AI policies were assessed using Poisson regression models with robust standard errors. Adjusted models were developed separately for JIF and JCI, including variables with p ≤ 0.2. Significance was set at p ≤ 0.05.
Results
Among the 158 journals analyzed, 70.9 % reported AI policies. Policies targeted authors (100 %), reviewers (88.4 %), and editors (46.4 %). The most common areas addressed were authorship, language review, and writing assistance. Journals in the upper quartiles of JIF and JCI were about twice as likely to report an AI policy compared to those in the lowest quartile. In the adjusted models, no association was found between total citations and AI policy presence, whereas open access percentage showed a negative association. While AI tools are permitted to aid in language refinement, critical tasks were consistently required to remain human-led, with rare exceptions.
Conclusion
AI-related editorial policies were frequent in dental journals, and higher-impact journals were statistically more likely to report such policies.
Clinical significance
Clearer and more standardized AI policies may promote transparency and ethical AI use.}
}
@article{GAO2025105050,
title = {Imaging-aided diagnosis and treatment based on artificial intelligence for pulmonary nodules: A review},
journal = {Physica Medica},
volume = {136},
pages = {105050},
year = {2025},
issn = {1120-1797},
doi = {https://doi.org/10.1016/j.ejmp.2025.105050},
url = {https://www.sciencedirect.com/science/article/pii/S1120179725001607},
author = {Huanlong Gao and Jintao Li and Yansong Wu and Zijian Tang and Xuelei He and Fengjun Zhao and Yanwei Chen and Xiaowei He},
keywords = {Artificial intelligence, Pulmonary nodule, Deep learning, Medical imaging, Pulmonary nodule diagnosis},
abstract = {Background:
Pulmonary nodules are critical indicators for the early detection of lung cancer; however, their diagnosis and management pose significant challenges due to the variability in nodule characteristics, reader fatigue, and limited clinical expertise, often leading to diagnostic errors. The rapid advancement of artificial intelligence (AI) presents promising solutions to address these issues.
Methods:
This review compares traditional rule-based methods, handcrafted feature-based machine learning, radiomics, deep learning, and hybrid models incorporating Transformers or attention mechanisms. It systematically compares their methodologies, clinical applications (diagnosis, treatment, prognosis), and dataset usage to evaluate performance, applicability, and limitations in pulmonary nodule management.
Results:
AI advances have significantly improved pulmonary nodule management, with transformer-based models achieving leading accuracy in segmentation, classification, and subtyping. The fusion of multimodal imaging CT, PET, and MRI further enhances diagnostic precision. Additionally, AI aids treatment planning and prognosis prediction by integrating radiomics with clinical data. Despite these advances, challenges remain, including domain shift, high computational demands, limited interpretability, and variability across multi-center datasets.
Conclusion:
Artificial intelligence (AI) has transformative potential in improving the diagnosis and treatment of lung nodules, especially in improving the accuracy of lung cancer treatment and patient prognosis, where significant progress has been made.}
}
@article{HUNG2025100151,
title = {The efficacy of incorporating Artificial Intelligence (AI) chatbots in brief gratitude and self-affirmation interventions: Evidence from two exploratory experiments},
journal = {Computers in Human Behavior: Artificial Humans},
volume = {4},
pages = {100151},
year = {2025},
issn = {2949-8821},
doi = {https://doi.org/10.1016/j.chbah.2025.100151},
url = {https://www.sciencedirect.com/science/article/pii/S2949882125000350},
author = {Jing Wen Hung and Andree Hartanto and Adalia Y.H. Goh and Zoey K.Y. Eun and K.T.A. Sandeeshwara Kasturiratna and Zhi Xuan Lee and Nadyanna M. Majeed},
keywords = {Positive psychology intervention, Gratitude, Self-affirmation, Artificial intelligence, AI chatbots, Well-being},
abstract = {Numerous studies have demonstrated that positive psychology interventions, including brief interventions, can significantly improve well-being outcomes. These findings are particularly important given that many of these interventions are brief and self-administered, making them both accessible and scalable for large populations. However, the efficacy of positive psychology interventions is often constrained by small effect sizes. In light of advancements in generative Artificial Intelligence (AI), this study explored whether integrating AI chatbots into positive psychology interventions could enhance their efficacy compared to traditional self-administered approaches. Study 1 examined the efficacy of a gratitude intervention delivered through Snapchat's My AI, while Study 2 evaluated a self-affirmation intervention integrated with a customized ChatGPT. Both studies employed within-subject experimental designs. Contrary to our hypotheses, the integration of AI did not yield incremental improvements in gratitude outcomes (Study 1), or self-view outcomes (Study 2) compared to existing non-AI interventions. However, exploratory analyses revealed that the AI-integrated self-affirmation intervention significantly enhanced life satisfaction and medium-arousal positive affect, suggesting potential benefits for selected well-being outcomes. These findings indicate that while AI integration in brief, self-administered positive psychology interventions may enhance certain outcomes, its suitability varies across intervention types. Further research is needed to better understand the contexts in which AI can effectively augment positive psychology interventions.}
}
@article{ZHIFENG2025100793,
title = {Virtual entertainment robot based on artificial intelligence image capture system for sports and fitness posture recognition},
journal = {Entertainment Computing},
volume = {52},
pages = {100793},
year = {2025},
issn = {1875-9521},
doi = {https://doi.org/10.1016/j.entcom.2024.100793},
url = {https://www.sciencedirect.com/science/article/pii/S1875952124001617},
author = {Xiong Zhifeng},
keywords = {Deep learning, Virtual robot, Motion capture, Pose recognition},
abstract = {Currently, artificial intelligence and virtual technology are widely used in motion monitoring. Virtual entertainment robots can provide adaptive and personalized fitness services for different user groups, allowing users to experience the exercise process in games. This article studies the virtual entertainment robot based on artificial intelligence image capture system for sports and fitness posture recognition. Firstly, this article explores deep learning methods for motion recognition. By constructing a generative adversarial network to obtain discrimination results, and calculating its anti-loss function. This approach can improve the efficiency of human body movement style conversion through adversarial training. Finally, through the evaluation of movement posture and action recognition, quantitative evaluation results and targeted guidance strategies can be provided to help correct incorrect movements and master correct techniques. Using motion capture systems to identify user movements during exercise not only accurately extracts user fitness movement information, but also makes it easier to use and reduces user costs. The system uses motion evaluation techniques for evaluation to help users correct incorrect fitness habits, prevent exercise losses, and exercise more safely and effectively.}
}
@article{LIU2024110347,
title = {Advanced dual-input artificial optical synapse for recognition and generative neural network},
journal = {Nano Energy},
volume = {132},
pages = {110347},
year = {2024},
issn = {2211-2855},
doi = {https://doi.org/10.1016/j.nanoen.2024.110347},
url = {https://www.sciencedirect.com/science/article/pii/S2211285524010991},
author = {Zhengjun Liu and Yuxiao Fang and Zhaohui Cai and Yijun Liu and Ziling Dong and Renming Zheng and Zongjie Shen and Rui Wu and Wenjing Qu and Jufei Fu and Changhai Ru and Ye Wu and Jiangmin Gu and Yina Liu and Qing Liu and Chun Zhao and Zhen Wen},
keywords = {Synaptic transistor, Neuromorphic computing, Image recognition, Image generation},
abstract = {Perovskite materials have emerged as leading candidates for optical synaptic devices due to their superior photosensitivity and tunable optoelectronic properties. However, the practical application of perovskite-based optoelectronic synaptic transistors has been hindered by issues of poor stability and high toxicity. This study developed an artificial synaptic thin film transistor (TFT) based on a Cs2AgBiBr6/InOx bilayer. The device demonstrated synaptic behavior under optoelectronic hybrid stimulation (largest wavelength ∼520 nm), such as excitatory postsynaptic current (EPSC), inhibitory postsynaptic current (IPSC), paired-pulse facilitation (PPF), spike-timing-dependent plasticity (STDP), short-term memory (STM) and long-term memory (LTM). Notably, the “light writing and voltage erasing” characteristics of these devices could be utilized to construct a convolutional neural network (CNN) classifier for the CIFAR-10 dataset, demonstrating noise tolerance close to the human eye. The loss in recognition accuracy was within 1 % when Gaussian white noise and salt pepper noise were added. Furthermore, these devices exhibited great potential in cycle-consistent generative adversarial networks (CycleGAN), with the generated image quality achieving levels of 0.637 and 0.715 in improved perceptual image processing system (IPIPS) and structural similarity index measure (SSIM) evaluation metrics for the zebra dataset, indicating good image quality. This study indicates that our Cs2AgBiBr6-based artificial optical synaptic TFTs are promising for sensing and in-memory computing applications.}
}
@article{SHOBANKE2025100211,
title = {Advancements and future outlook of Artificial Intelligence in energy and climate change modeling},
journal = {Advances in Applied Energy},
volume = {17},
pages = {100211},
year = {2025},
issn = {2666-7924},
doi = {https://doi.org/10.1016/j.adapen.2025.100211},
url = {https://www.sciencedirect.com/science/article/pii/S2666792425000058},
author = {Mobolaji Shobanke and Mehul Bhatt and Ekundayo Shittu},
keywords = {Artificial Intelligence (AI), Machine Learning (ML), Energy models, Climate change models, Predictive analytics, Meta-analysis, Review},
abstract = {This paper explores the employment of artificial intelligence and machine learning to decipher strategic responses to incidences of climate change and to inform the management of energy systems. Given the increasing global dependence on sustainable and efficient energy solutions and the rise of artificial intelligence and machine learning, it has become imperative to evaluate existing routines in energy and climate change modeling to identify areas for further application. The process of conducting a systematic review of the contemporary literature highlights significant advances in optimization and predictive analytics within energy and climate change modeling systems driven by artificial intelligence and machine learning. This paper contributes to cutting-edge research on energy innovation, i.e., through the examination of the applications of artificial intelligence and machine learning in energy modeling and climate change assessments. The article bridges the gaps between research, development, and implementation with significant insights into the broader applications of artificial intelligence and machine learning in the analysis of future energy transitions and climate change mitigation and adaptation.}
}
@article{OYEDIRAN2025100080,
title = {Artificial intelligence in human immunodeficiency virus mutation prediction and drug design: Advancing personalized treatment and prevention},
journal = {Pharmaceutical Science Advances},
volume = {3},
pages = {100080},
year = {2025},
issn = {2773-2169},
doi = {https://doi.org/10.1016/j.pscia.2025.100080},
url = {https://www.sciencedirect.com/science/article/pii/S2773216925000182},
author = {Karamot O. Oyediran and Peace-Ofonabasi O. Bassey and Deborah A. Ogundemuren and Abdullahi Abdulraheem and Chukwuemeka P. Azubuike and Andrew N. Amenaghawon and Margaret O. Ilomunaya},
keywords = {Artificial intelligence, HIV viral mutation, Drug resistance, Formulation optimization, Personalized treatment},
abstract = {Despite significant advancements in highly active antiretroviral therapy (HAART), Human Immunodeficiency Virus (HIV) remains a global health challenge due to its high mutation rate, drug resistance, and the complexity of treatment optimization. Artificial intelligence (AI) has emerged as a transformative tool in HIV research, offering innovative solutions for predicting viral mutations, optimizing drug discovery and formulation design. However, challenges such as limited access to diverse datasets, ethical concerns, and model interpretability hinder the full potential of AI in HIV research. This review highlights gaps in AI-driven HIV research and explores advancements to address these challenges. AI-driven platforms, such as DeepHIV and geno2pheno, have demonstrated success in forecasting resistance mutations and guiding therapeutic decisions. AI is also revolutionizing drug formulation development by enhancing solubility, bioavailability, and stability, while improving patient adherence through advanced delivery systems. Current applications of AI in HIV mutation prediction, drug discovery, and formulation optimization have highlighted the potential of AI towards HIV management and eradication while addressing gaps in data availability and model transparency. By integrating structural, pharmacological, and clinical data, AI provides a comprehensive framework for rational drug design and personalized treatment strategies. By leveraging AI-driven insights, HIV treatment and prevention can become more personalized, efficient, and sustainable. Future research should focus on overcoming data limitations, enhancing model interpretability, and exploring innovative AI approaches to contribute to the global fight against the HIV epidemic.}
}
@article{KALMYKOV2025103352,
title = {Towards eXplicitly eXplainable Artificial Intelligence},
journal = {Information Fusion},
volume = {123},
pages = {103352},
year = {2025},
issn = {1566-2535},
doi = {https://doi.org/10.1016/j.inffus.2025.103352},
url = {https://www.sciencedirect.com/science/article/pii/S1566253525004257},
author = {Vyacheslav L. Kalmykov and Lev V. Kalmykov},
keywords = {Industry 5.0, AI transparency, Trustworthiness of AI, Symbolic AI, Agent-based models, Cellular automata},
abstract = {Artificial Intelligence (AI) plays a leading role in Industry 4.0 and future Industry 5.0. Concerns about the opacity of today's neural network AI solutions have led to the Explainable AI (XAI) project, which attempts to open the black box of neural networks. While XAI can help to partially interpret and explain the workings of neural networks, it has not changed their original subsymbolic nature and the opaque statistical nature of their workings. Significant uncertainties remain about the safety, reliability, and accountability of modern neural network AI solutions. Here we present a novel AI method that has a fully transparent white-box nature - eXplicitly eXplainable Artificial Intelligence (XXAI). XXAI is implemented on deterministic cellular automata whose rules are based on first principles of the problem domain. XXAI overcomes the limitations for a broader application of symbolic AI. The practical value of XXAI lies in its ability to make autonomous, fully transparent decisions due to its multi-component, multi-level, networked, hyper-logical nature. Looking ahead, XXAI has the potential to become a leading strategic partner in the field of neuro-symbolic hybrid AI systems. XXAI is able to systematically validate neural network solutions, ensuring that the required standards of reliability, security and ethics are met throughout the AI lifecycle, from training to deployment. By creating a clear cognitive framework, XXAI will enable the development of advanced autonomous solutions to achieve the human-centric values of the future Industry 5.0. A comprehensive program for the further development of the proposed approach is presented.}
}
@article{SHEIL2026107604,
title = {Artificial intelligence transformations in geotechnics: progress, challenges and future enablers},
journal = {Computers and Geotechnics},
volume = {189},
pages = {107604},
year = {2026},
issn = {0266-352X},
doi = {https://doi.org/10.1016/j.compgeo.2025.107604},
url = {https://www.sciencedirect.com/science/article/pii/S0266352X25005531},
author = {Brian Sheil and Christos Anagnostopoulos and Róisín Buckley and Matteo Oryem Ciantia and Eky Febrianto and Jinlong Fu and Zhiwei Gao and Xueyu Geng and Bin Gong and Kevin Hanley and Pengpeng He and Kostas Kolomvatsos and Bruna {de C.F.L. Lopes} and Jelena Ninic and Marco Previtali and Mohammad Rezania and Agustin Ruiz-Lopez and Jin Sun and Stephen Suryasentana and David Taborda and Stefano Utili and Scott Whyte and Pin Zhang},
abstract = {Our reliance on the underground space to deliver critical civil engineering infrastructure is growing: to accommodate utility and transport infrastructure in urban environments, to provide innovative housing and commercial solutions, and to support proliferating renewable energy infrastructure, particularly offshore. Artificial intelligence (AI) is arguably the most promising enabler to transform geotechnical engineering by extracting knowledge from data to achieve step-change increases in efficiency, sustainability, reliability and safety. This paper seeks to develop a shared understanding of the state of the art of AI in geotechnics and to explore future developments. By way of example, specific popular use cases in geotechnics are considered to highlight current progress in AI applications including intelligent site investigation, predictive modelling for soil behaviour, and optimisation of design and construction processes. The paper then addresses key research challenges, such as data scarcity and interpretability, and discusses the opportunities that lie ahead in the integration of AI with geotechnical engineering. Finally, priority technological enablers are identified for future transformations.}
}
@article{IACUCCI2025416,
title = {Artificial Intelligence–Driven Personalized Medicine: Transforming Clinical Practice in Inflammatory Bowel Disease},
journal = {Gastroenterology},
volume = {169},
number = {3},
pages = {416-431},
year = {2025},
note = {Shaping the Future of Gastroenterology and Hepatology With Artificial Intelligence},
issn = {0016-5085},
doi = {https://doi.org/10.1053/j.gastro.2025.03.005},
url = {https://www.sciencedirect.com/science/article/pii/S0016508525004949},
author = {Marietta Iacucci and Giovanni Santacroce and Maeda Yasuharu and Subrata Ghosh},
keywords = {Advanced Endoscopy, Barrier Healing, Digital Pathology, Machine Learning},
abstract = {Inflammatory bowel disease is marked by significant clinical heterogeneity, posing challenges for accurate diagnosis and personalized treatment strategies. Conventional approaches, such as endoscopy and histology, often fail to adequately and accurately predict medium- and long-term outcomes, leading to suboptimal patient management. Artificial intelligence is emerging as a transformative force enabling standardized, accurate, and timely disease assessment and outcome prediction, including therapeutic response. Artificial intelligence–driven intestinal barrier healing assessment provides novel insights into deep healing, facilitating the discovery of novel therapeutic targets. In addition, the automated integration of multi-omics data can enhance patient profiling and personalized management strategies. The future of inflammatory bowel disease care lies in the artificial intelligence–enabled "endo-histo-omics" integrative real-time approach, harmoniously fusing endoscopic, histologic, and molecular data. Despite challenges in its adoption, this paradigm shift has the potential to refine risk stratification, improve therapeutic precision, and enable personalized interventions, ultimately advancing the implementation of precision medicine in routine clinical practice.}
}
@article{LYAKHOVA2024108742,
title = {Systematic review of approaches to detection and classification of skin cancer using artificial intelligence: Development and prospects},
journal = {Computers in Biology and Medicine},
volume = {178},
pages = {108742},
year = {2024},
issn = {0010-4825},
doi = {https://doi.org/10.1016/j.compbiomed.2024.108742},
url = {https://www.sciencedirect.com/science/article/pii/S0010482524008278},
author = {U.A. Lyakhova and P.A. Lyakhov},
keywords = {Skin cancer, Melanoma, Dermatology, Pigmented skin lesions, Pigmented neoplasms, Pigmented lesions, Non-melanoma skin cancer/ nonmelanoma skin cancer, Dermoscopy, Dermatological images and dermatological heterogeneous data, Artificial intelligence, Neural network, Deep learning, Convolutional neural network, Multimodal neural network, Ensemble neural network, SUPPORT VECTOR MACHINES, K-nearest neighbor, Decision trees, Recognition, Classification, Detection, Automated screening},
abstract = {In recent years, there has been a significant improvement in the accuracy of the classification of pigmented skin lesions using artificial intelligence algorithms. Intelligent analysis and classification systems are significantly superior to visual diagnostic methods used by dermatologists and oncologists. However, the application of such systems in clinical practice is severely limited due to a lack of generalizability and risks of potential misclassification. Successful implementation of artificial intelligence-based tools into clinicopathological practice requires a comprehensive study of the effectiveness and performance of existing models, as well as further promising areas for potential research development. The purpose of this systematic review is to investigate and evaluate the accuracy of artificial intelligence technologies for detecting malignant forms of pigmented skin lesions. For the study, 10,589 scientific research and review articles were selected from electronic scientific publishers, of which 171 articles were included in the presented systematic review. All selected scientific articles are distributed according to the proposed neural network algorithms from machine learning to multimodal intelligent architectures and are described in the corresponding sections of the manuscript. This research aims to explore automated skin cancer recognition systems, from simple machine learning algorithms to multimodal ensemble systems based on advanced encoder-decoder models, visual transformers (ViT), and generative and spiking neural networks. In addition, as a result of the analysis, future directions of research, prospects, and potential for further development of automated neural network systems for classifying pigmented skin lesions are discussed.}
}
@article{QIU2025106027,
title = {Application of artificial intelligence in bone quality and quantity assessment for dental implant planning: A scoping review},
journal = {Journal of Dentistry},
volume = {162},
pages = {106027},
year = {2025},
issn = {0300-5712},
doi = {https://doi.org/10.1016/j.jdent.2025.106027},
url = {https://www.sciencedirect.com/science/article/pii/S0300571225004749},
author = {Shuo Qiu and Xinbo Yu and Yiqun Wu},
keywords = {Dental implants, Artificial intelligence, Deep learning, Medical imaging, Bone density, Systematic review},
abstract = {Objectives
To assess how artificial intelligence (AI) models perform in evaluating bone quality and quantity in the preoperative planning process for dental implants.
Data
This review included studies that utilized AI-based assessments of bone quality and/or quantity based on radiographic images in the preoperative phase.
Sources
Studies published in English before April 2025 were used in this review, which were obtained from searches in PubMed/MEDLINE, Embase, Web of Science, Scopus, and the Cochrane Library, as well as from manual searches.
Study selection
Eleven studies met the inclusion criteria. Five studies focused on bone quality evaluation and six studies included volumetric assessments using AI models. The performance measures included accuracy, sensitivity, specificity, precision, F1 score, and Dice coefficient, and were compared with human expert evaluations. AI models demonstrated high accuracy (76.2 %-99.84 %), high sensitivity (78.9 %-100 %), and high specificity (66.2 %-99 %).
Conclusions
AI models have potential for the evaluation of bone quality and quantity, although standardization and external validation studies are lacking. Future studies should propose multicenter datasets, integration into clinical workflows, and the development of refined models to better reflect real-life conditions.
Clinical significance
AI has the potential to offer clinicians with reliable automated evaluations of bone quality and quantity, with the promise of a fully automated system of implant planning. It may also support preoperative workflows for clinical decision-making based on evidence more efficiently.}
}
@article{ZACE2025100973,
title = {Artificial intelligence in resuscitation: a scoping review},
journal = {Resuscitation Plus},
volume = {24},
pages = {100973},
year = {2025},
issn = {2666-5204},
doi = {https://doi.org/10.1016/j.resplu.2025.100973},
url = {https://www.sciencedirect.com/science/article/pii/S2666520425001109},
author = {Drieda Zace and Federico Semeraro and Sebastian Schnaubelt and Jonathan Montomoli and Giuseppe Ristagno and Nino Fijačko and Lorenzo Gamberini and Elena G. Bignami and Robert Greif and Koenraad G. Monsieurs and Andrea Scapigliati},
keywords = {Cardiac arrest, Resuscitation, Artificial intelligence, Machine learning, Deep learning, Large language model, Scoping review},
abstract = {Background
Artificial intelligence (AI) is increasingly applied in medicine, with growing interest in its potential to improve outcomes in cardiac arrest (CA). However, the scope and characteristics of current AI applications in resuscitation remain unclear.
Methods
This scoping review aims to map the existing literature on AI applications in CA and resuscitation and identify research gaps for further investigation. PRISMA-ScR framework and ILCOR guidelines were followed. A systematic literature search across PubMed, EMBASE, and Cochrane identified AI applications in resuscitation. Articles were screened and classified by AI methodology, study design, outcomes, and implementation settings. AI-assisted data extraction was manually validated for accuracy.
Results
Out of 4046 records, 197 studies met inclusion criteria. Most were retrospective (90%), with only 16 prospective studies and 2 randomised controlled trials. AI was predominantly applied in prediction of CA, rhythm classification, and post-resuscitation outcome prognostication. Machine learning was the most commonly used method (50% of studies), followed by deep learning and, less frequently, natural language processing. Reported performance was generally high, with AUROC values often exceeding 0.85; however, external validation was rare and real-world implementation limited.
Conclusions
While AI applications in resuscitation demonstrate encouraging performance in prediction and decision support tasks, clear evidence of improved patient outcomes or routine clinical use remains limited. Future research should focus on prospective validation, equity in data sources, explainability, and seamless integration of AI tools into clinical workflows.}
}
@article{CHEN20251404,
title = {Artificial intelligence approaches for anti-addiction drug discovery},
journal = {Digital Discovery},
volume = {4},
number = {6},
pages = {1404-1416},
year = {2025},
issn = {2635-098X},
doi = {https://doi.org/10.1039/d5dd00032g},
url = {https://www.sciencedirect.com/science/article/pii/S2635098X25000932},
author = {Dong Chen and Jian Jiang and Nicole Hayes and Zhe Su and Guo-Wei Wei},
abstract = {Drug addiction remains a complex global public health challenge, with traditional anti-addiction drug discovery hindered by limited efficacy and slow progress in targeting intricate neurochemical systems. Advanced algorithms within artificial intelligence (AI) present a transformative solution that boosts both speed and precision in therapeutic development. This review examines how artificial intelligence serves as a crucial element in developing anti-addiction medications by targeting the opioid system along with dopaminergic and GABAergic systems, which are essential in addiction pathology. It identifies upcoming trends promising in studying less-researched addiction-linked systems through innovative general-purpose drug discovery techniques. AI holds the potential to transform anti-addiction research by breaking down conventional limitations, which will enable the development of superior treatment methods.}
}
@article{MORENOBELLA2025111637,
title = {Supporting the technocracy of artificial intelligence: Data from a representative Spanish sample},
journal = {Data in Brief},
volume = {60},
pages = {111637},
year = {2025},
issn = {2352-3409},
doi = {https://doi.org/10.1016/j.dib.2025.111637},
url = {https://www.sciencedirect.com/science/article/pii/S2352340925003683},
author = {Eva Moreno-Bella and Marcos Dono and Miguel Moya},
keywords = {Artificial intelligence, Technocracy, Socioeconomic status, Political psychology, Economic factors, Open access},
abstract = {The recent development and improvement of generative AI have significantly influenced the lives of all citizens in developed countries. However, this technological advancement is occurring in a context of economic distress and political uncertainty with the rise of the political extremism. In this article we present a dataset collected for examining social and political attitudes of the Spanish population. We obtained participants’ responses through a research company using an online survey. The sample was stratified by quotas following the distribution of the Spanish population. All participants received an economic compensation for their participation. The dataset featured in this article contains data of 1,541 participants on support for technocracy of artificial intelligence (AI), subjective socioeconomic status, political orientation, and other related variables such as financial threat, financial scarcity, perceived socioeconomic decline, perceived economic inequality, and relative deprivation. The survey also collected sociodemographic data. Importantly, these data were collected during a period of political elections in some regions of Spain. This is the first dataset on support for technocracy of AI and social and political attitudes that may shape it in current societies. It is proposed to consider this dataset as a help to clarify and examine the relationship between the perception of economic situation and support for an AI technocracy. This data publication could offer new perspectives for addressing current political and economic challenges, proposing solutions based on data and the potential factors that foster trust in AI as a part of government.}
}
@article{KONG2025100447,
title = {Developing and validating an artificial intelligence ethical awareness scale for secondary and university students: Cultivating ethical awareness through problem-solving with artificial intelligence tools},
journal = {Computers and Education: Artificial Intelligence},
volume = {9},
pages = {100447},
year = {2025},
issn = {2666-920X},
doi = {https://doi.org/10.1016/j.caeai.2025.100447},
url = {https://www.sciencedirect.com/science/article/pii/S2666920X25000876},
author = {Siu Cheung Kong and Jinyu Zhu},
keywords = {Artificial intelligence literacy, Ethical awareness, Problem-solving, Scale, Secondary and university students},
abstract = {Although there is growing attention to artificial intelligence (AI) ethics education with the rapid surge of AI technology, little research has explored the use of problem-solving to cultivate students' AI ethical awareness. To address this gap, this study developed a scale to multidimensionally measure AI ethical awareness and cultivated students' AI ethical awareness through problem-solving using AI tools within an AI literacy course. A total of 573 Hong Kong secondary and university students participated in a 14-h course. Data was collected through the AI Ethical Awareness Scale (AIEAS) questionnaire and students' self-reflective writings. The AIEAS framework, encompassing three dimensions, was based on the Belmont Report principles of human autonomy, beneficence, and fairness. Confirmatory factor analysis (CFA) supported this three-factor structure, with nine items retained. Multigroup CFA results demonstrated strong measurement invariance across gender, education level, and programming knowledge. All Cronbach's alpha and omega coefficient values exceeded 0.70, indicating satisfactory internal consistency and fair temporal stability. Furthermore, students' ethical awareness showed a significant improvement following the course intervention. This study not only provides a robust measure for researchers and practitioners to assess students' ethical awareness through behavioural engagement but also demonstrates the necessity of implementing an education course for cultivating ethical awareness through integrating experience and reflection.}
}
@article{IACOB2026101081,
title = {Effectiveness of automated segmentation of maxillofacial structures in cone-beam computed tomography images using artificial intelligence: A systematic review},
journal = {International Orthodontics},
volume = {24},
number = {1},
pages = {101081},
year = {2026},
issn = {1761-7227},
doi = {https://doi.org/10.1016/j.ortho.2025.101081},
url = {https://www.sciencedirect.com/science/article/pii/S1761722725001160},
author = {Alin M. Iacob and Alessio Verdecchia and Yolanda García-Mesa and Enrico Spinas and Teresa Cobo},
keywords = {Artificial intelligence, Convolutional neural network, Cone-beam computed, Tomography, Image processing, Jawbone, Segmentation, Orthodontics, Dentistry},
abstract = {Summary
Background
The automated segmentation of maxillary and mandibular bones in cone-beam computed tomography (CBCT) using artificial intelligence (AI) is redefining the standards of digital dentistry and orthodontics, with applications in mini-implant placement, dental implantology, orthognathic surgery, and bone graft planning.
Objective
To systematically assess the performance of AI models – particularly U-Net-based convolutional neural networks (CNNs) – for automated segmentation of maxillary bone structures in CBCT, following the PICOS model (Population – CBCT scans of human maxillae; Intervention – AI-based segmentation; Comparator – manual segmentation; Outcome – accuracy; Study design – diagnostic accuracy studies).
Material and methods
This systematic review adhered to PRISMA 2020 guidelines and was registered in PROSPERO (CRD42024592182). Eligibility criteria included studies applying AI to maxillary bone segmentation in CBCT and reporting quantitative accuracy metrics. Risk of bias was evaluated using the QUADAS-2 tool. The GRADE tool for formulating and grading recommendations in clinical practice was also employed. Data collected comprised number of CBCT scans, AI model architecture, evaluation metrics, and reported clinical applications.
Results
Thirty-one studies, analysing 11,432 CBCT scans, met the inclusion criteria. AI models consistently achieved high segmentation accuracy, with Dice similarity coefficients frequently exceeding 0.98, while substantially reducing processing time compared to manual segmentation. Applications ranged from implant planning and orthognathic surgery to digital orthodontics. Persistent challenges included anatomical variability, imaging artifacts, and the limited availability of high-quality annotated datasets.
Conclusions
AI-based segmentation of maxillary and mandibular bones in CBCT demonstrates promising accuracy and efficiency compared with manual techniques. Nevertheless, the certainty of evidence is limited by retrospective designs and small, heterogeneous samples. Large-scale, prospective multicentre studies with standardized evaluation are needed before these methods can be reliably adopted in routine clinical practice.}
}
@article{OHN202568,
title = {The future of paediatric obstructive sleep apnoea assessment: Integrating artificial intelligence, biomarkers, and more},
journal = {Paediatric Respiratory Reviews},
volume = {55},
pages = {68-74},
year = {2025},
issn = {1526-0542},
doi = {https://doi.org/10.1016/j.prrv.2025.01.004},
url = {https://www.sciencedirect.com/science/article/pii/S1526054225000065},
author = {Mon Ohn and Kathleen J. Maddison and Jennifer H. Walsh and Britta S. {von Ungern-Sternberg}},
keywords = {Paediatric obstructive sleep apnoea (OSA), Screening, Artificial Intelligence (AI), Biomarkers, Polysomnography, Oximetry, Innovative assessment},
abstract = {Assessing obstructive sleep apnoea (OSA) in children involves various methodologies, including sleep studies, nocturnal oximetry, and clinical evaluations. Previous literature has extensively discussed these traditional methods. Despite this, there is no consensus on the optimal screening method for childhood OSA, further complicated by the complexity and limited availability of diagnostic polysomnography (PSG). Recent advancements, such as the integration of artificial intelligence, biomarkers, 3D facial photography, and wearable technology, offer promising alternatives for early detection and more accurate diagnosis of OSA in children. This article provides a comprehensive review of these innovative techniques, highlighting their potential to enhance diagnostic accuracy and overcome the limitations of current methods. With an emphasis on cutting-edge technologies and emerging biomarkers, we discuss the future directions for paediatric OSA assessments and their potential to revolutionise clinical practice.}
}
@article{WANG2025990,
title = {Optimization of architectural design scheme based on artificial intelligence algorithm},
journal = {Procedia Computer Science},
volume = {261},
pages = {990-997},
year = {2025},
note = {The 5th International Conference on Machine Learning and Big Data Analytics for IoT Security and Privacy (SPIoT2024)},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2025.04.491},
url = {https://www.sciencedirect.com/science/article/pii/S1877050925015947},
author = {Xin Wang and Tingting Yang},
keywords = {Artificial intelligence, Neural network, Architectural design scheme},
abstract = {Aiming at the problems of inefficiency, information disjunction and lack of innovation in traditional architectural design schemes, this paper proposes an intelligent evaluation model combining grey correlation analysis, radial basis function neural network and ant colony algorithm. By constructing multi-dimensional building performance index system, combining data dimensionality reduction and nonlinear mapping technology, the problem of index homogeneity and parameter convergence in traditional evaluation is solved. Through experiments, it is found that the average evaluation accuracy of ACO-RBF and GRA-RBF models is 87.48% and 86.60% respectively, while the fusion model in this paper achieves a performance improvement with an accuracy of 93.31%. The model adopts a three-stage collaborative mechanism -- feature space reconstruction, parameter global optimization and nonlinear decision mapping. It significantly improves the objectivity and reliability of complex building performance evaluation, provides a verifiable technical framework for intelligence-driven design decisions, and promotes the transformation of architectural design scheme evaluation from an experience-dependent paradigm to a data-driven paradigm.}
}
@article{YILMAZ202591,
title = {Controversies in Artificial Intelligence in Neurosurgery},
journal = {Neurosurgery Clinics of North America},
volume = {36},
number = {1},
pages = {91-100},
year = {2025},
note = {Controversies in Neurosurgery: 2025},
issn = {1042-3680},
doi = {https://doi.org/10.1016/j.nec.2024.08.008},
url = {https://www.sciencedirect.com/science/article/pii/S104236802400069X},
author = {Recai Yilmaz and Samuel Browd and Daniel A. Donoho},
keywords = {Neurosurgery, Surgical practice, Artificial intelligence, Intraoperative, Technical skills, Surgical training}
}
@article{MONTEIRO2025101279,
title = {The wheel of artificial intelligence governance},
journal = {Sustainable Futures},
volume = {10},
pages = {101279},
year = {2025},
issn = {2666-1888},
doi = {https://doi.org/10.1016/j.sftr.2025.101279},
url = {https://www.sciencedirect.com/science/article/pii/S2666188825008408},
author = {Nithin Monteiro and Vaishali Singh},
keywords = {Artificial Intelligence (AI), AI Governance, Regulation, Ethics, Risk management, Polycentric governance},
abstract = {Amidst growing concerns over the risks of unhinged Artificial Intelligence (AI) innovation, initiatives for AI governance are gaining centre stage across diverse sectors and national contexts. This review addresses the need for effective governance by synthesising the fragmented landscape of AI governance approaches. Using bibliometric analysis and an in-depth literature review, it maps and classifies governance approaches to develop a hybrid, iterative and integrated AI governance model. The literature analysis reveals four primary categories that govern AI: formal, informal, risk management, and eclectic. The findings are used to embed these approaches directly into the different phases of the AI lifecycle, adapted from CRISP-DM and CDAC AI lifecycles. Furthermore, grounded in Ostrom’s polycentric governance theory, the study proposes ‘The Wheel of AI Governance’ (WAG) model to align governance actions with distinct phases of the AI lifecycle. It offers proper checkpoints to AI developers, project managers, policymakers and organisations to design, direct the development, assess the deployment, regulate the societal integration and advocate changes through constant monitoring of the AI applications. The paper concludes with policy recommendations that focus not just on technical soundness but also on ethical alignment, legal compliance, participatory co-creation, and the good of the community. The WAG model emphasises local agency, adaptive governance and sustainability while governing AI, particularly for less industrialised nations.}
}
@article{MOUSAVIAN2025200572,
title = {Review of artificial intelligence-based applications for money laundering detection},
journal = {Intelligent Systems with Applications},
volume = {27},
pages = {200572},
year = {2025},
issn = {2667-3053},
doi = {https://doi.org/10.1016/j.iswa.2025.200572},
url = {https://www.sciencedirect.com/science/article/pii/S2667305325000985},
author = {Seyedmohammad Mousavian and Shah J Miah},
keywords = {Artificial intelligence, Money laundering, Topic modeling, Detection solutions},
abstract = {Since studies of pattern recognition for detecting money laundering have overflowed with various outcomes, effective applications of artificial intelligence (AI) for delivering précised outcomes are still emerging. In this paper, we evaluate AI-based approaches for their performance measure (e.g., accuracy), data requirement, processing speed, and cost-effectiveness in detecting money laundering activities, find related gaps, and suggest possible courses of action. Adopting a smart literature review analysis, including PRISMA and a topic modeling technique, this study examines published peer-reviewed and conference articles from 2015 to June 2023. The study identifies dominant topics in the period, concluding that AI-based solutions have increasingly been deployed in detecting money laundering, though they face various challenges in application. It also emphasizes that AI solutions are required to be evaluated to measure their performance before applying to large-scale problem-solving.}
}
@article{GANGWAL2025104360,
title = {Artificial intelligence in preclinical research: enhancing digital twins and organ-on-chip to reduce animal testing},
journal = {Drug Discovery Today},
volume = {30},
number = {5},
pages = {104360},
year = {2025},
issn = {1359-6446},
doi = {https://doi.org/10.1016/j.drudis.2025.104360},
url = {https://www.sciencedirect.com/science/article/pii/S135964462500073X},
author = {Amit Gangwal and Antonio Lavecchia},
keywords = {animal studies, artificial intelligence, 3Rs principle, machine learning, deep learning, organ-on-chip, digital twins, generative adversarial networks},
abstract = {Artificial intelligence (AI) is reshaping preclinical drug research offering innovative alternatives to traditional animal testing. Advanced techniques, including machine learning (ML), deep learning (DL), AI-powered digital twins (DTs), and AI-enhanced organ-on-a-chip (OoC) platforms, enable precise simulations of complex biological systems. AI plays a critical role in overcoming the limitations of DTs and OoC, improving their predictive power and scalability. These technologies facilitate early-stage, reliable evaluations of drug safety and efficacy, addressing ethical concerns, reducing costs, and accelerating drug development while adhering to the 3Rs principle (Replace, Reduce, Refine). By integrating AI with these advanced models, preclinical research can achieve greater accuracy and efficiency in drug discovery. This review examines the transformative impact of AI in preclinical research, highlighting its advancements, challenges, and the critical steps needed to establish AI as a cornerstone of ethical and efficient drug discovery.}
}
@article{SHAH2025137,
title = {Retina Meets Artificial Intelligence: ChatGPT Is Changing Retinal Care},
journal = {Advances in Ophthalmology and Optometry},
volume = {10},
number = {1},
pages = {137-146},
year = {2025},
note = {Advances in Ophthalmology and Optometry, Volume 10},
issn = {2452-1760},
doi = {https://doi.org/10.1016/j.yaoo.2025.02.004},
url = {https://www.sciencedirect.com/science/article/pii/S2452176025000046},
author = {Paras P. Shah and Margarita Labkovich and Daniel Zhu and Samantha Goldburg and Ronni M. Lieberman},
keywords = {Retina, Artificial intelligence, AI, ChatGPT, Education}
}
@article{BESSA2025100007,
title = {Integrating artificial intelligence into scenario analysis: a validated framework for strategic planning under economic uncertainty},
journal = {Global Economics Research},
volume = {1},
number = {2},
pages = {100007},
year = {2025},
issn = {3050-8037},
doi = {https://doi.org/10.1016/j.ecores.2025.100007},
url = {https://www.sciencedirect.com/science/article/pii/S305080372500007X},
author = {Gabriela Bessa and Belem Barbosa},
keywords = {Scenario Analysis, Artificial Intelligence, Business Strategy, Economic Uncertainty, Risk Management, Decision-Making, Forecasting, AI-SA Framework},
abstract = {Businesses require adaptable and data-driven decision-making to address economic uncertainty. Scenario Analysis (SA) is a key strategic tool for assessing potential futures, mitigating risks, and strengthening resilience. This study examines how Artificial Intelligence (AI) can support SA, making it more accessible while improving decision speed and accuracy. Using a three-round Delphi method with eighteen experts (scholars and practitioners), a structured framework for integrating AI into SA was developed and validated. The findings show that AI can enhance Scenario Analysis by increasing efficiency, expanding scenario generation, and improving data-driven insights while preserving the essential role of human judgment in contextual interpretation and final decision-making. Rather than replacing managerial expertise, AI serves as a powerful decision-support tool. The resulting AI-SA framework gives managers a structured approach for leveraging AI within SA, promoting more adaptive, forward-looking strategic planning in uncertain economic environments. Overall, this study bridges AI and SA research by offering a structured framework for AI-enhanced SA development.}
}
@article{RAUCHFLEISCH2025103072,
title = {Explaining public preferences for regulating Artificial Intelligence in election campaigns: Evidence from the U.S. and Taiwan},
journal = {Telecommunications Policy},
pages = {103072},
year = {2025},
issn = {0308-5961},
doi = {https://doi.org/10.1016/j.telpol.2025.103072},
url = {https://www.sciencedirect.com/science/article/pii/S0308596125001697},
author = {Adrian Rauchfleisch and Andreas Jungherr and Alexander Wuttke},
keywords = {Political campaigns, Regulation, Artificial Intelligence, Public opinion, United States, Taiwan},
abstract = {The increasing use of Artificial Intelligence (AI) in election campaigns, such as AI-generated political ads, automated messaging, and the widespread availability of AI-assisted photorealistic content, is transforming political communication. This new era of AI-enabled election campaigns presents regulatory challenges for digital media ecosystems, prompting calls for an updated governance framework. While research has begun mapping AI's role in digital media ecosystems, an often-overlooked factor is public attitudes toward regulating AI in election campaigns. Understanding these attitudes is essential as regulatory debates unfold at national and international levels, where public opinion often constrains the leeway of political decision-makers. We analyze data from two cross-sectional surveys conducted in the United States and Taiwan—two democracies with relatively lenient campaign regulations, which held presidential elections in the same year. We examine the role of general attitudes toward AI, psychological dispositions, and partisan alignments in shaping public support for AI regulation during elections. Our findings underscore the significance of psychological and attitudinal perspectives in predicting regulatory preferences. These insights contribute to broader discussions on AI governance within digital media ecosystems and its implications for democratic processes.}
}
@article{VARSHNEY2025100001,
title = {The synergy of artificial intelligence in biomaterials, regenerative medicine and drug delivery},
journal = {Next Bioengineering},
volume = {1},
pages = {100001},
year = {2025},
issn = {3050-7235},
doi = {https://doi.org/10.1016/j.nxbio.2025.100001},
url = {https://www.sciencedirect.com/science/article/pii/S305072352500001X},
author = {Mayora Varshney and Anita Gehlot and Aditya Sharma},
keywords = {Biomaterials, Artificial intelligence, Machine learning},
abstract = {Modern biomaterials benefit regenerative medicine, improve drug delivery, and leave their mark on diagnostic and treatment methods. At the same time, artificial intelligence (AI) and machine learning (ML) algorithms have greatly helped in developing new materials for biomedical research. AI obeys the capabilities of analyzing large data sets, reviewing various biomaterials, planning complex experiments, and predicting materials that fulfill strict specifications for a desired application. There is recent progress in regenerative medicine and drug delivery by applying AI to predict, optimize, and strategically analyze different biomaterials. This brief review emphasizes the progress of AI in analyzing and designing smart biomaterials for better healthcare outcomes. This review covers recent innovations in regenerative medicine and drug delivery by optimizing novel biomaterials through AI tools. The benefits, challenges, and prospects of AI's integration into biomaterials are exemplary discussed.}
}
@article{MUMI2025100688,
title = {The nexus of artificial intelligence and entrepreneurship research: Bibliometric analysis},
journal = {Sustainable Futures},
volume = {9},
pages = {100688},
year = {2025},
issn = {2666-1888},
doi = {https://doi.org/10.1016/j.sftr.2025.100688},
url = {https://www.sciencedirect.com/science/article/pii/S2666188825002552},
author = {Atthaphon Mumi and Niramarn Ngammoh and Asadang Suwanpakdee},
keywords = {Artificial intelligence, AI, Entrepreneurship, Bibliometric analysis, Bibliographic coupling, Venture creation, Innovation processes, AI ecosystem},
abstract = {Artificial intelligence (AI) has garnered significant attention in both academic and practical domains due to its transformative potential across various business practices. However, despite the increasing interest in AI, research specifically examining its role in entrepreneurship remains limited. This study aims to address this gap by conducting a comprehensive bibliometric analysis of AI and entrepreneurship research. Using the bibliographic coupling method, we analyzed 45 studies from the Scopus database to identify eight key thematic areas that define the current landscape: venture creation, institutional entrepreneurship, entrepreneurial capabilities, opportunity identification, innovation processes, data-driven digital entrepreneurship, entrepreneurship education, and the AI ecosystem. Our findings demonstrate that AI is becoming increasingly integral to entrepreneurial activities, fostering innovation, enhancing decision-making, and supporting business model development. Additionally, this study offers valuable recommendations for future research, highlighting unexplored areas in entrepreneurship where AI can have a significant impact, thereby broadening the scope of AI applications within the entrepreneurial field.}
}
@article{MERINO2025,
title = {Complex diseases meet deep phenotyping and generative AI},
journal = {Trends in Genetics},
year = {2025},
issn = {0168-9525},
doi = {https://doi.org/10.1016/j.tig.2025.08.005},
url = {https://www.sciencedirect.com/science/article/pii/S0168952525002173},
author = {Jordi Merino},
keywords = {precision health, deep phenotyping, complex diseases, heterogeneity},
abstract = {Complex diseases are heterogeneous and evolve along a continuum, limiting individual-level prediction with current approaches. The Human Phenotype Project (HPP) integrates deep phenotyping with generative artificial intelligence (AI) to identify early deviations in health parameters. While the project has already provided significant insights, the challenge is converting these findings into actionable, equitable, and scalable interventions, advancing precision healthcare across diverse populations.}
}
@article{NORRIS2025103170,
title = {Artificial intelligence aided ultrasound imaging of foetal congenital heart disease: A scoping review},
journal = {Radiography},
volume = {31},
number = {6},
pages = {103170},
year = {2025},
issn = {1078-8174},
doi = {https://doi.org/10.1016/j.radi.2025.103170},
url = {https://www.sciencedirect.com/science/article/pii/S1078817425003141},
author = {L. Norris and P. Lockwood},
abstract = {Objectives
Congenital heart diseases (CHD) are a significant cause of neonatal mortality and morbidity. Detecting these abnormalities during pregnancy increases survival rates, enhances prognosis, and improves pregnancy management and quality of life for the affected families. Foetal echocardiography can be considered an accurate method for detecting CHDs. However, the detection of CHDs can be limited by factors such as the sonographer's skill, expertise and patient specific variables. Using artificial intelligence (AI) has the potential to address these challenges, increasing antenatal CHD detection during prenatal care. A scoping review was conducted using Google Scholar, PubMed, and ScienceDirect databases, employing keywords, Boolean operators, and inclusion and exclusion criteria to identify peer-reviewed studies. Thematic mapping and synthesis of the found literature were conducted to review key concepts, research methods and findings.
Key findings
A total of n = 233 articles were identified, after exclusion criteria, the focus was narrowed to n = 7 that met the inclusion criteria. Themes in the literature identified the potential of AI to assist clinicians and trainees, alongside emerging new ethical limitations in ultrasound imaging.
Conclusion
AI-based tools in ultrasound imaging offer great potential in assisting sonographers and doctors with decision-making in CHD diagnosis. However, due to the paucity of data and small sample sizes, further research and technological advancements are needed to improve reliability and integrate AI into routine clinical practice.
Implications for practice
This scoping review identified the reported accuracy and limitations of AI-based tools within foetal cardiac ultrasound imaging. AI has the potential to aid in reducing missed diagnoses, enhance training, and improve pregnancy management. There is a need to understand and address the ethical and legal considerations involved with this new paradigm in imaging.}
}
@article{WUNI2025111192,
title = {Critical success factors for implementing artificial intelligence in construction projects: A systematic review and social network analysis},
journal = {Engineering Applications of Artificial Intelligence},
volume = {156},
pages = {111192},
year = {2025},
issn = {0952-1976},
doi = {https://doi.org/10.1016/j.engappai.2025.111192},
url = {https://www.sciencedirect.com/science/article/pii/S0952197625011935},
author = {Ibrahim Yahaya Wuni},
keywords = {Artificial intelligence, Critical success factors, Construction industry, Construction projects, Social network analysis},
abstract = {Artificial intelligence (AI) is increasingly deployed to automate routine tasks, generate accurate insights from big data, and build predictive models to inform better decision-making in construction projects. However, AI deployment in construction projects constitutes a sociotechnical process, such that adopting solely a technical approach becomes inadequate. This study investigated the critical success factors for implementing AI in construction projects. It combined a systematic literature review, meta-analysis, and social network analysis to evaluate the scientific evidence on the critical success factors, and quantitatively reveal the underrepresented factors. The meta-analysis identified 38 critical success factors, ranked according to normalized scores and degree centralities. The study derived four dimensions of the critical success factors, including organizational, technological, stakeholder, and data success factors. The social network analysis quantitatively revealed the strengths and existing gaps in the reviewed studies and provide insights into factors that need further investigation.}
}
@article{DESAGE20243,
title = {A Revised Framework for Evaluating the Quality of Mental Health Artificial Intelligence-Based Chatbots},
journal = {Procedia Computer Science},
volume = {248},
pages = {3-7},
year = {2024},
note = {International Society for Research on Internet Interventions 12th Scientific Meeting (ISRII 12)},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2024.10.356},
url = {https://www.sciencedirect.com/science/article/pii/S1877050924031880},
author = {Christina Desage and Bautista Bunge and Eduardo L. Bunge},
keywords = {Artificial Intelligence, chatbot, conversational agent, mental health, evaluation},
abstract = {With the emergence of generative artificial intelligence (Gen AI) and conversational agents (CAs), a rigorous assessment process of the quality of the conversations delivered by the agents is needed. In previous work, we proposed a framework (i.e., the Thera-Turing Test - TTT) for measuring the quality of conversations between users and CAs by independent (potentially blind) therapists, comparing the performance of CAs to human therapists. In this paper, we revised and expanded upon the TTT; by including a new stage of assessment (i.e. testing simulated conversations) and providing further guidance on the phases of the TTT. First, the CA is tested in a safe environment with simulated clients (with Gen AI), instead of human clients; second, the TTT is conducted with a selected sample of actual users; and third, the TTT is conducted with a large sample of users. Adopting this innovative assessment method will guide the future development of mental health CAs, ensuring AI-led interventions meet the rigorous standards expected of human therapists.}
}
@article{WOILLARD2025,
title = {Digital pharmacological twins: Bridging multi-scale modelling and artificial intelligence for precision medicine: The DIGPHAT consortium},
journal = {Therapies},
year = {2025},
issn = {0040-5957},
doi = {https://doi.org/10.1016/j.therap.2025.09.006},
url = {https://www.sciencedirect.com/science/article/pii/S004059572500112X},
author = {Jean-Baptiste Woillard and Sébastien Benzekry and Julie Josse and Mélanie White-Koning and Etienne Chatelut and Emmanuelle Comets and Florian Lemaitre and Bénédicte Franck and Matthieu Gregoire and Françoise Stanke-Labesque and Sarah Zohar and Moreno Ursino and Christophe Battail},
keywords = {Digital Twins, Pharmacometrics, Artificial intelligence, Multiscale modeling, Machine learning},
abstract = {Summary
The advent of digital twins in pharmacology presents transformative potential for precision medicine, enabling personalized treatment optimization through dynamic computational simulations of drug interactions at molecular, cellular, and patient levels. These advanced virtual replicas of a patient's biological system are designed to predict individual therapeutic responses with high fidelity, thereby moving beyond the one-size-fits-all paradigm. This paper explores the concept of digital pharmacological twins, detailing how they can integrate heterogeneous data, including multi-omic, pharmacokinetic, pharmacodynamic, clinical, and environmental information, and employing a synergy of advanced mechanistic and machine learning models. Using illustrative examples from ongoing international initiatives, this work highlights the methodological frameworks necessary for developing and validating such comprehensive predictive tools. We underscore the critical importance of model interoperability, robust data integration strategies, and rigorous validation to ensure clinical utility. Ultimately, digital pharmacological twins promise to enhance therapeutic efficacy, minimize adverse drug reactions, and accelerate the translation of pharmacological science into tangible patient benefits.}
}
@article{RASHIDI2025100673,
title = {Introducing an Essential 7-Part Artificial Intelligence Review Series: A Guided Journey Into the Future of Pathology and Medicine},
journal = {Modern Pathology},
volume = {38},
number = {3},
pages = {100673},
year = {2025},
issn = {0893-3952},
doi = {https://doi.org/10.1016/j.modpat.2024.100673},
url = {https://www.sciencedirect.com/science/article/pii/S0893395224002539},
author = {Hooman H. Rashidi and Matthew G. Hanna and Liron Pantanowitz},
keywords = {AI, artificial Intelligence, ChatGPT, generative AI, machine learning, medicine & pathology}
}
@article{LEUNG2025105655,
title = {Artificial Intelligence in Computed Tomography Coronary Angiography},
journal = {JACC: Case Reports},
volume = {30},
number = {32},
pages = {105655},
year = {2025},
issn = {2666-0849},
doi = {https://doi.org/10.1016/j.jaccas.2025.105655},
url = {https://www.sciencedirect.com/science/article/pii/S2666084925024386},
author = {Calvin Leung},
keywords = {artificial intelligence, atherosclerosis, calcium blooming, computed tomography coronary angiography, coronary artery disease, deep learning, image reconstruction, machine learning}
}
@article{QUTISHAT2025e1315,
title = {Benefits, challenges, and future recommendations in the integration of artificial intelligence in nursing education: A scoping review},
journal = {Teaching and Learning in Nursing},
volume = {20},
number = {4},
pages = {e1315-e1323},
year = {2025},
issn = {1557-3087},
doi = {https://doi.org/10.1016/j.teln.2025.05.016},
url = {https://www.sciencedirect.com/science/article/pii/S1557308725001623},
author = {Mohammed Qutishat and Majdi Al-Hadidi and Lina Shakman and Aisha Al- Shdefat and Al-Azhar Al- Ghunaimi and Suhaib Sinan Al-Barwani},
keywords = {Artificial intelligence, Challenges and benefits, Nursing education},
abstract = {Objectives
This review aims to critically examine the benefits and challenges of integrating artificial intelligence (AI) in nursing education.
Design
A scoping review was conducted using the Arksey & O'Malley framework.
Data sources
A systematic search was performed across 8 databases, including PubMed and CINAHL, identifying peer-reviewed studies published between 2015 and 2024.
Review methods
After screening, 30 articles were included, employing various research designs such as cross-sectional (76.7%) and qualitative (13.3%).
Results
Findings indicate that AI enhances personalized learning, simulation training, and administrative efficiency. However, challenges include insufficient curricula, limited faculty expertise, resource inequities, and high implementation costs. Quality ratings of studies ranged from 15 to 20 out of 20, reflecting high methodological rigor.
Conclusions
Strategic investments in curriculum development, faculty training, and interdisciplinary collaboration are essential to overcome barriers and fully realize AI's potential in nursing education. Prioritizing ethical considerations will prepare future nurses for complex clinical environments in a technology-driven healthcare landscape.}
}
@article{GRAUMANN20251865,
title = {Artificial Intelligence in Abdominal, Gynecological, Obstetric, Musculoskeletal, Vascular and Interventional Ultrasound},
journal = {Ultrasound in Medicine & Biology},
volume = {51},
number = {11},
pages = {1865-1877},
year = {2025},
issn = {0301-5629},
doi = {https://doi.org/10.1016/j.ultrasmedbio.2025.07.008},
url = {https://www.sciencedirect.com/science/article/pii/S0301562925002376},
author = {Ole Graumann and Wu {Cui Xin} and Adrian Goudie and Michael Blaivas and Barbara Braden and Susan {Campbell Westerway} and Maria Cristina Chammas and Yi Dong and Odd Helge Gilja and Peter Ching-Chang Hsieh and An {Jiang Tian} and Ping Liang and Kathleen Möller and Christian Pállson Nolsøe and Adrian Săftoiu and Christoph Frank Dietrich},
keywords = {Artificial intelligence, AI, Medical ultrasound, Abdominal ultrasound, Obstetric & gynecological ultrasound, Vascular- and interventional ultrasound, Musculoskeletal ultrasound},
abstract = {Artificial Intelligence (AI) is a theoretical framework and systematic development of computational models designed to execute tasks that traditionally require human cognition. In medical imaging, AI is used for various modalities, such as computed tomography (CT), magnetic resonance imaging (MRI), ultrasound, and pathologies across multiple organ systems. However, integrating AI into medical ultrasound presents unique challenges compared to modalities like CT and MRI due to its operator-dependent nature and inherent variability in the image acquisition process. AI application to ultrasound holds the potential to mitigate multiple variabilities, recalibrate interpretative consistency, and uncover diagnostic patterns that may be difficult for humans to detect. Progress has led to significant innovation in medical ultrasound-based AI applications, facilitating their adoption in various clinical settings and for multiple diseases. This manuscript primarily aims to provide a concise yet comprehensive exploration of current and emerging AI applications in medical ultrasound within abdominal, musculoskeletal, and obstetric & gynecological and interventional medical ultrasound. The secondary aim is to discuss present limitations and potential challenges such technological implementations may encounter.}
}
@article{GOROSPE2025510,
title = {Why do Artificial-Intelligence Based Chest Radiograph Applications Ignore the Lateral View?},
journal = {Archivos de Bronconeumología},
volume = {61},
number = {8},
pages = {510-511},
year = {2025},
issn = {0300-2896},
doi = {https://doi.org/10.1016/j.arbres.2025.03.016},
url = {https://www.sciencedirect.com/science/article/pii/S0300289625001139},
author = {Luis Gorospe}
}
@article{ALSHEHRI202544,
title = {Integrating artificial intelligence with small molecule therapeutics and precision medicine for neurochemical understanding of Alzheimer’s diseases},
journal = {Neuroscience},
volume = {586},
pages = {44-57},
year = {2025},
issn = {0306-4522},
doi = {https://doi.org/10.1016/j.neuroscience.2025.08.055},
url = {https://www.sciencedirect.com/science/article/pii/S0306452225009030},
author = {Zafer Saad Alshehri},
keywords = {Alzheimer’s disease, Artificial intelligence, Small molecule therapeutics, Targeted therapy, Neurodegeneration},
abstract = {Alzheimer’s disease (AD) is the most common neurodegenerative condition and continues to pose significant clinical and research challenges due to its complex causes and limited treatment success. Conventional therapies have primarily focused on amyloid-beta (Aβ) and tau proteins, but these efforts have yet to produce optimal results. This review explores emerging interdisciplinary strategies that integrate artificial intelligence (AI), small molecule drugs, and precision treatments to tackle AD’s intricacies. AI has significantly enhanced early detection, neuroimaging, and biomarker discovery using machine learning and deep learning. These state-of-art methods helps to analyze biomarker profiles and imaging data, thereby enabling tailored diagnostic and therapeutic strategies for individual patients. At the same time, computational methods have expedited the development of small molecules targeting Aβ buildup, tau pathology, and inflammation. Emerging treatments, including monoclonal antibodies, RNA-based therapies, and nanotechnology, provide promising alternatives to conventional approaches. The integration of AI with multi-omics and structure-guided drug design supports the creation of precise, individualized treatments. However, challenges in ethics, regulation, and clinical application persist. This review emphasizes the collaborative potential of AI, pharmacology, and biomedical engineering in revolutionizing AD treatment, highlighting the need for cross-disciplinary efforts to confront this urgent neurological condition.}
}
@article{LIN202510577,
title = {Cyclic Peptide Therapeutic Agents Discovery: Computational and Artificial Intelligence-Driven Strategies},
journal = {Journal of Medicinal Chemistry},
volume = {68},
number = {11},
pages = {10577-10598},
year = {2025},
issn = {1520-4804},
doi = {https://doi.org/10.1021/acs.jmedchem.5c00712},
url = {https://www.sciencedirect.com/science/article/pii/S1520480425006167},
author = {Kang Lin and Chengyun Zhang and Renren Bai and Hongliang Duan},
abstract = {Cyclic peptides have emerged as promising modulators of protein–protein interactions due to their unique pharmacological properties and ability to target extensive flat binding interfaces. However, traditional strategies for developing cyclic peptides are often hindered by significant resource constraints. Recent advancements in computational techniques and artificial intelligence-driven methodologies have significantly enhanced the cyclic peptide drug discovery pipeline, while breakthroughs in automated synthesis platforms have accelerated experimental validation, presenting transformative potential for pharmaceutical innovation. In this review, we examine state-of-the-art computational and artificial intelligence-driven strategies that address challenges such as peptide flexibility, limited data availability, and complex conformational landscapes. We discuss how the integration of physics-based simulations with deep learning techniques is redefining the design and optimization of cyclic peptide therapeutics and propose future perspectives to advance the precision and efficiency of cyclic peptide drug development, ultimately offering innovative solutions to unmet medical needs.
}
}
@article{SINGH2025129,
title = {Artificial intelligence in surgery: what is needed for ongoing innovation},
journal = {Surgery (Oxford)},
volume = {43},
number = {3},
pages = {129-134},
year = {2025},
note = {Innovations in Surgery - I},
issn = {0263-9319},
doi = {https://doi.org/10.1016/j.mpsur.2024.12.005},
url = {https://www.sciencedirect.com/science/article/pii/S0263931924002242},
author = {Vivek Singh and Shubha Vasisht and Daniel A Hashimoto},
keywords = {AI literacy, artificial intelligence, machine learning, surgery, surgical innovation, surgical robotics},
abstract = {Artificial intelligence (AI) is rapidly transforming various fields, including surgery. AI's ability to process large datasets and deliver real-time insights has the potential to enhance diagnostic accuracy, risk prediction, and intraoperative decision-making. However, challenges such as algorithmic bias, data privacy, and the need for surgeon AI literacy hinder broader implementation. While AI holds significant potential to revolutionize surgical practice, its safe and effective integration requires improved AI literacy among surgeons and more effective regulatory frameworks. Addressing these challenges will be critical to ensuring that AI enhances, rather than disrupts, patient care. This paper reviews the integration of AI into surgery, examining its current applications, challenges, and future directions.}
}
@article{CHADHA2025152349,
title = {Advancements and implications of artificial intelligence for early detection, diagnosis and tailored treatment of cancer},
journal = {Seminars in Oncology},
volume = {52},
number = {3},
pages = {152349},
year = {2025},
issn = {0093-7754},
doi = {https://doi.org/10.1016/j.seminoncol.2025.152349},
url = {https://www.sciencedirect.com/science/article/pii/S0093775425000417},
author = {Sonia Chadha and Sayali Mukherjee and Somali Sanyal},
keywords = {Artificial intelligence, Cancer, Precision medicine, Diagnosis},
abstract = {ABSTRACT
The complexity and heterogeneity of cancer makes early detection and effective treatment crucial to enhance patient survival and quality of life. The intrinsic creative ability of artificial intelligence (AI) offers improvements in patient screening, diagnosis, and individualized care. Advanced technologies, like computer vision, machine learning, deep learning, and natural language processing, can analyze large datasets and identify patterns that permit early cancer detection, diagnosis, management and incorporation of conclusive treatment plans, ensuring improved quality of life for patients by personalizing care and minimizing unnecessary interventions. Genomics, transcriptomics and proteomics data can be combined with AI algorithms to unveil an extensive overview of cancer biology, assisting in its detailed understanding and will help in identifying new drug targets and developing effective therapies. This can also help to identify personalized molecular signatures which can facilitate tailored interventions addressing the unique aspects of each patient. AI-driven transcriptomics, proteomics, and genomes represents a revolutionary strategy to improve patient outcome by offering precise diagnosis and tailored therapy. The inclusion of AI in oncology may boost efficiency, reduce errors, and save costs, but it cannot take the role of medical professionals. While clinicians and doctors have the final say in all matters, it might serve as their faithful assistant}
}
@article{GRICOURT20242276,
title = {Artificial Intelligence Methods and Models for Retro-Biosynthesis: A Scoping Review},
journal = {ACS Synthetic Biology},
volume = {13},
number = {8},
pages = {2276-2294},
year = {2024},
issn = {2161-5063},
doi = {https://doi.org/10.1021/acssynbio.4c00091},
url = {https://www.sciencedirect.com/science/article/pii/S216150632400041X},
author = {Guillaume Gricourt and Philippe Meyer and Thomas Duigou and Jean-Loup Faulon},
keywords = {retrosynthesis, retro-biosynthesis, artificial intelligence},
abstract = {Retrosynthesis aims to efficiently plan the synthesis of desirable chemicals by strategically breaking down molecules into readily available building block compounds. Having a long history in chemistry, retro-biosynthesis has also been used in the fields of biocatalysis and synthetic biology. Artificial intelligence (AI) is driving us toward new frontiers in synthesis planning and the exploration of chemical spaces, arriving at an opportune moment for promoting bioproduction that would better align with green chemistry, enhancing environmental practices. In this review, we summarize the recent advancements in the application of AI methods and models for retrosynthetic and retro-biosynthetic pathway design. These techniques can be based either on reaction templates or generative models and require scoring functions and planning strategies to navigate through the retrosynthetic graph of possibilities. We finally discuss limitations and promising research directions in this field.
}
}
@article{DCOSTA2025101758,
title = {Artificial-intelligence-assisted CCTA quantifies sex differences in coronary atherosclerotic burden at low atheroma volumes},
journal = {IJC Heart & Vasculature},
volume = {60},
pages = {101758},
year = {2025},
issn = {2352-9067},
doi = {https://doi.org/10.1016/j.ijcha.2025.101758},
url = {https://www.sciencedirect.com/science/article/pii/S2352906725001617},
author = {Zoee D’Costa and Ronald P. Karlsberg and Geoffrey W. Cho},
keywords = {Artificial intelligence, Coronary computed tomography angiography, Coronary atheroma volume, Sex differences, Non-calcified plaque, Plaque composition, Cardiovascular risk stratification},
abstract = {Background
Coronary artery disease (CAD) manifests differently between sexes, with data suggesting females develop more non-calcified plaques that traditional calcium-centric tools may not detect.
Methods
We conducted a retrospective cohort study of 100 individuals with low total atheroma volume (TAV) < 250 mm3 using artificial intelligence (AI)-enabled coronary computed tomography angiography (CCTA) to assess sex-based differences in coronary plaque composition. Plaque subtypes included calcified, non-calcified, and low-density non-calcified atheroma volumes.
Results
Females had significantly lower total (p = 0.018) and non-calcified plaque (p < 0.001) burden compared to males. Calcified (p = 0.52) and low-density non-calcified (p = 0.16) plaque volumes did not differ significantly. Age was a consistent predictor of plaque volume across most subtypes.
Conclusions
Despite low overall plaque burden, males demonstrated a higher non-calcified plaque burden than females. This finding contrasts with previous literature and underscores the potential of AI-enabled CCTA to detect subclinical coronary disease, particularly in low-risk cohorts. These results support the use of comprehensive plaque profiling in both sexes to improve early risk stratification.}
}
@article{SERGI2025101545,
title = {Artificial Intelligence and the future of clinical trials},
journal = {Contemporary Clinical Trials Communications},
volume = {47},
pages = {101545},
year = {2025},
issn = {2451-8654},
doi = {https://doi.org/10.1016/j.conctc.2025.101545},
url = {https://www.sciencedirect.com/science/article/pii/S245186542500119X},
author = {Consolato M. Sergi and Howard D. Sesso}
}
@article{GURSOY2025104212,
title = {Artificial intelligence (AI) technology, its applications and the use of AI powered devices in hospitality service experience creation and delivery},
journal = {International Journal of Hospitality Management},
volume = {129},
pages = {104212},
year = {2025},
issn = {0278-4319},
doi = {https://doi.org/10.1016/j.ijhm.2025.104212},
url = {https://www.sciencedirect.com/science/article/pii/S0278431925001355},
author = {Dogan Gursoy},
keywords = {Artificial intelligence, Hospitality, Experience, Service creation, Service delivery},
abstract = {The rapid advancement of artificial intelligence (AI) is transforming the hospitality industry, enhancing service delivery, customer experiences, and operational efficiency. AI-powered innovations such as generative AI, service robots, autonomous systems, and smart assistants are streamlining operations, personalizing guest interactions, and optimizing resource management. While AI’s benefits for businesses and customers are well-documented, its broader impacts on employees, customer behavior, and ethical considerations remain underexplored. This special issue of the International Journal of Hospitality Management addresses these gaps by presenting cutting-edge research on AI applications in hospitality. The featured studies explore AI-driven customer engagement, workforce adaptation, service recovery, and sustainability. By highlighting emerging trends and evidence-based insights, this issue informs industry leaders, policymakers, and academics about AI’s opportunities and challenges, emphasizing the need for a balanced approach between technological innovation and human-centric service excellence}
}
@article{LOPARCO2025,
title = {Snapchat Artificial Intelligence as an Information Source on Delta-8 THC},
journal = {Journal of Adolescent Health},
year = {2025},
issn = {1054-139X},
doi = {https://doi.org/10.1016/j.jadohealth.2025.06.036},
url = {https://www.sciencedirect.com/science/article/pii/S1054139X25002873},
author = {Cassidy R. LoParco and Kayla K. Tillett and Ayyüce Begüm Bektaş and Matthew E. Rossheim and Carla J. Berg},
keywords = {Social media, AI, Cannabis, Delta-8, Youth},
abstract = {Purpose
Snapchat is a prominent social media site among youth. In April 2023, Snapchat released an artificial intelligence (AI)-powered chatbot that was automatically implemented on all accounts. Given the apparent ease in communicating with this feature, youth may use it as an information source.
Methods
While Snapchat purports to block results for drug keywords, it is unclear the extent to which this type of content is blocked. In August 2024–January 2025, we asked Snapchat AI questions related to delta-8, a derived intoxicating cannabis product that has been rapidly rising in popularity in the United States and has limited regulations. Qualitative responses were independently coded into thematic categories.
Results
The AI prompted individuals to ask follow-up questions, which largely drove the themes. Themes included general information (similarity to delta-9 THC, but with a purported lower potency; relaxing/euphoric effects; legality), use motives (pain relief, anti-nausea, appetite stimulation, anxiety reduction), potential consequences (dry mouth, red eyes, increased heart rate, drowsiness, contaminated products, inaccurate labeling), retail availability, and product recommendations. Responses did not provide supporting citations. While the AI did not block results related to delta-8, it did block results pertaining to “weed” and “THC.”
Discussion
Snapchat AI is a plausible information source about delta-8 THC among youth. No citations were provided to support claims made by the AI, which portrayed delta-8 THC use favorably, as having benefits and low risks from use. Findings have policy implications, including restricting or regulating this type of content—particularly relating to claims without supporting scientific evidence.}
}
@article{BOULHRIR2025100442,
title = {Unpacking artificial intelligence in elementary education: A comprehensive thematic analysis systematic review},
journal = {Computers and Education: Artificial Intelligence},
volume = {9},
pages = {100442},
year = {2025},
issn = {2666-920X},
doi = {https://doi.org/10.1016/j.caeai.2025.100442},
url = {https://www.sciencedirect.com/science/article/pii/S2666920X25000827},
author = {Taoufik Boulhrir and Mahmoud Hamash},
keywords = {Artificial intelligence, Elementary education, Ed-Tech, Educational AI, AI ethics, Future of education},
abstract = {Artificial Intelligence (AI) has gained much research interest recently and is rapidly transforming education around the world. However, there is still limited research with regards to its applications and effects on learning, in comparison to the available studies conducted at higher levels of education. This paper presents a systematic literature review conducted following the Preferred Reporting Items for Systematic Reviews and Meta-Analyses (PRISMA) guidelines. It explores the geographical distribution and frequency of research on AI in elementary education between 2013 and 2023. It provides an analysis of the various educational areas in which AI has been applied, and it synthesizes reported benefits and challenges, culminating in recommendations for future research. This analysis shows a growing interest in exploring perspectives around using AI in teaching and learning, spotlighting, in the meantime, significant research gaps, including the long-term effects on child development, privacy issues, and role of the teacher in the classroom. Hence, AI's potential to enhance educational experiences is evident, though more research is needed to address ethical concerns and ensure responsible implementation. Recommendations include further investigation into AI's impact on student learning outcomes and teacher roles and the development of comprehensive ethical frameworks for AI use in schools.}
}
@article{ARAGONA2026103722,
title = {Definitions of artificial intelligence and quantum technologies: A comparative thematic analysis of the strategic documents of 29 European countries},
journal = {Futures},
volume = {175},
pages = {103722},
year = {2026},
issn = {0016-3287},
doi = {https://doi.org/10.1016/j.futures.2025.103722},
url = {https://www.sciencedirect.com/science/article/pii/S0016328725001843},
author = {Biagio Aragona and Suania Acampa},
keywords = {Sociotechnical imaginaries, Emerging technologies, Technological governance, Technological narrative, Artificial intelligence, Quantum technologies, Thematic analysis},
abstract = {This article provides new insights into the intertwining between technological definitions, sociotechnical futures, and governance trajectories in an increasingly complex geopolitical context. It analyses the definitions of artificial intelligence (AI) and quantum technologies (QTs) that have been adopted by 27 EU member states and two associated countries (Norway and the United Kingdom), and which are contained in their national strategy documents. Drawing on the theoretical framework of sociotechnical imaginaries and employing qualitative thematic analysis, the article shows how these definitions co-constitute narratives that intertwine visions of technological development with governance choices. The lexicon used in definitions is not neutral, and reflects distinct epistemological assumptions and political priorities, thus demonstrating how definitional language acts as a performative tool that legitimizes strategic decisions and aligns collective expectations. AI and QTs are emerging technologies (ETs), characterized by rapid growth, high uncertainty, and potential for significant socio-economic impact, and they are the only two ETs for which most European countries have produced national strategic documents in response to specific requests and coordination efforts by the European Commission. A comparative thematic analysis reveals the relevance of these definitions for national and supranational governance, and indicates that the strategic documents are explicitly oriented toward imagining and shaping specific technological futures that justify increasing public investment in both domains.}
}
@article{MI2026100844,
title = {Distributed edge artificial intelligence empowered data trading: Theories, algorithms, and applications},
journal = {Computer Science Review},
volume = {59},
pages = {100844},
year = {2026},
issn = {1574-0137},
doi = {https://doi.org/10.1016/j.cosrev.2025.100844},
url = {https://www.sciencedirect.com/science/article/pii/S1574013725001200},
author = {Bing Mi and Kongyang Chen},
keywords = {Data trading, Edge artificial intelligence, Data pricing, Privacy computing, Data quality assessment, Incentive mechanism, Decentralized data transactions},
abstract = {As data emerges as a crucial production factor in the digital economy, data trading has become a key innovation across industrial applications. However, traditional data trading models face significant challenges, including privacy concerns, pricing mechanisms, transaction efficiency, and decentralization. Edge Artificial Intelligence (AI) offers a transformative approach to data trading by enabling local intelligence, privacy-preserving computation, and decentralized architectures. This paper explores the integration of Edge AI with data trading, analyzing its technical foundations, key challenges, and diverse applications. Edge AI enhances data trading by reducing data transmission costs, enabling privacy-preserving federated learning, and facilitating decentralized trust mechanisms through blockchain. Compared to centralized models, Edge AI-based data trading supports secure, efficient, and transparent transactions while mitigating the data misuse. This paradigm benefits various domains, including IoT-enabled smart factories and connected vehicles, financial risk assessment and credit scoring, secure electronic health record sharing, supply chain optimization, and personalized advertising. Despite its advantages, Edge AI-driven data trading still faces challenges in standardization, security, computational efficiency, data quality assessment, and regulatory compliance. Future research should focus on establishing global data trading protocols, optimizing privacy-preserving mechanisms, and improving decentralized transaction models to enhance security and efficiency. Edge AI-enabled data trading will play an increasingly vital role in facilitating trustworthy and efficient data markets across digital industries.}
}
@article{ABDELRAOUF2025113828,
title = {From maxwell’s equations to artificial intelligence: The evolution of physics-guided AI in nanophotonics and electromagnetics},
journal = {Optics & Laser Technology},
volume = {192},
pages = {113828},
year = {2025},
issn = {0030-3992},
doi = {https://doi.org/10.1016/j.optlastec.2025.113828},
url = {https://www.sciencedirect.com/science/article/pii/S0030399225014197},
author = {Omar A.M. Abdelraouf and Abdulrahman M.A. Ahmed and Emadeldeen Eldele and Ahmed A. Omar},
abstract = {The fusion of artificial intelligence (AI) with physics-guided frameworks has opened transformative avenues for advancing the design and optimization of electromagnetic and nanophotonic systems. Innovations in deep neural networks (DNNs) and physics-informed neural networks (PINNs) now provide robust tools to tackle longstanding challenges in light scattering engineering, meta-optics, and nonlinear photonics. This review outlines recent progress in leveraging these computational methodologies to enhance device performance across domains such as dynamic light modulation, antenna design, and nonlinear optical phenomena. We systematically survey advancements in AI-driven forward and inverse design strategies, which bypass conventional trial-and-error approaches by embedding physical laws directly into optimization workflows. Furthermore, the integration of AI accelerates electromagnetic simulations and enables precise modelling of complex optical effects, including topological photonic states and nonlinear interactions. A comparative evaluation of algorithmic frameworks highlights their strengths in balancing computational efficiency, multi-objective optimization, and fabrication feasibility. Challenges such as limited interpretability of AI models and data scarcity for unconventional optical modes are critically addressed. Finally, we emphasize future opportunities in scalable multi-physics modelling, adaptive architectures, and practical deployment of AI-optimized photonic devices. This work underscores the pivotal role of AI in transcending traditional design limitations, thereby propelling the development of next-generation photonic technologies with unprecedented functionality and efficiency.}
}
@article{LYU2025131659,
title = {Artificial intelligence for student performance prediction in blended learning: A systematic literature review},
journal = {Neurocomputing},
volume = {658},
pages = {131659},
year = {2025},
issn = {0925-2312},
doi = {https://doi.org/10.1016/j.neucom.2025.131659},
url = {https://www.sciencedirect.com/science/article/pii/S0925231225023318},
author = {Hui Lyu and Pengfei Shan and Chunli Hou and Sufen Duan},
keywords = {Machine learning, Deep learning, Multimodal fusion, Student performance prediction, Blended learning},
abstract = {Blended learning provides a new student-centered teaching model, which integrates both online and offline educational resources. In this approach, a vast volume of multimodal data is generated, originating from both online and offline learning behaviors. Effectively mining this massive dataset to extract valuable insights for educators and improve teaching quality remains a significant challenge. Student performance prediction based on blended learning data has become a research focus due to its valuable applications. It is achieved using artificial intelligence models and historical data to predict student performance. With the rapid advancement of deep learning technology, a range of high-performance predictive models has been developed, significantly enhancing the accuracy of student performance prediction. This paper presents a comprehensive review of student performance prediction methods under blended learning paradigm. Specifically, it systematically examines the factors influencing student performance, the evolution of prediction models, practical applications, and potential future research directions. The primary contribution of this survey is to present an up-to-date and comprehensive review of student performance prediction under blended learning teaching model offering a new perspective on the integration of artificial intelligence technologies into educational practices.}
}
@article{MARTENS2025,
title = {Recapitulation of Ageism in Artificial Intelligence–Generated Images: Longitudinal Comparative Study},
journal = {Journal of Medical Internet Research},
volume = {27},
year = {2025},
issn = {1438-8871},
doi = {https://doi.org/10.2196/68428},
url = {https://www.sciencedirect.com/science/article/pii/S1438887125010866},
author = {Lindsey Martens and Nicole Virgin and Phillip Hoffarth and Jade Goodwill and Nicole Derenne and Richard Van Eck and Marilyn Klug and Gunjan Dhawan Manocha and Donald Jurivich},
keywords = {artificial intelligence, aging, ageism, digital ageism, geriatrics},
abstract = {Background
Positive images of aging in traditional media promote better health outcomes in older adults, including increased life expectancy. Images produced by generative artifical intelligence (AI) technologies may reflect and amplify societal age-related biases, a phenomenon known as digital ageism. This study addresses a gap in research on the perpetuation of digital ageism in AI-generated images over time.
Objective
This study examined how visual characteristics of digital ageism in AI-generated representations of older adults changed over time. It aims to provide insight into the interplay between technology advancements, societal attitudes toward aging, and the well-being of older adults interacting with digital media.
Methods
This longitudinal study compared 164 images generated by Open AI’s DALL-E 2 at 2 time points, 1 year apart (2022 and 2023). Identical text prompts from the geriatric lexicon (eg, frail older adult, dementia) were used at both time points. Authors evaluated the images generated for demographic characteristics (perceived gender, race, and socioeconomic status), and primary emotion characteristics, then compared the frequency of these characteristics between years and evaluation characteristics using a type III 2-way ANOVA.
Results
Representations of White-racialized older adults were 5-fold higher than those of other races in both years. The mean number of representations of Asian-racialized individuals increased from 20 to 31 (P=.004), and the mean number of other racialized representations also increased, from 6 to 14 (P=.007). Representations of people with a middle-class socioeconomic status were significantly more frequent than other statuses in 2022 and 2023 with no changes in socioeconomic status from one year to the next. Prompts were largely neutral for expression terms, while image analyses for expressions did not show significant differences in positive, neutral, or negative emotions between 2022 and 2023. Prompts used for image generation had more male-oriented terms than expected, and male representation was higher then female representation in the images, with no difference in sex representation between the 2 time points.
Conclusions
Despite a social emphasis on positive views on aging, AI text-to-image generators persistently generated images with characteristics of digital ageism. Images predominantly featured White-racialized individuals at both time points, with no improvement in emotional representation despite using neutral text prompts. These findings highlight the persistence of ageist visual characteristics in AI-generated images over time. A limitation of this study is that it focused only on AI image generation and did not analyze other AI-generated content that may express digital ageism.}
}
@article{SU2024108080,
title = {Encoding the space of protein-protein binding interfaces by artificial intelligence},
journal = {Computational Biology and Chemistry},
volume = {110},
pages = {108080},
year = {2024},
issn = {1476-9271},
doi = {https://doi.org/10.1016/j.compbiolchem.2024.108080},
url = {https://www.sciencedirect.com/science/article/pii/S1476927124000689},
author = {Zhaoqian Su and Kalyani Dhusia and Yinghao Wu},
keywords = {Protein-protein interactions, Artificial intelligence, Structural modeling of protein, Complexes},
abstract = {The physical interactions between proteins are largely determined by the structural properties at their binding interfaces. It was found that the binding interfaces in distinctive protein complexes are highly similar. The structural properties underlying different binding interfaces could be further captured by artificial intelligence. In order to test this hypothesis, we broke protein-protein binding interfaces into pairs of interacting fragments. We employed a generative model to encode these interface fragment pairs in a low-dimensional latent space. After training, new conformations of interface fragment pairs were generated. We found that, by only using a small number of interface fragment pairs that were generated by artificial intelligence, we were able to guide the assembly of protein complexes into their native conformations. These results demonstrate that the conformational space of fragment pairs at protein-protein binding interfaces is highly degenerate. Features in this degenerate space can be well characterized by artificial intelligence. In summary, our machine learning method will be potentially useful to search for and predict the conformations of unknown protein-protein interactions.}
}
@article{ALVES2025106168,
title = {Towards an integrative framework for BIM and artificial intelligence capabilities in smart architecture, engineering, construction, and operations projects},
journal = {Automation in Construction},
volume = {174},
pages = {106168},
year = {2025},
issn = {0926-5805},
doi = {https://doi.org/10.1016/j.autcon.2025.106168},
url = {https://www.sciencedirect.com/science/article/pii/S0926580525002080},
author = {Josivan Leite Alves and Rachel Perez Palha and Adiel Teixeira de {Almeida Filho}},
keywords = {Smart construction, Deep learning, Machine learning, Data science, Project life cycle, Benefits},
abstract = {The Architecture, Engineering, Construction, and Operations (AECO) sector gains significant advantages through generating and effectively managing BIM data. This increased available data can be fundamental in deriving innovative advances by processing them through artificial intelligence (AI) models. In this context, this paper investigates how BIM and AI capabilities can benefit the development of smart AECO projects. The research design is a systematic literature review, applying bibliometric and content analysis. First, the paper explores the relationships between the topics of AI and BIM applications, identifies seven core domains of BIM and AI finds application, explores research contributions, the problems addressed, and their primary outcomes. Second, the paper maps out 14 BIM and 16 AI capabilities fundamental to developing smart projects. Third, three propositions that sustain an integrative framework are suggested. The article also suggests that practitioners identify critical organizational capabilities to be built and strengthened.}
}
@article{HASSAN2025102470,
title = {Explainable artificial intelligence for natural language processing: A survey},
journal = {Data & Knowledge Engineering},
volume = {160},
pages = {102470},
year = {2025},
issn = {0169-023X},
doi = {https://doi.org/10.1016/j.datak.2025.102470},
url = {https://www.sciencedirect.com/science/article/pii/S0169023X25000655},
author = {Md. Mehedi Hassan and Anindya Nag and Riya Biswas and Md Shahin Ali and Sadika Zaman and Anupam Kumar Bairagi and Chetna Kaushal},
keywords = {Explainable Artificial Intelligence, Natural language processing, Artificial Intelligence, Machine learning, Interpretability},
abstract = {Recently, artificial intelligence has gained a lot of momentum and is predicted to surpass expectations across a range of industries. However, explainability is a major challenge due to sub-symbolic techniques like Deep Neural Networks and Ensembles, which were absent during the boom of AI. The practical application of AI in numerous application areas is greatly undermined by this lack of explainability. In order to counter the lack of perception of AI-based systems, Explainable AI (XAI) aims to increase transparency and human comprehension of black-box AI models. Explainable AI (XAI) also strives to promote transparency and human comprehension of black-box AI models. The explainability problem has been approached using a variety of XAI strategies; however, given the complexity of the search space, it may be tricky for ML developers and data scientists to construct XAI applications and choose the optimal XAI algorithms. This paper provides different frameworks, surveys, operations, and explainability methodologies that are currently available for producing reasoning for predictions from Natural Language Processing models in order to aid developers. Additionally, a thorough analysis of current work in explainable NLP and AI is undertaken, providing researchers worldwide with exploration, insight, and idea development opportunities. Finally, the authors highlight gaps in the literature and offer ideas for future research in this area.}
}
@article{GARLET2026103824,
title = {Artificial intelligence to enhance BIM-BEPS integration via IFC: Challenges, solutions, and future directions},
journal = {Advanced Engineering Informatics},
volume = {69},
pages = {103824},
year = {2026},
issn = {1474-0346},
doi = {https://doi.org/10.1016/j.aei.2025.103824},
url = {https://www.sciencedirect.com/science/article/pii/S1474034625007177},
author = {Liége Garlet and Matheus Körbes Bracht and Roberto Lamberts and Ana Paula Melo and James O’Donnell},
keywords = {Artificial Intelligence, BIM, BEPS, IFC, Interoperability},
abstract = {In the Architecture, Engineering, and Construction (AEC) domain, integrating Building Information Modeling (BIM) and Building Performance Simulations (BEPS) is essential for optimizing building design and performance. This study investigates the potential of AI to enhance the integration of BIM and BEPS through Industry Foundation Classes (IFC). This study also examines the challenges inherent in the BIM-BEPS workflow and the barriers to AI adoption in this domain. The paper aims to present solutions that support IFC-based interoperability, identifying the most effective approaches within the categories of the mapped problems. These include tools for extracting geometry from IFC models, algorithms for geometric enrichment, ontologies for rule-based model verification, machine learning techniques for space classification, external libraries, and IFC extensions for property addition to models. The integration of AI demonstrates significant potential to improve BIM-BEPS workflows, particularly in automating geometry extraction from BIM, enriching model data, and detecting inconsistencies in IFC models. The study also explores opportunities to enhance the BIM-BEPS workflow through IFC4 and future IFC generations, focusing on combining ontology frameworks with machine learning. Furthermore, the study emphasizes the industry’s role in developing better user support solutions, underscoring the need for users to adhere to well-defined design requirements and workflows to maximize the benefits of these advancements.}
}
@article{ZHAO2024e38008,
title = {The synergistic effect of artificial intelligence technology in the evolution of visual communication of new media art},
journal = {Heliyon},
volume = {10},
number = {18},
pages = {e38008},
year = {2024},
issn = {2405-8440},
doi = {https://doi.org/10.1016/j.heliyon.2024.e38008},
url = {https://www.sciencedirect.com/science/article/pii/S240584402414039X},
author = {Yan Zhao},
keywords = {Artificial intelligence, New media, Convolutional neural network, Visual communication, Design logic},
abstract = {This study aims to clarify the synergistic effect of artificial intelligence (AI) technology in the evolution of visual communication of new media art, thereby exploring an AI layout design method based on Convolutional Neural Network (CNN) in the practice of visual communication design. Firstly, this study designs an AI layout design model based on CNN, and trains and optimizes it with training data. Secondly, the automatic generation of layout design is realized by constantly adjusting the model parameters and network structure. Finally, various AI layout design algorithms are compared, and their effects and performances in layout design generation are analyzed. To verify the layout and composition matching model's performance, traditional layout design methods are selected for comparison (layout, comparison, harmonic composition, etc.). This study involved 20 design students as participants, evaluating them across three dimensions: overall comprehensive assessment, readability of text information, and rationality of visual path using a Likert 7-point scale. The results reveal that the proposed method's evaluation outcomes in these three aspects are 5.95, 5.68, and 5.74, respectively, higher than the traditional layout design methods. To sum up, the generative AI discussed here can automatically generate design elements and schemes through deep learning and big data analysis, thus providing a reference for the innovation of visual communication design.}
}
@article{ZHANG2025,
title = {Artificial intelligence in thyroid eye disease imaging: A systematic review},
journal = {Survey of Ophthalmology},
year = {2025},
issn = {0039-6257},
doi = {https://doi.org/10.1016/j.survophthal.2025.07.008},
url = {https://www.sciencedirect.com/science/article/pii/S0039625725001250},
author = {Haiyang Zhang and Ziyuan Li and Hoi Chi Chan and Xuefei Song and Huifang Zhou and Xianqun Fan},
keywords = {Thyroid eye disease, Artificial intelligence, Medical imaging},
abstract = {Thyroid eye disease (TED) is a common, complex orbital disorder characterized by soft-tissue changes visible on imaging. Artificial intelligence (AI) offers promises for improving TED diagnosis and treatment; however, no systematic review has yet characterized the research landscape, key challenges, and future directions. We followed PRISMA guidelines to search multiple databases until January, 2025, for studies applying AI to computed tomography (CT), magnetic resonance imaging, and nuclear, facial or retinal imaging in TED patients. Using the APPRAISE-AI tool, we assessed study quality and included 41 studies covering various AI applications. Sample sizes ranged from 33 to 2288 participants, predominantly East Asian. CT and facial imaging were the most common modalities, reported in 16 and 13 articles, respectively. Studies addressed clinical tasks—diagnosis, activity assessment, severity classification, and treatment prediction—and technical tasks—classification, segmentation, and image generation—with classification being the most frequent. Researchers primarily employed deep-learning models, such as residual network (ResNet) and Visual Geometry Group (VGG). Overall, the majority of the studies were of moderate quality. Image-based AI shows strong potential to improve diagnostic accuracy and guide personalized treatment strategies in TED. Future research should prioritize robust study designs, the creation of public datasets, multimodal imaging integration, and interdisciplinary collaboration to accelerate clinical translation.}
}
@article{MONTAG2025124222,
title = {On the relevance of Maslow's need theory in the age of artificial intelligence},
journal = {Technological Forecasting and Social Change},
volume = {219},
pages = {124222},
year = {2025},
issn = {0040-1625},
doi = {https://doi.org/10.1016/j.techfore.2025.124222},
url = {https://www.sciencedirect.com/science/article/pii/S0040162525002537},
author = {Christian Montag and A. Mehdi Riazi and George Mikros and Benjamin Becker and Raian Ali},
keywords = {Artificial intelligence, Human needs, Maslow, Personality, IMPACT-framework, Self-determination-theory},
abstract = {The impact of Artificial Intelligence (AI) is being felt in societies worldwide and is increasingly affecting all aspects of our daily lives. This paper discusses how AI can foster or hinder human well-being. In detail, we adopt Maslow's classic theory on human needs to take a human-centered focus and discuss how this theory can guide the creation and governance of AI systems promoting human well-being. In addition, the present work explores the concept of humanity and being human in the age of AI and the challenges humans may encounter in the next decades.}
}
@article{YE2025,
title = {Medical education professionals need the necessary support to effectively integrate artificial intelligence into medical education practices (Letter-to-the-Editor)},
journal = {American Journal of Obstetrics and Gynecology},
year = {2025},
issn = {0002-9378},
doi = {https://doi.org/10.1016/j.ajog.2025.10.024},
url = {https://www.sciencedirect.com/science/article/pii/S0002937825007628},
author = {Hongnan Ye},
keywords = {Medical education professionals, Medical education, Artificial intelligence}
}
@article{ABUDABOUS2025510,
title = {Artificial intelligence applications in pavement infrastructure damage detection with automated three-dimensional imaging – A systematic review},
journal = {Alexandria Engineering Journal},
volume = {117},
pages = {510-533},
year = {2025},
issn = {1110-0168},
doi = {https://doi.org/10.1016/j.aej.2024.11.081},
url = {https://www.sciencedirect.com/science/article/pii/S1110016824015539},
author = {Saleh {Abu Dabous} and Mohamed {Ait Gacem} and Waleed Zeiada and Khaled Hamad and Rami Al-Ruzouq},
keywords = {Pavement, Road, Damage, Artificial intelligence, 3D imaging},
abstract = {Pavement damage detection is vital in ensuring road-users safety and reducing economic losses related to maintenance and road incidents, thus making it a highly discussed research topic. Non-destructive pavement damage inspection methods have been rigorously explored, compared and integrated in the road health and safety practices. In particular, 3D imaging stands out due to its ability to extract the depth and geometric characteristics of the detected defects, thus facilitating performing accurate maintenance and corrective actions. During the past few years, with the rise of the highly accurate and robust artificial intelligence-driven analysis, researchers have increasingly adopted machine learning and deep learning models in pavement damage assessment. This paper systematically and exhaustively reviews the use of artificial intelligence-based 3D automated damage detection of pavement performed using laser scanners, stereo cameras/structure from motion and infrared sensors. It compiled 85 contributions published between 2011 to mid-2024. From which, the adopted artificial intelligence models, utilized 3D data collection hardware, utilized datasets, 3D data pre-processing techniques and application domains were extracted, compared and critically analyzed. The survey ultimately highlights the gaps and potential future research directions. Key findings highlight the need to explore more cost-effective and advanced 3D data collection methods, such as drones, in addition to enhancing 3D data preprocessing techniques to boost AI performance. Furthermore, the lack of comprehensive open 3D datasets is a significant gap that, if addressed, could help standardize research. Moreover, the research highlights the need for expanding the use of AI models to cover a wider range of pavement deformities.}
}
@article{KHONINA2024110270,
title = {A perspective on the artificial intelligence’s transformative role in advancing diffractive optics},
journal = {iScience},
volume = {27},
number = {7},
pages = {110270},
year = {2024},
issn = {2589-0042},
doi = {https://doi.org/10.1016/j.isci.2024.110270},
url = {https://www.sciencedirect.com/science/article/pii/S2589004224014950},
author = {S.N. Khonina and N.L. Kazanskiy and A.R. Efimov and A.V. Nikonorov and I.V. Oseledets and R.V. Skidanov and M.A. Butt},
keywords = {Applied sciences, Artificial intelligence},
abstract = {Summary
Artificial intelligence (AI) is transforming diffractive optics development through its advanced capabilities in design optimization, pattern generation, fabrication enhancement, performance forecasting, and customization. Utilizing AI algorithms like machine learning, generative models, and transformers, researchers can analyze extensive datasets to refine the design of diffractive optical elements (DOEs) tailored to specific applications and performance requirements. AI-driven pattern generation methods enable the creation of intricate and efficient optical structures that manipulate light with exceptional precision. Furthermore, AI optimizes manufacturing processes by fine-tuning fabrication parameters, resulting in higher quality and productivity. AI models also simulate diffractive optics behavior, accelerating design iterations and facilitating rapid prototyping. This integration of AI into diffractive optics holds tremendous potential to revolutionize optical technology applications across diverse sectors, spanning from imaging and sensing to telecommunications and beyond.}
}
@article{FORTUNOV2024151992,
title = {Artificial intelligence and informatics in neonatal resuscitation},
journal = {Seminars in Perinatology},
volume = {48},
number = {8},
pages = {151992},
year = {2024},
note = {Resuscitation in the Neonatal Intensive Care Unit},
issn = {0146-0005},
doi = {https://doi.org/10.1016/j.semperi.2024.151992},
url = {https://www.sciencedirect.com/science/article/pii/S0146000524001265},
author = {Regine M Fortunov and Erwin Cabacungan and James S Barry and Jawahar Jagarapu},
keywords = {Machine Learning, Augmented Reality, Documentation, Artificial Intelligence, Large Language Model, Intensive Care, Neonatal Resuscitation},
abstract = {Neonatal intensive care unit resuscitative care continually evolves and increasingly relies on data. Data driven precision resuscitation care can be enabled by leveraging informatics tools and artificial intelligence. Despite technological advancements, these data are often underutilized due to suboptimal data capture, aggregation, and low adoption of artificial intelligence and analytic tools. This review describes the fundamentals and explores the evidence behind informatics and artificial intelligence tools supporting neonatal intensive care unit resuscitative care, training and education. Key findings include the need for effective interface design for accurate data capture followed by storage and translation to wisdom using analytics and artificial intelligence tools. This review addresses the issues of data privacy, bias, liability and ethical frameworks when adopting these tools. While these emerging technologies hold great promise to improve resuscitation, further study of these applications in neonatal population and awareness of informatics and artificial intelligence principles among clinicians is imperative.}
}
@article{WHITROCK20241610,
title = {Does using artificial intelligence take the person out of personal statements? We can't tell},
journal = {Surgery},
volume = {176},
number = {6},
pages = {1610-1616},
year = {2024},
issn = {0039-6060},
doi = {https://doi.org/10.1016/j.surg.2024.08.018},
url = {https://www.sciencedirect.com/science/article/pii/S0039606024005907},
author = {Jenna N. Whitrock and Catherine G. Pratt and Michela M. Carter and Ryan C. Chae and Adam D. Price and Carla F. Justiniano and Robert M. {Van Haren} and Latifa S. Silski and Ralph C. Quillin and Shimul A. Shah},
abstract = {Background
Use of artificial intelligence to generate personal statements for residency is currently not permitted but is difficult to monitor. This study sought to evaluate the ability of surgical residency application reviewers to identify artificial intelligence–generated personal statements and to understand perceptions of this practice.
Methods
Three personal statements were generated using ChatGPT, and 3 were written by medical students who previously matched into surgery residency. Blinded participants at a single institution were instructed to read all personal statements and identify which were generated by artificial intelligence; they then completed a survey exploring their opinions regarding artificial intelligence use.
Results
Of the 30 participants, 50% were faculty (n = 15) and 50% were residents (n = 15). Overall, experience ranged from 0 to 20 years (median, 2 years; interquartile range, 1–6.25 years). Artificial intelligence–derived personal statements were identified correctly only 59% of the time, with 3 (10%) participants identifying all the artificial intelligence–derived personal statements correctly. Artificial intelligence–generated personal statements were labeled as the best 60% of the time and the worst 43.3% of the time. When asked whether artificial intelligence use should be allowed in personal statements writing, 66.7% (n = 20) said no and 30% (n = 9) said yes. When asked if the use of artificial intelligence would impact their opinion of an applicant, 80% (n = 24) said yes, and 20% (n = 6) said no. When survey questions and ability to identify artificial intelligence–generated personal statements were evaluated by faculty/resident status and experience, no differences were noted (P > .05).
Conclusion
This study shows that surgical faculty and residents cannot reliably identify artificial intelligence–generated personal statements and that concerns exist regarding the impact of artificial intelligence on the application process.}
}
@article{SHUNG2025391,
title = {Artificial Intelligence in Gastroenterology and Hepatology: Potential and Perils},
journal = {Gastroenterology},
volume = {169},
number = {3},
pages = {391-392},
year = {2025},
note = {Shaping the Future of Gastroenterology and Hepatology With Artificial Intelligence},
issn = {0016-5085},
doi = {https://doi.org/10.1053/j.gastro.2025.05.004},
url = {https://www.sciencedirect.com/science/article/pii/S0016508525007103},
author = {Dennis L. Shung and Marietta Iacucci}
}
@article{MAO2025707,
title = {The Optimization Strategy and Application Practice of Business Management Supply Chain Based on Artificial Intelligence Technology},
journal = {Procedia Computer Science},
volume = {261},
pages = {707-715},
year = {2025},
note = {The 5th International Conference on Machine Learning and Big Data Analytics for IoT Security and Privacy (SPIoT2024)},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2025.04.324},
url = {https://www.sciencedirect.com/science/article/pii/S1877050925014267},
author = {Hui Mao},
keywords = {Artificial intelligence, supply chain optimization, genetic algorithm, inventory management, logistics efficiency},
abstract = {Suppliers, producers, distributors, and retailers are among the many stakeholders in the supply side chain. The data silos between the parties are serious, resulting in poor information flow, which affects the accuracy and practicality of the optimization model. To this end, this paper studies the application strategies and practices of artificial intelligence technology and genetic algorithms in business management supply chain optimization. First, the advantages of artificial intelligence-driven solutions in supply chain management are explored, especially in demand forecasting, inventory management, and warehouse process automation. These technologies provide real-time decision support by processing massive data, reducing inventory waste and improving logistics efficiency. Secondly, a supply chain optimization model based on genetic algorithm is constructed, and the objective function and constraints are clarified, covering key optimization goals such as cost minimization, profit maximization and service level improvement. The model continuously iterates and optimizes the supply chain configuration through the core operation steps of genetic algorithm, including population initialization, fitness evaluation, selection, crossover and mutation. The experimental results show that artificial intelligence technology and genetic algorithm can significantly reduce supply chain costs, improve logistics efficiency and enhance service levels, verifying the effectiveness of the model in practical applications.}
}
@article{HASHEMI2024e40265,
title = {Therapeutic peptide development revolutionized: Harnessing the power of artificial intelligence for drug discovery},
journal = {Heliyon},
volume = {10},
number = {22},
pages = {e40265},
year = {2024},
issn = {2405-8440},
doi = {https://doi.org/10.1016/j.heliyon.2024.e40265},
url = {https://www.sciencedirect.com/science/article/pii/S2405844024162962},
author = {Samaneh Hashemi and Parisa Vosough and Saeed Taghizadeh and Amir Savardashtaki},
keywords = {Therapeutic peptides, Artificial intelligence, Machine learning, Drug discovery},
abstract = {Due to the spread of antibiotic resistance, global attention is focused on its inhibition and the expansion of effective medicinal compounds. The novel functional properties of peptides have opened up new horizons in personalized medicine. With artificial intelligence methods combined with therapeutic peptide products, pharmaceuticals and biotechnology advance drug development rapidly and reduce costs. Short-chain peptides inhibit a wide range of pathogens and have great potential for targeting diseases. To address the challenges of synthesis and sustainability, artificial intelligence methods, namely machine learning, must be integrated into their production. Learning methods can use complicated computations to select the active and toxic compounds of the drug and its metabolic activity. Through this comprehensive review, we investigated the artificial intelligence method as a potential tool for finding peptide-based drugs and providing a more accurate analysis of peptides through the introduction of predictable databases for effective selection and development.}
}
@article{CHEN2025104711,
title = {The intelligent brain and the energy heart: Synergistic evolution of artificial intelligence and energy storage technology in China},
journal = {Acta Psychologica},
volume = {253},
pages = {104711},
year = {2025},
issn = {0001-6918},
doi = {https://doi.org/10.1016/j.actpsy.2025.104711},
url = {https://www.sciencedirect.com/science/article/pii/S0001691825000241},
author = {Yan Chen and Jiayi Lyu and Umair Akram and Yuqi Hou},
keywords = {Artificial intelligence, Energy storage technology, Time-dependent interrelationship, China},
abstract = {In the context of China's ongoing industrial revolution and technological transformation, there is a growing demand for advanced energy management solutions and the increasing role of artificial intelligence in various industries. This paper aims to explore how artificial intelligence (AI) and Energy Storage Technology (EST) interact and co-evolve. Utilizing a full-sample Granger causality test, we identified significant interactions between AI and EST. Afterwards, we further revealed their dynamic influence relationship using advanced sub-sampling techniques. Quantitative analysis indicates that AI positively influences EST by optimizing energy management systems, with an improvement of 15 % in efficiency, and by enhancing the intelligence level of energy storage. However, there are also negative effects, such as a 10 % increase in operational risks due to over-reliance on AI. Similarly, EST facilitates the development of AI by providing a stable energy supply. AI and EST, like the intelligent brain and the energy heart, require mutual dependence for stable development. In context of the industrial revolution and technical advancement, this study provides meaningful recommendations. Strengthening technological research and innovation support, optimizing energy policies, and enhancing standardization will promote the deep integration and synergistic development of AI and EST. This will provide significant impetus for China's technological advancement and economic development, aiding in the achievement of sustainable development goals.}
}
@article{JAROTSCHKIN2025115383,
title = {Artificial intelligence in sales research: Identifying emergent themes and looking forward},
journal = {Journal of Business Research},
volume = {198},
pages = {115383},
year = {2025},
issn = {0148-2963},
doi = {https://doi.org/10.1016/j.jbusres.2025.115383},
url = {https://www.sciencedirect.com/science/article/pii/S0148296325002061},
author = {Viktor Jarotschkin and Mostofa Wahid Soykoth and Nawar N. Chaker},
keywords = {Artificial intelligence, Sales, Machine learning, Topic modeling, Bibliometric analysis, Literature review},
abstract = {The rapid advancement of artificial intelligence (AI) in sales lends promising grounds for sales practice and academic research. Using a two-study, multi-method approach to examining the literature, this study provides a detailed overview of the current position of AI in sales research. We consider how AI is studied as a substantive topic and how it is used as an analytical tool to study sales phenomena. Study 1 uses bibliometric analysis to provide a “horizontal” view of the literature by uncovering the network characteristics and structure. Study 2 uses topic modeling based on Latent Dirichlet Allocation (LDA)—a machine learning (ML) approach—to offer a “vertical” view of the literature by plunging into the contents of each article to reveal five important themes that characterize the state of the literature. We also offer a future research agenda to guide more studies that integrate AI and sales.}
}
@article{GALLANO2025,
title = {Artificial Intelligence in Speech-Language Pathology and Dysphagia: A Review From Latin American Perspective and Pilot Test of LLMs for Rehabilitation Planning},
journal = {Journal of Voice},
year = {2025},
issn = {0892-1997},
doi = {https://doi.org/10.1016/j.jvoice.2025.04.010},
url = {https://www.sciencedirect.com/science/article/pii/S0892199725001584},
author = {Giuliano Gallano and Andres Giglio and Andres Ferre},
keywords = {Artificial intelligence—Speech-language pathology—Rehabilitation—Machine learning—Dysphagia},
abstract = {Summary
Artificial Intelligence (AI) is transforming speech-language pathology (SLP) and dysphagia management, offering innovative solutions for assessment, diagnosis, and rehabilitation. This narrative review examines AI applications in these fields from 2014 to 2024, with particular focus on implementation challenges in Latin America. We analyze key AI technologies—including deep learning, machine learning algorithms, and natural language processing—that have demonstrated high accuracy in detecting voice disorders, analyzing swallowing function, and supporting personalized rehabilitation. The review identifies three primary domains of AI application: diagnostic tools with improved sensitivity for speech-language disorders, rehabilitation technologies that enable customized therapy, and telehealth platforms that expand access to specialized care in underserved regions. However, significant barriers persist, particularly in Latin America, where limited infrastructure, insufficient linguistic adaptation, and scarce regional datasets hamper widespread implementation. Our pilot study evaluating commercially available large language models for rehabilitation planning demonstrates their potential utility in generating structured therapy activities, especially in resource-constrained settings. While AI shows promise in enhancing clinical workflows and expanding service delivery, the evidence suggests that current applications remain predominantly focused on diagnosis rather than integrated rehabilitation. This review highlights the need for culturally and linguistically adapted AI models, expanded regional research collaborations, and regulatory frameworks that ensure ethical AI integration into SLP and dysphagia care, positioning these technologies as complementary tools that enhance rather than replace clinical expertise.}
}
@article{LI2025969,
title = {Structural Design of College English Teaching System Based on Artificial Intelligence Technology},
journal = {Procedia Computer Science},
volume = {261},
pages = {969-975},
year = {2025},
note = {The 5th International Conference on Machine Learning and Big Data Analytics for IoT Security and Privacy (SPIoT2024)},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2025.04.488},
url = {https://www.sciencedirect.com/science/article/pii/S1877050925015911},
author = {Xianhua Li},
keywords = {College English, Artificial intelligence technology, Teaching system, Personalized Recommendation},
abstract = {Nowadays, artificial intelligence technology is becoming increasingly mature and widely applied in many industries and fields, which has played a significant role in promoting current college English teaching. In order to better utilize the role of artificial intelligence technology, this article starts from the current teaching practice of college English, selects artificial intelligence technology as an auxiliary, and designs a professional English teaching system to meet the teaching needs of English teachers and improve the teaching effectiveness of college English. Subsequently, the effectiveness of the college English teaching system based on artificial intelligence technology was analyzed through simulation experiments and control experiments. The results showed that the system can maintain high processing capacity, transmission rate, and response speed in specific applications, and its performance can also maintain good stability at different time nodes; It has good effects in improving the practicality, real-time feedback, evaluation accuracy, diversity, coverage, user satisfaction, and other aspects of improvement suggestions, which can better improve students’ English learning performance.}
}

