#!/usr/bin/env python
# -*- coding: utf-8 -*-

"""
Dashboard principal para an√°lisis bibliom√©trico.
Integra los requerimientos 1, 2 y 3 en una interfaz unificada.
"""

import streamlit as st
import pandas as pd
import numpy as np
import plotly.express as px
import plotly.graph_objects as go
from pathlib import Path
import bibtexparser
from matplotlib import pyplot as plt
from matplotlib_venn import venn2
import io
import base64

# Importar m√≥dulos propios
from utils.extractor_bib import ExtratorBibTeX
from requerimiento2.similitud_textos import SimilitudTextos
from requerimiento3.frecuencia_palabras import AnalizadorFrecuencia
from requerimiento1.acm_descarga import ACMDescarga
from requerimiento1.scienciedirect import ScienceDirectDescarga
from requerimiento1.unir_bib_deduplicado import UnificadorBibTeX

def verificar_archivos():
    """Verifica la existencia de archivos y retorna estado."""
    archivos = {
        "ACM": Path("requerimiento1/descargas/acm/acmCompleto.bib"),
        "ScienceDirect": Path("requerimiento1/descargas/ScienceDirect/sciencedirectCompleto.bib"),
        "Unificado": Path("requerimiento1/descargas/resultado_unificado.bib")
    }
    return {nombre: ruta.exists() for nombre, ruta in archivos.items()}

# Configuraci√≥n de la p√°gina
st.set_page_config(
    page_title="An√°lisis Bibliom√©trico UQ",
    page_icon="üìö",
    layout="wide",
    initial_sidebar_state="expanded"
)

# Funciones auxiliares
def cargar_bibliografia():
    """Carga el archivo BibTeX unificado."""
    ruta_bib = Path("requerimiento1/descargas/resultado_unificado.bib")
    if not ruta_bib.exists():
        return None
    
    with open(ruta_bib, 'r', encoding='utf-8') as archivo:
        parser = bibtexparser.bparser.BibTexParser()
        return bibtexparser.load(archivo, parser=parser)

def plot_to_base64(fig):
    """Convierte un plot de matplotlib a base64."""
    buf = io.BytesIO()
    fig.savefig(buf, format='png', bbox_inches='tight')
    buf.seek(0)
    return base64.b64encode(buf.getvalue()).decode()

def explicar_algoritmo(nombre):
    """Retorna la explicaci√≥n matem√°tica y algor√≠tmica de cada m√©todo."""
    explicaciones = {
        "Levenshtein": """
        ### Distancia de Levenshtein üìè
        
        La distancia de Levenshtein mide el n√∫mero m√≠nimo de operaciones necesarias para transformar una cadena en otra.
        
        #### Operaciones permitidas:
        1. Inserci√≥n (costo = 1)
        2. Eliminaci√≥n (costo = 1)
        3. Sustituci√≥n (costo = 1 o 2)
        
        #### F√≥rmula matem√°tica:
        
        Para dos cadenas a, b de longitud i, j:
        
        lev(i,j) = min(
            lev(i-1,j) + 1,              # eliminaci√≥n
            lev(i,j-1) + 1,              # inserci√≥n
            lev(i-1,j-1) + costo_sust    # sustituci√≥n
        )
        
        donde costo_sust = 0 si a[i] = b[j], 2 en otro caso
        
        #### Complejidad:
        - Tiempo: O(mn)
        - Espacio: O(mn)
        donde m,n son las longitudes de las cadenas
        """,
        
        "Jaccard": """
        ### √çndice de Jaccard üîÑ
        
        Mide la similitud entre conjuntos comparando elementos comunes vs totales.
        
        #### F√≥rmula matem√°tica:
        
        J(A,B) = |A ‚à© B| / |A ‚à™ B|
        
        Donde:
        - A ‚à© B: elementos comunes
        - A ‚à™ B: todos los elementos √∫nicos
        
        #### Propiedades:
        - Rango: [0,1]
        - 0: conjuntos disjuntos
        - 1: conjuntos id√©nticos
        
        #### Complejidad:
        - Tiempo: O(n)
        - Espacio: O(n)
        donde n es el total de elementos √∫nicos
        """,
        
        "TF-IDF Coseno": """
        ### Similitud Coseno con TF-IDF üìä
        
        Combina la ponderaci√≥n TF-IDF con la similitud del coseno.
        
        #### F√≥rmulas:
        
        1. TF (Term Frequency):
           tf(t,d) = (frecuencia de t en d)
        
        2. IDF (Inverse Document Frequency):
           idf(t) = log(N/df_t)
           donde:
           - N: n√∫mero total de documentos
           - df_t: documentos que contienen t
        
        3. Similitud Coseno:
           cos(A,B) = (A¬∑B)/(||A||¬∑||B||)
        
        #### Proceso:
        1. Calcular matriz TF-IDF
        2. Normalizar vectores
        3. Calcular coseno
        
        #### Complejidad:
        - Tiempo: O(nm)
        - Espacio: O(nm)
        donde n=t√©rminos, m=documentos
        """,
        
        "N-gramas": """
        ### Similitud por N-gramas üî§
        
        Compara secuencias de n caracteres o palabras consecutivas.
        
        #### Proceso:
        1. Generar n-gramas:
           texto: "hello"
           3-gramas: ["hel", "ell", "llo"]
        
        2. Calcular similitud:
           sim = |com√∫n| / |total|
        
        #### Ventajas:
        - Resistente a errores menores
        - Captura patrones locales
        - Flexible en n
        
        #### Complejidad:
        - Tiempo: O(n-m+1)
        - Espacio: O(n-m+1)
        donde n=longitud texto, m=tama√±o n-grama
        """,
        
        "Semantic Embedding": """
        ### Embedding Sem√°ntico üß†
        
        Convierte texto en vectores que capturan significado sem√°ntico.
        
        #### Proceso:
        1. Tokenizaci√≥n
        2. Vectorizaci√≥n de palabras
        3. Agregaci√≥n de vectores
        4. Similitud coseno
        
        #### Caracter√≠sticas:
        - Captura sem√°ntica
        - Independiente de orden exacto
        - Robusto a sin√≥nimos
        
        #### Ventajas:
        - Entiende significado
        - Maneja variaciones
        - Escalable
        
        #### Complejidad:
        - Tiempo: O(n¬∑d)
        - Espacio: O(d)
        donde n=palabras, d=dimensiones
        """,
        
        "Contextual Similarity": """
        ### Similitud Contextual üåç
        
        Analiza similitud considerando contexto y relaciones.
        
        #### Componentes:
        1. An√°lisis de contexto local
        2. Ponderaci√≥n por relevancia
        3. Agregaci√≥n contextual
        
        #### Proceso:
        1. Identificar contextos
        2. Calcular similitudes locales
        3. Ponderar por importancia
        4. Agregar resultados
        
        #### Ventajas:
        - Sensible al contexto
        - Maneja ambig√ºedad
        - Resultados interpretables
        
        #### Complejidad:
        - Tiempo: O(n¬≤)
        - Espacio: O(n)
        donde n=t√©rminos en contexto
        """
    }
    return explicaciones.get(nombre, "Explicaci√≥n no disponible")

def mostrar_header():
    """Muestra el encabezado de la aplicaci√≥n."""
    st.title("üìö Sistema de An√°lisis Bibliom√©trico UQ")
    st.markdown("""
    Sistema integrado para an√°lisis bibliom√©trico que incluye:
    - Gesti√≥n de referencias bibliogr√°ficas
    - An√°lisis de similitud textual
    - An√°lisis de frecuencia de palabras
    """)

def mostrar_estado_actual():
    """Muestra el estado actual de los archivos bibliogr√°ficos."""
    st.subheader("üìÅ Estado Actual")
    
    # Verificar archivos
    archivos = {
        "ACM": Path("requerimiento1/descargas/acm/acmCompleto.bib"),
        "ScienceDirect": Path("requerimiento1/descargas/ScienceDirect/sciencedirectCompleto.bib"),
        "Unificado": Path("requerimiento1/descargas/resultado_unificado.bib")
    }
    
    for nombre, ruta in archivos.items():
        if ruta.exists():
            with open(ruta, 'r', encoding='utf-8') as f:
                db = bibtexparser.load(f)
                st.success(f"‚úÖ {nombre}: {len(db.entries)} referencias")
        else:
            st.warning(f"‚ö†Ô∏è {nombre}: Archivo no encontrado")

@st.cache_data
def analizar_similitud_articulos(texto1, texto2, metodo):
    """Analiza la similitud entre dos textos."""
    similitud = SimilitudTextos()
    metodos = {
        "Levenshtein": similitud.levenshtein,
        "Jaccard": similitud.jaccard,
        "TF-IDF Coseno": similitud.tfidf_coseno,
        "N-gramas": similitud.ngramas,
        "Semantic Embedding": similitud.semantic_embedding,
        "Contextual Similarity": similitud.contextual_similarity
    }
    return metodos[metodo](texto1, texto2)

def visualizar_similitud(score, metodo):
    """Visualiza el score de similitud con un gauge."""
    fig = go.Figure(go.Indicator(
        mode="gauge+number",
        value=score * 100,
        title={'text': f"Similitud {metodo}"},
        gauge={
            'axis': {'range': [0, 100]},
            'bar': {'color': "darkblue"},
            'steps': [
                {'range': [0, 33], 'color': "lightgray"},
                {'range': [33, 66], 'color': "gray"},
                {'range': [66, 100], 'color': "darkgray"}
            ],
        }
    ))
    return fig

def ejecutar_scraping(fuente):
    """Ejecuta el scraping para la fuente especificada."""
    if fuente == "ACM":
        with st.spinner("Extrayendo referencias de ACM..."):
            extractor = ACMDescarga()
            try:
                extractor.abrir_base_datos()
                return True
            except Exception as e:
                st.error(f"Error: {str(e)}")
                return False
            finally:
                extractor.cerrar()
    elif fuente == "ScienceDirect":
        with st.spinner("Extrayendo referencias de ScienceDirect..."):
            extractor = ScienceDirectDescarga()
            try:
                extractor.abrir_base_datos()
                return True
            except Exception as e:
                st.error(f"Error: {str(e)}")
                return False
            finally:
                extractor.cerrar()
    return False

def mostrar_seccion_scraping():
    """Muestra la secci√≥n de scraping con botones condicionales."""
    st.header("üåê Web Scraping de Referencias")
    
    # Verificar estado de archivos
    estados = verificar_archivos()
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.subheader("ACM Digital Library")
        boton_acm = st.button(
            "Extraer de ACM",
            disabled=estados["ACM"],
            help="Extraer referencias de ACM Digital Library"
        )
        if estados["ACM"]:
            st.success("‚úÖ Referencias de ACM ya extra√≠das")
        if boton_acm:
            if ejecutar_scraping("ACM"):
                st.success("‚úÖ Referencias extra√≠das exitosamente")
                estados["ACM"] = True
            else:
                st.error("‚ùå Error en la extracci√≥n")
    
    with col2:
        st.subheader("ScienceDirect")
        boton_sd = st.button(
            "Extraer de ScienceDirect",
            disabled=estados["ScienceDirect"],
            help="Extraer referencias de ScienceDirect"
        )
        if estados["ScienceDirect"]:
            st.success("‚úÖ Referencias de ScienceDirect ya extra√≠das")
        if boton_sd:
            if ejecutar_scraping("ScienceDirect"):
                st.success("‚úÖ Referencias extra√≠das exitosamente")
                estados["ScienceDirect"] = True
            else:
                st.error("‚ùå Error en la extracci√≥n")
    
    # Unificaci√≥n
    st.subheader("Unificaci√≥n de Referencias")
    boton_unificar = st.button(
        "Unificar Referencias",
        disabled=estados["Unificado"] or not (estados["ACM"] and estados["ScienceDirect"]),
        help="Unificar y deduplicar referencias de ambas fuentes"
    )
    
    if estados["Unificado"]:
        st.success("‚úÖ Referencias ya unificadas")
    elif boton_unificar:
        with st.spinner("Unificando referencias..."):
            unificador = UnificadorBibTeX()
            try:
                if unificador.unificar():
                    st.success("‚úÖ Referencias unificadas exitosamente")
                    estados["Unificado"] = True
                else:
                    st.error("‚ùå Error en la unificaci√≥n")
            except Exception as e:
                st.error(f"‚ùå Error en la unificaci√≥n: {str(e)}")

def main():
    """Funci√≥n principal."""
    mostrar_header()
    
    # Sistema de pesta√±as principales
    tab1, tab2, tab3 = st.tabs([
        "üåê Web Scraping",
        "üîÑ An√°lisis de Similitud",
        "üìä An√°lisis de Frecuencia"
    ])
    
    # Pesta√±a 1: Web Scraping
    with tab1:
        mostrar_seccion_scraping()
    
    # Pesta√±a 2: An√°lisis de Similitud
    with tab2:
        st.header("üîÑ An√°lisis de Similitud")
        
        # Cargar bibliograf√≠a
        bibliografia = cargar_bibliografia()
        if bibliografia is None:
            st.error("‚ùå No se encontr√≥ el archivo de referencias unificado")
            return
        
        # Selector de art√≠culos
        articulos = [(entry.get('ID', ''), entry.get('title', '')) 
                    for entry in bibliografia.entries 
                    if 'abstract' in entry]
        
        col1, col2 = st.columns(2)
        
        with col1:
            art1 = st.selectbox(
                "Seleccionar primer art√≠culo",
                options=articulos,
                format_func=lambda x: x[1]
            )
        
        with col2:
            art2 = st.selectbox(
                "Seleccionar segundo art√≠culo",
                options=articulos,
                format_func=lambda x: x[1]
            )
        
        if art1 and art2:
            # Obtener abstracts
            abstract1 = next(e['abstract'] for e in bibliografia.entries if e['ID'] == art1[0])
            abstract2 = next(e['abstract'] for e in bibliografia.entries if e['ID'] == art2[0])
            
            # Mostrar abstracts
            with st.expander("Ver Abstracts"):
                st.markdown("**Abstract 1:**")
                st.write(abstract1)
                st.markdown("**Abstract 2:**")
                st.write(abstract2)
            
            # Analizar similitud con todos los m√©todos
            metodos = [
                "Levenshtein",
                "Jaccard",
                "TF-IDF Coseno",
                "N-gramas",
                "Semantic Embedding",
                "Contextual Similarity"
            ]
            
            # Crear tabs para cada m√©todo
            method_tabs = st.tabs(metodos)
            
            resultados = {}
            for metodo, tab in zip(metodos, method_tabs):
                with tab:
                    col1, col2 = st.columns([1, 1])
                    
                    with col1:
                        st.markdown(explicar_algoritmo(metodo))
                    
                    with col2:
                        with st.spinner(f"Calculando similitud con {metodo}..."):
                            score = analizar_similitud_articulos(abstract1, abstract2, metodo)
                            resultados[metodo] = score
                            st.plotly_chart(
                                visualizar_similitud(score, metodo),
                                use_container_width=True
                            )
            
            # Mostrar comparativa
            st.header("üìä Comparativa de M√©todos")
            
            # Gr√°fico de radar
            categorias = list(resultados.keys())
            valores = list(resultados.values())
            
            fig = go.Figure()
            fig.add_trace(go.Scatterpolar(
                r=valores,
                theta=categorias,
                fill='toself',
                name='Similitud'
            ))
            fig.update_layout(
                polar=dict(
                    radialaxis=dict(
                        visible=True,
                        range=[0, 1]
                    )
                ),
                showlegend=False
            )
            st.plotly_chart(fig, use_container_width=True)
    
    # Pesta√±a 3: An√°lisis de Frecuencia
    with tab3:
        st.header("üìä An√°lisis de Frecuencia")
        
        # Verificar archivo unificado
        ruta_bib = Path("requerimiento1/descargas/resultado_unificado.bib")
        if not ruta_bib.exists():
            st.error("‚ùå No se encontr√≥ el archivo de referencias unificado. Por favor, complete el proceso de scraping primero.")
            return
            
        try:
            analizador = AnalizadorFrecuencia(str(ruta_bib))
            
            # Configuraci√≥n
            col1, col2 = st.columns(2)
            with col1:
                min_df = st.slider(
                    "Frecuencia m√≠nima de documento",
                    min_value=0.01,
                    max_value=0.5,
                    value=0.05,
                    step=0.01,
                    help="Proporci√≥n m√≠nima de documentos en los que debe aparecer una palabra"
                )
            
            with col2:
                incluir_bigramas = st.checkbox(
                    "Incluir bigramas",
                    value=True,
                    help="Analizar pares de palabras adem√°s de palabras individuales"
                )
            
            if st.button("Realizar An√°lisis", key="analisis_frecuencia"):
                with st.spinner("Analizando textos..."):
                    # Frecuencias predefinidas
                    df_freq = analizador.contar_palabras_predefinidas()
                    
                    # TF-IDF
                    df_tfidf = analizador.extraer_palabras_tfidf(
                        min_df=min_df,
                        incluir_bigramas=incluir_bigramas
                    )
                    
                    # Visualizaciones
                    st.subheader("üìà An√°lisis de Palabras Predefinidas")
                    col1, col2 = st.columns(2)
                    
                    with col1:
                        fig_freq = px.bar(
                            df_freq.head(10),
                            x='palabra',
                            y='frecuencia_total',
                            title='Top 10 Palabras m√°s Frecuentes',
                            labels={
                                'palabra': 'Palabra',
                                'frecuencia_total': 'Frecuencia Total'
                            }
                        )
                        fig_freq.update_layout(xaxis_tickangle=-45)
                        st.plotly_chart(fig_freq, use_container_width=True)
                    
                    with col2:
                        fig_docs = px.bar(
                            df_freq.head(10),
                            x='palabra',
                            y='porcentaje_docs',
                            title='Cobertura en Documentos',
                            labels={
                                'palabra': 'Palabra',
                                'porcentaje_docs': 'Porcentaje de Documentos (%)'
                            }
                        )
                        fig_docs.update_layout(xaxis_tickangle=-45)
                        st.plotly_chart(fig_docs, use_container_width=True)
                    
                    st.markdown("##### Detalles de Frecuencias")
                    st.dataframe(
                        df_freq.style.format({
                            'porcentaje_docs': '{:.2f}%'
                        })
                    )
                    
                    st.markdown("---")
                    
                    st.subheader("üîç An√°lisis TF-IDF")
                    col1, col2 = st.columns(2)
                    
                    with col1:
                        fig_tfidf = px.bar(
                            df_tfidf.head(10),
                            x='palabra',
                            y='score_tfidf',
                            title='Top 10 Palabras por Score TF-IDF',
                            labels={
                                'palabra': 'Palabra',
                                'score_tfidf': 'Score TF-IDF'
                            }
                        )
                        fig_tfidf.update_layout(xaxis_tickangle=-45)
                        st.plotly_chart(fig_tfidf, use_container_width=True)
                    
                    with col2:
                        fig_rel = px.pie(
                            df_tfidf.head(10),
                            values='freq_relativa',
                            names='palabra',
                            title='Distribuci√≥n de Frecuencia Relativa'
                        )
                        st.plotly_chart(fig_rel, use_container_width=True)
                    
                    st.markdown("##### M√©tricas Detalladas")
                    st.dataframe(
                        df_tfidf.style.format({
                            'score_tfidf': '{:.4f}',
                            'freq_relativa': '{:.2%}',
                            'score_combinado': '{:.4f}'
                        })
                    )
        
        except Exception as e:
            st.error(f"Error al realizar el an√°lisis: {str(e)}")
            st.error("Por favor, aseg√∫rese de que el archivo de referencias est√° correctamente formateado y contiene abstracts.")

if __name__ == "__main__":
    main()
